diff --git a/.githooks/pre-commit b/.githooks/pre-commit
new file mode 100755
index 000000000..c0b461246
--- /dev/null
+++ b/.githooks/pre-commit
@@ -0,0 +1,28 @@
+#!/bin/sh
+#
+# Verify what is about to be committed.
+# Called by "git commit" with no arguments.  The hook should
+# exit with non-zero status after issuing an appropriate message if
+# it wants to stop the commit.
+
+rc=0
+
+# Redirect output to stderr.
+exec 1>&2
+
+# If there are formatting errors, print the offending file names and fail.
+if [ -x "./scripts/check_format.sh" ]; then
+	echo "Running check_format.sh ..."
+	"./scripts/check_format.sh" > check_format.log 2>&1
+	rc=$?
+	if [ $rc -ne 0 ]; then
+		cat check_format.log
+		echo ""
+		echo "ERROR check_format.sh returned errors!"
+		echo "ERROR Fix the problem and use 'git add' to update your changes."
+		echo "ERROR See `pwd`/check_format.log for more information."
+		echo ""
+	fi
+fi
+
+exit $rc
diff --git a/.githooks/pre-push b/.githooks/pre-push
new file mode 100755
index 000000000..cb9efb5bf
--- /dev/null
+++ b/.githooks/pre-push
@@ -0,0 +1,138 @@
+#!/bin/sh
+# Verify what is about to be pushed.  Called by "git
+# push" after it has checked the remote status, but before anything has been
+# pushed.  If this script exits with a non-zero status nothing will be pushed.
+#
+# This hook is called with the following parameters:
+#
+# $1 -- Name of the remote to which the push is being done
+# $2 -- URL to which the push is being done
+#
+# If pushing without using a named remote those arguments will be equal.
+
+#   <local ref> <local sha1> <remote ref> <remote sha1>
+#
+
+rc=0
+SYSTEM=`uname -s`
+
+# Redirect output to stderr.
+exec 1>&2
+
+if [ "$SYSTEM" = "FreeBSD" ]; then
+	MAKE="gmake MAKE=gmake -j ${nproc}"
+	COMP="clang"
+else
+	MAKE="make -j ${nproc}"
+	COMP="gcc"
+fi
+
+echo "Running make with $COMP ..."
+echo "${MAKE} clean " > make.log
+$MAKE clean  >> make.log 2>&1
+echo "${MAKE} CONFIG_DEBUG=n CONFIG_WERROR=y " >> make.log
+$MAKE CONFIG_DEBUG=n CONFIG_WERROR=y  >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+	tail -20 make.log
+	echo ""
+	echo "ERROR make returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+echo "${MAKE} SKIP_DPDK_BUILD=1 clean " >> make.log
+$MAKE clean SKIP_DPDK_BUILD=1 >> make.log 2>&1
+echo "${MAKE} CONFIG_DEBUG=y CONFIG_WERROR=y SKIP_DPDK_BUILD=1 " >> make.log
+$MAKE CONFIG_DEBUG=y CONFIG_WERROR=y SKIP_DPDK_BUILD=1  >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+	tail -20 make.log
+	echo ""
+	echo "ERROR make returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+echo "Running unittest.sh ..."
+echo "./test/unit/unittest.sh" >> make.log
+"./test/unit/unittest.sh" >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+	tail -20 make.log
+	echo ""
+	echo "ERROR unittest returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+echo "$MAKE clean " >> make.log
+$MAKE clean  >> make.log 2>&1
+
+if [ "$SYSTEM" = "FreeBSD" ]; then
+	echo
+        echo "Pushing to $1 $2"
+        exit $rc
+fi
+
+if ! hash clang 2>/dev/null; then
+	echo "clang not found; skipping the clang tests"
+	echo
+	echo "Pushing to $1 $2"
+	exit $rc
+fi
+
+echo "Running make with clang ..."
+echo "make CONFIG_DEBUG=n CONFIG_WERROR=y CC=clang CXX=clang++ " >> make.log
+$MAKE CONFIG_DEBUG=n CONFIG_WERROR=y CC=clang CXX=clang++  >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+tail -20 make.log
+	echo ""
+	echo "ERROR make CC=clang CXX=clang++ returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+echo "make clean CC=clang CXX=clang++ SKIP_DPDK_BUILD=1 " >> make.log
+$MAKE clean CC=clang CXX=clang++ SKIP_DPDK_BUILD=1 >> make.log 2>&1
+echo "make CONFIG_DEBUG=y CONFIG_WERROR=y CC=clang CXX=clang++ SKIP_DPDK_BUILD=1 " >> make.log
+$MAKE CONFIG_DEBUG=y CONFIG_WERROR=y CC=clang CXX=clang++ SKIP_DPDK_BUILD=1 >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+	tail -20 make.log
+	echo ""
+	echo "ERROR make CC=clang CXX=clang++ returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+echo "Running unittest.sh ..."
+echo "./test/unit/unittest.sh" >> make.log
+"./test/unit/unittest.sh" >> make.log 2>&1
+rc=$?
+if [ $rc -ne 0 ]; then
+	tail -20 make.log
+	echo ""
+	echo "ERROR unittest returned errors!"
+	echo "ERROR Fix the problem and use 'git commit' to update your changes."
+	echo "ERROR See `pwd`/make.log for more information."
+	echo ""
+	exit $rc
+fi
+
+${MAKE} clean CC=clang CXX=clang++ 2> /dev/null
+
+echo "Pushing to $1 $2"
+
+exit $rc
diff --git a/.gitignore b/.gitignore
index 0a193fea7..bb07e034f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -7,7 +7,6 @@
 *.kdev4
 *.ko
 *.log
-*.map
 *.o
 *.pyc
 *.so
diff --git a/.gitmodules b/.gitmodules
index d0ecf725f..f1d223b71 100644
--- a/.gitmodules
+++ b/.gitmodules
@@ -1,3 +1,6 @@
 [submodule "dpdk"]
 	path = dpdk
 	url = https://github.com/spdk/dpdk.git
+[submodule "intel-ipsec-mb"]
+	path = intel-ipsec-mb
+	url = https://github.com/spdk/intel-ipsec-mb.git
diff --git a/CHANGELOG.md b/CHANGELOG.md
index 46a845ccf..5501276fa 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,5 +1,92 @@
 # Changelog
 
+## v18.07: (Upcoming Release)
+
+### RAID module
+A new bdev module called "raid" has been added as experimental module which
+aggregates underlying nvme bdevs and expose a single raid bdev to upper bdev
+layers. Over this LVS/LVOL can be created as per use-cases and they can be
+exposed to NVMe-oF subsystems. Please note that vhost will not work with RAID
+module as RAID module does not support multipe IOV Vectors yet.
+
+### Log
+
+The debug log component flag has been renamed from `-t` to `-L` to prevent confusion
+with tracepoints and to allow the option to be added to tools that already use `-t`
+to mean something else.
+
+### NVMe Driver
+
+New API function spdk_nvme_qpair_add_cmd_error_injection() and
+spdk_nvme_qpair_remove_cmd_error_injection() have been added for NVMe error emulation,
+users can set specified command with specified error status for error emulation.
+
+Change the name `timeout_sec` parameter to `timeout_us` in API function
+spdk_nvme_ctrlr_register_timeout_callback, and also change the type from uint32_t to
+uint64_t. This will give users more fine-grained control over the timeout period for
+calling callback functions.
+
+### Build System
+
+The build system now generates a combined shared library (libspdk.so) that may be used
+in place of the individual static libraries (libspdk_*.a).
+The combined library includes all components of SPDK and is intended to make linking
+against SPDK easier.
+The static libraries are also still provided for users that prefer to link only the
+minimal set of components required.
+
+A new configure option was added `--with-crypto` that, when set, will build the crypto
+vbdev as well as its dependencies.
+
+### RPC
+
+The `start_nbd_disk` RPC method now returns the path to the kernel NBD device node
+rather than always returning `true`.
+
+### Bdev
+
+The spdk_bdev_get_io_stat() function now returns cumulative totals instead of resetting
+on each call. This allows multiple callers to query I/O statistics without conflicting
+with each other. Existing users will need to adjust their code to record the previous
+I/O statistics to calculate the delta between calls.
+
+A new public header file bdev_module.h has been introduced to facilitate the development
+of new bdev modules. This header includes an interface for the spdk_bdev_part and
+spdk_bdev_part_base objects to enable the creation of multiple virtual bdevs on top of a
+single base bdev.
+
+### Env
+
+The spdk_mem_map_translate() function now takes a size parameter to indicate the size of
+the memory region.  This can be used by environment implementations to validate the
+requested translation.
+
+The I/O Channel implementation has been moved to its own library - lib/thread. The
+public API that was previously in spdk/io_channel.h is now in spdk/thread.h The
+file spdk/io_channel.h remains and includes spdk/thread.h.
+
+### NVMe Over Fabrics
+
+The spdk_nvmf_tgt_destroy() function is now asynchronous and takes a callback
+as a parameter.
+
+### git pre-commit and pre-push hooks
+
+The pre-commit hook will run `scripts/check_format.sh` and verify there are no formating
+errors before allowing `git commit` to run. The pre-push hook runs `make CONFIG_WERROR=y`
+with and without `CONFIG_DEBUG=y` using both the gcc and clang compiler before allowing
+`git push` to run.  Following each DEBUG build `test/unit/unittest.sh` is run and verified.
+Results are recorded in the `make.log` file.
+
+To enable type: 'git config core.hooksPath .githooks'. To override after configuration use
+the `git --no-verify` flag.
+
+### IOAT
+
+IOAT for copy engine is disabled by default. It can be enabled by specifying the Enable
+option with "Yes" in `[Ioat]` section of the configuration file. The Disable option is
+now deprecated and will be removed in a future release.
+
 ## v18.04: Logical Volume Snapshot/Clone, iSCSI Initiator, Bdev QoS, VPP Userspace TCP/IP
 
 ### vhost
diff --git a/CONFIG b/CONFIG
index d503629ae..2142d9c12 100644
--- a/CONFIG
+++ b/CONFIG
@@ -98,3 +98,9 @@ CONFIG_VPP?=n
 
 # Requires libiscsi development libraries.
 CONFIG_ISCSI_INITIATOR?=n
+
+# Build with raid
+CONFIG_RAID?=n
+
+# Enable the dependencies for building the crypto vbdev
+CONFIG_CRYPTO?=n
diff --git a/Makefile b/Makefile
index 25b1fbab8..cb0585afb 100644
--- a/Makefile
+++ b/Makefile
@@ -36,7 +36,7 @@ S :=
 SPDK_ROOT_DIR := $(CURDIR)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y += lib examples app include
+DIRS-y += lib shared_lib examples app include
 DIRS-$(CONFIG_TESTS) += test
 
 .PHONY: all clean $(DIRS-y) config.h CONFIG.local mk/cc.mk cc_version cxx_version
@@ -56,6 +56,7 @@ clean: $(DIRS-y)
 install: all
 	$(Q)echo "Installed to $(DESTDIR)$(CONFIG_PREFIX)"
 
+shared_lib: lib
 lib: $(DPDKBUILD)
 app: lib
 test: lib
diff --git a/app/iscsi_tgt/Makefile b/app/iscsi_tgt/Makefile
index 3ac8aabb6..f04d034ae 100644
--- a/app/iscsi_tgt/Makefile
+++ b/app/iscsi_tgt/Makefile
@@ -46,7 +46,7 @@ C_SRCS := iscsi_tgt.c
 
 SPDK_LIB_LIST = event_bdev event_copy event_iscsi event_net event_scsi
 SPDK_LIB_LIST += jsonrpc json rpc bdev_rpc bdev iscsi scsi copy trace conf
-SPDK_LIB_LIST += util log log_rpc event app_rpc
+SPDK_LIB_LIST += thread util log log_rpc event app_rpc net
 
 ifeq ($(OS),Linux)
 SPDK_LIB_LIST += event_nbd nbd
@@ -54,14 +54,14 @@ endif
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
 	$(COPY_MODULES_LINKER_ARGS) \
-	$(NET_MODULES_LINKER_ARGS)
-LIBS += $(SPDK_LIB_LINKER_ARGS) -lcrypto
+	$(SOCK_MODULES_LINKER_ARGS)
+LIBS += $(SPDK_LIB_LINKER_ARGS)
 LIBS += $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(NET_MODULES_FILES)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES)
 	$(LINK_C)
 
 clean :
diff --git a/app/nvmf_tgt/Makefile b/app/nvmf_tgt/Makefile
index 2f161d553..e93ed1bf0 100644
--- a/app/nvmf_tgt/Makefile
+++ b/app/nvmf_tgt/Makefile
@@ -41,7 +41,7 @@ APP = nvmf_tgt
 C_SRCS := nvmf_main.c
 
 SPDK_LIB_LIST = event_bdev event_copy event_nvmf
-SPDK_LIB_LIST += nvmf event log trace conf util bdev copy rpc jsonrpc json
+SPDK_LIB_LIST += nvmf event log trace conf thread util bdev copy rpc jsonrpc json
 SPDK_LIB_LIST += app_rpc log_rpc bdev_rpc
 
 ifeq ($(OS),Linux)
@@ -50,12 +50,13 @@ endif
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
 	$(COPY_MODULES_LINKER_ARGS) \
+	$(SOCK_MODULES_LINKER_ARGS) \
 	$(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/app/nvmf_tgt/nvmf_main.c b/app/nvmf_tgt/nvmf_main.c
index 815ec73af..e3795fb53 100644
--- a/app/nvmf_tgt/nvmf_main.c
+++ b/app/nvmf_tgt/nvmf_main.c
@@ -77,6 +77,6 @@ main(int argc, char **argv)
 
 	/* Blocks until the application is exiting */
 	rc = spdk_app_start(&opts, nvmf_tgt_started, NULL, NULL);
-
+	spdk_app_fini();
 	return rc;
 }
diff --git a/app/spdk_tgt/Makefile b/app/spdk_tgt/Makefile
index 1b7bb2500..a459ca428 100644
--- a/app/spdk_tgt/Makefile
+++ b/app/spdk_tgt/Makefile
@@ -41,8 +41,8 @@ APP = spdk_tgt
 C_SRCS := spdk_tgt.c
 
 SPDK_LIB_LIST = event_bdev event_copy event_iscsi event_net event_scsi event_nvmf
-SPDK_LIB_LIST += nvmf event log trace conf util bdev iscsi scsi copy rpc jsonrpc json
-SPDK_LIB_LIST += app_rpc log_rpc bdev_rpc
+SPDK_LIB_LIST += nvmf event log trace conf thread util bdev iscsi scsi copy rpc jsonrpc json
+SPDK_LIB_LIST += app_rpc log_rpc bdev_rpc net
 
 ifeq ($(OS),Linux)
 SPDK_LIB_LIST += event_nbd nbd
@@ -55,14 +55,13 @@ endif
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
 	$(COPY_MODULES_LINKER_ARGS) \
-	$(NET_MODULES_LINKER_ARGS) \
+	$(SOCK_MODULES_LINKER_ARGS) \
 	$(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
-LIBS += -lcrypto
 
 all: $(APP)
 	@:
 
-$(APP): $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(NET_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP): $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean:
diff --git a/app/spdk_tgt/spdk_tgt.c b/app/spdk_tgt/spdk_tgt.c
index 237b12ede..cf6281d07 100644
--- a/app/spdk_tgt/spdk_tgt.c
+++ b/app/spdk_tgt/spdk_tgt.c
@@ -42,18 +42,47 @@
 #undef SPDK_CONFIG_VHOST
 #endif
 
+#ifdef SPDK_CONFIG_VHOST
+#define SPDK_VHOST_OPTS "S:"
+#else
+#define SPDK_VHOST_OPTS
+#endif
+
+static const char *g_pid_path = NULL;
+static const char g_spdk_tgt_get_opts_string[] = "f:" SPDK_VHOST_OPTS;
+
 static void
 spdk_tgt_usage(void)
 {
+	printf(" -f pidfile save pid to file under given path\n");
 #ifdef SPDK_CONFIG_VHOST
 	printf(" -S dir     directory where to create vhost sockets (default: pwd)\n");
 #endif
 }
 
+static void
+spdk_tgt_save_pid(const char *pid_path)
+{
+	FILE *pid_file;
+
+	pid_file = fopen(pid_path, "w");
+	if (pid_file == NULL) {
+		fprintf(stderr, "Couldn't create pid file '%s': %s\n", pid_path, strerror(errno));
+		exit(EXIT_FAILURE);
+	}
+
+	fprintf(pid_file, "%d\n", getpid());
+	fclose(pid_file);
+}
+
+
 static void
 spdk_tgt_parse_arg(int ch, char *arg)
 {
 	switch (ch) {
+	case 'f':
+		g_pid_path = arg;
+		break;
 #ifdef SPDK_CONFIG_VHOST
 	case 'S':
 		spdk_vhost_set_socket_path(arg);
@@ -65,6 +94,10 @@ spdk_tgt_parse_arg(int ch, char *arg)
 static void
 spdk_tgt_started(void *arg1, void *arg2)
 {
+	if (g_pid_path) {
+		spdk_tgt_save_pid(g_pid_path);
+	}
+
 	if (getenv("MEMZONE_DUMP") != NULL) {
 		spdk_memzone_dump(stdout);
 		fflush(stdout);
@@ -79,12 +112,14 @@ main(int argc, char **argv)
 
 	spdk_app_opts_init(&opts);
 	opts.name = "spdk_tgt";
-	if ((rc = spdk_app_parse_args(argc, argv, &opts, "",
+	if ((rc = spdk_app_parse_args(argc, argv, &opts, g_spdk_tgt_get_opts_string,
 				      spdk_tgt_parse_arg, spdk_tgt_usage)) !=
 	    SPDK_APP_PARSE_ARGS_SUCCESS) {
 		return rc;
 	}
 
 	rc = spdk_app_start(&opts, spdk_tgt_started, NULL, NULL);
+	spdk_app_fini();
+
 	return rc;
 }
diff --git a/app/trace/trace.cpp b/app/trace/trace.cpp
index 2ecee9511..6efe912e6 100644
--- a/app/trace/trace.cpp
+++ b/app/trace/trace.cpp
@@ -310,7 +310,7 @@ int main(int argc, char **argv)
 	int			fd, i;
 	int			lcore = SPDK_TRACE_MAX_LCORE;
 	uint64_t		tsc_offset;
-	const char		*app_name = "ids";
+	const char		*app_name = "spdk";
 	int			op;
 	char			shm_name[64];
 	int			shm_id = -1, shm_pid = -1;
diff --git a/app/vhost/Makefile b/app/vhost/Makefile
index 52ee99742..adf2701a6 100644
--- a/app/vhost/Makefile
+++ b/app/vhost/Makefile
@@ -42,19 +42,19 @@ C_SRCS := vhost.c
 
 SPDK_LIB_LIST = event_bdev event_copy event_net event_scsi event_vhost
 SPDK_LIB_LIST += jsonrpc json rpc bdev_rpc bdev scsi copy trace conf
-SPDK_LIB_LIST += util log log_rpc event app_rpc
-SPDK_LIB_LIST += vhost rte_vhost event_nbd nbd
+SPDK_LIB_LIST += thread util log log_rpc event app_rpc
+SPDK_LIB_LIST += vhost rte_vhost event_nbd nbd net
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
 	$(COPY_MODULES_LINKER_ARGS) \
-	$(NET_MODULES_LINKER_ARGS)
+	$(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS)
 LIBS += $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(NET_MODULES_FILES)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES)
 	$(LINK_C)
 
 clean :
diff --git a/autobuild.sh b/autobuild.sh
index 2dbf35ce9..f051c6180 100755
--- a/autobuild.sh
+++ b/autobuild.sh
@@ -31,12 +31,6 @@ if [ $SPDK_RUN_CHECK_FORMAT -eq 1 ]; then
 fi
 timing_exit check_format
 
-timing_enter build_kmod
-if [ $SPDK_BUILD_IOAT_KMOD -eq 1 ]; then
-	./scripts/build_kmod.sh build
-fi
-timing_exit build_kmod
-
 scanbuild=''
 make_timing_label='make'
 if [ $SPDK_RUN_SCANBUILD -eq 1 ] && hash scan-build; then
@@ -113,16 +107,24 @@ timing_exit make_install
 
 timing_enter doxygen
 if [ $SPDK_BUILD_DOC -eq 1 ] && hash doxygen; then
-	(cd "$rootdir"/doc; $MAKE $MAKEFLAGS) &> "$out"/doxygen.log
-	if hash pdflatex; then
-		(cd "$rootdir"/doc/output/latex && $MAKE $MAKEFLAGS) &>> "$out"/doxygen.log
+	$MAKE -C "$rootdir"/doc --no-print-directory $MAKEFLAGS &> "$out"/doxygen.log
+	if [ -s "$out"/doxygen.log ]; then
+		cat "$out"/doxygen.log
+		echo "Doxygen errors found!"
+		exit 1
+	fi
+	if hash pdflatex 2>/dev/null; then
+		$MAKE -C "$rootdir"/doc/output/latex --no-print-directory $MAKEFLAGS &>> "$out"/doxygen.log
 	fi
 	mkdir -p "$out"/doc
 	mv "$rootdir"/doc/output/html "$out"/doc
 	if [ -f "$rootdir"/doc/output/latex/refman.pdf ]; then
 		mv "$rootdir"/doc/output/latex/refman.pdf "$out"/doc/spdk.pdf
 	fi
-	(cd "$rootdir"/doc; $MAKE $MAKEFLAGS clean) &>> "$out"/doxygen.log
+	$MAKE -C "$rootdir"/doc --no-print-directory $MAKEFLAGS clean &>> "$out"/doxygen.log
+	if [ -s "$out"/doxygen.log ]; then
+		rm "$out"/doxygen.log
+	fi
 	rm -rf "$rootdir"/doc/output
 fi
 timing_exit doxygen
diff --git a/autotest.sh b/autotest.sh
index 1ce4fad89..e16db3b21 100755
--- a/autotest.sh
+++ b/autotest.sh
@@ -28,6 +28,8 @@ cd $src
 
 ./scripts/setup.sh status
 
+freebsd_update_contigmem_mod
+
 if hash lcov; then
 	# setup output dir for unittest.sh
 	export UT_COVERAGE=$out/ut_coverage
@@ -92,6 +94,9 @@ timing_enter lib
 
 if [ $SPDK_TEST_BLOCKDEV -eq 1 ]; then
 	run_test test/bdev/blockdev.sh
+	if [ $(uname -s) = Linux ]; then
+		run_test test/bdev/bdevjson/json_config.sh
+	fi
 fi
 
 if [ $SPDK_TEST_EVENT -eq 1 ]; then
@@ -100,7 +105,9 @@ fi
 
 if [ $SPDK_TEST_NVME -eq 1 ]; then
 	run_test test/nvme/nvme.sh
-	run_test test/nvme/spdk_nvme_cli.sh
+	if [ $SPDK_TEST_NVME_CLI -eq 1 ]; then
+		run_test test/nvme/spdk_nvme_cli.sh
+	fi
 	# Only test hotplug without ASAN enabled. Since if it is
 	# enabled, it catches SEGV earlier than our handler which
 	# breaks the hotplug logic
@@ -118,7 +125,8 @@ fi
 timing_exit lib
 
 if [ $SPDK_TEST_ISCSI -eq 1 ]; then
-	run_test ./test/iscsi_tgt/iscsi_tgt.sh
+	run_test ./test/iscsi_tgt/iscsi_tgt.sh posix
+	run_test ./test/iscsi_tgt/iscsijson/json_config.sh
 fi
 
 if [ $SPDK_TEST_BLOBFS -eq 1 ]; then
@@ -128,6 +136,7 @@ fi
 
 if [ $SPDK_TEST_NVMF -eq 1 ]; then
 	run_test ./test/nvmf/nvmf.sh
+	run_test ./test/nvmf/nvmfjson/json_config.sh
 fi
 
 if [ $SPDK_TEST_VHOST -eq 1 ]; then
@@ -136,6 +145,10 @@ if [ $SPDK_TEST_VHOST -eq 1 ]; then
 	run_test ./test/vhost/spdk_vhost.sh --negative
 	timing_exit negative
 
+	timing_enter vhost_json_config
+	run_test ./test/vhost/json_config/json_config.sh
+	timing_exit vhost_json_config
+
 	if [ $RUN_NIGHTLY -eq 1 ]; then
 		timing_enter integrity_blk
 		run_test ./test/vhost/spdk_vhost.sh --integrity-blk
@@ -165,9 +178,9 @@ if [ $SPDK_TEST_VHOST -eq 1 ]; then
 		run_test ./test/vhost/spdk_vhost.sh --migration
 		timing_exit vhost_migration
 
-		timing_enter readonly
-		run_test ./test/vhost/spdk_vhost.sh --readonly
-		timing_exit readonly
+		# timing_enter readonly
+		# run_test ./test/vhost/spdk_vhost.sh --readonly
+		# timing_exit readonly
 	fi
 
 	timing_enter integrity_lvol_scsi
@@ -185,7 +198,8 @@ if [ $SPDK_TEST_LVOL -eq 1 ]; then
 	timing_enter lvol
 	test_cases="1,50,51,52,53,100,101,102,150,200,201,250,251,252,253,254,255,"
 	test_cases+="300,301,450,451,452,550,600,601,650,651,652,654,655,"
-	test_cases+="700,701,750,751,752,753,754,755,800,801,802,803,804,10000"
+	test_cases+="700,701,750,751,752,753,754,755,756,757,"
+	test_cases+="800,801,802,803,804,10000"
 	run_test ./test/lvol/lvol.sh --test-cases=$test_cases
 	report_test_completion "lvol"
 	timing_exit lvol
@@ -193,11 +207,17 @@ fi
 
 if [ $SPDK_TEST_VHOST_INIT -eq 1 ]; then
 	run_test ./test/vhost/initiator/blockdev.sh
+	run_test ./test/vhost/initiator/json_config.sh
 	report_test_completion "vhost_initiator"
 fi
 
 if [ $SPDK_TEST_PMDK -eq 1 ]; then
 	run_test ./test/pmem/pmem.sh -x
+	run_test ./test/pmem/json_config/json_config.sh
+fi
+
+if [ $SPDK_TEST_RBD -eq 1 ]; then
+	run_test ./test/bdev/bdevjson/rbd_json_config.sh
 fi
 
 timing_enter cleanup
diff --git a/configure b/configure
index e1b1eb0bd..775c017c7 100755
--- a/configure
+++ b/configure
@@ -31,6 +31,8 @@ function usage()
 	echo "                           disable features and components."
 	echo ""
 	echo "Valid dependencies are listed below."
+	echo " crypto                    Required to build vbdev crypto module."
+	echo "                           No path required."
 	echo " dpdk                      Optional.  Uses dpdk submodule in spdk tree if not specified."
 	echo "                           example: /usr/share/dpdk/x86_64-default-linuxapp-gcc"
 	echo " fio                       Required to build fio_plugin."
@@ -49,6 +51,8 @@ function usage()
 	echo "                           No path required."
 	echo " iscsi-initiator           [disabled]"
 	echo "                           No path required."
+	echo " raid                      [disabled]"
+	echo "                           No path required."
 	echo " vtune                     Required to profile I/O under Intel VTune Amplifier XE."
 	echo "                           example: /opt/intel/vtune_amplifier_xe_version"
 	echo ""
@@ -136,6 +140,13 @@ for i in "$@"; do
 		--without-rbd)
 			CONFIG_RBD=n
 			;;
+		--with-raid)
+			CONFIG_RAID=y
+			echo "Warning: vhost will not work with RAID module as multiple IOV support is not there"
+			;;
+		--without-raid)
+			CONFIG_RAID=n
+			;;
 		--with-rdma)
 			CONFIG_RDMA=y
 			;;
@@ -155,6 +166,12 @@ for i in "$@"; do
 		--without-dpdk)
 			CONFIG_DPDK_DIR=
 			;;
+		--with-crypto)
+			CONFIG_CRYPTO=y
+			;;
+		--without-crypto)
+			CONFIG_CRYPTO=n
+			;;
 		--with-vhost)
 			CONFIG_VHOST=y
 			;;
@@ -294,6 +311,9 @@ fi
 if [ -n "$CONFIG_DPDK_DIR" ]; then
 	echo "CONFIG_DPDK_DIR?=$CONFIG_DPDK_DIR" >> CONFIG.local
 fi
+if [ -n "$CONFIG_CRYPTO" ]; then
+	echo "CONFIG_CRYPTO?=$CONFIG_CRYPTO" >> CONFIG.local
+fi
 if [ -n "$CONFIG_VHOST" ]; then
 	echo "CONFIG_VHOST?=$CONFIG_VHOST" >> CONFIG.local
 fi
@@ -327,6 +347,9 @@ fi
 if [ -n "$CONFIG_RBD" ]; then
 	echo "CONFIG_RBD?=$CONFIG_RBD" >> CONFIG.local
 fi
+if [ -n "$CONFIG_RAID" ]; then
+	echo "CONFIG_RAID?=$CONFIG_RAID" >> CONFIG.local
+fi
 if [ -n "$CONFIG_VTUNE" ]; then
 	echo "CONFIG_VTUNE?=$CONFIG_VTUNE" >> CONFIG.local
 fi
diff --git a/doc/.gitignore b/doc/.gitignore
index 679389977..e28511785 100644
--- a/doc/.gitignore
+++ b/doc/.gitignore
@@ -1,2 +1,3 @@
 # changelog.md is generated by Makefile
 changelog.md
+output/
diff --git a/doc/Doxyfile b/doc/Doxyfile
index 609cdc5ab..7a38c1032 100644
--- a/doc/Doxyfile
+++ b/doc/Doxyfile
@@ -730,7 +730,7 @@ WARNINGS               = YES
 # will automatically be disabled.
 # The default value is: YES.
 
-WARN_IF_UNDOCUMENTED   = YES
+WARN_IF_UNDOCUMENTED   = NO
 
 # If the WARN_IF_DOC_ERROR tag is set to YES, doxygen will generate warnings for
 # potential errors in the documentation, such as not documenting some parameters
@@ -782,6 +782,18 @@ WARN_LOGFILE           =
 
 INPUT                  = ../include/spdk \
                          index.md \
+                         \
+                         intro.md \
+                         concepts.md \
+                         user_guides.md \
+                         prog_guides.md \
+                         general.md \
+                         misc.md \
+                         modules.md \
+                         tools.md \
+                         experimental_tools.md \
+                         performance_reports.md \
+                         \
                          about.md \
                          changelog.md \
                          concurrency.md \
@@ -806,9 +818,11 @@ INPUT                  = ../include/spdk \
                          peer_2_peer.md \
                          spdkcli.md \
                          ssd_internals.md \
+                         user_guides_common.md \
                          userspace.md \
                          vagrant.md \
                          vhost.md \
+                         vhost_processing.md \
                          virtio.md
 
 # This tag can be used to specify the character encoding of the source files
@@ -906,7 +920,7 @@ EXAMPLE_RECURSIVE      = NO
 # that contain images that are to be included in the documentation (see the
 # \image command).
 
-IMAGE_PATH             =
+IMAGE_PATH             = img
 
 # The INPUT_FILTER tag can be used to specify a program that doxygen should
 # invoke to filter for each input file. Doxygen will invoke the filter program
@@ -1163,7 +1177,7 @@ HTML_EXTRA_STYLESHEET  = stylesheet.css
 # files will be copied as-is; there are no commands or markers available.
 # This tag requires that the tag GENERATE_HTML is set to YES.
 
-HTML_EXTRA_FILES       =
+HTML_EXTRA_FILES       = two.min.js
 
 # The HTML_COLORSTYLE_HUE tag controls the color of the HTML output. Doxygen
 # will adjust the colors in the style sheet and background images according to
diff --git a/doc/Makefile b/doc/Makefile
index 7fe11c633..ec3f396d9 100644
--- a/doc/Makefile
+++ b/doc/Makefile
@@ -1,3 +1,6 @@
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+
 all: doc
 	@:
 
@@ -6,15 +9,15 @@ all: doc
 doc: output
 
 changelog.md: ../CHANGELOG.md
-	sed -e 's/^# Changelog/# Changelog {#changelog}/' \
+	$(Q)sed -e 's/^# Changelog/# Changelog {#changelog}/' \
 	    -e 's/^##/#/' \
 	    -e 's/^# \(\(v..\...\):.*\)/# \1 {#changelog-\2}/' \
 	    -e '/# v..\...:/s/\./-/2' \
 	    < $< > $@
 
 output: Doxyfile changelog.md $(wildcard *.md) $(wildcard ../include/spdk/*.h)
-	rm -rf $@
-	doxygen Doxyfile
+	$(Q)rm -rf $@
+	$(Q)doxygen Doxyfile
 
 clean:
-	rm -rf output changelog.md
+	$(Q)rm -rf output changelog.md
diff --git a/doc/bdev.md b/doc/bdev.md
index 326a6a0b5..d93f5b63b 100644
--- a/doc/bdev.md
+++ b/doc/bdev.md
@@ -72,6 +72,11 @@ To remove previously created bdev user can use `delete_bdev` RPC command.
 Bdev can be deleted at any time and this will be fully handled by any upper
 layers. As an argument user should provide bdev name.
 
+# Malloc bdev {#bdev_config_malloc}
+
+Malloc bdevs are ramdisks. Because of its nature they are volatile. They are created from hugepage memory given to SPDK
+application.
+
 # NVMe bdev {#bdev_config_nvme}
 
 There are two ways to create block device based on NVMe device in SPDK. First
@@ -136,10 +141,10 @@ This command will create a bdev that represents the 'foo' image from a pool call
 # GPT (GUID Partition Table) {#bdev_config_gpt}
 
 The GPT virtual bdev driver is enabled by default and does not require any configuration.
-It will automatically detect @ref bdev_ug_gpt_table on any attached bdev and will create
+It will automatically detect @ref bdev_ug_gpt on any attached bdev and will create
 possibly multiple virtual bdevs.
 
-## SPDK GPT partition table {#bdev_ug_gpt_table}
+## SPDK GPT partition table {#bdev_ug_gpt}
 The SPDK partition type GUID is `7c5222bd-8f5d-4087-9c00-bf9843c7b58c`. Existing SPDK bdevs
 can be exposed as Linux block devices via NBD and then ca be partitioned with
 standard partitioning tools. After partitioning, the bdevs will need to be deleted and
diff --git a/doc/bdev_module.md b/doc/bdev_module.md
index a315b33b3..24a08df4b 100644
--- a/doc/bdev_module.md
+++ b/doc/bdev_module.md
@@ -18,7 +18,7 @@ how to write a module.
 
 ## Creating A New Module
 
-Block device modules are located in lib/bdev/<module_name> today. It is not
+Block device modules are located in subdirectories under lib/bdev today. It is not
 currently possible to place the code for a bdev module elsewhere, but updates
 to the build system could be made to enable this in the future. To create a
 module, add a new directory with a single C file and a Makefile. A great
diff --git a/doc/blob.md b/doc/blob.md
index b6596748f..2fa3db81e 100644
--- a/doc/blob.md
+++ b/doc/blob.md
@@ -57,6 +57,58 @@ store metadata in the form of key/value pairs with each blob which we'll refer t
 Blobstore owns the entire underlying device which is made up of a private Blobstore metadata region and the collection of
 blobs as managed by the application.
 
+@htmlonly
+
+  <div id="blob_hierarchy"></div>
+
+  <script>
+    let elem = document.getElementById('blob_hierarchy');
+
+    let canvasWidth = 800;
+    let canvasHeight = 200;
+    var two = new Two({ width: 800, height: 200 }).appendTo(elem);
+
+    var blobRect = two.makeRectangle(canvasWidth / 2, canvasHeight / 2, canvasWidth, canvasWidth);
+    blobRect.fill = '#7ED3F7';
+
+    var blobText = two.makeText('Blob', canvasWidth / 2, 10, { alignment: 'center'});
+
+    for (var i = 0; i < 2; i++) {
+        let clusterWidth = 400;
+        let clusterHeight = canvasHeight;
+        var clusterRect = two.makeRectangle((clusterWidth / 2) + (i * clusterWidth),
+                                            clusterHeight / 2,
+                                            clusterWidth - 10,
+                                            clusterHeight - 50);
+        clusterRect.fill = '#00AEEF';
+
+        var clusterText =  two.makeText('Cluster',
+                                        (clusterWidth / 2) + (i * clusterWidth),
+                                        35,
+                                        { alignment: 'center', fill: 'white' });
+
+
+        for (var j = 0; j < 4; j++) {
+            let pageWidth = 100;
+            let pageHeight = canvasHeight;
+            var pageRect = two.makeRectangle((pageWidth / 2) + (j * pageWidth) + (i * clusterWidth),
+                                             pageHeight / 2,
+                                             pageWidth - 20,
+                                             pageHeight - 100);
+            pageRect.fill = '#003C71';
+
+            var pageText =  two.makeText('Page',
+                                         (pageWidth / 2) + (j * pageWidth) + (i * clusterWidth),
+                                         pageHeight / 2,
+                                         { alignment: 'center', fill: 'white' });
+        }
+    }
+
+    two.update();
+  </script>
+
+@endhtmlonly
+
 ### Atomicity
 
 For all Blobstore operations regarding atomicity, there is a dependency on the underlying device to guarantee atomic
diff --git a/doc/concepts.md b/doc/concepts.md
new file mode 100644
index 000000000..84c91f32e
--- /dev/null
+++ b/doc/concepts.md
@@ -0,0 +1,8 @@
+# Concepts {#concepts}
+
+- @subpage userspace
+- @subpage memory
+- @subpage concurrency
+- @subpage ssd_internals
+- @subpage vhost_processing
+- @subpage porting
diff --git a/doc/concurrency.md b/doc/concurrency.md
index c95b37d15..dcc3c0c1c 100644
--- a/doc/concurrency.md
+++ b/doc/concurrency.md
@@ -65,7 +65,7 @@ fundamental libraries in SPDK, for instance, don't do any message passing on
 their own and instead enumerate rules about when functions may be called in
 their documentation (e.g. @ref nvme). Most libraries, however, depend on SPDK's
 [io_channel](http://www.spdk.io/doc/io__channel_8h.html) infrastructure,
-located in `libspdk_util.a`. The io_channel infrastructure is an abstraction
+located in `libspdk_thread.a`. The io_channel infrastructure is an abstraction
 around a basic message passing framework and defines a few key abstractions.
 
 First, spdk_thread is an abstraction for a thread of execution and
diff --git a/doc/experimental_tools.md b/doc/experimental_tools.md
new file mode 100644
index 000000000..970e63e1c
--- /dev/null
+++ b/doc/experimental_tools.md
@@ -0,0 +1,3 @@
+# Experimental Tools {#experimental_tools}
+
+- @subpage spdkcli
diff --git a/doc/general.md b/doc/general.md
new file mode 100644
index 000000000..0f87e01a1
--- /dev/null
+++ b/doc/general.md
@@ -0,0 +1,6 @@
+# General Information {#general}
+
+- @subpage directory_structure
+- [Public API header files](files.html)
+- @subpage event
+- @subpage logical_volumes
diff --git a/doc/header.html b/doc/header.html
index dc3ea62c2..0d2a12fd8 100644
--- a/doc/header.html
+++ b/doc/header.html
@@ -11,6 +11,7 @@
 
   <script type="text/javascript" src="$relpath^jquery.js"></script>
   <script type="text/javascript" src="$relpath^dynsections.js"></script>
+  <script type="text/javascript" src="$relpath^two.min.js"></script>
 
   $treeview
   $search
diff --git a/doc/img/lvol_clone_snapshot_read.svg b/doc/img/lvol_clone_snapshot_read.svg
new file mode 100644
index 000000000..0f91d417b
--- /dev/null
+++ b/doc/img/lvol_clone_snapshot_read.svg
@@ -0,0 +1,3 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Created with Inkscape (http://www.inkscape.org/) -->
+<svg width="173.3mm" height="87.312mm" version="1.1" viewBox="0 0 173.3 87.312" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><defs><marker id="a" overflow="visible" orient="auto"><path transform="scale(.4) rotate(180) translate(10)" d="m0 0 5-5-17.5 5 17.5 5-5-5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="Arrow1Mend" overflow="visible" orient="auto"><path transform="scale(.4) rotate(180) translate(10)" d="m0 0 5-5-17.5 5 17.5 5-5-5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="g" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="f" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="h" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="d" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="b" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="c" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="e" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title/></cc:Work></rdf:RDF></metadata><g transform="translate(2.6458 2.5135)"><rect x="-2.6458" y="-2.5135" width="173.3" height="87.312" ry="0" fill="#fff"/><path d="m5.2917 53.049v-9.2604" fill="none" marker-end="url(#a)" stroke="#000" stroke-width=".26458px"/><path d="m5.2917 38.497v-9.2604" fill="none" marker-end="url(#Arrow1Mend)" stroke="#000" stroke-width=".26458px"/></g><g transform="translate(-14.552 -4.6354)"><g stroke="#000" stroke-width=".26458"><rect x="47.625" y="29.771" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="70.115" y="29.771" width="22.49" height="6.6146" fill="#d7d7f4"/><rect x="92.604" y="29.771" width="22.49" height="6.6146" fill="#d7d7f4"/><rect x="115.09" y="29.771" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="137.58" y="29.771" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="160.07" y="29.771" width="22.49" height="6.6146" fill="#d7d7f4"/></g><g fill="#d7f4d7" stroke="#000" stroke-width=".26458"><rect x="92.604" y="44.323" width="22.49" height="6.6146"/><rect x="115.09" y="44.323" width="22.49" height="6.6146"/><rect x="137.58" y="44.323" width="22.49" height="6.6146"/><rect x="160.07" y="44.323" width="22.49" height="6.6146"/></g><text x="18.309231" y="49.435097" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="18.309231" y="49.435097" stroke-width=".26458">snapshot</tspan></text><text x="18.362614" y="11.230336" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="18.362614" y="11.230336" stroke-width=".26458">read</tspan></text><g stroke="#000"><path d="m17.198 21.833 168.01-1e-6" fill="none" stroke-dasharray="1.59, 1.59" stroke-width=".265"/><g stroke-width=".26458"><rect x="47.625" y="7.2812" width="22.49" height="6.6146" fill="#f4d7d7" stroke-dasharray="0.52916663, 0.26458332"/><rect x="115.09" y="7.2813" width="22.49" height="6.6146" fill="#d7f4d7"/><rect x="137.58" y="7.2812" width="22.49" height="6.6146" fill="#d7f4d7"/></g></g><g fill="#d7d7f4" stroke="#000" stroke-width=".26458"><rect x="70.115" y="7.2813" width="22.49" height="6.6146"/><rect x="92.604" y="7.2813" width="22.49" height="6.6146"/><rect x="160.07" y="7.2813" width="22.49" height="6.6146"/></g><text x="18.280743" y="35.463409" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="18.280743" y="35.463409" stroke-width=".26458">clone</tspan></text><rect x="47.625" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="59.058754" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="59.058754" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="70.115" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="81.54834" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="81.54834" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="92.604" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="104.03793" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="104.03793" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="115.09" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="126.52751" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="126.52751" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="137.58" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="149.01709" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="149.01709" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="160.07" y="58.875" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="171.50665" y="63.505211" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="171.50665" y="63.505211" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><text x="18.309223" y="63.987183" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="18.309223" y="63.987183" stroke-width=".26458">zeroes_dev</tspan></text><g fill="none"><rect x="47.625" y="44.323" width="22.49" height="6.6146" stroke="#000" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="70.115" y="44.323" width="22.49" height="6.6146" stroke="#000" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="39.688" y="27.125" width="145.52" height="11.906" ry="1.3229" stroke="#808080" stroke-width=".265"/><rect x="39.688" y="41.677" width="145.52" height="11.906" ry="1.3229" stroke="#808080" stroke-width=".265"/></g><g fill="#00f" stroke="#00f" stroke-width=".265"><path d="m80.698 13.896v15.875" marker-end="url(#c)"/><path d="m58.208 13.896v44.979" marker-end="url(#b)"/><path d="m103.19 13.896v15.875" marker-end="url(#d)"/><path d="m171.98 13.896v15.875" marker-end="url(#h)"/><path d="m127 13.896v30.427" marker-end="url(#f)"/><path d="m149.49 13.896v30.427" marker-end="url(#g)"/><path d="m124.35 74.75 10.583 3e-6" marker-end="url(#e)"/></g><g stroke-width=".26458"><text x="137.58331" y="76.072906" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="137.58331" y="76.072906" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">read cluster</tspan></text><rect x="124.35" y="78.719" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-dasharray="0.52916663, 0.52916663"/><text x="137.58331" y="81.364571" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="137.58331" y="81.364571" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">unallocated cluster</tspan></text></g><rect x="124.35" y="84.01" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-width=".265"/><text x="137.58331" y="86.656242" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="137.58331" y="86.656242" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocated cluster</tspan></text></g></svg>
diff --git a/doc/img/lvol_clone_snapshot_write.svg b/doc/img/lvol_clone_snapshot_write.svg
new file mode 100644
index 000000000..d5da58132
--- /dev/null
+++ b/doc/img/lvol_clone_snapshot_write.svg
@@ -0,0 +1,3 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Created with Inkscape (http://www.inkscape.org/) -->
+<svg width="173.3mm" height="91.281mm" version="1.1" viewBox="0 0 173.3 91.281" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><defs><marker id="h" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="e" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="d" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="g" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="b" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="c" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="f" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="a" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="Arrow1Mend" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title/></cc:Work></rdf:RDF></metadata><g transform="translate(3.9688 -99.351)"><rect x="-3.9688" y="99.351" width="173.3" height="91.281" ry="0" fill="#fff"/></g><g transform="translate(1.3229 -101.86)"><g stroke="#000" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"><rect x="31.75" y="127" width="22.49" height="6.6146" fill="none"/><rect x="99.219" y="127" width="22.49" height="6.6146" fill="#d7f4d7"/><rect x="121.71" y="127" width="22.49" height="6.6146" fill="none"/></g><g fill="#d7d7f4" stroke="#000" stroke-width=".26458"><rect x="76.729" y="141.55" width="22.49" height="6.6146"/><rect x="99.219" y="141.55" width="22.49" height="6.6146"/><rect x="121.71" y="141.55" width="22.49" height="6.6146"/><rect x="144.2" y="141.55" width="22.49" height="6.6146"/></g><text x="2.4342299" y="146.66425" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="2.4342299" y="146.66425" stroke-width=".26458">snapshot</tspan></text><text x="2.4876127" y="108.4595" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="2.4876127" y="108.4595" stroke-width=".26458">write</tspan></text><path d="m1.3229 119.06 168.01 1e-5" fill="none" stroke="#000" stroke-dasharray="1.59000004, 1.59000004" stroke-width=".265"/><rect x="99.219" y="104.51" width="22.49" height="6.6146" fill="#fff6d5" stroke="#000" stroke-width=".26458"/><text x="2.4057417" y="132.69257" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="2.4057417" y="132.69257" stroke-width=".26458">clone</tspan></text><rect x="31.75" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="43.183758" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="43.183758" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="54.24" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="65.673347" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="65.673347" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="76.729" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="88.162926" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="88.162926" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="99.219" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="110.65253" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="110.65253" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="121.71" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="133.14209" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="133.14209" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="144.2" y="156.1" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="155.63165" y="160.73438" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="155.63165" y="160.73438" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><text x="2.4342222" y="161.21635" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="2.4342222" y="161.21635" stroke-width=".26458">zeroes_dev</tspan></text><g fill="none"><rect x="31.75" y="141.55" width="22.49" height="6.6146" stroke="#000" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="54.24" y="141.55" width="22.49" height="6.6146" stroke="#000" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="23.813" y="124.35" width="145.52" height="11.906" ry="1.3229" stroke="#808080" stroke-width=".265"/><rect x="23.813" y="138.91" width="145.52" height="11.906" ry="1.3229" stroke="#808080" stroke-width=".265"/></g><path d="m115.09 111.12v15.875" fill="#00f" marker-end="url(#e)" stroke="#00f" stroke-width=".265"/><path d="m105.83 141.55v-7.9375" fill="#f00" marker-end="url(#h)" stroke="#ff2a2a" stroke-width=".265"/><g stroke="#000" stroke-width=".26458"><rect x="54.24" y="127" width="22.49" height="6.6146" fill="#ffe3be" stroke-dasharray="0.52916663, 0.52916663"/><rect x="144.2" y="127" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="54.24" y="104.51" width="22.49" height="6.6146" fill="#fff6d5"/></g><g><path d="m70.115 111.12v15.875" fill="#00f" marker-end="url(#d)" stroke="#00f" stroke-width=".265"/><path d="m60.854 156.1v-22.49" fill="#f00" marker-end="url(#g)" stroke="#ff2a2a" stroke-width=".265"/><rect x="76.729" y="104.51" width="22.49" height="6.6146" fill="#fff6d5" stroke="#000" stroke-width=".26458"/></g><g stroke-width=".265"><path d="m87.313 111.12v15.875" fill="#00f" marker-end="url(#b)" stroke="#00f"/><path d="m109.8 170.66 10.583 1e-5" fill="#00f" marker-end="url(#c)" stroke="#00f"/><path d="m109.8 175.95h10.583" fill="#f00" marker-end="url(#f)" stroke="#ff2a2a"/></g><g stroke-width=".26458"><text x="123.03123" y="171.97917" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="123.03123" y="171.97917" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">write</tspan></text><text x="123.03123" y="177.27084" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="123.03123" y="177.27084" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocate and copy cluster</tspan></text><rect x="109.8" y="179.92" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-dasharray="0.52916663, 0.52916663"/><text x="123.03123" y="182.5625" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="123.03123" y="182.5625" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">unallocated cluster before write</tspan></text></g><rect x="109.8" y="185.21" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-width=".265"/><text x="123.03123" y="187.85417" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="123.03123" y="187.85417" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocated cluster</tspan></text><g stroke="#000"><rect x="76.729" y="127" width="22.49" height="6.6146" fill="#fff6d5" stroke-width=".26458"/><path d="m6.6146 157.43v-9.2604" fill="none" marker-end="url(#a)" stroke-width=".26458px"/><path d="m6.6146 142.88v-9.2604" fill="none" marker-end="url(#Arrow1Mend)" stroke-width=".26458px"/></g></g></svg>
diff --git a/doc/img/lvol_inflate_clone_snapshot.svg b/doc/img/lvol_inflate_clone_snapshot.svg
new file mode 100644
index 000000000..85c85b4eb
--- /dev/null
+++ b/doc/img/lvol_inflate_clone_snapshot.svg
@@ -0,0 +1,3 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Created with Inkscape (http://www.inkscape.org/) -->
+<svg width="169.33mm" height="89.958mm" version="1.1" viewBox="0 0 169.33 89.958" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><defs><marker id="h" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="i" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="Arrow1Mend" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="e" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="g" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="Arrow1Mstart" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="j" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="f" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="a" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="d" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="b" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="c" overflow="visible" orient="auto"><path transform="matrix(.4 0 0 .4 4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title/></cc:Work></rdf:RDF></metadata><g transform="translate(3.9687 2.5133)"><rect x="-3.9687" y="-2.5133" width="169.33" height="89.958" fill="#fff"/></g><g transform="translate(-37.042 -17.865)"><g stroke="#000" stroke-width=".26458"><rect transform="scale(1,-1)" x="66.146" y="-56.229" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect transform="scale(1,-1)" x="88.635" y="-56.229" width="22.49" height="6.6146" fill="#d7d7f4"/><rect transform="scale(1,-1)" x="111.13" y="-56.229" width="22.49" height="6.6146" fill="#d7d7f4"/><rect transform="scale(1,-1)" x="133.61" y="-56.229" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect transform="scale(1,-1)" x="156.1" y="-56.229" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect transform="scale(1,-1)" x="178.59" y="-56.229" width="22.49" height="6.6146" fill="#d7d7f4"/></g><g fill="#d7f4d7" stroke="#000" stroke-width=".26458"><rect transform="scale(1,-1)" x="111.13" y="-41.677" width="22.49" height="6.6146"/><rect transform="scale(1,-1)" x="133.61" y="-41.677" width="22.49" height="6.6146"/><rect transform="scale(1,-1)" x="156.1" y="-41.677" width="22.49" height="6.6146"/><rect transform="scale(1,-1)" x="178.59" y="-41.677" width="22.49" height="6.6146"/></g><text x="39.850315" y="38.377769" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="39.850315" y="38.377769" stroke-width=".26458">snapshot</tspan></text><text x="39.348198" y="97.549011" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="39.348198" y="97.549011">Inflated</tspan><tspan x="39.348198" y="101.95873">clone</tspan></text><g stroke="#000"><path d="m39.688 64.167 161.4 9e-6" fill="none" stroke-dasharray="1.59000006, 1.59000006" stroke-width=".265"/><g stroke-width=".26458"><rect transform="scale(1,-1)" x="66.146" y="-102.53" width="22.49" height="6.6146" fill="#f4d7d7"/><rect transform="scale(1,-1)" x="133.61" y="-102.53" width="22.49" height="6.6146" fill="#d7f4d7"/><rect transform="scale(1,-1)" x="156.1" y="-102.53" width="22.49" height="6.6146" fill="#d7f4d7"/></g></g><g fill="#d7d7f4" stroke="#000" stroke-width=".26458"><rect transform="scale(1,-1)" x="88.635" y="-102.53" width="22.49" height="6.6146"/><rect transform="scale(1,-1)" x="111.13" y="-102.53" width="22.49" height="6.6146"/><rect transform="scale(1,-1)" x="178.59" y="-102.53" width="22.49" height="6.6146"/></g><text x="39.821827" y="53.033295" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="39.821827" y="53.033295" stroke-width=".26458">clone</tspan></text><rect transform="scale(1,-1)" x="66.146" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="77.57962" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="77.57962" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect transform="scale(1,-1)" x="88.635" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="100.06921" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="100.06921" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect transform="scale(1,-1)" x="111.13" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="122.55879" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="122.55879" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect transform="scale(1,-1)" x="133.61" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="145.04839" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="145.04839" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect transform="scale(1,-1)" x="156.1" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="167.53796" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="167.53796" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect transform="scale(1,-1)" x="178.59" y="-27.125" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.53, 0.265" stroke-width=".265"/><text x="190.02751" y="25.063118" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="190.02751" y="25.063118" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><text x="39.850307" y="23.727493" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="39.850307" y="23.727493" stroke-width=".26458">zeroes_dev</tspan></text><g fill="none" stroke="#000"><rect transform="scale(1,-1)" x="66.146" y="-41.677" width="22.49" height="6.6146" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect transform="scale(1,-1)" x="88.635" y="-41.677" width="22.49" height="6.6146" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="66.146" y="72.104" width="134.94" height="7.9375" ry="2.6458" stroke-width=".5"/></g><text x="113.74464" y="77.262192" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="113.74464" y="77.262192" stroke-width=".26458">Allocate and copy</tspan></text><g fill="none" stroke-width=".265"><path d="m39.688 87.979 161.4 4e-6" stroke="#000" stroke-dasharray="1.59000008, 1.59000008"/><g stroke="#808080"><rect x="58.208" y="32.417" width="145.52" height="11.906" ry="1.3229"/><rect x="58.208" y="46.969" width="145.52" height="11.906" ry="1.3229"/><rect x="58.208" y="93.271" width="145.52" height="11.906" ry="1.3229"/></g></g><g fill="#00f" stroke="#00f" stroke-width=".265"><path d="m76.729 72.104v-44.979" marker-start="url(#e)"/><path d="m145.52 72.104v-30.427" marker-start="url(#g)"/><path d="m168.01 72.104v-30.427" marker-start="url(#Arrow1Mstart)"/><path d="m76.729 95.917 1.4e-5 -15.875" marker-start="url(#a)"/><path d="m145.52 95.917v-15.875" marker-start="url(#f)"/><path d="m168.01 95.917 1e-5 -15.875" marker-start="url(#j)"/></g><path d="m58.208 53.583c-7.4527 13.662-6.6489 28.799 0 44.979" fill="none" marker-end="url(#Arrow1Mend)" stroke="#000" stroke-width=".5"/><g fill="#00f" stroke="#00f" stroke-width=".265"><path d="m100.54 95.917v-39.688" marker-start="url(#d)" stroke-dasharray="1.58999992, 1.58999992"/><path d="m123.03 95.917v-39.688" marker-start="url(#b)" stroke-dasharray="1.58999994, 1.58999994"/><path d="m190.5 95.917v-39.688" marker-start="url(#c)" stroke-dasharray="1.58999994, 1.58999994"/></g><text x="39.498512" y="77.301338" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="39.498512" y="77.301338" stroke-width=".26458">Inflate</tspan></text><path d="m44.979 24.479v10.583" fill="none" marker-end="url(#h)" stroke="#000" stroke-width=".26458px"/><path d="m44.979 40.354v7.9375" fill="none" marker-end="url(#i)" stroke="#000" stroke-width=".26458px"/></g></svg>
diff --git a/doc/img/lvol_thin_provisioning.svg b/doc/img/lvol_thin_provisioning.svg
new file mode 100644
index 000000000..1d95d1b08
--- /dev/null
+++ b/doc/img/lvol_thin_provisioning.svg
@@ -0,0 +1,3 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Created with Inkscape (http://www.inkscape.org/) -->
+<svg width="181.24mm" height="79.375mm" version="1.1" viewBox="0 0 181.24 79.375" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><title>Thin Provisioning</title><defs><marker id="marker2036" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="marker1960" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="marker1890" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="marker1826" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="marker1816" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="Arrow1Mend" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill-rule="evenodd" stroke="#000" stroke-width="1pt"/></marker><marker id="marker11771-4-9" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="marker1826-2-4-7-1-7" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title>Thin Provisioning</dc:title></cc:Work></rdf:RDF></metadata><g transform="translate(2.6458 2.3956)"><rect x="-2.6458" y="-2.3956" width="181.24" height="79.375" fill="#fffffe" stroke-width=".26458"/></g><g transform="translate(-3.9688 -4.6356)"><g stroke="#000"><g stroke-width=".26458"><rect x="44.979" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="67.469" y="32.417" width="22.49" height="6.6146" fill="#d7d7f4"/><rect x="89.958" y="32.417" width="22.49" height="6.6146" fill="#d7d7f4"/><rect x="112.45" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="134.94" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="157.43" y="32.417" width="22.49" height="6.6146" fill="#d7d7f4"/></g><rect x="44.979" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/></g><text x="56.412949" y="51.598957" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="56.412949" y="51.598957" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="67.469" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="78.902527" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="78.902527" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="89.958" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="101.39211" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="101.39211" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="112.45" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="123.88169" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="123.88169" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="134.94" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="146.37128" y="51.598957" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="146.37128" y="51.598957" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="157.43" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><g font-family="sans-serif" letter-spacing="0px" stroke-width=".26458" word-spacing="0px"><text x="168.86086" y="51.598961" font-size="10.583px" style="line-height:1.25" xml:space="preserve"><tspan x="168.86086" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><text x="6.6430736" y="51.680019" font-size="3.5278px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="6.6430736" y="51.680019" stroke-width=".26458">zeroes_dev</tspan></text><text x="6.6296382" y="12.539818" font-size="3.5278px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="6.6296382" y="12.539818">Thin-provisioned</tspan><tspan x="6.6296382" y="16.949539">volume</tspan></text></g><g stroke="#000"><path d="m6.6146 24.479 173.3 1e-6" fill="none" stroke-dasharray="1.59, 1.59" stroke-width=".265"/><g fill="#f4d7d7" stroke-dasharray="0.52916663, 0.26458332" stroke-width=".26458"><rect x="44.979" y="9.9271" width="22.49" height="6.6146"/><rect x="112.45" y="9.9271" width="22.49" height="6.6146"/><rect x="134.94" y="9.9271" width="22.49" height="6.6146"/></g><g fill="#d7d7f4" stroke-width=".26458"><rect x="67.469" y="9.9271" width="22.49" height="6.6146"/><rect x="89.958" y="9.9271" width="22.49" height="6.6146"/><rect x="157.43" y="9.9271" width="22.49" height="6.6146"/></g></g><text x="6.614583" y="37.708332" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="6.614583" y="37.708332" stroke-width=".26458">active clusters</tspan></text><rect x="37.042" y="7.2812" width="145.52" height="11.906" ry="1.3229" fill="none" stroke="#999" stroke-width=".5"/><rect x="37.042" y="29.771" width="145.52" height="26.458" ry="1.3229" fill="none" stroke="#999" stroke-width=".5"/><g fill="#00f" stroke="#00f"><g stroke-width=".26458"><path d="m78.052 16.542v15.875" marker-end="url(#marker1960)"/><path d="m55.562 16.542v30.427" marker-end="url(#marker2036)"/><path d="m100.54 16.542v15.875" marker-end="url(#marker1890)"/><path d="m169.33 16.542v15.875" marker-end="url(#Arrow1Mend)"/><path d="m124.35 16.542v30.427" marker-end="url(#marker1826)"/><path d="m146.84 16.542v30.427" marker-end="url(#marker1816)"/></g><path d="m132.29 61.521 10.583 1e-5" marker-end="url(#marker1826-2-4-7-1-7)" stroke-width=".265"/></g><path d="m132.29 66.813h10.583" fill="#f00" marker-end="url(#marker11771-4-9)" stroke="#ff2a2a" stroke-width=".265"/><g stroke-width=".26458"><text x="145.52083" y="62.843975" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="145.52083" y="62.843975" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">read</tspan></text><text x="145.52083" y="68.135651" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="145.52083" y="68.135651" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocate and copy cluster</tspan></text><rect x="132.29" y="70.781" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-dasharray="0.52916664, 0.52916664"/><text x="145.52083" y="73.427307" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="145.52083" y="73.427307" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">unallocated cluster</tspan></text></g><rect x="132.29" y="76.073" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-width=".265"/><text x="145.52083" y="78.718971" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="145.52083" y="78.718971" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocated cluster</tspan></text></g></svg>
diff --git a/doc/img/lvol_thin_provisioning_write.svg b/doc/img/lvol_thin_provisioning_write.svg
new file mode 100644
index 000000000..37cf6af93
--- /dev/null
+++ b/doc/img/lvol_thin_provisioning_write.svg
@@ -0,0 +1,3 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Created with Inkscape (http://www.inkscape.org/) -->
+<svg width="181.24mm" height="79.375mm" version="1.1" viewBox="0 0 181.24 79.375" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><title>Thin Provisioning Write</title><defs><marker id="marker11771-4-9" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="marker1826-2-4-7-1-7" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="marker11771-4-9-6" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#f00" fill-rule="evenodd" stroke="#ff2a2a" stroke-width="1pt"/></marker><marker id="marker1826-2-4-7-1-7-4" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker><marker id="marker1826-2-4-7-1-7-4-1" overflow="visible" orient="auto"><path transform="matrix(-.4 0 0 -.4 -4 0)" d="m0 0 5-5-17.5 5 17.5 5z" fill="#00f" fill-rule="evenodd" stroke="#00f" stroke-width="1pt"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title>Thin Provisioning Write</dc:title></cc:Work></rdf:RDF></metadata><g transform="translate(2.6458 2.3956)"><rect x="-2.6458" y="-2.3956" width="181.24" height="79.375" fill="#fffffe" stroke-width=".26458"/></g><g transform="translate(-3.9688 -4.6356)"><g stroke="#000"><rect x="44.979" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><rect x="67.469" y="32.417" width="22.49" height="6.6146" fill="#ffe3be" stroke-dasharray="0.52916663, 0.52916663" stroke-width=".26458"/><g stroke-width=".26458"><rect x="112.45" y="32.417" width="22.49" height="6.6146" fill="#fff6d5"/><rect x="89.959" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/><rect x="134.94" y="32.417" width="22.49" height="6.6146" fill="none" stroke-dasharray="0.52916663, 0.52916663"/></g><rect x="44.979" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/></g><text x="56.412949" y="51.598957" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="56.412949" y="51.598957" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="67.469" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="78.902527" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="78.902527" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="89.958" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="101.39211" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="101.39211" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="112.45" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="123.88169" y="51.598961" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="123.88169" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="134.94" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><text x="146.37128" y="51.598957" fill="#000000" font-family="sans-serif" font-size="10.583px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="146.37128" y="51.598957" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><rect x="157.43" y="46.969" width="22.49" height="6.6146" fill="#f4d7d7" stroke="#000" stroke-dasharray="0.52999997, 0.26499999" stroke-width=".265"/><g font-family="sans-serif" letter-spacing="0px" stroke-width=".26458" word-spacing="0px"><text x="168.86086" y="51.598961" font-size="10.583px" style="line-height:1.25" xml:space="preserve"><tspan x="168.86086" y="51.598961" font-family="sans-serif" font-size="3.5278px" stroke-width=".26458" text-align="center" text-anchor="middle" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">00000...</tspan></text><text x="6.6430736" y="51.680019" font-size="3.5278px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="6.6430736" y="51.680019" stroke-width=".26458">zeroes_dev</tspan></text><text x="6.6296382" y="12.539818" font-size="3.5278px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve">write</text></g><g stroke="#000"><path d="m6.6146 24.479 173.3 1e-6" fill="none" stroke-dasharray="1.59, 1.59" stroke-width=".265"/><rect x="67.469" y="9.9271" width="22.49" height="6.6146" fill="#fff6d5" stroke-width=".26458"/><rect x="112.45" y="9.927" width="22.49" height="6.6146" fill="#fff6d5" stroke-width=".26458"/></g><text x="6.614583" y="37.708332" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="6.614583" y="37.708332" stroke-width=".26458">active clusters</tspan></text><rect x="37.042" y="29.771" width="145.52" height="26.458" ry="1.3229" fill="none" stroke="#999" stroke-width=".5"/><path d="m121.71 61.521 10.583 1e-5" fill="#00f" marker-end="url(#marker1826-2-4-7-1-7)" stroke="#00f" stroke-width=".265"/><path d="m121.71 66.813h10.583" fill="#f00" marker-end="url(#marker11771-4-9)" stroke="#ff2a2a" stroke-width=".265"/><g stroke-width=".26458"><text x="134.93752" y="62.843967" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="134.93752" y="62.843967" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">write</tspan></text><text x="134.93752" y="68.135635" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="134.93752" y="68.135635" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocate and copy cluster</tspan></text><rect x="121.71" y="70.781" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-dasharray="0.52916663, 0.52916663"/><text x="134.93752" y="73.427292" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="134.93752" y="73.427292" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">unallocated cluster before write</tspan></text></g><rect x="121.71" y="76.073" width="10.583" height="2.6458" fill="none" stroke="#000" stroke-width=".265"/><text x="134.93752" y="78.718956" fill="#000000" font-family="sans-serif" font-size="3.5278px" letter-spacing="0px" stroke-width=".26458" word-spacing="0px" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;line-height:1.25" xml:space="preserve"><tspan x="134.93752" y="78.718956" font-family="sans-serif" font-size="2.8222px" stroke-width=".26458" style="font-feature-settings:normal;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">allocated cluster</tspan></text><rect x="157.43" y="32.417" width="22.49" height="6.6146" fill="none" stroke="#000" stroke-dasharray="0.52916664, 0.52916664" stroke-width=".26458"/><path d="m72.76 46.969 7e-6 -7.9375" fill="#f00" marker-end="url(#marker11771-4-9-6)" stroke="#ff2a2a" stroke-width=".265"/></g><path d="m79.375 11.906v15.875" fill="#00f" marker-end="url(#marker1826-2-4-7-1-7-4)" stroke="#00f" stroke-width=".265"/><path d="m119.06 11.906v15.875" fill="#00f" marker-end="url(#marker1826-2-4-7-1-7-4-1)" stroke="#00f" stroke-width=".265"/></svg>
diff --git a/doc/img/qemu_vhost_data_flow.svg b/doc/img/qemu_vhost_data_flow.svg
new file mode 100644
index 000000000..96b4673e1
--- /dev/null
+++ b/doc/img/qemu_vhost_data_flow.svg
@@ -0,0 +1,2 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<svg version="1.1" viewBox="0 0 187.85 104.34" xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><defs><marker id="a" style="overflow:visible" orient="auto"><path transform="matrix(1.1,0,0,1.1,1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="b" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="j" style="overflow:visible" orient="auto"><path transform="matrix(1.1,0,0,1.1,1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="l" style="overflow:visible" orient="auto"><path transform="matrix(1.1,0,0,1.1,1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="c" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="d" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="e" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="f" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="g" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="h" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="i" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker><marker id="k" style="overflow:visible" orient="auto"><path transform="matrix(-1.1,0,0,-1.1,-1.1,0)" d="m8.7186 4.0337-10.926-4.0177 10.926-4.0177c-1.7455 2.3721-1.7354 5.6175-6e-7 8.0354z" style="fill-rule:evenodd;fill:#000000;stroke-linejoin:round;stroke-width:.625;stroke:#000000"/></marker></defs><metadata><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/><dc:title/><dc:creator><cc:Agent><dc:title>Tomasz Kulasek</dc:title></cc:Agent></dc:creator></cc:Work></rdf:RDF></metadata><g transform="translate(2.5133 -10.794)"><rect x="-2.5133" y="10.794" width="187.85" height="104.34" style="fill:#fffffe"/></g><g transform="translate(-2.6458 -133.04)"><rect x="10.583" y="135.6" width="79.375" height="74.083" ry="2.6458" style="fill:#d5e5ff;stroke-width:.5;stroke:#000000"/><rect x="63.5" y="199.1" width="21.167" height="5.2917" style="fill:none;stroke-dasharray:1.05833327, 1.05833327;stroke-width:.26458;stroke:#000000"/><rect x="21.167" y="152.8" width="58.208" height="30.427" ry="2.6458" style="fill:none;stroke-width:.26458;stroke:#000000"/><path d="m26.458 191.17v-7.9375" style="fill:none;marker-end:url(#h);stroke-dasharray:1.05999995, 1.05999995;stroke-width:.265;stroke:#000000"/><path d="m34.396 183.23v7.9375" style="fill:none;marker-end:url(#i);stroke-dasharray:1.05999995, 1.05999995;stroke-width:.265;stroke:#000000"/><rect x="63.5" y="218.95" width="15.875" height="15.875" ry="2.6458" style="fill:#ffd5e5;stroke-width:.5;stroke:#000000"/><path d="m71.438 204.4v14.552" style="fill:none;marker-end:url(#g);stroke-dasharray:1.5874999, 1.5874999;stroke-width:.26458;stroke:#000000"/><rect x="15.875" y="143.54" width="68.792" height="39.687" ry="2.6458" style="fill:none;stroke-width:.26458;stroke:#000000"/><path d="m63.5 226.89h-58.208l-1e-7-62.177 10.583-1e-5" style="fill:none;marker-end:url(#f);stroke-dasharray:1.58999992, 1.58999992;stroke-width:.265;stroke:#000000"/><g transform="translate(-.13251 -.1325)"><rect x="90.091" y="135.74" width="97.896" height="52.917" ry="2.6458" style="fill:#fff6d5;stroke-width:.5;stroke:#000000"/><g><g transform="translate(-10.451 .1325)"><rect x="132.29" y="152.8" width="60.854" height="31.75" ry="2.6458" style="fill:none;stroke-width:.265;stroke:#000000"/><text x="150.91241" y="158.04379" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;text-align:center;text-anchor:middle;word-spacing:0px" xml:space="preserve"><tspan x="150.91241" y="158.04379">Vhost-SCSI device</tspan></text></g><g transform="translate(-10.451 -2.5133)"><rect x="137.58" y="164.71" width="50.271" height="15.875" ry="2.6458" style="fill:none;stroke-opacity:.99034;stroke-width:.265;stroke:#000000"/><text x="139.99663" y="171.41422" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="139.99663" y="171.41422" style="font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">SPDK bdev(s)</tspan><tspan x="139.99663" y="175.82394" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal">(NVMe, NVMf, Ceph RBD, PMEM)</tspan></text></g></g></g><text x="92.37162" y="140.93028" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="92.37162" y="140.93028" style="font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">SPDK vhost</tspan></text><text x="13.482382" y="140.44109" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="13.482382" y="140.44109" style="font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">QEMU</tspan></text><g transform="translate(2.5609e-6 -5.2917)"><rect x="15.875" y="196.46" width="29.104" height="13.229" style="fill:none;stroke-width:.26458;stroke:#000000"/><text x="16.636366" y="201.47922" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="16.636366" y="201.47922" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Virtio-SCSI device</tspan></text></g><g transform="translate(-5.0685e-6 -5.2917)"><rect x="44.979" y="196.46" width="39.688" height="13.229" ry="0" style="fill:none;stroke-width:.26458;stroke:#000000"/><text x="46.195286" y="201.31316" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="46.195286" y="201.31316" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Vhost-user driver (master)</tspan></text></g><g transform="translate(0 6.6146)"><g><rect x="54.24" y="154.12" width="55.562" height="17.198" ry="2.6458" style="fill:#e3f4d7;stroke-dasharray:0.52999997, 0.52999997;stroke-width:.265;stroke:#000000"/><text x="64.25103" y="157.5067" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="64.25103" y="157.5067" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Shared hugepage memory</tspan></text></g><g><g><rect x="58.208" y="159.42" width="47.625" height="5.2917" ry="5.0849e-6" style="fill:#c3e8aa;stroke-width:.265;stroke:#000000"/><text x="76.179329" y="162.79837" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="76.179329" y="162.79837" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Virtqueues</tspan></text></g><g><rect x="58.208" y="164.71" width="47.625" height="5.2917" ry="1.5259e-5" style="fill:#c3e8aa;stroke-width:.265;stroke:#000000"/><text x="76.452179" y="168.17548" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="76.452179" y="168.17548" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">I/O buffers</tspan></text></g></g></g><path d="m127 173.97-21.167 1e-5" style="fill:none;marker-end:url(#c);marker-start:url(#l);stroke-dasharray:1.05833327, 1.05833327;stroke-width:.26458;stroke:#000000"/><path d="m106.28 168.61 15.433.0673" style="fill:none;marker-end:url(#d);stroke-dasharray:1.05833327, 1.05833327;stroke-width:.26458;stroke:#000000"/><text x="110.86868" y="166.85257" style="fill:#000000;font-family:sans-serif;font-size:10.583px;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="110.86868" y="166.85257" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">polling</tspan></text><text x="112.17093" y="173.11574" style="fill:#000000;font-family:sans-serif;font-size:10.583px;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="112.17093" y="173.11574" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">DMA</tspan></text><text x="67.980347" y="228.13426" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="67.980347" y="228.13426" style="stroke-width:.26458">KVM</tspan></text><text x="69.351151" y="202.76837" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="69.351151" y="202.76837" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">callfd</tspan></text><text x="106.9275" y="200.63379" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="106.9275" y="200.63379" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">eventfd interrupt</tspan></text><path d="m166.69 184.55v17.198c-21.167 0-60.854 1e-5-82.021 1e-5" style="fill:none;marker-end:url(#e);stroke-dasharray:1.58999992, 1.58999992;stroke-width:.265;stroke:#000000"/><text x="72.494453" y="214.47757" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="72.494453" y="214.47757" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">irqfd</tspan></text><text x="23.784939" y="158.1282" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="23.784939" y="158.1282">Virtio-SCSI PCI</tspan><tspan x="23.784939" y="162.53793">driver</tspan></text><path d="m54.24 171.32h-10.583" style="fill:none;marker-end:url(#k);marker-start:url(#j);stroke-dasharray:0.79499996, 0.79499996;stroke-width:.265;stroke:#000000"/><text x="18.493273" y="148.83333" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="18.493273" y="148.83333" style="font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">VM</tspan></text><rect x="127" y="179.26" width="30.427" height="5.2917" style="fill:none;stroke-dasharray:1.05833328, 1.05833328;stroke-width:.26458;stroke:#000000"/><text x="128.16721" y="182.72755" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="128.16721" y="182.72755" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Unix domain socket</tspan></text><text x="104.54487" y="194.10464" style="fill:#000000;font-family:sans-serif;font-feature-settings:normal;font-size:3.5278px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;letter-spacing:0px;line-height:1.25;stroke-width:.26458;word-spacing:0px" xml:space="preserve"><tspan x="104.54487" y="194.10464" style="font-family:sans-serif;font-feature-settings:normal;font-size:2.8222px;font-variant-caps:normal;font-variant-ligatures:normal;font-variant-numeric:normal;stroke-width:.26458">Vhost-user messages</tspan></text><path d="m142.88 184.55v10.583h-58.208" style="fill:none;marker-end:url(#b);marker-start:url(#a);stroke-dasharray:1.58999992, 1.58999992;stroke-width:.265;stroke:#000000"/></g></svg>
diff --git a/doc/index.md b/doc/index.md
index 61024f2e3..d7a5d6c35 100644
--- a/doc/index.md
+++ b/doc/index.md
@@ -1,62 +1,31 @@
 # Storage Performance Development Kit {#index}
 
-# Introduction {#intro}
+# Introduction
+@copydoc intro
 
-- @ref about
-- @ref getting_started
-- @ref vagrant
-- @ref changelog
-- [Source Code (GitHub)](https://github.com/spdk/spdk/)
+# Concepts
+@copydoc concepts
 
-# Concepts {#concepts}
+# User Guides
+@copydoc user_guides
 
-- @ref userspace
-- @ref memory
-- @ref concurrency
-- @ref ssd_internals
-- @ref porting
+# Programmer Guides
+@copydoc prog_guides
 
-# User Guides {#user_guides}
+# General Information
+@copydoc general
 
-- @ref iscsi
-- @ref nvmf
-- @ref vhost
-- @ref bdev
-- @ref blobfs
-- @ref jsonrpc
+# Miscellaneous
+@copydoc misc
 
-# Programmer Guides {#prog_guides}
+# Modules
+@copydoc modules
 
-- @ref blob
+# Tools
+@copydoc tools
 
-# General Information {#general}
+# Experimental Tools
+@copydoc experimental_tools
 
-- @ref bdev_pg
-- @ref bdev_module
-- @ref directory_structure
-- [Public API header files](files.html)
-- @ref nvmf_tgt_pg
-- @ref event
-- @ref blob
-
-# Miscellaneous {#misc}
-
-- @ref peer_2_peer
-
-# Modules {#modules}
-
-- @ref nvme
-- @ref ioat
-- @ref virtio
-
-# Tools {#tools}
-
-- @ref nvme-cli
-
-# Experimental Tools {#experimental_tools}
-
-- @ref spdkcli
-
-# Performance Reports {#performancereports}
-
-- [SPDK 17.07 vhost-scsi Performance Report](https://ci.spdk.io/download/performance-reports/SPDK17_07_vhost_scsi_performance_report.pdf)
+# Performance Reports
+@copydoc performance_reports
diff --git a/doc/intro.md b/doc/intro.md
new file mode 100644
index 000000000..ebae8d454
--- /dev/null
+++ b/doc/intro.md
@@ -0,0 +1,7 @@
+# Introduction {#intro}
+
+- @subpage about
+- @subpage getting_started
+- @subpage vagrant
+- @subpage changelog
+- [Source Code (GitHub)](https://github.com/spdk/spdk)
diff --git a/doc/iscsi.md b/doc/iscsi.md
index 0ddfff5d3..6816eb62c 100644
--- a/doc/iscsi.md
+++ b/doc/iscsi.md
@@ -52,7 +52,7 @@ ReactorMask 0xF000000
 
 ## Configuring a LUN in the iSCSI Target {#iscsi_lun}
 
-Each LUN in an iSCSI target node is associated with an SPDK block device.  See @ref bdev_getting_started
+Each LUN in an iSCSI target node is associated with an SPDK block device.  See @ref bdev
 for details on configuring SPDK block devices.  The block device to LUN mappings are specified in the
 configuration file as:
 
diff --git a/doc/jsonrpc.md b/doc/jsonrpc.md
index cc85d6166..5d06a6577 100644
--- a/doc/jsonrpc.md
+++ b/doc/jsonrpc.md
@@ -5,6 +5,55 @@
 SPDK implements a [JSON-RPC 2.0](http://www.jsonrpc.org/specification) server
 to allow external management tools to dynamically configure SPDK components.
 
+## Parameters
+
+Most of the commands can take parameters. If present, parameter is validated against its domain. If this check fail
+whole command will fail with response error message [Invalid params](@ref jsonrpc_error_message).
+
+### Required parameters
+
+These parameters are mandatory. If any required parameter is missing RPC command will fail with proper error response.
+
+### Optional parameters
+
+Those parameters might be omitted. If an optional parameter is present it must be valid otherwise command will fail
+proper error response.
+
+## Error response message {#jsonrpc_error_message}
+
+Each error response will contain proper message. As much as possible the message should indicate what went wrong during
+command processing.
+
+There is ongoing effort to customize this messages but some RPC methods just return "Invalid parameters" as message body
+for any kind of error.
+
+Code   | Description
+------ | -----------
+-1     | Invalid state - given method exists but it is not callable in [current runtime state](@ref rpc_start_subsystem_init)
+-32600 | Invalid request - not compliant with JSON-RPC 2.0 Specification
+-32601 | Method not found
+-32602 | @ref jsonrpc_invalid_params
+-32603 | Internal error for e.g.: errors like out of memory
+-32700 | @ref jsonrpc_parser_error
+
+### Parser error {#jsonrpc_parser_error}
+
+Encountered some error during parsing request like:
+
+- the JSON object is malformed
+- parameter is too long
+- request is too long
+
+### Invalid params {#jsonrpc_invalid_params}
+
+This type of error is most common one. It mean that there is an error while processing the request like:
+
+- Parameters decoding in RPC method handler failed because required parameter is missing.
+- Unknown parameter present encountered.
+- Parameter type doesn't match expected type e.g.: given number when expected a string.
+- Parameter domain check failed.
+- Request is valid but some other error occurred during processing request. If possible message explains the error reason nature.
+
 # App Framework {#jsonrpc_components_app}
 
 ## kill_instance {#rpc_kill_instance}
@@ -40,62 +89,2501 @@ Example response:
 }
 ~~~
 
-## context_switch_monitor {#rpc_context_switch_monitor}
+## context_switch_monitor {#rpc_context_switch_monitor}
+
+Query, enable, or disable the context switch monitoring functionality.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+enabled                 | Optional | boolean     | Enable (`true`) or disable (`false`) monitoring (omit this parameter to query the current state)
+
+### Response
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+enabled                 | boolean     | The current state of context switch monitoring
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "context_switch_monitor",
+  "params": {
+    "enabled": false
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": {
+    "enabled": false
+  }
+}
+~~~
+
+## start_subsystem_init {#rpc_start_subsystem_init}
+
+Start initialization of SPDK subsystems when it is deferred by starting SPDK application with option -w.
+During its deferral some RPCs can be used to set global parameters for SPDK subsystems.
+This RPC can be called only once.
+
+### Parameters
+
+This method has no parameters.
+
+### Response
+
+Completion status of SPDK subsystem initialization is returned as a boolean.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "start_subsystem_init"
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## get_rpc_methods {#rpc_get_rpc_methods}
+
+Get an array of supported RPC methods.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+current                 | Optional | boolean     | Get an array of RPC methods only callable in the current state.
+
+### Response
+
+The response is an array of supported RPC methods.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_rpc_methods"
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    "start_subsystem_init",
+    "get_rpc_methods",
+    "get_scsi_devices",
+    "get_interfaces",
+    "delete_ip_address",
+    "add_ip_address",
+    "get_nbd_disks",
+    "stop_nbd_disk",
+    "start_nbd_disk",
+    "get_trace_flags",
+    "clear_trace_flag",
+    "set_trace_flag",
+    "get_log_level",
+    "set_log_level",
+    "get_log_print_level",
+    "set_log_print_level",
+    "get_iscsi_global_params",
+    "target_node_add_lun",
+    "get_iscsi_connections",
+    "delete_portal_group",
+    "add_portal_group",
+    "get_portal_groups",
+    "delete_target_node",
+    "delete_pg_ig_maps",
+    "add_pg_ig_maps",
+    "construct_target_node",
+    "get_target_nodes",
+    "delete_initiator_group",
+    "delete_initiators_from_initiator_group",
+    "add_initiators_to_initiator_group",
+    "add_initiator_group",
+    "get_initiator_groups",
+    "set_iscsi_options",
+    "set_bdev_options",
+    "set_bdev_qos_limit_iops",
+    "delete_bdev",
+    "get_bdevs_config",
+    "get_bdevs",
+    "get_bdevs_iostat",
+    "get_subsystem_config",
+    "get_subsystems",
+    "context_switch_monitor",
+    "kill_instance",
+    "scan_ioat_copy_engine",
+    "construct_virtio_dev",
+    "construct_virtio_pci_blk_bdev",
+    "construct_virtio_user_blk_bdev",
+    "get_virtio_scsi_devs",
+    "remove_virtio_scsi_bdev",
+    "construct_virtio_pci_scsi_bdev",
+    "construct_virtio_user_scsi_bdev",
+    "delete_aio_bdev",
+    "construct_aio_bdev",
+    "destruct_split_vbdev",
+    "construct_split_vbdev",
+    "bdev_inject_error",
+    "delete_error_bdev",
+    "construct_error_bdev",
+    "construct_passthru_bdev",
+    "apply_nvme_firmware",
+    "construct_nvme_bdev",
+    "construct_null_bdev",
+    "delete_malloc_bdev",
+    "construct_malloc_bdev",
+    "get_lvol_stores",
+    "destroy_lvol_bdev",
+    "resize_lvol_bdev",
+    "decouple_parent_lvol_bdev",
+    "inflate_lvol_bdev",
+    "rename_lvol_bdev",
+    "clone_lvol_bdev",
+    "snapshot_lvol_bdev",
+    "construct_lvol_bdev",
+    "destroy_lvol_store",
+    "rename_lvol_store",
+    "construct_lvol_store"
+  ]
+}
+~~~
+
+## get_subsystems {#rpc_get_subsystems}
+
+Get an array of name and dependency relationship of SPDK subsystems in initialization order.
+
+### Parameters
+
+None
+
+### Response
+
+The response is an array of name and dependency relationship of SPDK subsystems in initialization order.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_subsystems"
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "subsystem": "copy",
+      "depends_on": []
+    },
+    {
+      "subsystem": "interface",
+      "depends_on": []
+    },
+    {
+      "subsystem": "net_framework",
+      "depends_on": [
+        "interface"
+      ]
+    },
+    {
+      "subsystem": "bdev",
+      "depends_on": [
+        "copy"
+      ]
+    },
+    {
+      "subsystem": "nbd",
+      "depends_on": [
+        "bdev"
+      ]
+    },
+    {
+      "subsystem": "nvmf",
+      "depends_on": [
+        "bdev"
+      ]
+    },
+    {
+      "subsystem": "scsi",
+      "depends_on": [
+        "bdev"
+      ]
+    },
+    {
+      "subsystem": "vhost",
+      "depends_on": [
+        "scsi"
+      ]
+    },
+    {
+      "subsystem": "iscsi",
+      "depends_on": [
+        "scsi"
+      ]
+    }
+  ]
+}
+~~~
+
+## get_subsystem_config {#rpc_get_subsystem_config}
+
+Get current configuration of the specified SPDK subsystem
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | SPDK subsystem name
+
+### Response
+
+The response is current configuration of the specfied SPDK subsystem.
+Null is returned if it is not retrievable by the get_subsystem_config method and empty array is returned if it is empty.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_subsystem_config",
+  "params": {
+    "name": "bdev"
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "params": {
+        "base_bdev": "Malloc2",
+        "split_size_mb": 0,
+        "split_count": 2
+      },
+      "method": "construct_split_vbdev"
+    },
+    {
+      "params": {
+        "trtype": "PCIe",
+        "name": "Nvme1",
+        "traddr": "0000:01:00.0"
+      },
+      "method": "construct_nvme_bdev"
+    },
+    {
+      "params": {
+        "trtype": "PCIe",
+        "name": "Nvme2",
+        "traddr": "0000:03:00.0"
+      },
+      "method": "construct_nvme_bdev"
+    },
+    {
+      "params": {
+        "block_size": 512,
+        "num_blocks": 131072,
+        "name": "Malloc0",
+        "uuid": "913fc008-79a7-447f-b2c4-c73543638c31"
+      },
+      "method": "construct_malloc_bdev"
+    },
+    {
+      "params": {
+        "block_size": 512,
+        "num_blocks": 131072,
+        "name": "Malloc1",
+        "uuid": "dd5b8f6e-b67a-4506-b606-7fff5a859920"
+      },
+      "method": "construct_malloc_bdev"
+    }
+  ]
+}
+~~~
+
+# Block Device Abstraction Layer {#jsonrpc_components_bdev}
+
+## set_bdev_options {#rpc_set_bdev_options}
+
+Set global parameters for the block device (bdev) subsystem.  This RPC may only be called
+before SPDK subsystems have been initialized.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+bdev_io_pool_size       | Optional | number      | Number of spdk_bdev_io structures in shared buffer pool
+bdev_io_cache_size      | Optional | number      | Maximum number of spdk_bdev_io structures cached per thread
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "set_bdev_options",
+  "params": {
+    "bdev_io_pool_size": 65536,
+    "bdev_io_cache_size": 256
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## get_bdevs {#rpc_get_bdevs}
+
+Get information about block devices (bdevs).
+
+### Parameters
+
+The user may specify no parameters in order to list all block devices, or a block device may be
+specified by name.
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Optional | string      | Block device name
+
+### Response
+
+The response is an array of objects containing information about the requested block devices.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_bdevs",
+  "params": {
+    "name": "Malloc0"
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "name": "Malloc0",
+      "product_name": "Malloc disk",
+      "block_size": 512,
+      "num_blocks": 20480,
+      "claimed": false,
+      "supported_io_types": {
+        "read": true,
+        "write": true,
+        "unmap": true,
+        "write_zeroes": true,
+        "flush": true,
+        "reset": true,
+        "nvme_admin": false,
+        "nvme_io": false
+      },
+      "driver_specific": {}
+    }
+  ]
+}
+~~~
+
+## get_bdevs_iostat {#rpc_get_bdevs_iostat}
+
+Get I/O statistics of block devices (bdevs).
+
+### Parameters
+
+The user may specify no parameters in order to list all block devices, or a block device may be
+specified by name.
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Optional | string      | Block device name
+
+### Response
+
+The response is an array of objects containing I/O statistics of the requested block devices.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_bdevs_iostat",
+  "params": {
+    "name": "Nvme0n1"
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "name": "Nvme0n1",
+      "bytes_read": 34051522560,
+      "num_read_ops": 8312910,
+      "bytes_written": 0,
+      "num_write_ops": 0
+    }
+  ]
+}
+~~~
+
+## delete_bdev {#rpc_delete_bdev}
+
+Unregister a block device.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Block device name
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "delete_bdev",
+  "params": {
+    "name": "Malloc0"
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## set_bdev_qos_limit_iops {#rpc_set_bdev_qos_limit_iops}
+
+Set an IOPS-based quality of service rate limit on a bdev.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Block device name
+ios_per_sec             | Required | number      | Number of I/Os per second to allow. 0 means unlimited.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "set_bdev_qos_limit_iops",
+  "params": {
+    "name": "Malloc0"
+    "ios_per_sec": 20000
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_malloc_bdev {#rpc_construct_malloc_bdev}
+
+Construct @ref bdev_config_malloc
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Optional | string      | Bdev name to use
+block_size              | Required | number      | Block size in bytes -must be multiple of 512
+num_blocks              | Required | number      | Number of blocks
+uuid                    | Optional | string      | UUID of new bdev
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "block_size": 4096,
+    "num_blocks": 16384,
+    "name": "Malloc0",
+    "uuid": "2b6601ba-eada-44fb-9a83-a20eb9eb9e90"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_malloc_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Malloc0"
+}
+~~~
+
+## delete_malloc_bdev {#rpc_delete_malloc_bdev}
+
+Delete @ref bdev_config_malloc
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Malloc0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_malloc_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_null_bdev {#rpc_construct_null_bdev}
+
+Construct @ref bdev_config_null
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Optional | string      | Bdev name to use
+block_size              | Required | number      | Block size in bytes
+num_blocks              | Required | number      | Number of blocks
+uuid                    | Optional | string      | UUID of new bdev
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "block_size": 4096,
+    "num_blocks": 16384,
+    "name": "Null0",
+    "uuid": "2b6601ba-eada-44fb-9a83-a20eb9eb9e90"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_null_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Null0"
+}
+~~~
+
+## delete_null_bdev {#rpc_delete_null_bdev}
+
+Delete @ref bdev_config_null.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Null0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_null_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_aio_bdev {#rpc_construct_aio_bdev}
+
+Construct @ref bdev_config_aio.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name to use
+filename                | Required | number      | Path to device or file
+block_size              | Optional | number      | Block size in bytes
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "block_size": 4096,
+    "name": "Aio0",
+    "filename": "/tmp/aio_bdev_file"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_aio_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Aio0"
+}
+~~~
+
+## delete_aio_bdev {#rpc_delete_aio_bdev}
+
+Delete @ref bdev_config_aio.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Aio0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_aio_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_nvme_bdev {#rpc_construct_nvme_bdev}
+
+Construct @ref bdev_config_nvme
+
+### Result
+
+Array of names of newly created bdevs.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+trtype                  | Required | string      | NVMe-oF target trtype: rdma or pcie
+traddr                  | Required | string      | NVMe-oF target address: ip or BDF
+adrfam                  | Optional | string      | NVMe-oF target adrfam: ipv4, ipv6, ib, fc, intra_host
+trsvcid                 | Optional | string      | NVMe-oF target trsvcid: port number
+subnqn                  | Optional | string      | NVMe-oF target subnqn
+hostnqn                 | Optional | string      | NVMe-oF target hostnqn
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "trtype": "pcie",
+    "name": "Nvme0",
+    "traddr": "0000:0a:00.0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_nvme_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    "Nvme0n1"
+  ]
+}
+~~~
+
+## construct_rbd_bdev {#rpc_construct_rbd_bdev}
+
+Construct @ref bdev_config_rbd bdev
+
+This method is available only if SPDK was build with Ceph RBD support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Optional | string      | Bdev name
+pool_name               | Required | string      | Pool name
+rbd_name                | Required | string      | Image name
+block_size              | Required | number      | Block size
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "pool_name": "rbd",
+    "rbd_name": "foo",
+    "block_size": 4096
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_rbd_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+response:
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Ceph0"
+}
+~~~
+
+## delete_rbd_bdev {#rpc_delete_rbd_bdev}
+
+Delete @ref bdev_config_rbd bdev
+
+This method is available only if SPDK was build with Ceph RBD support.
+
+### Result
+
+`true` if bdev with provided name was deleted or `false` otherwise.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Rbd0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_rbd_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_error_bdev {#rpc_construct_error_bdev}
+
+Construct error bdev.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+base_name               | Required | string      | Base bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "base_name": "Malloc0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_error_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## delete_error_bdev {#rpc_delete_error_bdev}
+
+Delete error bdev
+
+### Result
+
+`true` if bdev with provided name was deleted or `false` otherwise.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Error bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "EE_Malloc0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_error_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_iscsi_bdev {#rpc_construct_iscsi_bdev}
+
+Connect to iSCSI target and create bdev backed by this connection.
+
+This method is available only if SPDK was build with iSCSI initiator support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+initiator_iqn           | Required | string      | IQN name used during connection
+url                     | Required | string      | iSCSI resource URI
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "url": "iscsi://127.0.0.1/iqn.2016-06.io.spdk:disk1/0",
+    "initiator_iqn": "iqn.2016-06.io.spdk:init",
+    "name": "iSCSI0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_iscsi_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "iSCSI0"
+}
+~~~
+
+## delete_iscsi_bdev {#rpc_delete_iscsi_bdev}
+
+Delete iSCSI bdev and terminate connection to target.
+
+This method is available only if SPDK was built with iSCSI initiator support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "iSCSI0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_iscsi_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+
+## create_pmem_pool {#rpc_create_pmem_pool}
+
+Create a @ref bdev_config_pmem blk pool file. It is equivalent of following `pmempool create` command:
+
+~~~
+pmempool create -s $((num_blocks * block_size)) blk $block_size $pmem_file
+~~~
+
+This method is available only if SPDK was built with PMDK support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+pmem_file               | Required | string      | Path to new pmem file
+num_blocks              | Required | number      | Number of blocks
+block_size              | Required | number      | Size of each block in bytes
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "block_size": 512,
+    "num_blocks": 131072,
+    "pmem_file": "/tmp/pmem_file"
+  },
+  "jsonrpc": "2.0",
+  "method": "create_pmem_pool",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## pmem_pool_info {#rpc_pmem_pool_info}
+
+Retrive basic information about PMDK memory pool.
+
+This method is available only if SPDK was built with PMDK support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+pmem_file               | Required | string      | Path to existing pmem file
+
+### Result
+
+Array of objects describing memory pool:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+num_blocks              | number      | Number of blocks
+block_size              | number      | Size of each block in bytes
+
+### Example
+
+Example request:
+
+~~~
+request:
+{
+  "params": {
+    "pmem_file": "/tmp/pmem_file"
+  },
+  "jsonrpc": "2.0",
+  "method": "pmem_pool_info",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "block_size": 512,
+      "num_blocks": 129728
+    }
+  ]
+}
+~~~
+
+## delete_pmem_pool {#rpc_delete_pmem_pool}
+
+Delete pmem pool by removing file `pmem_file`. This method will fail if `pmem_file` is not a
+valid pmem pool file.
+
+This method is available only if SPDK was built with PMDK support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+pmem_file               | Required | string      | Path to new pmem file
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "pmem_file": "/tmp/pmem_file"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_pmem_pool",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_pmem_bdev {#rpc_construct_pmem_bdev}
+
+Construct @ref bdev_config_pmem bdev.
+
+This method is available only if SPDK was built with PMDK support.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+pmem_file               | Required | string      | Path to existing pmem blk pool file
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "pmem_file": "/tmp/pmem_file",
+    "name": "Pmem0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_pmem_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Pmem0"
+}
+~~~
+
+## delete_pmem_bdev {#rpc_delete_pmem_bdev}
+
+Delete @ref bdev_config_pmem bdev. This call will not remove backing pool files.
+
+This method is available only if SPDK was built with PMDK support.
+
+### Result
+
+`true` if bdev with provided name was deleted or `false` otherwise.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Pmem0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_pmem_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_passthru_bdev {#rpc_construct_passthru_bdev}
+
+Create passthru bdev. This bdev type redirects all IO to it's base bdev. It has no other purpose than being an example
+and a starting point in development of new bdev type.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+passthru_bdev_name      | Required | string      | Bdev name
+base_bdev_name          | Required | string      | Base bdev name
+
+### Result
+
+Name of newly created bdev.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "base_bdev_name": "Malloc0",
+    "passthru_bdev_name": "Passsthru0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_passthru_bdev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": "Passsthru0"
+}
+~~~
+
+## delete_passthru_bdev {#rpc_delete_passthru_bdev}
+
+Delete passthru bdev.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "Passsthru0"
+  },
+  "jsonrpc": "2.0",
+  "method": "delete_passthru_bdev",
+  "id": 1
+}
+
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_virtio_dev {#rpc_construct_virtio_dev}
+
+Create new initiator @ref bdev_config_virtio_scsi or @ref bdev_config_virtio_blk and expose all found bdevs.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+name                    | Required | string      | Virtio SCSI base bdev name or Virtio Blk bdev name
+trtype                  | Required | string      | Virtio target trtype: pci or user
+traddr                  | Required | string      | target address: BDF or UNIX socket file path
+dev_type                | Required | string      | Virtio device type: blk or scsi
+vq_count                | Optional | number      | Number of queues this controller will utilize (default: 1)
+vq_size                 | Optional | number      | Size of each queue. Must be power of 2. (default: 512)
+
+In case of Virtio SCSI the `name` parameter will be base name for new created bdevs. For Virtio Blk `name` will be the
+name of created bdev.
+
+`vq_count` and `vq_size` parameters are valid only if `trtype` is `user`.
+
+### Result
+
+Array of names of newly created bdevs.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "name": "VirtioScsi0",
+    "trtype": "user",
+    "vq_size": 128,
+    "dev_type": "scsi",
+    "traddr": "/tmp/VhostScsi0",
+    "vq_count": 4
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_virtio_dev",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": ["VirtioScsi0t2", "VirtioScsi0t4"]
+}
+~~~
+
+## construct_virtio_user_scsi_bdev {#rpc_construct_virtio_user_scsi_bdev}
+
+This is legacy RPC method. It is equivalent of @ref rpc_construct_virtio_dev with `trtype` set to `user` and `dev_type` set to `scsi`.
+
+Because it will be deprecated soon it is intentionally undocumented.
+
+
+## construct_virtio_pci_scsi_bdev {#rpc_construct_virtio_pci_scsi_bdev}
+
+This is legacy RPC method. It is equivalent of @ref rpc_construct_virtio_dev with `trtype` set to `pci` and `dev_type` set to `scsi`.
+
+Because it will be deprecated soon it is intentionally undocumented.
+
+## construct_virtio_user_blk_bdev {#rpc_construct_virtio_user_blk_bdev}
+
+This is legacy RPC method. It is equivalent of @ref rpc_construct_virtio_dev with `trtype` set to `user` and `dev_type` set to `blk`.
+
+Because it will be deprecated soon it is intentionally undocumented.
+
+
+## construct_virtio_pci_blk_bdev {#rpc_construct_virtio_pci_blk_bdev}
+
+This is legacy RPC method. It is equivalent of @ref rpc_construct_virtio_dev with `trtype` set to `pci` and `dev_type` set to `blk`.
+
+Because it will be deprecated soon it is intentionally undocumented.
+
+## get_virtio_scsi_devs {#rpc_get_virtio_scsi_devs}
+
+Show information about all available Virtio SCSI devices.
+
+### Parameters
+
+This method has no parameters.
+
+### Result
+
+Array of Virtio SCSI information objects.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "method": "get_virtio_scsi_devs",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "name": "VirtioScsi0",
+      "virtio": {
+          "vq_size": 128,
+          "vq_count": 4,
+          "type": "user",
+          "socket": "/tmp/VhostScsi0"
+      }
+    }
+  ]
+}
+~~~
+
+# NVMe-oF Target {#jsonrpc_components_nvmf_tgt}
+
+## get_nvmf_subsystems method {#rpc_get_nvmf_subsystems}
+
+### Parameters
+
+This method has no parameters.
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "get_nvmf_subsystems"
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "nqn": "nqn.2014-08.org.nvmexpress.discovery",
+      "subtype": "Discovery"
+      "listen_addresses": [],
+      "hosts": [],
+      "allow_any_host": true
+    },
+    {
+      "nqn": "nqn.2016-06.io.spdk:cnode1",
+      "subtype": "NVMe",
+      "listen_addresses": [
+        {
+          "trtype": "RDMA",
+          "adrfam": "IPv4",
+          "traddr": "192.168.0.123",
+          "trsvcid": "4420"
+        }
+      ],
+      "hosts": [
+        {"nqn": "nqn.2016-06.io.spdk:host1"}
+      ],
+      "allow_any_host": false,
+      "serial_number": "abcdef",
+      "namespaces": [
+        {"nsid": 1, "name": "Malloc2"},
+        {"nsid": 2, "name": "Nvme0n1"}
+      ]
+    }
+  ]
+}
+~~~
+
+## construct_nvmf_subsystem method {#rpc_construct_nvmf_subsystem}
+
+Construct an NVMe over Fabrics target subsystem.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+listen_addresses        | Optional | array       | Array of @ref rpc_construct_nvmf_subsystem_listen_address objects
+hosts                   | Optional | array       | Array of strings containing allowed host NQNs. Default: No hosts allowed.
+allow_any_host          | Optional | boolean     | Allow any host (`true`) or enforce allowed host whitelist (`false`). Default: `false`.
+serial_number           | Required | string      | Serial number of virtual controller
+namespaces              | Optional | array       | Array of @ref rpc_construct_nvmf_subsystem_namespace objects. Default: No namespaces.
+max_namespaces          | Optional | number      | Maximum number of namespaces that can be attached to the subsystem. Default: 0 (Unlimited)
+
+### listen_address {#rpc_construct_nvmf_subsystem_listen_address}
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+trtype                  | Required | string      | Transport type ("RDMA")
+adrfam                  | Required | string      | Address family ("IPv4", "IPv6", "IB", or "FC")
+traddr                  | Required | string      | Transport address
+trsvcid                 | Required | string      | Transport service ID
+
+### namespace {#rpc_construct_nvmf_subsystem_namespace}
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nsid                    | Optional | number      | Namespace ID between 1 and 4294967294, inclusive. Default: Automatically assign NSID.
+bdev_name               | Required | string      | Name of bdev to expose as a namespace.
+nguid                   | Optional | string      | 16-byte namespace globally unique identifier in hexadecimal (e.g. "ABCDEF0123456789ABCDEF0123456789")
+eui64                   | Optional | string      | 8-byte namespace EUI-64 in hexadecimal (e.g. "ABCDEF0123456789")
+uuid                    | Optional | string      | RFC 4122 UUID (e.g. "ceccf520-691e-4b46-9546-34af789907c5")
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "construct_nvmf_subsystem",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "listen_addresses": [
+      {
+        "trtype": "RDMA",
+        "adrfam": "IPv4",
+        "traddr": "192.168.0.123",
+        "trsvcid: "4420"
+      }
+    ],
+    "hosts": [
+      "nqn.2016-06.io.spdk:host1",
+      "nqn.2016-06.io.spdk:host2"
+    ],
+    "allow_any_host": false,
+    "serial_number": "abcdef",
+    "namespaces": [
+      {"nsid": 1, "name": "Malloc2"},
+      {"nsid": 2, "name": "Nvme0n1"}
+    ]
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## delete_nvmf_subsystem method {#rpc_delete_nvmf_subsystem}
+
+Delete an existing NVMe-oF subsystem.
+
+### Parameters
+
+Parameter              | Optional | Type        | Description
+---------------------- | -------- | ----------- | -----------
+nqn                    | Required | string      | Subsystem NQN to delete.
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "delete_nvmf_subsystem",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1"
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## nvmf_subsystem_add_listener  method {#rpc_nvmf_subsystem_add_listener}
+
+Add a new listen address to an NVMe-oF subsystem.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+listen_address          | Required | object      | @ref rpc_construct_nvmf_subsystem_listen_address object
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_add_listener",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "listen_address": {
+      "trtype": "RDMA",
+      "adrfam": "IPv4",
+      "traddr": "192.168.0.123",
+      "trsvcid: "4420"
+    }
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## nvmf_subsystem_add_ns method {#rpc_nvmf_subsystem_add_ns}
+
+Add a namespace to a subsystem. The namespace ID is returned as the result.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+namespace               | Required | object      | @ref rpc_construct_nvmf_subsystem_namespace object
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_add_ns",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "namespace": {
+      "nsid": 3,
+      "bdev_name": "Nvme0n1"
+    }
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": 3
+}
+~~~
+
+## nvmf_subsystem_remove_ns method {#rpc_nvmf_subsystem_remove_ns}
+
+Remove a namespace from a subsystem.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+nsid                    | Required | number      | Namespace ID
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_remove_ns",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "nsid": 1
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## nvmf_subsystem_add_host method {#rpc_nvmf_subsystem_add_host}
+
+Add a host NQN to the whitelist of allowed hosts.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+host                    | Required | string      | Host NQN to add to the list of allowed host NQNs
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_add_host",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "host": "nqn.2016-06.io.spdk:host1"
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## nvmf_subsystem_remove_host method {#rpc_nvmf_subsystem_remove_host}
+
+Remove a host NQN from the whitelist of allowed hosts.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+host                    | Required | string      | Host NQN to remove from the list of allowed host NQNs
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_remove_host",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "host": "nqn.2016-06.io.spdk:host1"
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## nvmf_subsystem_allow_any_host method {#rpc_nvmf_subsystem_allow_any_host}
+
+Configure a subsystem to allow any host to connect or to enforce the host NQN whitelist.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+nqn                     | Required | string      | Subsystem NQN
+allow_any_host          | Required | boolean     | Allow any host (`true`) or enforce allowed host whitelist (`false`).
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "nvmf_subsystem_allow_any_host",
+  "params": {
+    "nqn": "nqn.2016-06.io.spdk:cnode1",
+    "allow_any_host": true
+  }
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## set_nvmf_target_options {#rpc_set_nvmf_target_options}
+
+Set global parameters for the NVMe-oF target.  This RPC may only be called before SPDK subsystems
+have been initialized.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+max_queue_depth         | Optional | number      | Maximum number of outstanding I/Os per queue
+max_qpairs_per_ctrlr    | Optional | number      | Maximum number of SQ and CQ per controller
+in_capsule_data_size    | Optional | number      | Maximum number of in-capsule data size
+max_io_size             | Optional | number      | Maximum I/O size (bytes)
+max_subsystems          | Optional | number      | Maximum number of NVMe-oF subsystems
+io_unit_size            | Optional | number      | I/O unit size (bytes)
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "set_nvmf_target_options",
+  "params": {
+    "in_capsule_data_size": 4096,
+    "io_unit_size": 131072,
+    "max_qpairs_per_ctrlr": 64,
+    "max_queue_depth": 128,
+    "max_io_size": 131072,
+    "max_subsystems": 1024
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## set_nvmf_target_config {#rpc_set_nvmf_target_config}
+
+Set global configuration of NVMe-oF target.  This RPC may only be called before SPDK subsystems
+have been initialized.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+acceptor_poll_rate      | Optional | number      | Polling interval of the acceptor for incoming connections (microseconds)
+
+### Example
+
+Example request:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "method": "set_nvmf_target_config",
+  "params": {
+    "acceptor_poll_rate": 10000
+  }
+}
+~~~
+
+Example response:
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+# Vhost Target {#jsonrpc_components_vhost_tgt}
+
+The following common preconditions need to be met in all target types.
+
+Controller name will be used to create UNIX domain socket. This implies that name concatenated with vhost socket
+directory path needs to be valid UNIX socket name.
+
+@ref cpu_mask parameter is used to choose CPU on which pollers will be launched when new initiator is connecting.
+It must be a subset of application CPU mask. Default value is CPU mask of the application.
+
+## set_vhost_controller_coalescing {#rpc_set_vhost_controller_coalescing}
+
+Controls interrupt coalescing for specific target. Because `delay_base_us` is used to calculate delay in CPU ticks
+there is no hardcoded limit for this parameter. Only limitation is that final delay in CPU ticks might not overflow
+32 bit unsigned integer (which is more than 1s @ 4GHz CPU). In real scenarios `delay_base_us` should be much lower
+than 150us. To disable coalescing set `delay_base_us` to 0.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+delay_base_us           | Required | number      | Base (minimum) coalescing time in microseconds
+iops_threshold          | Required | number      | Coalescing activation level greater than 0 in IO per second
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "iops_threshold": 100000,
+    "ctrlr": "VhostScsi0",
+    "delay_base_us": 80
+  },
+  "jsonrpc": "2.0",
+  "method": "set_vhost_controller_coalescing",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_vhost_scsi_controller {#rpc_construct_vhost_scsi_controller}
+
+Construct vhost SCSI target.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+cpumask                 | Optional | string      | @ref cpu_mask for this controller
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "cpumask": "0x2",
+    "ctrlr": "VhostScsi0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_vhost_scsi_controller",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## add_vhost_scsi_lun {#rpc_add_vhost_scsi_lun}
+
+In vhost target `ctrlr` create SCSI target with ID `scsi_target_num` and add `bdev_name` as LUN 0.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+scsi_target_num         | Required | number      | SCSI target ID between 0 and 7
+bdev_name               | Required | string      | Name of bdev to expose as a LUN 0
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "scsi_target_num": 1,
+    "bdev_name": "Malloc0",
+    "ctrlr": "VhostScsi0"
+  },
+  "jsonrpc": "2.0",
+  "method": "add_vhost_scsi_lun",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+response:
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## remove_vhost_scsi_target {#rpc_remove_vhost_scsi_target}
+
+Remove SCSI target ID `scsi_target_num` from vhost target `scsi_target_num`.
+
+This method will fail if initiator is connected, but doesn't support hot-remove (the `VIRTIO_SCSI_F_HOTPLUG` is not negotiated).
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+scsi_target_num         | Required | number      | SCSI target ID between 0 and 7
+
+### Example
+
+Example request:
+
+~~~
+request:
+{
+  "params": {
+    "scsi_target_num": 1,
+    "ctrlr": "VhostScsi0"
+  },
+  "jsonrpc": "2.0",
+  "method": "remove_vhost_scsi_target",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_vhost_nvme_controller {#rpc_construct_vhost_nvme_controller}
+
+Construct empty vhost NVMe controller.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+io_queues               | Required | number      | Number between 1 and 31 of IO queues for the controller
+cpumask                 | Optional | string      | @ref cpu_mask for this controller
+
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "cpumask": "0x2",
+    "io_queues": 4,
+    "ctrlr": "VhostNvme0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_vhost_nvme_controller",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## add_vhost_nvme_ns {#rpc_add_vhost_nvme_ns}
+
+Add namespace backed by `bdev_name`
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+bdev_name               | Required | string      | Name of bdev to expose as a namespace
+cpumask                 | Optional | string      | @ref cpu_mask for this controller
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "bdev_name": "Malloc0",
+    "ctrlr": "VhostNvme0"
+  },
+  "jsonrpc": "2.0",
+  "method": "add_vhost_nvme_ns",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## construct_vhost_blk_controller {#rpc_construct_vhost_blk_controller}
+
+Construct vhost block controller
+
+If `readonly` is `true` then vhost block target will be created as read only and fail any write requests.
+The `VIRTIO_BLK_F_RO` feature flag will be offered to the initiator.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+ctrlr                   | Required | string      | Controller name
+bdev_name               | Required | string      | Name of bdev to expose block device
+readonly                | Optional | boolean     | If true, this target will be read only (default: false)
+cpumask                 | Optional | string      | @ref cpu_mask for this controller
+
+
+### Example
+
+Example request:
+
+~~~
+{
+  "params": {
+    "dev_name": "Malloc0",
+    "ctrlr": "VhostBlk0"
+  },
+  "jsonrpc": "2.0",
+  "method": "construct_vhost_blk_controller",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": true
+}
+~~~
+
+## get_vhost_controllers {#rpc_get_vhost_controllers}
+
+Display information about all vhost controllers.
+
+### Parameters
+
+This method has no parameters.
+
+### Response {#rpc_get_vhost_controllers_response}
+
+Response is an array of objects describing each controllers. Common fields are:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+ctrlr                   | string      | Controller name
+cpumask                 | string      | @ref cpu_mask of this controller
+delay_base_us           | number      | Base (minimum) coalescing time in microseconds (0 if disabled)
+iops_threshold          | number      | Coalescing activation level
+backend_specific        | object      | Backend specific informations
+
+### Vhost block {#rpc_get_vhost_controllers_blk}
+
+`backend_specific` contains one `block` object  of type:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+bdev                    | string      | Backing bdev name or Null if bdev is hot-removed
+readonly                | boolean     | True if controllers is readonly, false otherwise
+
+### Vhost SCSI {#rpc_get_vhost_controllers_scsi}
+
+`backend_specific` contains `scsi` array of following objects:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+target_name             | string      | Name of this SCSI target
+id                      | number      | Unique SPDK global SCSI target ID
+scsi_dev_num            | number      | SCSI target ID initiator will see when scanning this controller
+luns                    | array       | array of objects describing @ref rpc_get_vhost_controllers_scsi_luns
+
+### Vhost SCSI LUN {#rpc_get_vhost_controllers_scsi_luns}
+
+Object of type:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+id                      | number      | SCSI LUN ID
+bdev_name               | string      | Backing bdev name
+
+### Vhost NVMe {#rpc_get_vhost_controllers_nvme}
+
+`backend_specific` contains `namespaces` array of following objects:
+
+Name                    | Type        | Description
+----------------------- | ----------- | -----------
+nsid                    | number      | Namespace ID
+bdev                    | string      | Backing bdev name
+
+### Example
+
+Example request:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "method": "get_vhost_controllers",
+  "id": 1
+}
+~~~
+
+Example response:
+
+~~~
+{
+  "jsonrpc": "2.0",
+  "id": 1,
+  "result": [
+    {
+      "cpumask": "0x2",
+      "backend_specific": {
+        "block": {
+          "readonly": false,
+          "bdev": "Malloc0"
+        }
+      },
+      "iops_threshold": 60000,
+      "ctrlr": "VhostBlk0",
+      "delay_base_us": 100
+    },
+    {
+      "cpumask": "0x2",
+      "backend_specific": {
+        "scsi": [
+          {
+            "target_name": "Target 2",
+            "luns": [
+              {
+                "id": 0,
+                "bdev_name": "Malloc1"
+              }
+            ],
+            "id": 0,
+            "scsi_dev_num": 2
+          },
+          {
+            "target_name": "Target 5",
+            "luns": [
+              {
+                "id": 0,
+                "bdev_name": "Malloc2"
+              }
+            ],
+            "id": 1,
+            "scsi_dev_num": 5
+          }
+        ]
+      },
+      "iops_threshold": 60000,
+      "ctrlr": "VhostScsi0",
+      "delay_base_us": 0
+    },
+    {
+      "cpumask": "0x2",
+      "backend_specific": {
+        "namespaces": [
+          {
+            "bdev": "Malloc3",
+            "nsid": 1
+          },
+          {
+            "bdev": "Malloc4",
+            "nsid": 2
+          }
+        ]
+      },
+      "iops_threshold": 60000,
+      "ctrlr": "VhostNvme0",
+      "delay_base_us": 0
+    }
+  ]
+}
+~~~
+
+## remove_vhost_controller {#rpc_remove_vhost_controller}
 
-Query, enable, or disable the context switch monitoring functionality.
+Remove vhost target.
+
+This call will fail if there is an initiator connected or there is at least one SCSI target configured in case of
+vhost SCSI target. In the later case please remove all SCSI targets first using @ref rpc_remove_vhost_scsi_target.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-enabled                 | Optional | boolean     | Enable (`true`) or disable (`false`) monitoring (omit this parameter to query the current state)
-
-### Response
-
-The current state of context switch monitoring is returned as a boolean.
+ctrlr                   | Required | string      | Controller name
 
 ### Example
 
 Example request:
+
 ~~~
 {
-  "jsonrpc": "2.0",
-  "id": 1,
-  "method": "context_switch_monitor",
   "params": {
-    "enabled": false
-  }
+    "ctrlr": "VhostNvme0"
+  },
+  "jsonrpc": "2.0",
+  "method": "remove_vhost_controller",
+  "id": 1
 }
 ~~~
 
 Example response:
+
 ~~~
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": false
+  "result": true
 }
 ~~~
 
+# Logical Volume {#jsonrpc_components_lvol}
 
-# Block Device Abstraction Layer {#jsonrpc_components_bdev}
+Identification of logical volume store and logical volume is explained first.
 
-## get_bdevs {#rpc_get_bdevs}
+A logical volume store has a UUID and a name for its identification.
+The UUID is generated on creation and it can be used as a unique identifier.
+The name is specified on creation and can be renamed.
+Either UUID or name is used to access logical volume store in RPCs.
 
-Get information about block devices (bdevs).
+A logical volume has a UUID and a name for its identification.
+The UUID of the logical volume is generated on creation and it can be unique identifier.
+The alias of the logical volume takes the format _lvs_name/lvol_name_ where:
+* _lvs_name_ is the name of the logical volume store.
+* _lvol_name_ is specified on creation and can be renamed.
 
-### Parameters
+## construct_lvol_store {#rpc_construct_lvol_store}
 
-The user may specify no parameters in order to list all block devices, or a block device may be
-specified by name.
+Construct a logical volume store.
+
+### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-name                    | Optional | string      | Block device name
+bdev_name               | Required | string      | Bdev on which to construct logical volume store
+lvs_name                | Required | string      | Name of the logical volume store to create
+cluster_sz              | Optional | number      | Cluster size of the logical volume store in bytes
 
 ### Response
 
-The response is an array of objects containing information about the requested block devices.
+UUID of the created logical volume store is returned.
 
 ### Example
 
@@ -104,9 +2592,10 @@ Example request:
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "method": "get_bdevs",
+  "method": "construct_lvol_store",
   "params": {
-    "name": "Malloc0"
+    "lvs_name": "LVS0",
+    "bdev_name": "Malloc0"
   }
 }
 ~~~
@@ -116,32 +2605,22 @@ Example response:
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": [
-    {
-      "name": "Malloc0",
-      "product_name": "Malloc disk",
-      "block_size": 512,
-      "num_blocks": 20480,
-      "claimed": false,
-      "supported_io_types": {
-        "read": true,
-        "write": true,
-        "unmap": true,
-        "write_zeroes": true,
-        "flush": true,
-        "reset": true,
-        "nvme_admin": false,
-        "nvme_io": false
-      },
-      "driver_specific": {}
-    }
-  ]
+  "result": "a9959197-b5e2-4f2d-8095-251ffb6985a5"
 }
 ~~~
 
-## delete_bdev {#rpc_delete_bdev}
+## destroy_lvol_store {#rpc_destroy_lvol_store}
 
-Unregister a block device.
+Destroy a logical volume store.
+
+### Parameters
+
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+uuid                    | Optional | string      | UUID of the logical volume store to destroy
+lvs_name                | Optional | string      | Name of the logical volume store to destroy
+
+Either uuid or lvs_name must be specified, but not both.
 
 ### Example
 
@@ -149,10 +2628,10 @@ Example request:
 ~~~
 {
   "jsonrpc": "2.0",
-  "id": 1,
-  "method": "delete_bdev",
+  "method": "destroy_lvol_store",
+  "id": 1
   "params": {
-    "name": "Malloc0"
+    "uuid": "a9959197-b5e2-4f2d-8095-251ffb6985a5"
   }
 }
 ~~~
@@ -166,22 +2645,19 @@ Example response:
 }
 ~~~
 
-### Parameters
-
-Name                    | Optional | Type        | Description
------------------------ | -------- | ----------- | -----------
-name                    | Required | string      | Block device name
-
-## set_bdev_qos_limit_iops {#rpc_set_bdev_qos_limit_iops}
+## get_lvol_stores {#rpc_get_lvol_stores}
 
-Set an IOPS-based quality of service rate limit on a bdev.
+Get a list of logical volume stores.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-name                    | Required | string      | Block device name
-ios_per_sec             | Required | number      | Number of I/Os per second to allow. 0 means unlimited.
+uuid                    | Optional | string      | UUID of the logical volume store to retrieve information about
+lvs_name                | Optional | string      | Name of the logical volume store to retrieve information about
+
+Either uuid or lvs_name may be specified, but not both.
+If both uuid and lvs_name are omitted, information about all logical volume stores is returned.
 
 ### Example
 
@@ -189,11 +2665,10 @@ Example request:
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "get_lvol_stores",
   "id": 1,
-  "method": "set_bdev_qos_limit_iops",
   "params": {
-    "name": "Malloc0"
-    "ios_per_sec": 20000
+    "lvs_name": "LVS0"
   }
 }
 ~~~
@@ -203,17 +2678,30 @@ Example response:
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": true
+  "result": [
+    {
+      "uuid": "a9959197-b5e2-4f2d-8095-251ffb6985a5",
+      "base_bdev": "Malloc0",
+      "free_clusters": 31,
+      "cluster_size": 4194304,
+      "total_data_clusters": 31,
+      "block_size": 4096,
+      "name": "LVS0"
+    }
+  ]
 }
 ~~~
 
-# NVMe-oF Target {#jsonrpc_components_nvmf_tgt}
+## rename_lvol_store {#rpc_rename_lvol_store}
 
-## get_nvmf_subsystems method {#rpc_get_nvmf_subsystems}
+Rename a logical volume store.
 
 ### Parameters
 
-This method has no parameters.
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+old_name                | Required | string      | Existing logical volume store name
+new_name                | Required | string      | New logical volume store name
 
 ### Example
 
@@ -221,8 +2709,12 @@ Example request:
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "rename_lvol_store",
   "id": 1,
-  "method": "get_nvmf_subsystems"
+  "params": {
+    "old_name": "LVS0",
+    "new_name": "LVS2"
+  }
 }
 ~~~
 
@@ -231,262 +2723,197 @@ Example response:
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": [
-    {
-      "nqn": "nqn.2014-08.org.nvmexpress.discovery",
-      "subtype": "Discovery"
-      "listen_addresses": [],
-      "hosts": [],
-      "allow_any_host": true
-    },
-    {
-      "nqn": "nqn.2016-06.io.spdk:cnode1",
-      "subtype": "NVMe",
-      "listen_addresses": [
-        {
-          "trtype": "RDMA",
-          "adrfam": "IPv4",
-          "traddr": "192.168.0.123",
-          "trsvcid": "4420"
-        }
-      ],
-      "hosts": [
-        {"nqn": "nqn.2016-06.io.spdk:host1"}
-      ],
-      "allow_any_host": false,
-      "serial_number": "abcdef",
-      "namespaces": [
-        {"nsid": 1, "name": "Malloc2"},
-        {"nsid": 2, "name": "Nvme0n1"}
-      ]
-    }
-  ]
+  "result": true
 }
 ~~~
 
-## construct_nvmf_subsystem method {#rpc_construct_nvmf_subsystem}
+## construct_lvol_bdev {#rpc_construct_lvol_bdev}
 
-Construct an NVMe over Fabrics target subsystem.
+Create a logical volume on a logical volume store.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-listen_addresses        | Optional | array       | Array of @ref rpc_construct_nvmf_subsystem_listen_address objects
-hosts                   | Optional | array       | Array of strings containing allowed host NQNs. Default: No hosts allowed.
-allow_any_host          | Optional | boolean     | Allow any host (`true`) or enforce allowed host whitelist (`false`). Default: `false`.
-serial_number           | Required | string      | Serial number of virtual controller
-namespaces              | Optional | array       | Array of @ref rpc_construct_nvmf_subsystem_namespace objects. Default: No namespaces.
-max_namespaces          | Optional | number      | Maximum number of namespaces that can be attached to the subsystem. Default: 0 (Unlimited)
+lvol_name               | Required | string      | Name of logical volume to create
+size                    | Required | number      | Desired size of logical volume in bytes
+thin_provision          | Optional | boolean     | True to enable thin provisioning
+uuid                    | Optional | string      | UUID of logical volume store to create logical volume on
+lvs_name                | Optional | string      | Name of logical volume store to create logical volume on
 
-### listen_address {#rpc_construct_nvmf_subsystem_listen_address}
-
-Name                    | Optional | Type        | Description
------------------------ | -------- | ----------- | -----------
-trtype                  | Required | string      | Transport type ("RDMA")
-adrfam                  | Required | string      | Address family ("IPv4", "IPv6", "IB", or "FC")
-traddr                  | Required | string      | Transport address
-trsvcid                 | Required | string      | Transport service ID
+Size will be rounded up to a multiple of cluster size. Either uuid or lvs_name must be specified, but not both.
+lvol_name will be used in the alias of the created logical volume.
 
-### namespace {#rpc_construct_nvmf_subsystem_namespace}
+### Response
 
-Name                    | Optional | Type        | Description
------------------------ | -------- | ----------- | -----------
-nsid                    | Optional | number      | Namespace ID between 1 and 4294967294, inclusive. Default: Automatically assign NSID.
-bdev_name               | Required | string      | Name of bdev to expose as a namespace.
-nguid                   | Optional | string      | 16-byte namespace globally unique identifier in hexadecimal (e.g. "ABCDEF0123456789ABCDEF0123456789")
-eui64                   | Optional | string      | 8-byte namespace EUI-64 in hexadecimal (e.g. "ABCDEF0123456789")
+UUID of the created logical volume is returned.
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "construct_lvol_bdev",
   "id": 1,
-  "method": "construct_nvmf_subsystem",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "listen_addresses": [
-      {
-        "trtype": "RDMA",
-        "adrfam": "IPv4",
-        "traddr": "192.168.0.123",
-        "trsvcid: "4420"
-      }
-    ],
-    "hosts": [
-      "nqn.2016-06.io.spdk:host1",
-      "nqn.2016-06.io.spdk:host2"
-    ],
-    "allow_any_host": false,
-    "serial_number": "abcdef",
-    "namespaces": [
-      {"nsid": 1, "name": "Malloc2"},
-      {"nsid": 2, "name": "Nvme0n1"}
-    ]
+    "lvol_name": "LVOL0",
+    "size": 1048576,
+    "lvs_name": "LVS0",
+    "thin_provision": true
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": true
+  "result": "1b38702c-7f0c-411e-a962-92c6a5a8a602"
 }
 ~~~
 
-## delete_nvmf_subsystem method {#rpc_delete_nvmf_subsystem}
+## snapshot_lvol_bdev {#rpc_snapshot_lvol_bdev}
 
-Delete an existing NVMe-oF subsystem.
+Capture a snapshot of the current state of a logical volume.
 
 ### Parameters
 
-Parameter              | Optional | Type        | Description
----------------------- | -------- | ----------- | -----------
-nqn                    | Required | string      | Subsystem NQN to delete.
+Name                    | Optional | Type        | Description
+----------------------- | -------- | ----------- | -----------
+lvol_name               | Required | string      | UUID or alias of the logical volume to create a snapshot from
+snapshot_name           | Required | string      | Name for the newly created snapshot
+
+### Response
+
+UUID of the created logical volume snapshot is returned.
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "snapshot_lvol_bdev",
   "id": 1,
-  "method": "delete_nvmf_subsystem",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1"
+    "lvol_name": "1b38702c-7f0c-411e-a962-92c6a5a8a602",
+    "snapshot_name": "SNAP1"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": true
+  "result": "cc8d7fdf-7865-4d1f-9fc6-35da8e368670"
 }
 ~~~
 
-## nvmf_subsystem_add_listener  method {#rpc_nvmf_subsystem_add_listener}
+## clone_lvol_bdev {#rpc_clone_lvol_bdev}
 
-Add a new listen address to an NVMe-oF subsystem.
+Create a logical volume based on a snapshot.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-listen_address          | Required | object      | @ref rpc_construct_nvmf_subsystem_listen_address object
+snapshot_name           | Required | string      | UUID or alias of the snapshot to clone
+clone_name              | Required | string      | Name for the logical volume to create
+
+### Response
+
+UUID of the created logical volume clone is returned.
 
 ### Example
 
 Example request:
-
 ~~~
 {
-  "jsonrpc": "2.0",
+  "jsonrpc": "2.0"
+  "method": "clone_lvol_bdev",
   "id": 1,
-  "method": "nvmf_subsystem_add_listener",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "listen_address": {
-      "trtype": "RDMA",
-      "adrfam": "IPv4",
-      "traddr": "192.168.0.123",
-      "trsvcid: "4420"
-    }
+    "snapshot_name": "cc8d7fdf-7865-4d1f-9fc6-35da8e368670",
+    "clone_name": "CLONE1"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": true
+  "result": "8d87fccc-c278-49f0-9d4c-6237951aca09"
 }
 ~~~
 
-## nvmf_subsystem_add_ns method {#rpc_nvmf_subsystem_add_ns}
+## rename_lvol_bdev {#rpc_rename_lvol_bdev}
 
-Add a namespace to a subsystem. The namespace ID is returned as the result.
+Rename a logical volume. New name will rename only the alias of the logical volume.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-namespace               | Required | object      | @ref rpc_construct_nvmf_subsystem_namespace object
+old_name                | Required | string      | UUID or alias of the existing logical volume
+new_name                | Required | string      | New logical volume name
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "rename_lvol_bdev",
   "id": 1,
-  "method": "nvmf_subsystem_add_ns",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "namespace": {
-      "nsid": 3,
-      "bdev_name": "Nvme0n1"
-    }
+    "old_name": "067df606-6dbc-4143-a499-0d05855cb3b8",
+    "new_name": "LVOL2"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
   "id": 1,
-  "result": 3
+  "result": true
 }
 ~~~
 
-## nvmf_subsystem_remove_ns method {#rpc_nvmf_subsystem_remove_ns}
+## resize_lvol_bdev {#rpc_resize_lvol_bdev}
 
-Remove a namespace from a subsystem.
+Resize a logical volume.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-nsid                    | Required | number      | Namespace ID
+name                    | Required | string      | UUID or alias of the logical volume to resize
+size                    | Required | number      | Desired size of the logical volume in bytes
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "resize_lvol_bdev",
   "id": 1,
-  "method": "nvmf_subsystem_remove_ns",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "nsid": 1
+    "name": "51638754-ca16-43a7-9f8f-294a0805ab0a",
+    "size": 2097152
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
@@ -495,35 +2922,31 @@ Example response:
 }
 ~~~
 
-## nvmf_subsystem_add_host method {#rpc_nvmf_subsystem_add_host}
+## destroy_lvol_bdev {#rpc_destroy_lvol_bdev}
 
-Add a host NQN to the whitelist of allowed hosts.
+Destroy a logical volume.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-host                    | Required | string      | Host NQN to add to the list of allowed host NQNs
+name                    | Required | string      | UUID or alias of the logical volume to destroy
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "destroy_lvol_bdev",
   "id": 1,
-  "method": "nvmf_subsystem_add_host",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "host": "nqn.2016-06.io.spdk:host1"
+    "name": "51638754-ca16-43a7-9f8f-294a0805ab0a"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
@@ -532,35 +2955,31 @@ Example response:
 }
 ~~~
 
-## nvmf_subsystem_remove_host method {#rpc_nvmf_subsystem_remove_host}
+## inflate_lvol_bdev {#rpc_inflate_lvol_bdev}
 
-Remove a host NQN from the whitelist of allowed hosts.
+Inflate a logical volume. All unallocated clusters are allocated and copied from the parent or zero filled if not allocated in the parent. Then all dependencies on the parent are removed.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-host                    | Required | string      | Host NQN to remove from the list of allowed host NQNs
+name                    | Required | string      | UUID or alias of the logical volume to inflate
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
+  "method": "inflate_lvol_bdev",
   "id": 1,
-  "method": "nvmf_subsystem_remove_host",
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "host": "nqn.2016-06.io.spdk:host1"
+    "name": "8d87fccc-c278-49f0-9d4c-6237951aca09"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
@@ -569,35 +2988,31 @@ Example response:
 }
 ~~~
 
-## nvmf_subsystem_allow_any_host method {#rpc_nvmf_subsystem_allow_any_host}
+## decouple_parent_lvol_bdev {#rpc_decouple_parent_lvol_bdev}
 
-Configure a subsystem to allow any host to connect or to enforce the host NQN whitelist.
+Decouple the parent of a logical volume. For unallocated clusters which is allocated in the parent, they are allocated and copied from the parent, but for unallocated clusters which is thin provisioned in the parent, they are kept thin provisioned. Then all dependencies on the parent are removed.
 
 ### Parameters
 
 Name                    | Optional | Type        | Description
 ----------------------- | -------- | ----------- | -----------
-nqn                     | Required | string      | Subsystem NQN
-allow_any_host          | Required | boolean     | Allow any host (`true`) or enforce allowed host whitelist (`false`).
+name                    | Required | string      | UUID or alias of the logical volume to decouple the parent of it
 
 ### Example
 
 Example request:
-
 ~~~
 {
   "jsonrpc": "2.0",
-  "id": 1,
-  "method": "nvmf_subsystem_allow_any_host",
+  "method": "decouple_parent_lvol_bdev",
+  "id": 1.
   "params": {
-    "nqn": "nqn.2016-06.io.spdk:cnode1",
-    "allow_any_host": true
+    "name": "8d87fccc-c278-49f0-9d4c-6237951aca09"
   }
 }
 ~~~
 
 Example response:
-
 ~~~
 {
   "jsonrpc": "2.0",
diff --git a/doc/lvol.md b/doc/lvol.md
index 9bd0c2de4..9734bde62 100644
--- a/doc/lvol.md
+++ b/doc/lvol.md
@@ -1,4 +1,4 @@
-# Logical Volumes Introduction {#logical_volumes}
+# Logical Volumes {#logical_volumes}
 
 The Logical Volumes library is a flexible storage space management system. It provides creating and managing virtual block devices with variable size. The SPDK Logical Volume library is built on top of @ref blob.
 
@@ -28,14 +28,43 @@ A logical volume block device translates generic SPDK block device I/O (spdk_bde
 Size of the new bdev will be rounded up to nearest multiple of cluster_size.
 By default lvol bdevs claim part of lvol store equal to their set size. When thin provision option is enabled, no space is taken from lvol store until data is written to lvol bdev.
 
+## Thin provisioning {#lvol_thin_provisioning}
+
+Thin provisioned lvols rely on dynamic cluster allocation (e.g. when the first write operation on a cluster is performed), only space required to store data is used and unallocated clusters are obtained from underlying device (e.g. zeroes_dev).
+
+Sample write operations of thin provisioned blob are shown on the diagram below:
+
+![Writing clusters to the thin provisioned blob](lvol_thin_provisioning_write.svg)
+
+Sample read operations and the structure of thin provisioned blob are shown on the diagram below:
+
+![Reading clusters from thin provisioned blob](lvol_thin_provisioning.svg)
+
 ## Snapshots and clone {#lvol_snapshots}
 
 Logical volumes support snapshots and clones functionality. User may at any given time create snapshot of existing logical volume to save a backup of current volume state.
 When creating snapshot original volume becomes thin provisioned and saves only incremental differences from its underlying snapshot. This means that every read from unallocated cluster is actually a read from the snapshot and
 every write to unallocated cluster triggers new cluster allocation and data copy from corresponding cluster in snapshot to the new cluster in logical volume before the actual write occurs.
+
+The read operation is performed as shown in the diagram below:
+![Reading cluster from clone](lvol_clone_snapshot_read.svg)
+
+The write operation is performed as shown in the diagram below:
+![Writing cluster to the clone](lvol_clone_snapshot_write.svg)
+
 User may also create clone of existing snapshot that will be thin provisioned and it will behave in the same way as logical volume from which snapshot is created.
 There is no limit of clones and snapshots that may be created as long as there is enough space on logical volume store. Snapshots are read only. Clones may be created only from snapshots.
 
+## Inflation {#lvol_inflation}
+
+Blobs can be inflated to copy data from backing devices (e.g. snapshots) and allocate all remaining clusters. As a result of this operation all dependencies for the blob are removed.
+
+![Removing backing blob and bdevs relations using inflate call](lvol_inflate_clone_snapshot.svg)
+
+## Decoupling {#lvol_decoupling}
+
+Blobs can be decoupled from all dependencies by copying data from backing devices (e.g. snapshots) for all allocated clusters. Remainig unallocated clusters are kept thin provisioned.
+
 # Configuring Logical Volumes
 
 There is no static configuration available for logical volumes. All configuration is done trough RPC. Information about logical volumes is kept on block devices.
@@ -108,4 +137,12 @@ resize_lvol_bdev [-h] name size
     Resize existing lvol bdev
     optional arguments:
     -h, --help  show help
+inflate_lvol_bdev [-h] name
+    Inflate lvol bdev
+    optional arguments:
+    -h, --help  show help
+decouple_parent_lvol_bdev [-h] name
+    Decouple parent of a logical volume
+    optional arguments:
+    -h, --help  show help
 ```
diff --git a/doc/misc.md b/doc/misc.md
new file mode 100644
index 000000000..7eb22354b
--- /dev/null
+++ b/doc/misc.md
@@ -0,0 +1,3 @@
+# Miscellaneous {#misc}
+
+- @subpage peer_2_peer
diff --git a/doc/modules.md b/doc/modules.md
new file mode 100644
index 000000000..69a8dc88b
--- /dev/null
+++ b/doc/modules.md
@@ -0,0 +1,5 @@
+# Modules {#modules}
+
+- @subpage nvme
+- @subpage ioat
+- @subpage virtio
diff --git a/doc/performance_reports.md b/doc/performance_reports.md
new file mode 100644
index 000000000..8b3e353be
--- /dev/null
+++ b/doc/performance_reports.md
@@ -0,0 +1,3 @@
+# Performance Reports {#performance_reports}
+
+- [SPDK 17.07 vhost-scsi Performance Report](https://ci.spdk.io/download/performance-reports/SPDK17_07_vhost_scsi_performance_report.pdf)
diff --git a/doc/prog_guides.md b/doc/prog_guides.md
new file mode 100644
index 000000000..631c32fdc
--- /dev/null
+++ b/doc/prog_guides.md
@@ -0,0 +1,6 @@
+# Programmer Guides {#prog_guides}
+
+- @subpage blob
+- @subpage bdev_pg
+- @subpage bdev_module
+- @subpage nvmf_tgt_pg
diff --git a/doc/tools.md b/doc/tools.md
new file mode 100644
index 000000000..25cd4cdbe
--- /dev/null
+++ b/doc/tools.md
@@ -0,0 +1,3 @@
+# Tools {#tools}
+
+- @subpage nvme-cli
diff --git a/doc/two.min.js b/doc/two.min.js
new file mode 100644
index 000000000..cf608b67e
--- /dev/null
+++ b/doc/two.min.js
@@ -0,0 +1,250 @@
+var $jscomp=$jscomp||{};$jscomp.scope={};$jscomp.ASSUME_ES5=!1;$jscomp.ASSUME_NO_NATIVE_MAP=!1;$jscomp.ASSUME_NO_NATIVE_SET=!1;$jscomp.defineProperty=$jscomp.ASSUME_ES5||"function"==typeof Object.defineProperties?Object.defineProperty:function(c,k,m){c!=Array.prototype&&c!=Object.prototype&&(c[k]=m.value)};$jscomp.getGlobal=function(c){return"undefined"!=typeof window&&window===c?c:"undefined"!=typeof global&&null!=global?global:c};$jscomp.global=$jscomp.getGlobal(this);$jscomp.SYMBOL_PREFIX="jscomp_symbol_";
+$jscomp.initSymbol=function(){$jscomp.initSymbol=function(){};$jscomp.global.Symbol||($jscomp.global.Symbol=$jscomp.Symbol)};$jscomp.symbolCounter_=0;$jscomp.Symbol=function(c){return $jscomp.SYMBOL_PREFIX+(c||"")+$jscomp.symbolCounter_++};
+$jscomp.initSymbolIterator=function(){$jscomp.initSymbol();var c=$jscomp.global.Symbol.iterator;c||(c=$jscomp.global.Symbol.iterator=$jscomp.global.Symbol("iterator"));"function"!=typeof Array.prototype[c]&&$jscomp.defineProperty(Array.prototype,c,{configurable:!0,writable:!0,value:function(){return $jscomp.arrayIterator(this)}});$jscomp.initSymbolIterator=function(){}};$jscomp.arrayIterator=function(c){var k=0;return $jscomp.iteratorPrototype(function(){return k<c.length?{done:!1,value:c[k++]}:{done:!0}})};
+$jscomp.iteratorPrototype=function(c){$jscomp.initSymbolIterator();c={next:c};c[$jscomp.global.Symbol.iterator]=function(){return this};return c};$jscomp.iteratorFromArray=function(c,k){$jscomp.initSymbolIterator();c instanceof String&&(c+="");var m=0,l={next:function(){if(m<c.length){var h=m++;return{value:k(h,c[h]),done:!1}}l.next=function(){return{done:!0,value:void 0}};return l.next()}};l[Symbol.iterator]=function(){return l};return l};
+$jscomp.polyfill=function(c,k,m,l){if(k){m=$jscomp.global;c=c.split(".");for(l=0;l<c.length-1;l++){var h=c[l];h in m||(m[h]={});m=m[h]}c=c[c.length-1];l=m[c];k=k(l);k!=l&&null!=k&&$jscomp.defineProperty(m,c,{configurable:!0,writable:!0,value:k})}};$jscomp.polyfill("Array.prototype.keys",function(c){return c?c:function(){return $jscomp.iteratorFromArray(this,function(c){return c})}},"es6-impl","es3");
+$jscomp.polyfill("Array.prototype.values",function(c){return c?c:function(){return $jscomp.iteratorFromArray(this,function(c,m){return m})}},"es6","es3");$jscomp.polyfill("Array.prototype.fill",function(c){return c?c:function(c,m,l){var h=this.length||0;0>m&&(m=Math.max(0,h+m));if(null==l||l>h)l=h;l=Number(l);0>l&&(l=Math.max(0,h+l));for(m=Number(m||0);m<l;m++)this[m]=c;return this}},"es6-impl","es3");
+this.Two=function(c){function k(){var a=document.body.getBoundingClientRect(),c=this.width=a.width,a=this.height=a.height;this.renderer.setSize(c,a,this.ratio);this.trigger(p.Events.resize,c,a)}function m(){L(m);for(var a=0;a<p.Instances.length;a++){var c=p.Instances[a];c.playing&&c.update()}}var l="undefined"!=typeof window?window:"undefined"!=typeof global?global:null,h=Object.prototype.toString,d={_indexAmount:0,natural:{slice:Array.prototype.slice,indexOf:Array.prototype.indexOf,keys:Object.keys,
+bind:Function.prototype.bind,create:Object.create},identity:function(a){return a},isArguments:function(a){return"[object Arguments]"===h.call(a)},isFunction:function(a){return"[object Function]"===h.call(a)},isString:function(a){return"[object String]"===h.call(a)},isNumber:function(a){return"[object Number]"===h.call(a)},isDate:function(a){return"[object Date]"===h.call(a)},isRegExp:function(a){return"[object RegExp]"===h.call(a)},isError:function(a){return"[object Error]"===h.call(a)},isFinite:function(a){return isFinite(a)&&
+!isNaN(parseFloat(a))},isNaN:function(a){return d.isNumber(a)&&a!==+a},isBoolean:function(a){return!0===a||!1===a||"[object Boolean]"===h.call(a)},isNull:function(a){return null===a},isUndefined:function(a){return void 0===a},isEmpty:function(a){return null==a?!0:q&&(d.isArray(a)||d.isString(a)||d.isArguments(a))?0===a.length:0===d.keys(a).length},isElement:function(a){return!(!a||1!==a.nodeType)},isArray:Array.isArray||function(a){return"[object Array]"===h.call(a)},isObject:function(a){var c=typeof a;
+return"function"===c||"object"===c&&!!a},toArray:function(a){return a?d.isArray(a)?x.call(a):q(a)?d.map(a,d.identity):d.values(a):[]},range:function(a,c,f){null==c&&(c=a||0,a=0);f=f||1;c=Math.max(Math.ceil((c-a)/f),0);for(var e=Array(c),d=0;d<c;d++,a+=f)e[d]=a;return e},indexOf:function(a,c){if(d.natural.indexOf)return d.natural.indexOf.call(a,c);for(var f=0;f<a.length;f++)if(a[f]===c)return f;return-1},has:function(a,c){return null!=a&&hasOwnProperty.call(a,c)},bind:function(a,c){var f=d.natural.bind;
+if(f&&a.bind===f)return f.apply(a,x.call(arguments,1));var e=x.call(arguments,2);return function(){a.apply(c,e)}},extend:function(a){for(var c=x.call(arguments,1),f=0;f<c.length;f++){var e=c[f],d;for(d in e)a[d]=e[d]}return a},defaults:function(a){for(var c=x.call(arguments,1),f=0;f<c.length;f++){var e=c[f],d;for(d in e)void 0===a[d]&&(a[d]=e[d])}return a},keys:function(a){if(!d.isObject(a))return[];if(d.natural.keys)return d.natural.keys(a);var c=[],f;for(f in a)d.has(a,f)&&c.push(f);return c},values:function(a){for(var c=
+d.keys(a),f=[],e=0;e<c.length;e++)f.push(a[c[e]]);return f},each:function(a,c,f){f=f||this;for(var e=!q(a)&&d.keys(a),g=(e||a).length,y=0;y<g;y++){var n=e?e[y]:y;c.call(f,a[n],n,a)}return a},map:function(a,c,f){f=f||this;for(var e=!q(a)&&d.keys(a),g=(e||a).length,n=[],y=0;y<g;y++){var t=e?e[y]:y;n[y]=c.call(f,a[t],t,a)}return n},once:function(a){var c=!1;return function(){if(c)return a;c=!0;return a.apply(this,arguments)}},after:function(a,c){return function(){for(;1>--a;)return c.apply(this,arguments)}},
+uniqueId:function(a){var c=++d._indexAmount+"";return a?a+c:c}},e=Math.sin,a=Math.cos,g=Math.atan2,n=Math.sqrt,f=Math.PI,t=f/2,v=Math.pow,B=Math.min,z=Math.max,A=0,x=d.natural.slice,u=l.performance&&l.performance.now?l.performance:Date,r=Math.pow(2,53)-1,q=function(a){a=null==a?void 0:a.length;return"number"==typeof a&&0<=a&&a<=r},w={temp:l.document?l.document.createElement("div"):{},hasEventListeners:d.isFunction(l.addEventListener),bind:function(a,c,f,e){this.hasEventListeners?a.addEventListener(c,
+f,!!e):a.attachEvent("on"+c,f);return w},unbind:function(a,c,f,e){w.hasEventListeners?a.removeEventListeners(c,f,!!e):a.detachEvent("on"+c,f);return w},getRequestAnimationFrame:function(){var a=0,c=["ms","moz","webkit","o"],f=l.requestAnimationFrame;if(!f){for(var e=0;e<c.length;e++)f=l[c[e]+"RequestAnimationFrame"]||f;f=f||function(c,f){var e=(new Date).getTime(),d=Math.max(0,16-(e-a));f=l.setTimeout(function(){c(e+d)},d);a=e+d;return f}}f.init=d.once(m);return f}},p=l.Two=function(a){a=d.defaults(a||
+{},{fullscreen:!1,width:640,height:480,type:p.Types.svg,autostart:!1});d.each(a,function(a,c){"fullscreen"!==c&&"autostart"!==c&&(this[c]=a)},this);if(d.isElement(a.domElement)){var c=a.domElement.tagName.toLowerCase();/^(CanvasRenderer-canvas|WebGLRenderer-canvas|SVGRenderer-svg)$/.test(this.type+"-"+c)||(this.type=p.Types[c])}this.renderer=new p[this.type](this);p.Utils.setPlaying.call(this,a.autostart);this.frameCount=0;a.fullscreen?(a=d.bind(k,this),d.extend(document.body.style,{overflow:"hidden",
+margin:0,padding:0,top:0,left:0,right:0,bottom:0,position:"fixed"}),d.extend(this.renderer.domElement.style,{display:"block",top:0,left:0,right:0,bottom:0,position:"fixed"}),w.bind(l,"resize",a),a()):d.isElement(a.domElement)||(this.renderer.setSize(a.width,a.height,this.ratio),this.width=a.width,this.height=a.height);this.scene=this.renderer.scene;p.Instances.push(this);L.init()};d.extend(p,{root:l,Array:l.Float32Array||Array,Types:{webgl:"WebGLRenderer",svg:"SVGRenderer",canvas:"CanvasRenderer"},
+Version:"v0.7.0",Identifier:"two_",Properties:{hierarchy:"hierarchy",demotion:"demotion"},Events:{play:"play",pause:"pause",update:"update",render:"render",resize:"resize",change:"change",remove:"remove",insert:"insert",order:"order",load:"load"},Commands:{move:"M",line:"L",curve:"C",close:"Z"},Resolution:8,Instances:[],noConflict:function(){l.Two=c;return this},uniqueId:function(){var a=A;A++;return a},Utils:d.extend(d,{performance:u,defineProperty:function(a){var c="_"+a,f="_flag"+a.charAt(0).toUpperCase()+
+a.slice(1);Object.defineProperty(this,a,{enumerable:!0,get:function(){return this[c]},set:function(a){this[c]=a;this[f]=!0}})},release:function(a){d.isObject(a)&&(d.isFunction(a.unbind)&&a.unbind(),a.vertices&&(d.isFunction(a.vertices.unbind)&&a.vertices.unbind(),d.each(a.vertices,function(a){d.isFunction(a.unbind)&&a.unbind()})),a.children&&d.each(a.children,function(a){p.Utils.release(a)}))},xhr:function(a,c){var f=new XMLHttpRequest;f.open("GET",a);f.onreadystatechange=function(){4===f.readyState&&
+200===f.status&&c(f.responseText)};f.send();return f},Curve:{CollinearityEpsilon:v(10,-30),RecursionLimit:16,CuspLimit:0,Tolerance:{distance:.25,angle:0,epsilon:.01},abscissas:[[.5773502691896257],[0,.7745966692414834],[.33998104358485626,.8611363115940526],[0,.5384693101056831,.906179845938664],[.2386191860831969,.6612093864662645,.932469514203152],[0,.4058451513773972,.7415311855993945,.9491079123427585],[.1834346424956498,.525532409916329,.7966664774136267,.9602898564975363],[0,.3242534234038089,
+.6133714327005904,.8360311073266358,.9681602395076261],[.14887433898163122,.4333953941292472,.6794095682990244,.8650633666889845,.9739065285171717],[0,.26954315595234496,.5190961292068118,.7301520055740494,.8870625997680953,.978228658146057],[.1252334085114689,.3678314989981802,.5873179542866175,.7699026741943047,.9041172563704749,.9815606342467192],[0,.2304583159551348,.44849275103644687,.6423493394403402,.8015780907333099,.9175983992229779,.9841830547185881],[.10805494870734367,.31911236892788974,
+.5152486363581541,.6872929048116855,.827201315069765,.9284348836635735,.9862838086968123],[0,.20119409399743451,.3941513470775634,.5709721726085388,.7244177313601701,.8482065834104272,.937273392400706,.9879925180204854],[.09501250983763744,.2816035507792589,.45801677765722737,.6178762444026438,.755404408355003,.8656312023878318,.9445750230732326,.9894009349916499]],weights:[[1],[.8888888888888888,.5555555555555556],[.6521451548625461,.34785484513745385],[.5688888888888889,.47862867049936647,.23692688505618908],
+[.46791393457269104,.3607615730481386,.17132449237917036],[.4179591836734694,.3818300505051189,.27970539148927664,.1294849661688697],[.362683783378362,.31370664587788727,.22238103445337448,.10122853629037626],[.3302393550012598,.31234707704000286,.26061069640293544,.1806481606948574,.08127438836157441],[.29552422471475287,.26926671930999635,.21908636251598204,.1494513491505806,.06667134430868814],[.2729250867779006,.26280454451024665,.23319376459199048,.18629021092773426,.1255803694649046,.05566856711617366],
+[.24914704581340277,.2334925365383548,.20316742672306592,.16007832854334622,.10693932599531843,.04717533638651183],[.2325515532308739,.22628318026289723,.2078160475368885,.17814598076194574,.13887351021978725,.09212149983772845,.04048400476531588],[.2152638534631578,.2051984637212956,.18553839747793782,.15720316715819355,.12151857068790319,.08015808715976021,.03511946033175186],[.2025782419255613,.19843148532711158,.1861610000155622,.16626920581699392,.13957067792615432,.10715922046717194,.07036604748810812,
+.03075324199611727],[.1894506104550685,.18260341504492358,.16915651939500254,.14959598881657674,.12462897125553388,.09515851168249279,.062253523938647894,.027152459411754096]]},devicePixelRatio:l.devicePixelRatio||1,getBackingStoreRatio:function(a){return a.webkitBackingStorePixelRatio||a.mozBackingStorePixelRatio||a.msBackingStorePixelRatio||a.oBackingStorePixelRatio||a.backingStorePixelRatio||1},getRatio:function(a){return p.Utils.devicePixelRatio/O(a)},setPlaying:function(a){this.playing=!!a;return this},
+getComputedMatrix:function(a,c){c=c&&c.identity()||new p.Matrix;for(var f=[];a&&a._matrix;)f.push(a._matrix),a=a.parent;f.reverse();d.each(f,function(a){a=a.elements;c.multiply(a[0],a[1],a[2],a[3],a[4],a[5],a[6],a[7],a[8],a[9])});return c},deltaTransformPoint:function(a,c,f){return new p.Vector(c*a.a+f*a.c+0,c*a.b+f*a.d+0)},decomposeMatrix:function(a){var c=p.Utils.deltaTransformPoint(a,0,1),f=p.Utils.deltaTransformPoint(a,1,0),c=180/Math.PI*Math.atan2(c.y,c.x)-90;return{translateX:a.e,translateY:a.f,
+scaleX:Math.sqrt(a.a*a.a+a.b*a.b),scaleY:Math.sqrt(a.c*a.c+a.d*a.d),skewX:c,skewY:180/Math.PI*Math.atan2(f.y,f.x),rotation:c}},applySvgAttributes:function(a,c){var f={},e={},g;if(getComputedStyle){var n=getComputedStyle(a);for(g=n.length;g--;){var t=n[g];var y=n[t];void 0!==y&&(e[t]=y)}}for(g=a.attributes.length;g--;)y=a.attributes[g],f[y.nodeName]=y.value;d.isUndefined(e.opacity)||(e["stroke-opacity"]=e.opacity,e["fill-opacity"]=e.opacity);d.extend(e,f);e.visible=!(d.isUndefined(e.display)&&"none"===
+e.display)||d.isUndefined(e.visibility)&&"hidden"===e.visibility;for(t in e)switch(y=e[t],t){case "transform":if("none"===y)break;if(null===(a.getCTM?a.getCTM():null))break;f=p.Utils.decomposeMatrix(a.getCTM());c.translation.set(f.translateX,f.translateY);c.rotation=f.rotation;c.scale=f.scaleX;f=parseFloat((e.x+"").replace("px"));g=parseFloat((e.y+"").replace("px"));f&&(c.translation.x=f);g&&(c.translation.y=g);break;case "visible":c.visible=y;break;case "stroke-linecap":c.cap=y;break;case "stroke-linejoin":c.join=
+y;break;case "stroke-miterlimit":c.miter=y;break;case "stroke-width":c.linewidth=parseFloat(y);break;case "stroke-opacity":case "fill-opacity":case "opacity":c.opacity=parseFloat(y);break;case "fill":case "stroke":/url\(\#.*\)/i.test(y)?c[t]=this.getById(y.replace(/url\(\#(.*)\)/i,"$1")):c[t]="none"===y?"transparent":y;break;case "id":c.id=y;break;case "class":c.classList=y.split(" ")}return c},read:{svg:function(){return p.Utils.read.g.apply(this,arguments)},g:function(a){var c=new p.Group;p.Utils.applySvgAttributes.call(this,
+a,c);for(var f=0,e=a.childNodes.length;f<e;f++){var d=a.childNodes[f],g=d.nodeName;if(!g)return;g=g.replace(/svg\:/ig,"").toLowerCase();g in p.Utils.read&&(d=p.Utils.read[g].call(c,d),c.add(d))}return c},polygon:function(a,c){var f=[];a.getAttribute("points").replace(/(-?[\d\.?]+)[,|\s](-?[\d\.?]+)/g,function(a,c,e){f.push(new p.Anchor(parseFloat(c),parseFloat(e)))});c=(new p.Path(f,!c)).noStroke();c.fill="black";return p.Utils.applySvgAttributes.call(this,a,c)},polyline:function(a){return p.Utils.read.polygon.call(this,
+a,!0)},path:function(a){var c=a.getAttribute("d"),f=new p.Anchor,e,g,n=!1,t=!1,y=c.match(/[a-df-z][^a-df-z]*/ig),h=y.length-1;d.each(y.slice(0),function(a,c){var f=a[0],e=f.toLowerCase(),g=a.slice(1).trim().split(/[\s,]+|(?=\s?[+\-])/),d=[],n;0>=c&&(y=[]);switch(e){case "h":case "v":1<g.length&&(n=1);break;case "m":case "l":case "t":2<g.length&&(n=2);break;case "s":case "q":4<g.length&&(n=4);break;case "c":6<g.length&&(n=6)}if(n){a=0;c=g.length;for(e=0;a<c;a+=n){var t=f;if(0<e)switch(f){case "m":t=
+"l";break;case "M":t="L"}d.push([t].concat(g.slice(a,a+n)).join(" "));e++}y=Array.prototype.concat.apply(y,d)}else y.push(a)});var m=[];d.each(y,function(a,c){var y=a[0],D=y.toLowerCase();g=a.slice(1).trim();g=g.replace(/(-?\d+(?:\.\d*)?)[eE]([+\-]?\d+)/g,function(a,c,f){return parseFloat(c)*v(10,f)});g=g.split(/[\s,]+|(?=\s?[+\-])/);t=y===D;switch(D){case "z":if(c>=h)n=!0;else{a=f.x;c=f.y;var k=new p.Anchor(a,c,void 0,void 0,void 0,void 0,p.Commands.close)}break;case "m":case "l":a=parseFloat(g[0]);
+c=parseFloat(g[1]);k=new p.Anchor(a,c,void 0,void 0,void 0,void 0,"m"===D?p.Commands.move:p.Commands.line);t&&k.addSelf(f);f=k;break;case "h":case "v":c="h"===D?"x":"y";D="x"===c?"y":"x";k=new p.Anchor(void 0,void 0,void 0,void 0,void 0,void 0,p.Commands.line);k[c]=parseFloat(g[0]);k[D]=f[D];t&&(k[c]+=f[c]);f=k;break;case "c":case "s":k=f.x;c=f.y;e||(e=new p.Vector);if("c"===D){y=parseFloat(g[0]);var B=parseFloat(g[1]);var l=parseFloat(g[2]);var z=parseFloat(g[3]);D=parseFloat(g[4]);a=parseFloat(g[5])}else D=
+M(f,e,t),y=D.x,B=D.y,l=parseFloat(g[0]),z=parseFloat(g[1]),D=parseFloat(g[2]),a=parseFloat(g[3]);t&&(y+=k,B+=c,l+=k,z+=c,D+=k,a+=c);d.isObject(f.controls)||p.Anchor.AppendCurveProperties(f);f.controls.right.set(y-f.x,B-f.y);f=k=new p.Anchor(D,a,l-D,z-a,void 0,void 0,p.Commands.curve);e=k.controls.left;break;case "t":case "q":k=f.x;c=f.y;e||(e=new p.Vector);e.isZero()?(y=k,B=c):(y=e.x,c=e.y);"q"===D?(l=parseFloat(g[0]),z=parseFloat(g[1]),D=parseFloat(g[1]),a=parseFloat(g[2])):(D=M(f,e,t),l=D.x,z=D.y,
+D=parseFloat(g[0]),a=parseFloat(g[1]));t&&(y+=k,B+=c,l+=k,z+=c,D+=k,a+=c);d.isObject(f.controls)||p.Anchor.AppendCurveProperties(f);f.controls.right.set(y-f.x,B-f.y);f=k=new p.Anchor(D,a,l-D,z-a,void 0,void 0,p.Commands.curve);e=k.controls.left;break;case "a":k=f.x;c=f.y;var J=parseFloat(g[0]),x=parseFloat(g[1]);B=parseFloat(g[2])*Math.PI/180;y=parseFloat(g[3]);l=parseFloat(g[4]);D=parseFloat(g[5]);a=parseFloat(g[6]);t&&(D+=k,a+=c);var u=(D-k)/2,A=(a-c)/2;z=u*Math.cos(B)+A*Math.sin(B);var u=-u*Math.sin(B)+
+A*Math.cos(B),A=J*J,q=x*x,r=z*z,K=u*u,Q=r/A+K/q;1<Q&&(J*=Math.sqrt(Q),x*=Math.sqrt(Q));q=Math.sqrt((A*q-A*K-q*r)/(A*K+q*r));d.isNaN(q)?q=0:y!=l&&0<q&&(q*=-1);A=q*J*u/x;q=-q*x*z/J;k=A*Math.cos(B)-q*Math.sin(B)+(k+D)/2;var r=A*Math.sin(B)+q*Math.cos(B)+(c+a)/2,w=function(a,c){return(a[0]*c[0]+a[1]*c[1])/(Math.sqrt(Math.pow(a[0],2)+Math.pow(a[1],2))*Math.sqrt(Math.pow(c[0],2)+Math.pow(c[1],2)))};c=function(a,c){return(a[0]*c[1]<a[1]*c[0]?-1:1)*Math.acos(w(a,c))};var S=c([1,0],[(z-A)/J,(u-q)/x]),K=[(z-
+A)/J,(u-q)/x];z=[(-z-A)/J,(-u-q)/x];var C=c(K,z);-1>=w(K,z)&&(C=Math.PI);1<=w(K,z)&&(C=0);y&&(C=I(C,2*Math.PI));l&&0<C&&(C-=2*Math.PI);var R=p.Resolution,T=(new p.Matrix).translate(k,r).rotate(B);k=d.map(d.range(R),function(a){a=(1-a/(R-1))*C+S;a=T.multiply(J*Math.cos(a),x*Math.sin(a),1);return new p.Anchor(a.x,a.y,!1,!1,!1,!1,p.Commands.line)});k.push(new p.Anchor(D,a,!1,!1,!1,!1,p.Commands.line));f=k[k.length-1];e=f.controls.left}k&&(d.isArray(k)?m=m.concat(k):m.push(k))});if(!(1>=m.length)){c=
+(new p.Path(m,n,void 0,!0)).noStroke();c.fill="black";var k=c.getBoundingClientRect(!0);k.centroid={x:k.left+k.width/2,y:k.top+k.height/2};d.each(c.vertices,function(a){a.subSelf(k.centroid)});c.translation.addSelf(k.centroid);return p.Utils.applySvgAttributes.call(this,a,c)}},circle:function(a){var c=parseFloat(a.getAttribute("cx")),f=parseFloat(a.getAttribute("cy")),e=parseFloat(a.getAttribute("r")),c=(new p.Circle(c,f,e)).noStroke();c.fill="black";return p.Utils.applySvgAttributes.call(this,a,
+c)},ellipse:function(a){var c=parseFloat(a.getAttribute("cx")),f=parseFloat(a.getAttribute("cy")),e=parseFloat(a.getAttribute("rx")),g=parseFloat(a.getAttribute("ry")),c=(new p.Ellipse(c,f,e,g)).noStroke();c.fill="black";return p.Utils.applySvgAttributes.call(this,a,c)},rect:function(a){var c=parseFloat(a.getAttribute("x"))||0,f=parseFloat(a.getAttribute("y"))||0,e=parseFloat(a.getAttribute("width")),g=parseFloat(a.getAttribute("height")),c=(new p.Rectangle(c+e/2,f+g/2,e,g)).noStroke();c.fill="black";
+return p.Utils.applySvgAttributes.call(this,a,c)},line:function(a){var c=parseFloat(a.getAttribute("x1")),f=parseFloat(a.getAttribute("y1")),e=parseFloat(a.getAttribute("x2")),g=parseFloat(a.getAttribute("y2")),c=(new p.Line(c,f,e,g)).noFill();return p.Utils.applySvgAttributes.call(this,a,c)},lineargradient:function(a){for(var c,f=parseFloat(a.getAttribute("x1")),e=parseFloat(a.getAttribute("y1")),g=parseFloat(a.getAttribute("x2")),n=parseFloat(a.getAttribute("y2")),t=(g+f)/2,h=(n+e)/2,y=[],v=0;v<
+a.children.length;v++){c=a.children[v];var k=parseFloat(c.getAttribute("offset")),m=c.getAttribute("stop-color"),B=c.getAttribute("stop-opacity"),l=c.getAttribute("style");d.isNull(m)&&(m=(c=l?l.match(/stop\-color\:\s?([\#a-fA-F0-9]*)/):!1)&&1<c.length?c[1]:void 0);d.isNull(B)&&(B=(c=l?l.match(/stop\-opacity\:\s?([0-9\.\-]*)/):!1)&&1<c.length?parseFloat(c[1]):1);y.push(new p.Gradient.Stop(k,m,B))}f=new p.LinearGradient(f-t,e-h,g-t,n-h,y);return p.Utils.applySvgAttributes.call(this,a,f)},radialgradient:function(a){var c=
+parseFloat(a.getAttribute("cx"))||0,f=parseFloat(a.getAttribute("cy"))||0,e=parseFloat(a.getAttribute("r")),g=parseFloat(a.getAttribute("fx")),n=parseFloat(a.getAttribute("fy"));d.isNaN(g)&&(g=c);d.isNaN(n)&&(n=f);for(var t=Math.abs(c+g)/2,h=Math.abs(f+n)/2,v=[],y=0;y<a.children.length;y++){var k=a.children[y];var m=parseFloat(k.getAttribute("offset")),B=k.getAttribute("stop-color"),l=k.getAttribute("stop-opacity"),z=k.getAttribute("style");d.isNull(B)&&(B=(k=z?z.match(/stop\-color\:\s?([\#a-fA-F0-9]*)/):
+!1)&&1<k.length?k[1]:void 0);d.isNull(l)&&(l=(k=z?z.match(/stop\-opacity\:\s?([0-9\.\-]*)/):!1)&&1<k.length?parseFloat(k[1]):1);v.push(new p.Gradient.Stop(m,B,l))}c=new p.RadialGradient(c-t,f-h,e,v,g-t,n-h);return p.Utils.applySvgAttributes.call(this,a,c)}},subdivide:function(a,c,f,e,g,n,t,h,v){v=v||p.Utils.Curve.RecursionLimit;var y=v+1;return a===t&&c===h?[new p.Anchor(t,h)]:d.map(d.range(0,y),function(d){var v=d/y;d=N(v,a,f,g,t);v=N(v,c,e,n,h);return new p.Anchor(d,v)})},getPointOnCubicBezier:function(a,
+c,f,e,g){var d=1-a;return d*d*d*c+3*d*d*a*f+3*d*a*a*e+a*a*a*g},getCurveLength:function(a,c,f,e,g,d,t,v,h){if(a===f&&c===e&&g===t&&d===v)return a=t-a,c=v-c,n(a*a+c*c);var y=9*(f-g)+3*(t-a),k=6*(a+g)-12*f,B=3*(f-a),m=9*(e-d)+3*(v-c),l=6*(c+d)-12*e,D=3*(e-c);return P(function(a){var c=(y*a+k)*a+B;a=(m*a+l)*a+D;return n(c*c+a*a)},0,1,h||p.Utils.Curve.RecursionLimit)},integrate:function(a,c,f,e){var g=p.Utils.Curve.abscissas[e-2],d=p.Utils.Curve.weights[e-2];f=.5*(f-c);c=f+c;var n=0,t=e+1>>1;for(e=e&1?
+d[n++]*a(c):0;n<t;){var v=f*g[n];e+=d[n++]*(a(c+v)+a(c-v))}return f*e},getCurveFromPoints:function(a,c){for(var f=a.length,e=f-1,g=0;g<f;g++){var n=a[g];d.isObject(n.controls)||p.Anchor.AppendCurveProperties(n);var t=c?I(g-1,f):z(g-1,0),v=c?I(g+1,f):B(g+1,e);F(a[t],n,a[v]);n._command=0===g?p.Commands.move:p.Commands.curve;n.controls.left.x=d.isNumber(n.controls.left.x)?n.controls.left.x:n.x;n.controls.left.y=d.isNumber(n.controls.left.y)?n.controls.left.y:n.y;n.controls.right.x=d.isNumber(n.controls.right.x)?
+n.controls.right.x:n.x;n.controls.right.y=d.isNumber(n.controls.right.y)?n.controls.right.y:n.y}},getControlPoints:function(c,g,n){var v=G(c,g),h=G(n,g);c=E(c,g);n=E(n,g);var k=(v+h)/2;g.u=d.isObject(g.controls.left)?g.controls.left:new p.Vector(0,0);g.v=d.isObject(g.controls.right)?g.controls.right:new p.Vector(0,0);if(.0001>c||.0001>n)return g._relative||(g.controls.left.copy(g),g.controls.right.copy(g)),g;c*=.33;n*=.33;k=h<v?k+t:k-t;g.controls.left.x=a(k)*c;g.controls.left.y=e(k)*c;k-=f;g.controls.right.x=
+a(k)*n;g.controls.right.y=e(k)*n;g._relative||(g.controls.left.x+=g.x,g.controls.left.y+=g.y,g.controls.right.x+=g.x,g.controls.right.y+=g.y);return g},getReflection:function(a,c,f){return new p.Vector(2*a.x-(c.x+a.x)-(f?a.x:0),2*a.y-(c.y+a.y)-(f?a.y:0))},getAnchorsFromArcData:function(a,c,f,e,g,n,t){(new p.Matrix).translate(a.x,a.y).rotate(c);var v=p.Resolution;return d.map(d.range(v),function(a){a=(a+1)/v;t&&(a=1-a);a=a*n+g;a=new p.Anchor(f*Math.cos(a),e*Math.sin(a));p.Anchor.AppendCurveProperties(a);
+a.command=p.Commands.line;return a})},ratioBetween:function(a,c){return(a.x*c.x+a.y*c.y)/(a.length()*c.length())},angleBetween:function(a,c){if(4<=arguments.length){var f=arguments[0]-arguments[2];var e=arguments[1]-arguments[3];return g(e,f)}f=a.x-c.x;e=a.y-c.y;return g(e,f)},distanceBetweenSquared:function(a,c){var f=a.x-c.x;a=a.y-c.y;return f*f+a*a},distanceBetween:function(a,c){return n(H(a,c))},lerp:function(a,c,f){return f*(c-a)+a},toFixed:function(a){return Math.floor(1E3*a)/1E3},mod:function(a,
+c){for(;0>a;)a+=c;return a%c},Collection:function(){Array.call(this);1<arguments.length?Array.prototype.push.apply(this,arguments):arguments[0]&&Array.isArray(arguments[0])&&Array.prototype.push.apply(this,arguments[0])},Error:function(a){this.name="two.js";this.message=a},Events:{on:function(a,c){this._events||(this._events={});(this._events[a]||(this._events[a]=[])).push(c);return this},off:function(a,c){if(!this._events)return this;if(!a&&!c)return this._events={},this;for(var f=a?[a]:d.keys(this._events),
+e=0,g=f.length;e<g;e++){a=f[e];var n=this._events[a];if(n){var t=[];if(c)for(var v=0,h=n.length;v<h;v++){var k=n[v],k=k.callback?k.callback:k;c&&c!==k&&t.push(k)}this._events[a]=t}}return this},trigger:function(a){if(!this._events)return this;var c=x.call(arguments,1),f=this._events[a];f&&C(this,f,c);return this},listen:function(a,c,f){var e=this;if(a){var g=function(){f.apply(e,arguments)};g.obj=a;g.name=c;g.callback=f;a.on(c,g)}return this},ignore:function(a,c,f){a.off(c,f);return this}}})});p.Utils.Events.bind=
+p.Utils.Events.on;p.Utils.Events.unbind=p.Utils.Events.off;var C=function(a,c,f){switch(f.length){case 0:var e=function(e){c[e].call(a,f[0])};break;case 1:e=function(e){c[e].call(a,f[0],f[1])};break;case 2:e=function(e){c[e].call(a,f[0],f[1],f[2])};break;case 3:e=function(e){c[e].call(a,f[0],f[1],f[2],f[3])};break;default:e=function(e){c[e].apply(a,f)}}for(var g=0;g<c.length;g++)e(g)};p.Utils.Error.prototype=Error();p.Utils.Error.prototype.constructor=p.Utils.Error;p.Utils.Collection.prototype=[];
+p.Utils.Collection.prototype.constructor=p.Utils.Collection;d.extend(p.Utils.Collection.prototype,p.Utils.Events,{pop:function(){var a=Array.prototype.pop.apply(this,arguments);this.trigger(p.Events.remove,[a]);return a},shift:function(){var a=Array.prototype.shift.apply(this,arguments);this.trigger(p.Events.remove,[a]);return a},push:function(){var a=Array.prototype.push.apply(this,arguments);this.trigger(p.Events.insert,arguments);return a},unshift:function(){var a=Array.prototype.unshift.apply(this,
+arguments);this.trigger(p.Events.insert,arguments);return a},splice:function(){var a=Array.prototype.splice.apply(this,arguments);this.trigger(p.Events.remove,a);if(2<arguments.length){var c=this.slice(arguments[0],arguments[0]+arguments.length-2);this.trigger(p.Events.insert,c);this.trigger(p.Events.order)}return a},sort:function(){Array.prototype.sort.apply(this,arguments);this.trigger(p.Events.order);return this},reverse:function(){Array.prototype.reverse.apply(this,arguments);this.trigger(p.Events.order);
+return this}});var E=p.Utils.distanceBetween,H=p.Utils.distanceBetweenSquared,G=p.Utils.angleBetween,F=p.Utils.getControlPoints,I=p.Utils.mod,O=p.Utils.getBackingStoreRatio,N=p.Utils.getPointOnCubicBezier,P=p.Utils.integrate,M=p.Utils.getReflection;d.extend(p.prototype,p.Utils.Events,{appendTo:function(a){a.appendChild(this.renderer.domElement);return this},play:function(){p.Utils.setPlaying.call(this,!0);return this.trigger(p.Events.play)},pause:function(){this.playing=!1;return this.trigger(p.Events.pause)},
+update:function(){var a=!!this._lastFrame,c=u.now();this.frameCount++;a&&(this.timeDelta=parseFloat((c-this._lastFrame).toFixed(3)));this._lastFrame=c;var a=this.width,c=this.height,f=this.renderer;a===f.width&&c===f.height||f.setSize(a,c,this.ratio);this.trigger(p.Events.update,this.frameCount,this.timeDelta);return this.render()},render:function(){this.renderer.render();return this.trigger(p.Events.render,this.frameCount)},add:function(a){var c=a;c instanceof Array||(c=d.toArray(arguments));this.scene.add(c);
+return this},remove:function(a){var c=a;c instanceof Array||(c=d.toArray(arguments));this.scene.remove(c);return this},clear:function(){this.scene.remove(d.toArray(this.scene.children));return this},makeLine:function(a,c,f,e){a=new p.Line(a,c,f,e);this.scene.add(a);return a},makeRectangle:function(a,c,f,e){a=new p.Rectangle(a,c,f,e);this.scene.add(a);return a},makeRoundedRectangle:function(a,c,f,e,g){a=new p.RoundedRectangle(a,c,f,e,g);this.scene.add(a);return a},makeCircle:function(a,c,f){a=new p.Circle(a,
+c,f);this.scene.add(a);return a},makeEllipse:function(a,c,f,e){a=new p.Ellipse(a,c,f,e);this.scene.add(a);return a},makeStar:function(a,c,f,e,g){a=new p.Star(a,c,f,e,g);this.scene.add(a);return a},makeCurve:function(a){var c=arguments.length,f=a;if(!d.isArray(a))for(var f=[],e=0;e<c;e+=2){var g=arguments[e];if(!d.isNumber(g))break;f.push(new p.Anchor(g,arguments[e+1]))}c=arguments[c-1];f=new p.Path(f,!(d.isBoolean(c)&&c),!0);c=f.getBoundingClientRect();f.center().translation.set(c.left+c.width/2,
+c.top+c.height/2);this.scene.add(f);return f},makePolygon:function(a,c,f,e){a=new p.Polygon(a,c,f,e);this.scene.add(a);return a},makeArcSegment:function(a,c,f,e,g,d,n){a=new p.ArcSegment(a,c,f,e,g,d,n);this.scene.add(a);return a},makePath:function(a){var c=arguments.length,f=a;if(!d.isArray(a))for(var f=[],e=0;e<c;e+=2){var g=arguments[e];if(!d.isNumber(g))break;f.push(new p.Anchor(g,arguments[e+1]))}c=arguments[c-1];f=new p.Path(f,!(d.isBoolean(c)&&c));c=f.getBoundingClientRect();f.center().translation.set(c.left+
+c.width/2,c.top+c.height/2);this.scene.add(f);return f},makeText:function(a,c,f,e){a=new p.Text(a,c,f,e);this.add(a);return a},makeLinearGradient:function(a,c,f,e){var g=x.call(arguments,4),g=new p.LinearGradient(a,c,f,e,g);this.add(g);return g},makeRadialGradient:function(a,c,f){var e=x.call(arguments,3),e=new p.RadialGradient(a,c,f,e);this.add(e);return e},makeSprite:function(a,c,f,e,g,d,n){a=new p.Sprite(a,c,f,e,g,d);n&&a.play();this.add(a);return a},makeImageSequence:function(a,c,f,e,g){a=new p.ImageSequence(a,
+c,f,e);g&&a.play();this.add(a);return a},makeTexture:function(a,c){return new p.Texture(a,c)},makeGroup:function(a){var c=a;c instanceof Array||(c=d.toArray(arguments));var f=new p.Group;this.scene.add(f);f.add(c);return f},interpret:function(a,c){var f=a.tagName.toLowerCase();if(!(f in p.Utils.read))return null;a=p.Utils.read[f].call(this,a);c&&a instanceof p.Group?this.add(a.children):this.add(a);return a},load:function(a,c){var f=[],e;if(/.*\.svg/ig.test(a))return p.Utils.xhr(a,d.bind(function(a){w.temp.innerHTML=
+a;for(e=0;e<w.temp.children.length;e++)g=w.temp.children[e],f.push(this.interpret(g));c(1>=f.length?f[0]:f,1>=w.temp.children.length?w.temp.children[0]:w.temp.children)},this)),this;w.temp.innerHTML=a;for(e=0;e<w.temp.children.length;e++){var g=w.temp.children[e];f.push(this.interpret(g))}c(1>=f.length?f[0]:f,1>=w.temp.children.length?w.temp.children[0]:w.temp.children);return this}});var L=w.getRequestAnimationFrame();"function"===typeof define&&define.amd?define("two",[],function(){return p}):"undefined"!=
+typeof module&&module.exports&&(module.exports=p);return p}(("undefined"!==typeof global?global:this).Two);(function(c){var k=c.Utils;c=c.Registry=function(){this.map={}};k.extend(c,{});k.extend(c.prototype,{add:function(c,k){this.map[c]=k;return this},remove:function(c){delete this.map[c];return this},get:function(c){return this.map[c]},contains:function(c){return c in this.map}})})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.Vector=function(c,a){this.x=c||0;this.y=a||0};k.extend(m,{zero:new c.Vector});k.extend(m.prototype,c.Utils.Events,{set:function(c,a){this.x=c;this.y=a;return this},copy:function(c){this.x=c.x;this.y=c.y;return this},clear:function(){this.y=this.x=0;return this},clone:function(){return new m(this.x,this.y)},add:function(c,a){this.x=c.x+a.x;this.y=c.y+a.y;return this},addSelf:function(c){this.x+=c.x;this.y+=c.y;return this},sub:function(c,a){this.x=c.x-a.x;this.y=c.y-
+a.y;return this},subSelf:function(c){this.x-=c.x;this.y-=c.y;return this},multiplySelf:function(c){this.x*=c.x;this.y*=c.y;return this},multiplyScalar:function(c){this.x*=c;this.y*=c;return this},divideScalar:function(c){c?(this.x/=c,this.y/=c):this.set(0,0);return this},negate:function(){return this.multiplyScalar(-1)},dot:function(c){return this.x*c.x+this.y*c.y},lengthSquared:function(){return this.x*this.x+this.y*this.y},length:function(){return Math.sqrt(this.lengthSquared())},normalize:function(){return this.divideScalar(this.length())},
+distanceTo:function(c){return Math.sqrt(this.distanceToSquared(c))},distanceToSquared:function(c){var a=this.x-c.x;c=this.y-c.y;return a*a+c*c},setLength:function(c){return this.normalize().multiplyScalar(c)},equals:function(c,a){a="undefined"===typeof a?.0001:a;return this.distanceTo(c)<a},lerp:function(c,a){return this.set((c.x-this.x)*a+this.x,(c.y-this.y)*a+this.y)},isZero:function(c){c="undefined"===typeof c?.0001:c;return this.length()<c},toString:function(){return this.x+", "+this.y},toObject:function(){return{x:this.x,
+y:this.y}},rotate:function(c){var a=Math.cos(c);c=Math.sin(c);this.x=this.x*a-this.y*c;this.y=this.x*c+this.y*a;return this}});var l={set:function(e,a){this._x=e;this._y=a;return this.trigger(c.Events.change)},copy:function(e){this._x=e.x;this._y=e.y;return this.trigger(c.Events.change)},clear:function(){this._y=this._x=0;return this.trigger(c.Events.change)},clone:function(){return new m(this._x,this._y)},add:function(e,a){this._x=e.x+a.x;this._y=e.y+a.y;return this.trigger(c.Events.change)},addSelf:function(e){this._x+=
+e.x;this._y+=e.y;return this.trigger(c.Events.change)},sub:function(e,a){this._x=e.x-a.x;this._y=e.y-a.y;return this.trigger(c.Events.change)},subSelf:function(e){this._x-=e.x;this._y-=e.y;return this.trigger(c.Events.change)},multiplySelf:function(e){this._x*=e.x;this._y*=e.y;return this.trigger(c.Events.change)},multiplyScalar:function(e){this._x*=e;this._y*=e;return this.trigger(c.Events.change)},divideScalar:function(e){return e?(this._x/=e,this._y/=e,this.trigger(c.Events.change)):this.clear()},
+negate:function(){return this.multiplyScalar(-1)},dot:function(c){return this._x*c.x+this._y*c.y},lengthSquared:function(){return this._x*this._x+this._y*this._y},length:function(){return Math.sqrt(this.lengthSquared())},normalize:function(){return this.divideScalar(this.length())},distanceTo:function(c){return Math.sqrt(this.distanceToSquared(c))},distanceToSquared:function(c){var a=this._x-c.x;c=this._y-c.y;return a*a+c*c},setLength:function(c){return this.normalize().multiplyScalar(c)},equals:function(c,
+a){a="undefined"===typeof a?.0001:a;return this.distanceTo(c)<a},lerp:function(c,a){return this.set((c.x-this._x)*a+this._x,(c.y-this._y)*a+this._y)},isZero:function(c){c="undefined"===typeof c?.0001:c;return this.length()<c},toString:function(){return this._x+", "+this._y},toObject:function(){return{x:this._x,y:this._y}},rotate:function(c){var a=Math.cos(c);c=Math.sin(c);this._x=this._x*a-this._y*c;this._y=this._x*c+this._y*a;return this}},h={enumerable:!0,get:function(){return this._x},set:function(e){this._x=
+e;this.trigger(c.Events.change,"x")}},d={enumerable:!0,get:function(){return this._y},set:function(e){this._y=e;this.trigger(c.Events.change,"y")}};c.Vector.prototype.bind=c.Vector.prototype.on=function(){this._bound||(this._x=this.x,this._y=this.y,Object.defineProperty(this,"x",h),Object.defineProperty(this,"y",d),k.extend(this,l),this._bound=!0);c.Utils.Events.bind.apply(this,arguments);return this}})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Commands,m=c.Utils,l=c.Anchor=function(d,e,a,g,n,f,t){c.Vector.call(this,d,e);this._broadcast=m.bind(function(){this.trigger(c.Events.change)},this);this._command=t||k.move;this._relative=!0;if(!t)return this;l.AppendCurveProperties(this);m.isNumber(a)&&(this.controls.left.x=a);m.isNumber(g)&&(this.controls.left.y=g);m.isNumber(n)&&(this.controls.right.x=n);m.isNumber(f)&&(this.controls.right.y=f)};m.extend(l,{AppendCurveProperties:function(d){d.controls={left:new c.Vector(0,
+0),right:new c.Vector(0,0)}}});var h={listen:function(){m.isObject(this.controls)||l.AppendCurveProperties(this);this.controls.left.bind(c.Events.change,this._broadcast);this.controls.right.bind(c.Events.change,this._broadcast);return this},ignore:function(){this.controls.left.unbind(c.Events.change,this._broadcast);this.controls.right.unbind(c.Events.change,this._broadcast);return this},clone:function(){var d=this.controls,d=new c.Anchor(this.x,this.y,d&&d.left.x,d&&d.left.y,d&&d.right.x,d&&d.right.y,
+this.command);d.relative=this._relative;return d},toObject:function(){var c={x:this.x,y:this.y};this._command&&(c.command=this._command);this._relative&&(c.relative=this._relative);this.controls&&(c.controls={left:this.controls.left.toObject(),right:this.controls.right.toObject()});return c},toString:function(){return this.controls?[this._x,this._y,this.controls.left.x,this.controls.left.y,this.controls.right.x,this.controls.right.y].join(", "):[this._x,this._y].join(", ")}};Object.defineProperty(l.prototype,
+"command",{enumerable:!0,get:function(){return this._command},set:function(d){this._command=d;this._command!==k.curve||m.isObject(this.controls)||l.AppendCurveProperties(this);return this.trigger(c.Events.change)}});Object.defineProperty(l.prototype,"relative",{enumerable:!0,get:function(){return this._relative},set:function(d){if(this._relative==d)return this;this._relative=!!d;return this.trigger(c.Events.change)}});m.extend(l.prototype,c.Vector.prototype,h);c.Anchor.prototype.bind=c.Anchor.prototype.on=
+function(){c.Vector.prototype.bind.apply(this,arguments);m.extend(this,h)};c.Anchor.prototype.unbind=c.Anchor.prototype.off=function(){c.Vector.prototype.unbind.apply(this,arguments);m.extend(this,h)}})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=Math.cos,m=Math.sin,l=Math.tan,h=c.Utils,d=c.Matrix=function(e,a,g,d,f,t){this.elements=new c.Array(9);var n=e;h.isArray(n)||(n=h.toArray(arguments));this.identity().set(n)};h.extend(d,{Identity:[1,0,0,0,1,0,0,0,1],Multiply:function(e,a,g){if(3>=a.length){g=a[0]||0;var d=a[1]||0;a=a[2]||0;return{x:e[0]*g+e[1]*d+e[2]*a,y:e[3]*g+e[4]*d+e[5]*a,z:e[6]*g+e[7]*d+e[8]*a}}var d=e[0],f=e[1],t=e[2],v=e[3],h=e[4],k=e[5],m=e[6],l=e[7];e=e[8];var u=a[0],r=a[1],q=a[2],w=a[3],p=a[4],C=a[5],E=
+a[6],H=a[7];a=a[8];g=g||new c.Array(9);g[0]=d*u+f*w+t*E;g[1]=d*r+f*p+t*H;g[2]=d*q+f*C+t*a;g[3]=v*u+h*w+k*E;g[4]=v*r+h*p+k*H;g[5]=v*q+h*C+k*a;g[6]=m*u+l*w+e*E;g[7]=m*r+l*p+e*H;g[8]=m*q+l*C+e*a;return g}});h.extend(d.prototype,c.Utils.Events,{set:function(e){var a=e;h.isArray(a)||(a=h.toArray(arguments));h.extend(this.elements,a);return this.trigger(c.Events.change)},identity:function(){this.set(d.Identity);return this},multiply:function(e,a,g,d,f,t,v,k,m){var n=arguments,B=n.length;if(1>=B)return h.each(this.elements,
+function(a,c){this.elements[c]=a*e},this),this.trigger(c.Events.change);if(3>=B)return e=e||0,a=a||0,g=g||0,f=this.elements,{x:f[0]*e+f[1]*a+f[2]*g,y:f[3]*e+f[4]*a+f[5]*g,z:f[6]*e+f[7]*a+f[8]*g};var l=this.elements,B=l[0],z=l[1],q=l[2],w=l[3],p=l[4],C=l[5],E=l[6],H=l[7],l=l[8],G=n[0],F=n[1],I=n[2],O=n[3],N=n[4],P=n[5],M=n[6],L=n[7],n=n[8];this.elements[0]=B*G+z*O+q*M;this.elements[1]=B*F+z*N+q*L;this.elements[2]=B*I+z*P+q*n;this.elements[3]=w*G+p*O+C*M;this.elements[4]=w*F+p*N+C*L;this.elements[5]=
+w*I+p*P+C*n;this.elements[6]=E*G+H*O+l*M;this.elements[7]=E*F+H*N+l*L;this.elements[8]=E*I+H*P+l*n;return this.trigger(c.Events.change)},inverse:function(e){var a=this.elements;e=e||new c.Matrix;var g=a[0],d=a[1],f=a[2],t=a[3],v=a[4],h=a[5],k=a[6],l=a[7],a=a[8],m=a*v-h*l,u=-a*t+h*k,r=l*t-v*k,q=g*m+d*u+f*r;if(!q)return null;q=1/q;e.elements[0]=m*q;e.elements[1]=(-a*d+f*l)*q;e.elements[2]=(h*d-f*v)*q;e.elements[3]=u*q;e.elements[4]=(a*g-f*k)*q;e.elements[5]=(-h*g+f*t)*q;e.elements[6]=r*q;e.elements[7]=
+(-l*g+d*k)*q;e.elements[8]=(v*g-d*t)*q;return e},scale:function(c,a){1>=arguments.length&&(a=c);return this.multiply(c,0,0,0,a,0,0,0,1)},rotate:function(c){var a=k(c);c=m(c);return this.multiply(a,-c,0,c,a,0,0,0,1)},translate:function(c,a){return this.multiply(1,0,c,0,1,a,0,0,1)},skewX:function(c){c=l(c);return this.multiply(1,c,0,0,1,0,0,0,1)},skewY:function(c){c=l(c);return this.multiply(1,0,0,c,1,0,0,0,1)},toString:function(c){var a=[];this.toArray(c,a);return a.join(" ")},toArray:function(c,a){var g=
+this.elements,e=!!a,f=parseFloat(g[0].toFixed(3)),d=parseFloat(g[1].toFixed(3)),v=parseFloat(g[2].toFixed(3)),h=parseFloat(g[3].toFixed(3)),k=parseFloat(g[4].toFixed(3)),l=parseFloat(g[5].toFixed(3));if(c){c=parseFloat(g[6].toFixed(3));var m=parseFloat(g[7].toFixed(3)),g=parseFloat(g[8].toFixed(3));if(e){a[0]=f;a[1]=h;a[2]=c;a[3]=d;a[4]=k;a[5]=m;a[6]=v;a[7]=l;a[8]=g;return}return[f,h,c,d,k,m,v,l,g]}if(e)a[0]=f,a[1]=h,a[2]=d,a[3]=k,a[4]=v,a[5]=l;else return[f,h,d,k,v,l]},clone:function(){var e=this.elements[0];
+var a=this.elements[1];var g=this.elements[2];var d=this.elements[3];var f=this.elements[4];return new c.Matrix(e,a,g,d,f,this.elements[5],this.elements[6],this.elements[7],this.elements[8])}})})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils.mod,m=c.Utils.toFixed,l=c.Utils,h={version:1.1,ns:"http://www.w3.org/2000/svg",xlink:"http://www.w3.org/1999/xlink",alignments:{left:"start",center:"middle",right:"end"},createElement:function(c,a){var g=document.createElementNS(h.ns,c);"svg"===c&&(a=l.defaults(a||{},{version:h.version}));l.isEmpty(a)||h.setAttributes(g,a);return g},setAttributes:function(c,a){for(var g=Object.keys(a),e=0;e<g.length;e++)/href/.test(g[e])?c.setAttributeNS(h.xlink,g[e],a[g[e]]):c.setAttribute(g[e],
+a[g[e]]);return this},removeAttributes:function(c,a){for(var g in a)c.removeAttribute(g);return this},toString:function(e,a){for(var g=e.length,d=g-1,f,t="",h=0;h<g;h++){var l=e[h],z=a?k(h-1,g):Math.max(h-1,0);a&&k(h+1,g);var A=e[z];var x=m(l._x);var u=m(l._y);switch(l._command){case c.Commands.close:var r=c.Commands.close;break;case c.Commands.curve:var q=A.controls&&A.controls.right||c.Vector.zero;r=l.controls&&l.controls.left||c.Vector.zero;A._relative?(z=m(q.x+A.x),A=m(q.y+A.y)):(z=m(q.x),A=m(q.y));
+if(l._relative){q=m(r.x+l.x);var w=m(r.y+l.y)}else q=m(r.x),w=m(r.y);r=(0===h?c.Commands.move:c.Commands.curve)+" "+z+" "+A+" "+q+" "+w+" "+x+" "+u;break;case c.Commands.move:f=l;r=c.Commands.move+" "+x+" "+u;break;default:r=l._command+" "+x+" "+u}h>=d&&a&&(l._command===c.Commands.curve&&(u=f,A=l.controls&&l.controls.right||l,x=u.controls&&u.controls.left||u,l._relative?(z=m(A.x+l.x),A=m(A.y+l.y)):(z=m(A.x),A=m(A.y)),u._relative?(q=m(x.x+u.x),w=m(x.y+u.y)):(q=m(x.x),w=m(x.y)),x=m(u.x),u=m(u.y),r+=
+" C "+z+" "+A+" "+q+" "+w+" "+x+" "+u),r+=" Z");t+=r+" "}return t},getClip:function(c){var a=c._renderer.clip;if(!a){for(var g=c;g.parent;)g=g.parent;a=c._renderer.clip=h.createElement("clipPath");g.defs.appendChild(a)}return a},group:{appendChild:function(c){var a=c._renderer.elem;if(a){var g=a.nodeName;!g||/(radial|linear)gradient/i.test(g)||c._clip||this.elem.appendChild(a)}},removeChild:function(c){var a=c._renderer.elem;a&&a.parentNode==this.elem&&a.nodeName&&(c._clip||this.elem.removeChild(a))},
+orderChild:function(c){this.elem.appendChild(c._renderer.elem)},renderChild:function(c){h[c._renderer.type].render.call(c,this)},render:function(c){this._update();if(0===this._opacity&&!this._flagOpacity)return this;this._renderer.elem||(this._renderer.elem=h.createElement("g",{id:this.id}),c.appendChild(this._renderer.elem));var a={domElement:c,elem:this._renderer.elem};(this._matrix.manual||this._flagMatrix)&&this._renderer.elem.setAttribute("transform","matrix("+this._matrix.toString()+")");for(var g=
+0;g<this.children.length;g++){var e=this.children[g];h[e._renderer.type].render.call(e,c)}this._flagOpacity&&this._renderer.elem.setAttribute("opacity",this._opacity);this._flagAdditions&&this.additions.forEach(h.group.appendChild,a);this._flagSubtractions&&this.subtractions.forEach(h.group.removeChild,a);this._flagOrder&&this.children.forEach(h.group.orderChild,a);this._flagMask&&(this._mask?this._renderer.elem.setAttribute("clip-path","url(#"+this._mask.id+")"):this._renderer.elem.removeAttribute("clip-path"));
+return this.flagReset()}},path:{render:function(c){this._update();if(0===this._opacity&&!this._flagOpacity)return this;var a={};if(this._matrix.manual||this._flagMatrix)a.transform="matrix("+this._matrix.toString()+")";if(this._flagVertices){var g=h.toString(this._vertices,this._closed);a.d=g}this._fill&&this._fill._renderer&&(this._fill._update(),h[this._fill._renderer.type].render.call(this._fill,c,!0));this._flagFill&&(a.fill=this._fill&&this._fill.id?"url(#"+this._fill.id+")":this._fill);this._stroke&&
+this._stroke._renderer&&(this._stroke._update(),h[this._stroke._renderer.type].render.call(this._stroke,c,!0));this._flagStroke&&(a.stroke=this._stroke&&this._stroke.id?"url(#"+this._stroke.id+")":this._stroke);this._flagLinewidth&&(a["stroke-width"]=this._linewidth);this._flagOpacity&&(a["stroke-opacity"]=this._opacity,a["fill-opacity"]=this._opacity);this._flagVisible&&(a.visibility=this._visible?"visible":"hidden");this._flagCap&&(a["stroke-linecap"]=this._cap);this._flagJoin&&(a["stroke-linejoin"]=
+this._join);this._flagMiter&&(a["stroke-miterlimit"]=this._miter);this._renderer.elem?h.setAttributes(this._renderer.elem,a):(a.id=this.id,this._renderer.elem=h.createElement("path",a),c.appendChild(this._renderer.elem));this._flagClip&&(c=h.getClip(this),a=this._renderer.elem,this._clip?(a.removeAttribute("id"),c.setAttribute("id",this.id),c.appendChild(a)):(c.removeAttribute("id"),a.setAttribute("id",this.id),this.parent._renderer.elem.appendChild(a)));return this.flagReset()}},text:{render:function(c){this._update();
+var a={};if(this._matrix.manual||this._flagMatrix)a.transform="matrix("+this._matrix.toString()+")";this._flagFamily&&(a["font-family"]=this._family);this._flagSize&&(a["font-size"]=this._size);this._flagLeading&&(a["line-height"]=this._leading);this._flagAlignment&&(a["text-anchor"]=h.alignments[this._alignment]||this._alignment);this._flagBaseline&&(a["alignment-baseline"]=a["dominant-baseline"]=this._baseline);this._flagStyle&&(a["font-style"]=this._style);this._flagWeight&&(a["font-weight"]=this._weight);
+this._flagDecoration&&(a["text-decoration"]=this._decoration);this._fill&&this._fill._renderer&&(this._fill._update(),h[this._fill._renderer.type].render.call(this._fill,c,!0));this._flagFill&&(a.fill=this._fill&&this._fill.id?"url(#"+this._fill.id+")":this._fill);this._stroke&&this._stroke._renderer&&(this._stroke._update(),h[this._stroke._renderer.type].render.call(this._stroke,c,!0));this._flagStroke&&(a.stroke=this._stroke&&this._stroke.id?"url(#"+this._stroke.id+")":this._stroke);this._flagLinewidth&&
+(a["stroke-width"]=this._linewidth);this._flagOpacity&&(a.opacity=this._opacity);this._flagVisible&&(a.visibility=this._visible?"visible":"hidden");this._renderer.elem?h.setAttributes(this._renderer.elem,a):(a.id=this.id,this._renderer.elem=h.createElement("text",a),c.defs.appendChild(this._renderer.elem));this._flagClip&&(c=h.getClip(this),a=this._renderer.elem,this._clip?(a.removeAttribute("id"),c.setAttribute("id",this.id),c.appendChild(a)):(c.removeAttribute("id"),a.setAttribute("id",this.id),
+this.parent._renderer.elem.appendChild(a)));this._flagValue&&(this._renderer.elem.textContent=this._value);return this.flagReset()}},"linear-gradient":{render:function(c,a){a||this._update();a={};this._flagEndPoints&&(a.x1=this.left._x,a.y1=this.left._y,a.x2=this.right._x,a.y2=this.right._y);this._flagSpread&&(a.spreadMethod=this._spread);this._renderer.elem?h.setAttributes(this._renderer.elem,a):(a.id=this.id,a.gradientUnits="userSpaceOnUse",this._renderer.elem=h.createElement("linearGradient",a),
+c.defs.appendChild(this._renderer.elem));if(this._flagStops){if(c=this._renderer.elem.childNodes.length!==this.stops.length)this._renderer.elem.childNodes.length=0;for(a=0;a<this.stops.length;a++){var g=this.stops[a],d={};g._flagOffset&&(d.offset=100*g._offset+"%");g._flagColor&&(d["stop-color"]=g._color);g._flagOpacity&&(d["stop-opacity"]=g._opacity);g._renderer.elem?h.setAttributes(g._renderer.elem,d):g._renderer.elem=h.createElement("stop",d);c&&this._renderer.elem.appendChild(g._renderer.elem);
+g.flagReset()}}return this.flagReset()}},"radial-gradient":{render:function(c,a){a||this._update();a={};this._flagCenter&&(a.cx=this.center._x,a.cy=this.center._y);this._flagFocal&&(a.fx=this.focal._x,a.fy=this.focal._y);this._flagRadius&&(a.r=this._radius);this._flagSpread&&(a.spreadMethod=this._spread);this._renderer.elem?h.setAttributes(this._renderer.elem,a):(a.id=this.id,a.gradientUnits="userSpaceOnUse",this._renderer.elem=h.createElement("radialGradient",a),c.defs.appendChild(this._renderer.elem));
+if(this._flagStops){if(c=this._renderer.elem.childNodes.length!==this.stops.length)this._renderer.elem.childNodes.length=0;for(a=0;a<this.stops.length;a++){var g=this.stops[a],d={};g._flagOffset&&(d.offset=100*g._offset+"%");g._flagColor&&(d["stop-color"]=g._color);g._flagOpacity&&(d["stop-opacity"]=g._opacity);g._renderer.elem?h.setAttributes(g._renderer.elem,d):g._renderer.elem=h.createElement("stop",d);c&&this._renderer.elem.appendChild(g._renderer.elem);g.flagReset()}}return this.flagReset()}},
+texture:{render:function(d,a){a||this._update();a={};var g={x:0,y:0},e=this.image;if(this._flagLoaded&&this.loaded)switch(e.nodeName.toLowerCase()){case "canvas":g.href=g["xlink:href"]=e.toDataURL("image/png");break;case "img":case "image":g.href=g["xlink:href"]=this.src}if(this._flagOffset||this._flagLoaded||this._flagScale)a.x=this._offset.x,a.y=this._offset.y,e&&(a.x-=e.width/2,a.y-=e.height/2,this._scale instanceof c.Vector?(a.x*=this._scale.x,a.y*=this._scale.y):(a.x*=this._scale,a.y*=this._scale)),
+0<a.x&&(a.x*=-1),0<a.y&&(a.y*=-1);if(this._flagScale||this._flagLoaded||this._flagRepeat)if(a.width=0,a.height=0,e){g.width=a.width=e.width;g.height=a.height=e.height;switch(this._repeat){case "no-repeat":a.width+=1,a.height+=1}this._scale instanceof c.Vector?(a.width*=this._scale.x,a.height*=this._scale.y):(a.width*=this._scale,a.height*=this._scale)}if(this._flagScale||this._flagLoaded)this._renderer.image?l.isEmpty(g)||h.setAttributes(this._renderer.image,g):this._renderer.image=h.createElement("image",
+g);this._renderer.elem?l.isEmpty(a)||h.setAttributes(this._renderer.elem,a):(a.id=this.id,a.patternUnits="userSpaceOnUse",this._renderer.elem=h.createElement("pattern",a),d.defs.appendChild(this._renderer.elem));this._renderer.elem&&this._renderer.image&&!this._renderer.appended&&(this._renderer.elem.appendChild(this._renderer.image),this._renderer.appended=!0);return this.flagReset()}}},d=c[c.Types.svg]=function(d){this.domElement=d.domElement||h.createElement("svg");this.scene=new c.Group;this.scene.parent=
+this;this.defs=h.createElement("defs");this.domElement.appendChild(this.defs);this.domElement.defs=this.defs;this.domElement.style.overflow="hidden"};l.extend(d,{Utils:h});l.extend(d.prototype,c.Utils.Events,{setSize:function(c,a){this.width=c;this.height=a;h.setAttributes(this.domElement,{width:c,height:a});return this},render:function(){h.group.render.call(this.scene,this.domElement);return this}})})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils.mod,m=c.Utils.toFixed,l=c.Utils.getRatio,h=c.Utils,d=function(a){return 1==a[0]&&0==a[3]&&0==a[1]&&1==a[4]&&0==a[2]&&0==a[5]},e={isHidden:/(none|transparent)/i,alignments:{left:"start",middle:"center",right:"end"},shim:function(a){a.tagName="canvas";a.nodeType=1;return a},group:{renderChild:function(a){e[a._renderer.type].render.call(a,this.ctx,!0,this.clip)},render:function(a){this._update();var c=this._matrix.elements,f=this.parent;this._renderer.opacity=this._opacity*
+(f&&f._renderer?f._renderer.opacity:1);var f=d(c),g=this._mask;this._renderer.context||(this._renderer.context={});this._renderer.context.ctx=a;f||(a.save(),a.transform(c[0],c[3],c[1],c[4],c[2],c[5]));g&&e[g._renderer.type].render.call(g,a,!0);if(0<this.opacity&&0!==this.scale)for(c=0;c<this.children.length;c++)g=this.children[c],e[g._renderer.type].render.call(g,a);f||a.restore();return this.flagReset()}},path:{render:function(a,n,f){this._update();var g=this._matrix.elements;var v=this._stroke;
+var l=this._linewidth;var z=this._fill;var A=this._opacity*this.parent._renderer.opacity;var x=this._visible;var u=this._cap;var r=this._join;var q=this._miter;var w=this._closed;var p=this._vertices;var C=p.length;var E=C-1;var H=d(g);var G=this._clip;if(!n&&(!x||G))return this;H||(a.save(),a.transform(g[0],g[3],g[1],g[4],g[2],g[5]));z&&(h.isString(z)?a.fillStyle=z:(e[z._renderer.type].render.call(z,a),a.fillStyle=z._renderer.effect));v&&(h.isString(v)?a.strokeStyle=v:(e[v._renderer.type].render.call(v,
+a),a.strokeStyle=v._renderer.effect));l&&(a.lineWidth=l);q&&(a.miterLimit=q);r&&(a.lineJoin=r);u&&(a.lineCap=u);h.isNumber(A)&&(a.globalAlpha=A);a.beginPath();for(g=0;g<p.length;g++)switch(n=p[g],x=m(n._x),u=m(n._y),n._command){case c.Commands.close:a.closePath();break;case c.Commands.curve:A=w?k(g-1,C):Math.max(g-1,0);w&&k(g+1,C);r=p[A];q=r.controls&&r.controls.right||c.Vector.zero;var F=n.controls&&n.controls.left||c.Vector.zero;r._relative?(A=q.x+m(r._x),q=q.y+m(r._y)):(A=m(q.x),q=m(q.y));n._relative?
+(r=F.x+m(n._x),F=F.y+m(n._y)):(r=m(F.x),F=m(F.y));a.bezierCurveTo(A,q,r,F,x,u);g>=E&&w&&(u=I,r=n.controls&&n.controls.right||c.Vector.zero,x=u.controls&&u.controls.left||c.Vector.zero,n._relative?(A=r.x+m(n._x),q=r.y+m(n._y)):(A=m(r.x),q=m(r.y)),u._relative?(r=x.x+m(u._x),F=x.y+m(u._y)):(r=m(x.x),F=m(x.y)),x=m(u._x),u=m(u._y),a.bezierCurveTo(A,q,r,F,x,u));break;case c.Commands.line:a.lineTo(x,u);break;case c.Commands.move:var I=n;a.moveTo(x,u)}w&&a.closePath();if(!G&&!f){if(!e.isHidden.test(z)){if(w=
+z._renderer&&z._renderer.offset)a.save(),a.translate(-z._renderer.offset.x,-z._renderer.offset.y),a.scale(z._renderer.scale.x,z._renderer.scale.y);a.fill();w&&a.restore()}if(!e.isHidden.test(v)){if(w=v._renderer&&v._renderer.offset)a.save(),a.translate(-v._renderer.offset.x,-v._renderer.offset.y),a.scale(v._renderer.scale.x,v._renderer.scale.y),a.lineWidth=l/v._renderer.scale.x;a.stroke();w&&a.restore()}}H||a.restore();G&&!f&&a.clip();return this.flagReset()}},text:{render:function(a,c,f){this._update();
+var g=this._matrix.elements,n=this._stroke,k=this._linewidth,l=this._fill,A=this._opacity*this.parent._renderer.opacity,x=this._visible,u=d(g),r=l._renderer&&l._renderer.offset&&n._renderer&&n._renderer.offset,q=this._clip;if(!c&&(!x||q))return this;u||(a.save(),a.transform(g[0],g[3],g[1],g[4],g[2],g[5]));r||(a.font=[this._style,this._weight,this._size+"px/"+this._leading+"px",this._family].join(" "));a.textAlign=e.alignments[this._alignment]||this._alignment;a.textBaseline=this._baseline;l&&(h.isString(l)?
+a.fillStyle=l:(e[l._renderer.type].render.call(l,a),a.fillStyle=l._renderer.effect));n&&(h.isString(n)?a.strokeStyle=n:(e[n._renderer.type].render.call(n,a),a.strokeStyle=n._renderer.effect));k&&(a.lineWidth=k);h.isNumber(A)&&(a.globalAlpha=A);q||f||(e.isHidden.test(l)||(l._renderer&&l._renderer.offset?(c=m(l._renderer.scale.x),g=m(l._renderer.scale.y),a.save(),a.translate(-m(l._renderer.offset.x),-m(l._renderer.offset.y)),a.scale(c,g),c=this._size/l._renderer.scale.y,g=this._leading/l._renderer.scale.y,
+a.font=[this._style,this._weight,m(c)+"px/",m(g)+"px",this._family].join(" "),c=l._renderer.offset.x/l._renderer.scale.x,l=l._renderer.offset.y/l._renderer.scale.y,a.fillText(this.value,m(c),m(l)),a.restore()):a.fillText(this.value,0,0)),e.isHidden.test(n)||(n._renderer&&n._renderer.offset?(c=m(n._renderer.scale.x),g=m(n._renderer.scale.y),a.save(),a.translate(-m(n._renderer.offset.x),-m(n._renderer.offset.y)),a.scale(c,g),c=this._size/n._renderer.scale.y,g=this._leading/n._renderer.scale.y,a.font=
+[this._style,this._weight,m(c)+"px/",m(g)+"px",this._family].join(" "),c=n._renderer.offset.x/n._renderer.scale.x,l=n._renderer.offset.y/n._renderer.scale.y,n=k/n._renderer.scale.x,a.lineWidth=m(n),a.strokeText(this.value,m(c),m(l)),a.restore()):a.strokeText(this.value,0,0)));u||a.restore();q&&!f&&a.clip();return this.flagReset()}},"linear-gradient":{render:function(a){this._update();if(!this._renderer.effect||this._flagEndPoints||this._flagStops)for(this._renderer.effect=a.createLinearGradient(this.left._x,
+this.left._y,this.right._x,this.right._y),a=0;a<this.stops.length;a++){var c=this.stops[a];this._renderer.effect.addColorStop(c._offset,c._color)}return this.flagReset()}},"radial-gradient":{render:function(a){this._update();if(!this._renderer.effect||this._flagCenter||this._flagFocal||this._flagRadius||this._flagStops)for(this._renderer.effect=a.createRadialGradient(this.center._x,this.center._y,0,this.focal._x,this.focal._y,this._radius),a=0;a<this.stops.length;a++){var c=this.stops[a];this._renderer.effect.addColorStop(c._offset,
+c._color)}return this.flagReset()}},texture:{render:function(a){this._update();var d=this.image;if(!this._renderer.effect||(this._flagLoaded||this._flagImage||this._flagVideo||this._flagRepeat)&&this.loaded)this._renderer.effect=a.createPattern(this.image,this._repeat);if(this._flagOffset||this._flagLoaded||this._flagScale)this._renderer.offset instanceof c.Vector||(this._renderer.offset=new c.Vector),this._renderer.offset.x=-this._offset.x,this._renderer.offset.y=-this._offset.y,d&&(this._renderer.offset.x+=
+d.width/2,this._renderer.offset.y+=d.height/2,this._scale instanceof c.Vector?(this._renderer.offset.x*=this._scale.x,this._renderer.offset.y*=this._scale.y):(this._renderer.offset.x*=this._scale,this._renderer.offset.y*=this._scale));if(this._flagScale||this._flagLoaded)this._renderer.scale instanceof c.Vector||(this._renderer.scale=new c.Vector),this._scale instanceof c.Vector?this._renderer.scale.copy(this._scale):this._renderer.scale.set(this._scale,this._scale);return this.flagReset()}}},a=c[c.Types.canvas]=
+function(a){var d=!1!==a.smoothing;this.domElement=a.domElement||document.createElement("canvas");this.ctx=this.domElement.getContext("2d");this.overdraw=a.overdraw||!1;h.isUndefined(this.ctx.imageSmoothingEnabled)||(this.ctx.imageSmoothingEnabled=d);this.scene=new c.Group;this.scene.parent=this};h.extend(a,{Utils:e});h.extend(a.prototype,c.Utils.Events,{setSize:function(a,c,f){this.width=a;this.height=c;this.ratio=h.isUndefined(f)?l(this.ctx):f;this.domElement.width=a*this.ratio;this.domElement.height=
+c*this.ratio;this.domElement.style&&h.extend(this.domElement.style,{width:a+"px",height:c+"px"});return this},render:function(){var a=1===this.ratio;a||(this.ctx.save(),this.ctx.scale(this.ratio,this.ratio));this.overdraw||this.ctx.clearRect(0,0,this.width,this.height);e.group.render.call(this.scene,this.ctx);a||this.ctx.restore();return this}})})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.root,m=c.Matrix.Multiply,l=c.Utils.mod,h=[1,0,0,0,1,0,0,0,1],d=new c.Array(9),e=c.Utils.getRatio,a=c.Utils.toFixed,g=c.Utils,n={isHidden:/(none|transparent)/i,canvas:k.document?k.document.createElement("canvas"):{getContext:g.identity},alignments:{left:"start",middle:"center",right:"end"},matrix:new c.Matrix,uv:new c.Array([0,0,1,0,0,1,0,1,1,0,1,1]),group:{removeChild:function(a,c){if(a.children)for(var f=0;f<a.children.length;f++)n.group.removeChild(a.children[f],c);else c.deleteTexture(a._renderer.texture),
+delete a._renderer.texture},renderChild:function(a){n[a._renderer.type].render.call(a,this.gl,this.program)},render:function(a,g){this._update();var f=this.parent,e=f._matrix&&f._matrix.manual||f._flagMatrix,h=this._matrix.manual||this._flagMatrix;if(e||h)this._renderer.matrix||(this._renderer.matrix=new c.Array(9)),this._matrix.toArray(!0,d),m(d,f._renderer.matrix,this._renderer.matrix),this._renderer.scale=this._scale*f._renderer.scale,e&&(this._flagMatrix=!0);this._mask&&(a.enable(a.STENCIL_TEST),
+a.stencilFunc(a.ALWAYS,1,1),a.colorMask(!1,!1,!1,!0),a.stencilOp(a.KEEP,a.KEEP,a.INCR),n[this._mask._renderer.type].render.call(this._mask,a,g,this),a.colorMask(!0,!0,!0,!0),a.stencilFunc(a.NOTEQUAL,0,1),a.stencilOp(a.KEEP,a.KEEP,a.KEEP));this._flagOpacity=f._flagOpacity||this._flagOpacity;this._renderer.opacity=this._opacity*(f&&f._renderer?f._renderer.opacity:1);if(this._flagSubtractions)for(f=0;f<this.subtractions.length;f++)n.group.removeChild(this.subtractions[f],a);this.children.forEach(n.group.renderChild,
+{gl:a,program:g});this._mask&&(a.colorMask(!1,!1,!1,!1),a.stencilOp(a.KEEP,a.KEEP,a.DECR),n[this._mask._renderer.type].render.call(this._mask,a,g,this),a.colorMask(!0,!0,!0,!0),a.stencilFunc(a.NOTEQUAL,0,1),a.stencilOp(a.KEEP,a.KEEP,a.KEEP),a.disable(a.STENCIL_TEST));return this.flagReset()}},path:{updateCanvas:function(f){var d=f._vertices;var e=this.canvas;var h=this.ctx;var k=f._renderer.scale;var m=f._stroke,x=f._linewidth,u=f._fill;var r=f._renderer.opacity||f._opacity;var q=f._cap;var w=f._join;
+var p=f._miter;var C=f._closed,E=d.length,H=E-1;e.width=Math.max(Math.ceil(f._renderer.rect.width*k),1);e.height=Math.max(Math.ceil(f._renderer.rect.height*k),1);var G=f._renderer.rect.centroid,F=G.x,G=G.y;h.clearRect(0,0,e.width,e.height);u&&(g.isString(u)?h.fillStyle=u:(n[u._renderer.type].render.call(u,h,f),h.fillStyle=u._renderer.effect));m&&(g.isString(m)?h.strokeStyle=m:(n[m._renderer.type].render.call(m,h,f),h.strokeStyle=m._renderer.effect));x&&(h.lineWidth=x);p&&(h.miterLimit=p);w&&(h.lineJoin=
+w);q&&(h.lineCap=q);g.isNumber(r)&&(h.globalAlpha=r);h.save();h.scale(k,k);h.translate(F,G);h.beginPath();for(f=0;f<d.length;f++)switch(b=d[f],k=a(b._x),r=a(b._y),b._command){case c.Commands.close:h.closePath();break;case c.Commands.curve:e=C?l(f-1,E):Math.max(f-1,0);C&&l(f+1,E);q=d[e];w=q.controls&&q.controls.right||c.Vector.zero;p=b.controls&&b.controls.left||c.Vector.zero;q._relative?(e=a(w.x+q._x),w=a(w.y+q._y)):(e=a(w.x),w=a(w.y));b._relative?(q=a(p.x+b._x),p=a(p.y+b._y)):(q=a(p.x),p=a(p.y));
+h.bezierCurveTo(e,w,q,p,k,r);f>=H&&C&&(r=I,q=b.controls&&b.controls.right||c.Vector.zero,k=r.controls&&r.controls.left||c.Vector.zero,b._relative?(e=a(q.x+b._x),w=a(q.y+b._y)):(e=a(q.x),w=a(q.y)),r._relative?(q=a(k.x+r._x),p=a(k.y+r._y)):(q=a(k.x),p=a(k.y)),k=a(r._x),r=a(r._y),h.bezierCurveTo(e,w,q,p,k,r));break;case c.Commands.line:h.lineTo(k,r);break;case c.Commands.move:var I=b;h.moveTo(k,r)}C&&h.closePath();if(!n.isHidden.test(u)){if(d=u._renderer&&u._renderer.offset)h.save(),h.translate(-u._renderer.offset.x,
+-u._renderer.offset.y),h.scale(u._renderer.scale.x,u._renderer.scale.y);h.fill();d&&h.restore()}if(!n.isHidden.test(m)){if(d=m._renderer&&m._renderer.offset)h.save(),h.translate(-m._renderer.offset.x,-m._renderer.offset.y),h.scale(m._renderer.scale.x,m._renderer.scale.y),h.lineWidth=x/m._renderer.scale.x;h.stroke();d&&h.restore()}h.restore()},getBoundingClientRect:function(a,c,d){var f=Infinity,e=-Infinity,n=Infinity,h=-Infinity;a.forEach(function(a){var c=a.x,d=a.y,g=a.controls;n=Math.min(d,n);f=
+Math.min(c,f);e=Math.max(c,e);h=Math.max(d,h);if(a.controls){var k=g.left;var t=g.right;k&&t&&(g=a._relative?k.x+c:k.x,k=a._relative?k.y+d:k.y,c=a._relative?t.x+c:t.x,a=a._relative?t.y+d:t.y,g&&k&&c&&a&&(n=Math.min(k,a,n),f=Math.min(g,c,f),e=Math.max(g,c,e),h=Math.max(k,a,h)))}});g.isNumber(c)&&(n-=c,f-=c,e+=c,h+=c);d.top=n;d.left=f;d.right=e;d.bottom=h;d.width=e-f;d.height=h-n;d.centroid||(d.centroid={});d.centroid.x=-f;d.centroid.y=-n},render:function(a,g,e){if(!this._visible||!this._opacity)return this;
+this._update();var f=this.parent,h=this._matrix.manual||this._flagMatrix,k=this._flagVertices||this._flagFill||this._fill instanceof c.LinearGradient&&(this._fill._flagSpread||this._fill._flagStops||this._fill._flagEndPoints)||this._fill instanceof c.RadialGradient&&(this._fill._flagSpread||this._fill._flagStops||this._fill._flagRadius||this._fill._flagCenter||this._fill._flagFocal)||this._fill instanceof c.Texture&&(this._fill._flagLoaded&&this._fill.loaded||this._fill._flagOffset||this._fill._flagScale)||
+this._stroke instanceof c.LinearGradient&&(this._stroke._flagSpread||this._stroke._flagStops||this._stroke._flagEndPoints)||this._stroke instanceof c.RadialGradient&&(this._stroke._flagSpread||this._stroke._flagStops||this._stroke._flagRadius||this._stroke._flagCenter||this._stroke._flagFocal)||this._stroke instanceof c.Texture&&(this._stroke._flagLoaded&&this._stroke.loaded||this._stroke._flagOffset||this._fill._flagScale)||this._flagStroke||this._flagLinewidth||this._flagOpacity||f._flagOpacity||
+this._flagVisible||this._flagCap||this._flagJoin||this._flagMiter||this._flagScale||!this._renderer.texture;if(f._matrix.manual||f._flagMatrix||h)this._renderer.matrix||(this._renderer.matrix=new c.Array(9)),this._matrix.toArray(!0,d),m(d,f._renderer.matrix,this._renderer.matrix),this._renderer.scale=this._scale*f._renderer.scale;k&&(this._renderer.rect||(this._renderer.rect={}),this._renderer.triangles||(this._renderer.triangles=new c.Array(12)),this._renderer.opacity=this._opacity*f._renderer.opacity,
+n.path.getBoundingClientRect(this._vertices,this._linewidth,this._renderer.rect),n.getTriangles(this._renderer.rect,this._renderer.triangles),n.updateBuffer.call(n,a,this,g),n.updateTexture.call(n,a,this));if(!this._clip||e)return a.bindBuffer(a.ARRAY_BUFFER,this._renderer.textureCoordsBuffer),a.vertexAttribPointer(g.textureCoords,2,a.FLOAT,!1,0,0),a.bindTexture(a.TEXTURE_2D,this._renderer.texture),a.uniformMatrix3fv(g.matrix,!1,this._renderer.matrix),a.bindBuffer(a.ARRAY_BUFFER,this._renderer.buffer),
+a.vertexAttribPointer(g.position,2,a.FLOAT,!1,0,0),a.drawArrays(a.TRIANGLES,0,6),this.flagReset()}},text:{updateCanvas:function(c){var f=this.canvas,d=this.ctx,e=c._renderer.scale,h=c._stroke,k=c._linewidth*e,l=c._fill,m=c._renderer.opacity||c._opacity;f.width=Math.max(Math.ceil(c._renderer.rect.width*e),1);f.height=Math.max(Math.ceil(c._renderer.rect.height*e),1);var r=c._renderer.rect.centroid,q=r.x,r=r.y,w=l._renderer&&l._renderer.offset&&h._renderer&&h._renderer.offset;d.clearRect(0,0,f.width,
+f.height);w||(d.font=[c._style,c._weight,c._size+"px/"+c._leading+"px",c._family].join(" "));d.textAlign="center";d.textBaseline="middle";l&&(g.isString(l)?d.fillStyle=l:(n[l._renderer.type].render.call(l,d,c),d.fillStyle=l._renderer.effect));h&&(g.isString(h)?d.strokeStyle=h:(n[h._renderer.type].render.call(h,d,c),d.strokeStyle=h._renderer.effect));k&&(d.lineWidth=k);g.isNumber(m)&&(d.globalAlpha=m);d.save();d.scale(e,e);d.translate(q,r);n.isHidden.test(l)||(l._renderer&&l._renderer.offset?(f=a(l._renderer.scale.x),
+e=a(l._renderer.scale.y),d.save(),d.translate(-a(l._renderer.offset.x),-a(l._renderer.offset.y)),d.scale(f,e),f=c._size/l._renderer.scale.y,e=c._leading/l._renderer.scale.y,d.font=[c._style,c._weight,a(f)+"px/",a(e)+"px",c._family].join(" "),f=l._renderer.offset.x/l._renderer.scale.x,l=l._renderer.offset.y/l._renderer.scale.y,d.fillText(c.value,a(f),a(l)),d.restore()):d.fillText(c.value,0,0));n.isHidden.test(h)||(h._renderer&&h._renderer.offset?(f=a(h._renderer.scale.x),e=a(h._renderer.scale.y),d.save(),
+d.translate(-a(h._renderer.offset.x),-a(h._renderer.offset.y)),d.scale(f,e),f=c._size/h._renderer.scale.y,e=c._leading/h._renderer.scale.y,d.font=[c._style,c._weight,a(f)+"px/",a(e)+"px",c._family].join(" "),f=h._renderer.offset.x/h._renderer.scale.x,l=h._renderer.offset.y/h._renderer.scale.y,h=k/h._renderer.scale.x,d.lineWidth=a(h),d.strokeText(c.value,a(f),a(l)),d.restore()):d.strokeText(c.value,0,0));d.restore()},getBoundingClientRect:function(a,c){var f=n.ctx;f.font=[a._style,a._weight,a._size+
+"px/"+a._leading+"px",a._family].join(" ");f.textAlign="center";f.textBaseline=a._baseline;var f=f.measureText(a._value).width,d=Math.max(a._size||a._leading);this._linewidth&&!n.isHidden.test(this._stroke)&&(d+=this._linewidth);var e=f/2,g=d/2;switch(n.alignments[a._alignment]||a._alignment){case n.alignments.left:c.left=0;c.right=f;break;case n.alignments.right:c.left=-f;c.right=0;break;default:c.left=-e,c.right=e}switch(a._baseline){case "bottom":c.top=-d;c.bottom=0;break;case "top":c.top=0;c.bottom=
+d;break;default:c.top=-g,c.bottom=g}c.width=f;c.height=d;c.centroid||(c.centroid={});c.centroid.x=e;c.centroid.y=g},render:function(a,e,g){if(!this._visible||!this._opacity)return this;this._update();var f=this.parent,h=this._matrix.manual||this._flagMatrix,k=this._flagVertices||this._flagFill||this._fill instanceof c.LinearGradient&&(this._fill._flagSpread||this._fill._flagStops||this._fill._flagEndPoints)||this._fill instanceof c.RadialGradient&&(this._fill._flagSpread||this._fill._flagStops||this._fill._flagRadius||
+this._fill._flagCenter||this._fill._flagFocal)||this._fill instanceof c.Texture&&this._fill._flagLoaded&&this._fill.loaded||this._stroke instanceof c.LinearGradient&&(this._stroke._flagSpread||this._stroke._flagStops||this._stroke._flagEndPoints)||this._stroke instanceof c.RadialGradient&&(this._stroke._flagSpread||this._stroke._flagStops||this._stroke._flagRadius||this._stroke._flagCenter||this._stroke._flagFocal)||this._texture instanceof c.Texture&&this._texture._flagLoaded&&this._texture.loaded||
+this._flagStroke||this._flagLinewidth||this._flagOpacity||f._flagOpacity||this._flagVisible||this._flagScale||this._flagValue||this._flagFamily||this._flagSize||this._flagLeading||this._flagAlignment||this._flagBaseline||this._flagStyle||this._flagWeight||this._flagDecoration||!this._renderer.texture;if(f._matrix.manual||f._flagMatrix||h)this._renderer.matrix||(this._renderer.matrix=new c.Array(9)),this._matrix.toArray(!0,d),m(d,f._renderer.matrix,this._renderer.matrix),this._renderer.scale=this._scale*
+f._renderer.scale;k&&(this._renderer.rect||(this._renderer.rect={}),this._renderer.triangles||(this._renderer.triangles=new c.Array(12)),this._renderer.opacity=this._opacity*f._renderer.opacity,n.text.getBoundingClientRect(this,this._renderer.rect),n.getTriangles(this._renderer.rect,this._renderer.triangles),n.updateBuffer.call(n,a,this,e),n.updateTexture.call(n,a,this));if(!this._clip||g)return a.bindBuffer(a.ARRAY_BUFFER,this._renderer.textureCoordsBuffer),a.vertexAttribPointer(e.textureCoords,
+2,a.FLOAT,!1,0,0),a.bindTexture(a.TEXTURE_2D,this._renderer.texture),a.uniformMatrix3fv(e.matrix,!1,this._renderer.matrix),a.bindBuffer(a.ARRAY_BUFFER,this._renderer.buffer),a.vertexAttribPointer(e.position,2,a.FLOAT,!1,0,0),a.drawArrays(a.TRIANGLES,0,6),this.flagReset()}},"linear-gradient":{render:function(a,c){if(a.canvas.getContext("2d")){this._update();if(!this._renderer.effect||this._flagEndPoints||this._flagStops)for(this._renderer.effect=a.createLinearGradient(this.left._x,this.left._y,this.right._x,
+this.right._y),a=0;a<this.stops.length;a++)c=this.stops[a],this._renderer.effect.addColorStop(c._offset,c._color);return this.flagReset()}}},"radial-gradient":{render:function(a,c){if(a.canvas.getContext("2d")){this._update();if(!this._renderer.effect||this._flagCenter||this._flagFocal||this._flagRadius||this._flagStops)for(this._renderer.effect=a.createRadialGradient(this.center._x,this.center._y,0,this.focal._x,this.focal._y,this._radius),a=0;a<this.stops.length;a++)c=this.stops[a],this._renderer.effect.addColorStop(c._offset,
+c._color);return this.flagReset()}}},texture:{render:function(a,d){if(a.canvas.getContext("2d")){this._update();d=this.image;if(!this._renderer.effect||(this._flagLoaded||this._flagRepeat)&&this.loaded)this._renderer.effect=a.createPattern(d,this._repeat);if(this._flagOffset||this._flagLoaded||this._flagScale)this._renderer.offset instanceof c.Vector||(this._renderer.offset=new c.Vector),this._renderer.offset.x=this._offset.x,this._renderer.offset.y=this._offset.y,d&&(this._renderer.offset.x-=d.width/
+2,this._renderer.offset.y+=d.height/2,this._scale instanceof c.Vector?(this._renderer.offset.x*=this._scale.x,this._renderer.offset.y*=this._scale.y):(this._renderer.offset.x*=this._scale,this._renderer.offset.y*=this._scale));if(this._flagScale||this._flagLoaded)this._renderer.scale instanceof c.Vector||(this._renderer.scale=new c.Vector),this._scale instanceof c.Vector?this._renderer.scale.copy(this._scale):this._renderer.scale.set(this._scale,this._scale);return this.flagReset()}}},getTriangles:function(a,
+c){var f=a.top,d=a.left,e=a.right;a=a.bottom;c[0]=d;c[1]=f;c[2]=e;c[3]=f;c[4]=d;c[5]=a;c[6]=d;c[7]=a;c[8]=e;c[9]=f;c[10]=e;c[11]=a},updateTexture:function(a,c){this[c._renderer.type].updateCanvas.call(n,c);c._renderer.texture&&a.deleteTexture(c._renderer.texture);a.bindBuffer(a.ARRAY_BUFFER,c._renderer.textureCoordsBuffer);c._renderer.texture=a.createTexture();a.bindTexture(a.TEXTURE_2D,c._renderer.texture);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_WRAP_S,a.CLAMP_TO_EDGE);a.texParameteri(a.TEXTURE_2D,
+a.TEXTURE_WRAP_T,a.CLAMP_TO_EDGE);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_MIN_FILTER,a.LINEAR);0>=this.canvas.width||0>=this.canvas.height||a.texImage2D(a.TEXTURE_2D,0,a.RGBA,a.RGBA,a.UNSIGNED_BYTE,this.canvas)},updateBuffer:function(a,c,d){g.isObject(c._renderer.buffer)&&a.deleteBuffer(c._renderer.buffer);c._renderer.buffer=a.createBuffer();a.bindBuffer(a.ARRAY_BUFFER,c._renderer.buffer);a.enableVertexAttribArray(d.position);a.bufferData(a.ARRAY_BUFFER,c._renderer.triangles,a.STATIC_DRAW);g.isObject(c._renderer.textureCoordsBuffer)&&
+a.deleteBuffer(c._renderer.textureCoordsBuffer);c._renderer.textureCoordsBuffer=a.createBuffer();a.bindBuffer(a.ARRAY_BUFFER,c._renderer.textureCoordsBuffer);a.enableVertexAttribArray(d.textureCoords);a.bufferData(a.ARRAY_BUFFER,this.uv,a.STATIC_DRAW)},program:{create:function(a,d){var f=a.createProgram();g.each(d,function(c){a.attachShader(f,c)});a.linkProgram(f);if(!a.getProgramParameter(f,a.LINK_STATUS))throw d=a.getProgramInfoLog(f),a.deleteProgram(f),new c.Utils.Error("unable to link program: "+
+d);return f}},shaders:{create:function(a,d,e){e=a.createShader(a[e]);a.shaderSource(e,d);a.compileShader(e);if(!a.getShaderParameter(e,a.COMPILE_STATUS))throw d=a.getShaderInfoLog(e),a.deleteShader(e),new c.Utils.Error("unable to compile shader "+e+": "+d);return e},types:{vertex:"VERTEX_SHADER",fragment:"FRAGMENT_SHADER"},vertex:"attribute vec2 a_position;\nattribute vec2 a_textureCoords;\n\nuniform mat3 u_matrix;\nuniform vec2 u_resolution;\n\nvarying vec2 v_textureCoords;\n\nvoid main() {\n   vec2 projected \x3d (u_matrix * vec3(a_position, 1.0)).xy;\n   vec2 normal \x3d projected / u_resolution;\n   vec2 clipspace \x3d (normal * 2.0) - 1.0;\n\n   gl_Position \x3d vec4(clipspace * vec2(1.0, -1.0), 0.0, 1.0);\n   v_textureCoords \x3d a_textureCoords;\n}",
+fragment:"precision mediump float;\n\nuniform sampler2D u_image;\nvarying vec2 v_textureCoords;\n\nvoid main() {\n  gl_FragColor \x3d texture2D(u_image, v_textureCoords);\n}"},TextureRegistry:new c.Registry};n.ctx=n.canvas.getContext("2d");k=c[c.Types.webgl]=function(a){this.domElement=a.domElement||document.createElement("canvas");this.scene=new c.Group;this.scene.parent=this;this._renderer={matrix:new c.Array(h),scale:1,opacity:1};this._flagMatrix=!0;a=g.defaults(a||{},{antialias:!1,alpha:!0,premultipliedAlpha:!0,
+stencil:!0,preserveDrawingBuffer:!0,overdraw:!1});this.overdraw=a.overdraw;a=this.ctx=this.domElement.getContext("webgl",a)||this.domElement.getContext("experimental-webgl",a);if(!this.ctx)throw new c.Utils.Error("unable to create a webgl context. Try using another renderer.");var d=n.shaders.create(a,n.shaders.vertex,n.shaders.types.vertex);var f=n.shaders.create(a,n.shaders.fragment,n.shaders.types.fragment);this.program=n.program.create(a,[d,f]);a.useProgram(this.program);this.program.position=
+a.getAttribLocation(this.program,"a_position");this.program.matrix=a.getUniformLocation(this.program,"u_matrix");this.program.textureCoords=a.getAttribLocation(this.program,"a_textureCoords");a.disable(a.DEPTH_TEST);a.enable(a.BLEND);a.blendEquationSeparate(a.FUNC_ADD,a.FUNC_ADD);a.blendFuncSeparate(a.SRC_ALPHA,a.ONE_MINUS_SRC_ALPHA,a.ONE,a.ONE_MINUS_SRC_ALPHA)};g.extend(k,{Utils:n});g.extend(k.prototype,c.Utils.Events,{setSize:function(a,c,d){this.width=a;this.height=c;this.ratio=g.isUndefined(d)?
+e(this.ctx):d;this.domElement.width=a*this.ratio;this.domElement.height=c*this.ratio;g.extend(this.domElement.style,{width:a+"px",height:c+"px"});a*=this.ratio;c*=this.ratio;this._renderer.matrix[0]=this._renderer.matrix[4]=this._renderer.scale=this.ratio;this._flagMatrix=!0;this.ctx.viewport(0,0,a,c);d=this.ctx.getUniformLocation(this.program,"u_resolution");this.ctx.uniform2f(d,a,c);return this},render:function(){var a=this.ctx;this.overdraw||a.clear(a.COLOR_BUFFER_BIT|a.DEPTH_BUFFER_BIT);n.group.render.call(this.scene,
+a,this.program);this._flagMatrix=!1;return this}})})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.Shape=function(){this._renderer={};this._renderer.flagMatrix=k.bind(m.FlagMatrix,this);this.isShape=!0;this.id=c.Identifier+c.uniqueId();this.classList=[];this._matrix=new c.Matrix;this.translation=new c.Vector;this.rotation=0;this.scale=1};k.extend(m,{FlagMatrix:function(){this._flagMatrix=!0},MakeObservable:function(k){Object.defineProperty(k,"translation",{enumerable:!0,get:function(){return this._translation},set:function(h){this._translation&&this._translation.unbind(c.Events.change,
+this._renderer.flagMatrix);this._translation=h;this._translation.bind(c.Events.change,this._renderer.flagMatrix);m.FlagMatrix.call(this)}});Object.defineProperty(k,"rotation",{enumerable:!0,get:function(){return this._rotation},set:function(c){this._rotation=c;this._flagMatrix=!0}});Object.defineProperty(k,"scale",{enumerable:!0,get:function(){return this._scale},set:function(h){this._scale instanceof c.Vector&&this._scale.unbind(c.Events.change,this._renderer.flagMatrix);this._scale=h;this._scale instanceof
+c.Vector&&this._scale.bind(c.Events.change,this._renderer.flagMatrix);this._flagScale=this._flagMatrix=!0}})}});k.extend(m.prototype,c.Utils.Events,{_flagMatrix:!0,_flagScale:!1,_rotation:0,_scale:1,_translation:null,addTo:function(c){c.add(this);return this},clone:function(){var c=new m;c.translation.copy(this.translation);c.rotation=this.rotation;c.scale=this.scale;k.each(m.Properties,function(h){c[h]=this[h]},this);return c._update()},_update:function(k){!this._matrix.manual&&this._flagMatrix&&
+(this._matrix.identity().translate(this.translation.x,this.translation.y),this._scale instanceof c.Vector?this._matrix.scale(this._scale.x,this._scale.y):this._matrix.scale(this._scale),this._matrix.rotate(this.rotation));k&&this.parent&&this.parent._update&&this.parent._update();return this},flagReset:function(){this._flagMatrix=this._flagScale=!1;return this}});m.MakeObservable(m.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){function k(a,d,e){var f=d.controls&&d.controls.right,g=a.controls&&a.controls.left;var n=d.x;var h=d.y;var k=(f||d).x;var l=(f||d).y;var m=(g||a).x;var t=(g||a).y;var w=a.x;var p=a.y;f&&d._relative&&(k+=d.x,l+=d.y);g&&a._relative&&(m+=a.x,t+=a.y);return c.Utils.getCurveLength(n,h,k,l,m,t,w,p,e)}function m(a,d,e){var f=d.controls&&d.controls.right,g=a.controls&&a.controls.left;var h=d.x;var n=d.y;var k=(f||d).x;var l=(f||d).y;var m=(g||a).x;var t=(g||a).y;var w=a.x;var p=a.y;f&&d._relative&&
+(k+=d.x,l+=d.y);g&&a._relative&&(m+=a.x,t+=a.y);return c.Utils.subdivide(h,n,k,l,m,t,w,p,e)}var l=Math.min,h=Math.max,d=Math.round,e=c.Utils.getComputedMatrix,a=c.Utils;a.each(c.Commands,function(a,c){});var g=c.Path=function(d,f,e,h){c.Shape.call(this);this._renderer.type="path";this._renderer.flagVertices=a.bind(g.FlagVertices,this);this._renderer.bindVertices=a.bind(g.BindVertices,this);this._renderer.unbindVertices=a.bind(g.UnbindVertices,this);this._renderer.flagFill=a.bind(g.FlagFill,this);
+this._renderer.flagStroke=a.bind(g.FlagStroke,this);this._closed=!!f;this._curved=!!e;this.beginning=0;this.ending=1;this.fill="#fff";this.stroke="#000";this.opacity=this.linewidth=1;this.visible=!0;this.cap="butt";this.join="miter";this.miter=4;this._vertices=[];this.vertices=d;this.automatic=!h};a.extend(g,{Properties:"fill stroke linewidth opacity visible cap join miter closed curved automatic beginning ending".split(" "),FlagVertices:function(){this._flagLength=this._flagVertices=!0},BindVertices:function(a){for(var d=
+a.length;d--;)a[d].bind(c.Events.change,this._renderer.flagVertices);this._renderer.flagVertices()},UnbindVertices:function(a){for(var d=a.length;d--;)a[d].unbind(c.Events.change,this._renderer.flagVertices);this._renderer.flagVertices()},FlagFill:function(){this._flagFill=!0},FlagStroke:function(){this._flagStroke=!0},MakeObservable:function(d){c.Shape.MakeObservable(d);a.each(g.Properties.slice(2,8),c.Utils.defineProperty,d);Object.defineProperty(d,"fill",{enumerable:!0,get:function(){return this._fill},
+set:function(a){(this._fill instanceof c.Gradient||this._fill instanceof c.LinearGradient||this._fill instanceof c.RadialGradient||this._fill instanceof c.Texture)&&this._fill.unbind(c.Events.change,this._renderer.flagFill);this._fill=a;this._flagFill=!0;(this._fill instanceof c.Gradient||this._fill instanceof c.LinearGradient||this._fill instanceof c.RadialGradient||this._fill instanceof c.Texture)&&this._fill.bind(c.Events.change,this._renderer.flagFill)}});Object.defineProperty(d,"stroke",{enumerable:!0,
+get:function(){return this._stroke},set:function(a){(this._stroke instanceof c.Gradient||this._stroke instanceof c.LinearGradient||this._stroke instanceof c.RadialGradient||this._stroke instanceof c.Texture)&&this._stroke.unbind(c.Events.change,this._renderer.flagStroke);this._stroke=a;this._flagStroke=!0;(this._stroke instanceof c.Gradient||this._stroke instanceof c.LinearGradient||this._stroke instanceof c.RadialGradient||this._stroke instanceof c.Texture)&&this._stroke.bind(c.Events.change,this._renderer.flagStroke)}});
+Object.defineProperty(d,"length",{get:function(){this._flagLength&&this._updateLength();return this._length}});Object.defineProperty(d,"closed",{enumerable:!0,get:function(){return this._closed},set:function(a){this._closed=!!a;this._flagVertices=!0}});Object.defineProperty(d,"curved",{enumerable:!0,get:function(){return this._curved},set:function(a){this._curved=!!a;this._flagVertices=!0}});Object.defineProperty(d,"automatic",{enumerable:!0,get:function(){return this._automatic},set:function(c){if(c!==
+this._automatic){var d=(this._automatic=!!c)?"ignore":"listen";a.each(this.vertices,function(a){a[d]()})}}});Object.defineProperty(d,"beginning",{enumerable:!0,get:function(){return this._beginning},set:function(a){this._beginning=a;this._flagVertices=!0}});Object.defineProperty(d,"ending",{enumerable:!0,get:function(){return this._ending},set:function(a){this._ending=a;this._flagVertices=!0}});Object.defineProperty(d,"vertices",{enumerable:!0,get:function(){return this._collection},set:function(a){var d=
+this._renderer.bindVertices,e=this._renderer.unbindVertices;this._collection&&this._collection.unbind(c.Events.insert,d).unbind(c.Events.remove,e);this._collection=new c.Utils.Collection((a||[]).slice(0));this._collection.bind(c.Events.insert,d).bind(c.Events.remove,e);d(this._collection)}});Object.defineProperty(d,"clip",{enumerable:!0,get:function(){return this._clip},set:function(a){this._clip=a;this._flagClip=!0}})}});a.extend(g.prototype,c.Shape.prototype,{_flagVertices:!0,_flagLength:!0,_flagFill:!0,
+_flagStroke:!0,_flagLinewidth:!0,_flagOpacity:!0,_flagVisible:!0,_flagCap:!0,_flagJoin:!0,_flagMiter:!0,_flagClip:!1,_length:0,_fill:"#fff",_stroke:"#000",_linewidth:1,_opacity:1,_visible:!0,_cap:"round",_join:"round",_miter:4,_closed:!0,_curved:!1,_automatic:!0,_beginning:0,_ending:1,_clip:!1,clone:function(d){d=d||this.parent;var e=a.map(this.vertices,function(a){return a.clone()}),h=new g(e,this.closed,this.curved,!this.automatic);a.each(c.Path.Properties,function(a){h[a]=this[a]},this);h.translation.copy(this.translation);
+h.rotation=this.rotation;h.scale=this.scale;d&&d.add(h);return h},toObject:function(){var d={vertices:a.map(this.vertices,function(a){return a.toObject()})};a.each(c.Shape.Properties,function(a){d[a]=this[a]},this);d.translation=this.translation.toObject;d.rotation=this.rotation;d.scale=this.scale;return d},noFill:function(){this.fill="transparent";return this},noStroke:function(){this.stroke="transparent";return this},corner:function(){var c=this.getBoundingClientRect(!0);c.centroid={x:c.left+c.width/
+2,y:c.top+c.height/2};a.each(this.vertices,function(a){a.addSelf(c.centroid)});return this},center:function(){var c=this.getBoundingClientRect(!0);c.centroid={x:c.left+c.width/2,y:c.top+c.height/2};a.each(this.vertices,function(a){a.subSelf(c.centroid)});return this},remove:function(){if(!this.parent)return this;this.parent.remove(this);return this},getBoundingClientRect:function(a){var c,d=Infinity,g=-Infinity,k=Infinity,n=-Infinity;this._update(!0);a=a?this._matrix:e(this);var m=this.linewidth/
+2;var x=this._vertices.length;if(0>=x){var u=a.multiply(0,0,1);return{top:u.y,left:u.x,right:u.x,bottom:u.y,width:0,height:0}}for(c=0;c<x;c++){u=this._vertices[c];var r=u.x;u=u.y;u=a.multiply(r,u,1);k=l(u.y-m,k);d=l(u.x-m,d);g=h(u.x+m,g);n=h(u.y+m,n)}return{top:k,left:d,right:g,bottom:n,width:g-d,height:n-k}},getPointAt:function(d,e){var g,f;var h=this.length*Math.min(Math.max(d,0),1);var k=this.vertices.length;var n=k-1;var l=g=null;var m=0;var r=this._lengths.length;for(f=0;m<r;m++){if(f+this._lengths[m]>=
+h){this._closed?(g=c.Utils.mod(m,k),l=c.Utils.mod(m-1,k),0===m&&(g=l,l=m)):(g=m,l=Math.min(Math.max(m-1,0),n));g=this.vertices[g];l=this.vertices[l];h-=f;0!==this._lengths[m]&&(d=h/this._lengths[m]);break}f+=this._lengths[m]}if(a.isNull(g)||a.isNull(l))return null;var q=l.controls&&l.controls.right;var w=g.controls&&g.controls.left;n=l.x;h=l.y;r=(q||l).x;m=(q||l).y;var p=(w||g).x;f=(w||g).y;var C=g.x;k=g.y;q&&l._relative&&(r+=l.x,m+=l.y);w&&g._relative&&(p+=g.x,f+=g.y);g=c.Utils.getPointOnCubicBezier(d,
+n,r,p,C);d=c.Utils.getPointOnCubicBezier(d,h,m,f,k);return a.isObject(e)?(e.x=g,e.y=d,e):new c.Vector(g,d)},plot:function(){if(this.curved)return c.Utils.getCurveFromPoints(this._vertices,this.closed),this;for(var a=0;a<this._vertices.length;a++)this._vertices[a]._command=0===a?c.Commands.move:c.Commands.line;return this},subdivide:function(d){this._update();var e=this.vertices.length-1,g=this.vertices[e],h=this._closed||this.vertices[e]._command===c.Commands.close,k=[];a.each(this.vertices,function(f,
+n){if(!(0>=n)||h)if(f.command===c.Commands.move)k.push(new c.Anchor(g.x,g.y)),0<n&&(k[k.length-1].command=c.Commands.line);else{var l=m(f,g,d);k=k.concat(l);a.each(l,function(a,d){a.command=0>=d&&g.command===c.Commands.move?c.Commands.move:c.Commands.line});n>=e&&(this._closed&&this._automatic?(g=f,l=m(f,g,d),k=k.concat(l),a.each(l,function(a,d){a.command=0>=d&&g.command===c.Commands.move?c.Commands.move:c.Commands.line})):h&&k.push(new c.Anchor(f.x,f.y)),k[k.length-1].command=h?c.Commands.close:
+c.Commands.line)}g=f},this);this._curved=this._automatic=!1;this.vertices=k;return this},_updateLength:function(d){this._update();var e=this.vertices.length,g=e-1,h=this.vertices[g],n=this._closed||this.vertices[g]._command===c.Commands.close,l=0;a.isUndefined(this._lengths)&&(this._lengths=[]);a.each(this.vertices,function(a,f){0>=f&&!n||a.command===c.Commands.move?(h=a,this._lengths[f]=0):(this._lengths[f]=k(a,h,d),l+=this._lengths[f],f>=g&&n&&(h=this.vertices[(f+1)%e],this._lengths[f+1]=k(a,h,
+d),l+=this._lengths[f+1]),h=a)},this);this._length=l;return this},_update:function(){if(this._flagVertices){var a=this.vertices.length-1;var e=d(this._beginning*a);a=d(this._ending*a);this._vertices.length=0;for(var g=e;g<a+1;g++)e=this.vertices[g],this._vertices.push(e);this._automatic&&this.plot()}c.Shape.prototype._update.apply(this,arguments);return this},flagReset:function(){this._flagVertices=this._flagFill=this._flagStroke=this._flagLinewidth=this._flagOpacity=this._flagVisible=this._flagCap=
+this._flagJoin=this._flagMiter=this._flagClip=!1;c.Shape.prototype.flagReset.call(this);return this}});g.MakeObservable(g.prototype)})(("undefined"!==typeof global?global:this).Two);(function(c){var k=c.Path,m=c.Utils,l=c.Line=function(h,d,e,a){e=(e-h)/2;a=(a-d)/2;k.call(this,[new c.Anchor(-e,-a),new c.Anchor(e,a)]);this.translation.set(h+e,d+a)};m.extend(l.prototype,k.prototype);k.MakeObservable(l.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=c.Utils,l=c.Rectangle=function(h,d,e,a){k.call(this,[new c.Anchor,new c.Anchor,new c.Anchor,new c.Anchor],!0);this.width=e;this.height=a;this._update();this.translation.set(h,d)};m.extend(l,{Properties:["width","height"],MakeObservable:function(h){k.MakeObservable(h);m.each(l.Properties,c.Utils.defineProperty,h)}});m.extend(l.prototype,k.prototype,{_width:0,_height:0,_flagWidth:0,_flagHeight:0,_update:function(){if(this._flagWidth||this._flagHeight){var c=this._width/2,
+d=this._height/2;this.vertices[0].set(-c,-d);this.vertices[1].set(c,-d);this.vertices[2].set(c,d);this.vertices[3].set(-c,d)}k.prototype._update.call(this);return this},flagReset:function(){this._flagWidth=this._flagHeight=!1;k.prototype.flagReset.call(this);return this}});l.MakeObservable(l.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=2*Math.PI,l=Math.cos,h=Math.sin,d=c.Utils,e=c.Ellipse=function(a,e,h,f){d.isNumber(f)||(f=h);var g=d.map(d.range(c.Resolution),function(a){return new c.Anchor},this);k.call(this,g,!0,!0);this.width=2*h;this.height=2*f;this._update();this.translation.set(a,e)};d.extend(e,{Properties:["width","height"],MakeObservable:function(a){k.MakeObservable(a);d.each(e.Properties,c.Utils.defineProperty,a)}});d.extend(e.prototype,k.prototype,{_width:0,_height:0,_flagWidth:!1,_flagHeight:!1,
+_update:function(){if(this._flagWidth||this._flagHeight)for(var a=0,c=this.vertices.length;a<c;a++){var d=a/c*m,e=this._width*l(d)/2,d=this._height*h(d)/2;this.vertices[a].set(e,d)}k.prototype._update.call(this);return this},flagReset:function(){this._flagWidth=this._flagHeight=!1;k.prototype.flagReset.call(this);return this}});e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=2*Math.PI,l=Math.cos,h=Math.sin,d=c.Utils,e=c.Circle=function(a,e,h){var g=d.map(d.range(c.Resolution),function(a){return new c.Anchor},this);k.call(this,g,!0,!0);this.radius=h;this._update();this.translation.set(a,e)};d.extend(e,{Properties:["radius"],MakeObservable:function(a){k.MakeObservable(a);d.each(e.Properties,c.Utils.defineProperty,a)}});d.extend(e.prototype,k.prototype,{_radius:0,_flagRadius:!1,_update:function(){if(this._flagRadius)for(var a=0,c=this.vertices.length;a<
+c;a++){var d=a/c*m,e=this._radius*l(d),d=this._radius*h(d);this.vertices[a].set(e,d)}k.prototype._update.call(this);return this},flagReset:function(){this._flagRadius=!1;k.prototype.flagReset.call(this);return this}});e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=2*Math.PI,l=Math.cos,h=Math.sin,d=c.Utils,e=c.Polygon=function(a,e,h,f){f=Math.max(f||0,3);var g=d.map(d.range(f),function(a){return new c.Anchor});k.call(this,g,!0);this.width=2*h;this.height=2*h;this.sides=f;this._update();this.translation.set(a,e)};d.extend(e,{Properties:["width","height","sides"],MakeObservable:function(a){k.MakeObservable(a);d.each(e.Properties,c.Utils.defineProperty,a)}});d.extend(e.prototype,k.prototype,{_width:0,_height:0,_sides:0,_flagWidth:!1,
+_flagHeight:!1,_flagSides:!1,_update:function(){if(this._flagWidth||this._flagHeight||this._flagSides){var a=this._sides,d=this.vertices.length;d>a&&this.vertices.splice(a-1,d-a);for(var e=0;e<a;e++){var f=(e+.5)/a*m+Math.PI/2,t=this._width*l(f),f=this._height*h(f);e>=d?this.vertices.push(new c.Anchor(t,f)):this.vertices[e].set(t,f)}}k.prototype._update.call(this);return this},flagReset:function(){this._flagWidth=this._flagHeight=this._flagSides=!1;k.prototype.flagReset.call(this);return this}});
+e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){function k(a,c){for(;0>a;)a+=c;return a%c}var m=c.Path,l=2*Math.PI,h=Math.PI/2,d=c.Utils,e=c.ArcSegment=function(a,e,h,f,k,l,B){B=d.map(d.range(B||3*c.Resolution),function(){return new c.Anchor});m.call(this,B,!1,!1,!0);this.innerRadius=h;this.outerRadius=f;this.startAngle=k;this.endAngle=l;this._update();this.translation.set(a,e)};d.extend(e,{Properties:["startAngle","endAngle","innerRadius","outerRadius"],MakeObservable:function(a){m.MakeObservable(a);d.each(e.Properties,c.Utils.defineProperty,
+a)}});d.extend(e.prototype,m.prototype,{_flagStartAngle:!1,_flagEndAngle:!1,_flagInnerRadius:!1,_flagOuterRadius:!1,_startAngle:0,_endAngle:l,_innerRadius:0,_outerRadius:0,_update:function(){if(this._flagStartAngle||this._flagEndAngle||this._flagInnerRadius||this._flagOuterRadius){var a=this._startAngle,d=this._endAngle,e=this._innerRadius,f=this._outerRadius,t=k(a,l)===k(d,l),v=0<e,B=this.vertices,z=v?B.length/2:B.length,A=0;t?z--:v||(z-=2);for(var x=0,u=z-1;x<z;x++){var r=x/u;var q=B[A];r=r*(d-
+a)+a;var w=(d-a)/z;var p=f*Math.cos(r);var C=f*Math.sin(r);switch(x){case 0:var E=c.Commands.move;break;default:E=c.Commands.curve}q.command=E;q.x=p;q.y=C;q.controls.left.clear();q.controls.right.clear();q.command===c.Commands.curve&&(C=f*w/Math.PI,q.controls.left.x=C*Math.cos(r-h),q.controls.left.y=C*Math.sin(r-h),q.controls.right.x=C*Math.cos(r+h),q.controls.right.y=C*Math.sin(r+h),1===x&&q.controls.left.multiplyScalar(2),x===u&&q.controls.right.multiplyScalar(2));A++}if(v)for(t?(B[A].command=c.Commands.close,
+A++):(z--,u=z-1),x=0;x<z;x++)r=x/u,q=B[A],r=(1-r)*(d-a)+a,w=(d-a)/z,p=e*Math.cos(r),C=e*Math.sin(r),E=c.Commands.curve,0>=x&&(E=t?c.Commands.move:c.Commands.line),q.command=E,q.x=p,q.y=C,q.controls.left.clear(),q.controls.right.clear(),q.command===c.Commands.curve&&(C=e*w/Math.PI,q.controls.left.x=C*Math.cos(r+h),q.controls.left.y=C*Math.sin(r+h),q.controls.right.x=C*Math.cos(r-h),q.controls.right.y=C*Math.sin(r-h),1===x&&q.controls.left.multiplyScalar(2),x===u&&q.controls.right.multiplyScalar(2)),
+A++;else t||(B[A].command=c.Commands.line,B[A].x=0,B[A].y=0,A++);B[A].command=c.Commands.close}m.prototype._update.call(this);return this},flagReset:function(){m.prototype.flagReset.call(this);this._flagStartAngle=this._flagEndAngle=this._flagInnerRadius=this._flagOuterRadius=!1;return this}});e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=2*Math.PI,l=Math.cos,h=Math.sin,d=c.Utils,e=c.Star=function(a,e,h,f,l){d.isNumber(f)||(f=h/2);if(!d.isNumber(l)||0>=l)l=5;var g=d.map(d.range(2*l),function(a){return new c.Anchor});k.call(this,g,!0);this.innerRadius=f;this.outerRadius=h;this.sides=l;this._update();this.translation.set(a,e)};d.extend(e,{Properties:["innerRadius","outerRadius","sides"],MakeObservable:function(a){k.MakeObservable(a);d.each(e.Properties,c.Utils.defineProperty,a)}});d.extend(e.prototype,k.prototype,
+{_innerRadius:0,_outerRadius:0,_sides:0,_flagInnerRadius:!1,_flagOuterRadius:!1,_flagSides:!1,_update:function(){if(this._flagInnerRadius||this._flagOuterRadius||this._flagSides){var a=2*this._sides,d=this.vertices.length;d>a&&this.vertices.splice(a-1,d-a);for(var e=0;e<a;e++){var f=(e+.5)/a*m,t=e%2?this._innerRadius:this._outerRadius,v=t*l(f),f=t*h(f);e>=d?this.vertices.push(new c.Anchor(v,f)):this.vertices[e].set(v,f)}}k.prototype._update.call(this);return this},flagReset:function(){this._flagInnerRadius=
+this._flagOuterRadius=this._flagSides=!1;k.prototype.flagReset.call(this);return this}});e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Path,m=c.Utils,l=c.RoundedRectangle=function(h,d,e,a,g){m.isNumber(g)||(g=Math.floor(Math.min(e,a)/12));var l=m.map(m.range(10),function(a){return new c.Anchor(0,0,0,0,0,0,0===a?c.Commands.move:c.Commands.curve)});l[l.length-1].command=c.Commands.close;k.call(this,l,!1,!1,!0);this.width=e;this.height=a;this.radius=g;this._update();this.translation.set(h,d)};m.extend(l,{Properties:["width","height","radius"],MakeObservable:function(h){k.MakeObservable(h);m.each(l.Properties,c.Utils.defineProperty,
+h)}});m.extend(l.prototype,k.prototype,{_width:0,_height:0,_radius:0,_flagWidth:!1,_flagHeight:!1,_flagRadius:!1,_update:function(){if(this._flagWidth||this._flagHeight||this._flagRadius){var c=this._width,d=this._height,e=Math.min(Math.max(this._radius,0),Math.min(c,d)),c=c/2,a=d/2,d=this.vertices[0];d.x=-(c-e);d.y=-a;d=this.vertices[1];d.x=c-e;d.y=-a;d.controls.left.clear();d.controls.right.x=e;d.controls.right.y=0;d=this.vertices[2];d.x=c;d.y=-(a-e);d.controls.right.clear();d.controls.left.clear();
+d=this.vertices[3];d.x=c;d.y=a-e;d.controls.left.clear();d.controls.right.x=0;d.controls.right.y=e;d=this.vertices[4];d.x=c-e;d.y=a;d.controls.right.clear();d.controls.left.clear();d=this.vertices[5];d.x=-(c-e);d.y=a;d.controls.left.clear();d.controls.right.x=-e;d.controls.right.y=0;d=this.vertices[6];d.x=-c;d.y=a-e;d.controls.left.clear();d.controls.right.clear();d=this.vertices[7];d.x=-c;d.y=-(a-e);d.controls.left.clear();d.controls.right.x=0;d.controls.right.y=-e;d=this.vertices[8];d.x=-(c-e);
+d.y=-a;d.controls.left.clear();d.controls.right.clear();d=this.vertices[9];d.copy(this.vertices[8])}k.prototype._update.call(this);return this},flagReset:function(){this._flagWidth=this._flagHeight=this._flagRadius=!1;k.prototype.flagReset.call(this);return this}});l.MakeObservable(l.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.root,m=c.Utils.getComputedMatrix,l=c.Utils;(k.document?k.document.createElement("canvas"):{getContext:l.identity}).getContext("2d");var h=c.Text=function(d,e,a,g){c.Shape.call(this);this._renderer.type="text";this._renderer.flagFill=l.bind(h.FlagFill,this);this._renderer.flagStroke=l.bind(h.FlagStroke,this);this.value=d;l.isNumber(e)&&(this.translation.x=e);l.isNumber(a)&&(this.translation.y=a);if(!l.isObject(g))return this;l.each(c.Text.Properties,function(a){a in g&&(this[a]=
+g[a])},this)};l.extend(c.Text,{Properties:"value family size leading alignment linewidth style weight decoration baseline opacity visible fill stroke".split(" "),FlagFill:function(){this._flagFill=!0},FlagStroke:function(){this._flagStroke=!0},MakeObservable:function(d){c.Shape.MakeObservable(d);l.each(c.Text.Properties.slice(0,12),c.Utils.defineProperty,d);Object.defineProperty(d,"fill",{enumerable:!0,get:function(){return this._fill},set:function(d){(this._fill instanceof c.Gradient||this._fill instanceof
+c.LinearGradient||this._fill instanceof c.RadialGradient||this._fill instanceof c.Texture)&&this._fill.unbind(c.Events.change,this._renderer.flagFill);this._fill=d;this._flagFill=!0;(this._fill instanceof c.Gradient||this._fill instanceof c.LinearGradient||this._fill instanceof c.RadialGradient||this._fill instanceof c.Texture)&&this._fill.bind(c.Events.change,this._renderer.flagFill)}});Object.defineProperty(d,"stroke",{enumerable:!0,get:function(){return this._stroke},set:function(d){(this._stroke instanceof
+c.Gradient||this._stroke instanceof c.LinearGradient||this._stroke instanceof c.RadialGradient||this._stroke instanceof c.Texture)&&this._stroke.unbind(c.Events.change,this._renderer.flagStroke);this._stroke=d;this._flagStroke=!0;(this._stroke instanceof c.Gradient||this._stroke instanceof c.LinearGradient||this._stroke instanceof c.RadialGradient||this._stroke instanceof c.Texture)&&this._stroke.bind(c.Events.change,this._renderer.flagStroke)}});Object.defineProperty(d,"clip",{enumerable:!0,get:function(){return this._clip},
+set:function(c){this._clip=c;this._flagClip=!0}})}});l.extend(c.Text.prototype,c.Shape.prototype,{_flagValue:!0,_flagFamily:!0,_flagSize:!0,_flagLeading:!0,_flagAlignment:!0,_flagBaseline:!0,_flagStyle:!0,_flagWeight:!0,_flagDecoration:!0,_flagFill:!0,_flagStroke:!0,_flagLinewidth:!0,_flagOpacity:!0,_flagVisible:!0,_flagClip:!1,_value:"",_family:"sans-serif",_size:13,_leading:17,_alignment:"center",_baseline:"middle",_style:"normal",_weight:500,_decoration:"none",_fill:"#000",_stroke:"transparent",
+_linewidth:1,_opacity:1,_visible:!0,_clip:!1,remove:function(){if(!this.parent)return this;this.parent.remove(this);return this},clone:function(d){d=d||this.parent;var e=new c.Text(this.value);e.translation.copy(this.translation);e.rotation=this.rotation;e.scale=this.scale;l.each(c.Text.Properties,function(a){e[a]=this[a]},this);d&&d.add(e);return e},toObject:function(){var d={translation:this.translation.toObject(),rotation:this.rotation,scale:this.scale};l.each(c.Text.Properties,function(c){d[c]=
+this[c]},this);return d},noStroke:function(){this.stroke="transparent";return this},noFill:function(){this.fill="transparent";return this},getBoundingClientRect:function(c){this._update(!0);c=(c?this._matrix:m(this)).multiply(0,0,1);return{top:c.x,left:c.y,right:c.x,bottom:c.y,width:0,height:0}},flagReset:function(){this._flagValue=this._flagFamily=this._flagSize=this._flagLeading=this._flagAlignment=this._flagFill=this._flagStroke=this._flagLinewidth=this._flagOpaicty=this._flagVisible=this._flagClip=
+this._flagDecoration=this._flagBaseline=!1;c.Shape.prototype.flagReset.call(this);return this}});c.Text.MakeObservable(c.Text.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.Stop=function(c,d,e){this._renderer={};this._renderer.type="stop";this.offset=k.isNumber(c)?c:0>=m.Index?0:1;this.opacity=k.isNumber(e)?e:1;this.color=k.isString(d)?d:0>=m.Index?"#fff":"#000";m.Index=(m.Index+1)%2};k.extend(m,{Index:0,Properties:["offset","opacity","color"],MakeObservable:function(c){k.each(m.Properties,function(c){var d="_"+c,a="_flag"+c.charAt(0).toUpperCase()+c.slice(1);Object.defineProperty(this,c,{enumerable:!0,get:function(){return this[d]},set:function(c){this[d]=
+c;this[a]=!0;this.parent&&(this.parent._flagStops=!0)}})},c)}});k.extend(m.prototype,c.Utils.Events,{clone:function(){var c=new m;k.each(m.Properties,function(d){c[d]=this[d]},this);return c},toObject:function(){var c={};k.each(m.Properties,function(d){c[d]=this[d]},this);return c},flagReset:function(){this._flagOffset=this._flagColor=this._flagOpacity=!1;return this}});m.MakeObservable(m.prototype);var l=c.Gradient=function(h){this._renderer={};this._renderer.type="gradient";this.id=c.Identifier+
+c.uniqueId();this.classList=[];this._renderer.flagStops=k.bind(l.FlagStops,this);this._renderer.bindStops=k.bind(l.BindStops,this);this._renderer.unbindStops=k.bind(l.UnbindStops,this);this.spread="pad";this.stops=h};k.extend(l,{Stop:m,Properties:["spread"],MakeObservable:function(h){k.each(l.Properties,c.Utils.defineProperty,h);Object.defineProperty(h,"stops",{enumerable:!0,get:function(){return this._stops},set:function(d){var e=this._renderer.bindStops,a=this._renderer.unbindStops;this._stops&&
+this._stops.unbind(c.Events.insert,e).unbind(c.Events.remove,a);this._stops=new c.Utils.Collection((d||[]).slice(0));this._stops.bind(c.Events.insert,e).bind(c.Events.remove,a);e(this._stops)}})},FlagStops:function(){this._flagStops=!0},BindStops:function(h){for(var d=h.length;d--;)h[d].bind(c.Events.change,this._renderer.flagStops),h[d].parent=this;this._renderer.flagStops()},UnbindStops:function(h){for(var d=h.length;d--;)h[d].unbind(c.Events.change,this._renderer.flagStops),delete h[d].parent;
+this._renderer.flagStops()}});k.extend(l.prototype,c.Utils.Events,{_flagStops:!1,_flagSpread:!1,clone:function(h){h=h||this.parent;var d=k.map(this.stops,function(a){return a.clone()}),e=new l(d);k.each(c.Gradient.Properties,function(a){e[a]=this[a]},this);h&&h.add(e);return e},toObject:function(){var c={stops:k.map(this.stops,function(c){return c.toObject()})};k.each(l.Properties,function(d){c[d]=this[d]},this);return c},_update:function(){(this._flagSpread||this._flagStops)&&this.trigger(c.Events.change);
+return this},flagReset:function(){this._flagSpread=this._flagStops=!1;return this}});l.MakeObservable(l.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.LinearGradient=function(l,h,d,e,a){c.Gradient.call(this,a);this._renderer.type="linear-gradient";a=k.bind(m.FlagEndPoints,this);this.left=(new c.Vector).bind(c.Events.change,a);this.right=(new c.Vector).bind(c.Events.change,a);k.isNumber(l)&&(this.left.x=l);k.isNumber(h)&&(this.left.y=h);k.isNumber(d)&&(this.right.x=d);k.isNumber(e)&&(this.right.y=e)};k.extend(m,{Stop:c.Gradient.Stop,MakeObservable:function(k){c.Gradient.MakeObservable(k)},FlagEndPoints:function(){this._flagEndPoints=
+!0}});k.extend(m.prototype,c.Gradient.prototype,{_flagEndPoints:!1,clone:function(l){l=l||this.parent;var h=k.map(this.stops,function(c){return c.clone()}),d=new m(this.left._x,this.left._y,this.right._x,this.right._y,h);k.each(c.Gradient.Properties,function(c){d[c]=this[c]},this);l&&l.add(d);return d},toObject:function(){var k=c.Gradient.prototype.toObject.call(this);k.left=this.left.toObject();k.right=this.right.toObject();return k},_update:function(){(this._flagEndPoints||this._flagSpread||this._flagStops)&&
+this.trigger(c.Events.change);return this},flagReset:function(){this._flagEndPoints=!1;c.Gradient.prototype.flagReset.call(this);return this}});m.MakeObservable(m.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.RadialGradient=function(l,h,d,e,a,g){c.Gradient.call(this,e);this._renderer.type="radial-gradient";this.center=(new c.Vector).bind(c.Events.change,k.bind(function(){this._flagCenter=!0},this));this.radius=k.isNumber(d)?d:20;this.focal=(new c.Vector).bind(c.Events.change,k.bind(function(){this._flagFocal=!0},this));k.isNumber(l)&&(this.center.x=l);k.isNumber(h)&&(this.center.y=h);this.focal.copy(this.center);k.isNumber(a)&&(this.focal.x=a);k.isNumber(g)&&(this.focal.y=
+g)};k.extend(m,{Stop:c.Gradient.Stop,Properties:["radius"],MakeObservable:function(l){c.Gradient.MakeObservable(l);k.each(m.Properties,c.Utils.defineProperty,l)}});k.extend(m.prototype,c.Gradient.prototype,{_flagRadius:!1,_flagCenter:!1,_flagFocal:!1,clone:function(l){l=l||this.parent;var h=k.map(this.stops,function(c){return c.clone()}),d=new m(this.center._x,this.center._y,this._radius,h,this.focal._x,this.focal._y);k.each(c.Gradient.Properties.concat(m.Properties),function(c){d[c]=this[c]},this);
+l&&l.add(d);return d},toObject:function(){var l=c.Gradient.prototype.toObject.call(this);k.each(m.Properties,function(c){l[c]=this[c]},this);l.center=this.center.toObject();l.focal=this.focal.toObject();return l},_update:function(){(this._flagRadius||this._flatCenter||this._flagFocal||this._flagSpread||this._flagStops)&&this.trigger(c.Events.change);return this},flagReset:function(){this._flagRadius=this._flagCenter=this._flagFocal=!1;c.Gradient.prototype.flagReset.call(this);return this}});m.MakeObservable(m.prototype)})(("undefined"!==
+typeof global?global:this).Two);
+(function(c){var k=c.Utils,m,l=/\.(mp4|webm)$/i;this.document&&(m=document.createElement("a"));var h=c.Texture=function(d,e){this._renderer={};this._renderer.type="texture";this._renderer.flagOffset=k.bind(h.FlagOffset,this);this._renderer.flagScale=k.bind(h.FlagScale,this);this.id=c.Identifier+c.uniqueId();this.classList=[];this.offset=new c.Vector;if(k.isFunction(e)){var a=k.bind(function(){this.unbind(c.Events.load,a);k.isFunction(e)&&e()},this);this.bind(c.Events.load,a)}k.isString(d)?this.src=
+d:k.isElement(d)&&(this.image=d);this._update()};k.extend(h,{Properties:["src","loaded","repeat"],ImageRegistry:new c.Registry,getAbsoluteURL:function(c){if(!m)return c;m.href=c;return m.href},getImage:function(c){c=h.getAbsoluteURL(c);if(h.ImageRegistry.contains(c))return h.ImageRegistry.get(c);c=l.test(c)?document.createElement("video"):document.createElement("img");c.crossOrigin="anonymous";return c},Register:{canvas:function(c,e){c._src="#"+c.id;h.ImageRegistry.add(c.src,c.image);k.isFunction(e)&&
+e()},img:function(d,e){var a=function(c){d.image.removeEventListener("load",a,!1);d.image.removeEventListener("error",g,!1);k.isFunction(e)&&e()},g=function(e){d.image.removeEventListener("load",a,!1);d.image.removeEventListener("error",g,!1);throw new c.Utils.Error("unable to load "+d.src);};k.isNumber(d.image.width)&&0<d.image.width&&k.isNumber(d.image.height)&&0<d.image.height?a():(d.image.addEventListener("load",a,!1),d.image.addEventListener("error",g,!1));d._src=h.getAbsoluteURL(d._src);d.image&&
+d.image.getAttribute("two-src")||(d.image.setAttribute("two-src",d.src),h.ImageRegistry.add(d.src,d.image),d.image.src=d.src)},video:function(d,e){var a=function(c){d.image.removeEventListener("load",a,!1);d.image.removeEventListener("error",g,!1);d.image.width=d.image.videoWidth;d.image.height=d.image.videoHeight;d.image.play();k.isFunction(e)&&e()},g=function(e){d.image.removeEventListener("load",a,!1);d.image.removeEventListener("error",g,!1);throw new c.Utils.Error("unable to load "+d.src);};
+d._src=h.getAbsoluteURL(d._src);d.image.addEventListener("canplaythrough",a,!1);d.image.addEventListener("error",g,!1);d.image&&d.image.getAttribute("two-src")||(d.image.setAttribute("two-src",d.src),h.ImageRegistry.add(d.src,d.image),d.image.src=d.src,d.image.loop=!0,d.image.load())}},load:function(c,e){var a=c.image,d=a&&a.nodeName.toLowerCase();c._flagImage&&(/canvas/i.test(d)?h.Register.canvas(c,e):(c._src=a.getAttribute("two-src")||a.src,h.Register[d](c,e)));c._flagSrc&&(a||(c.image=h.getImage(c.src)),
+d=c.image.nodeName.toLowerCase(),h.Register[d](c,e))},FlagOffset:function(){this._flagOffset=!0},FlagScale:function(){this._flagScale=!0},MakeObservable:function(d){k.each(h.Properties,c.Utils.defineProperty,d);Object.defineProperty(d,"image",{enumerable:!0,get:function(){return this._image},set:function(c){switch(c&&c.nodeName.toLowerCase()){case "canvas":var a="#"+c.id;break;default:a=c.src}h.ImageRegistry.contains(a)?this._image=h.ImageRegistry.get(c.src):this._image=c;this._flagImage=!0}});Object.defineProperty(d,
+"offset",{enumerable:!0,get:function(){return this._offset},set:function(d){this._offset&&this._offset.unbind(c.Events.change,this._renderer.flagOffset);this._offset=d;this._offset.bind(c.Events.change,this._renderer.flagOffset);this._flagOffset=!0}});Object.defineProperty(d,"scale",{enumerable:!0,get:function(){return this._scale},set:function(d){this._scale instanceof c.Vector&&this._scale.unbind(c.Events.change,this._renderer.flagScale);this._scale=d;this._scale instanceof c.Vector&&this._scale.bind(c.Events.change,
+this._renderer.flagScale);this._flagScale=!0}})}});k.extend(h.prototype,c.Utils.Events,c.Shape.prototype,{_flagSrc:!1,_flagImage:!1,_flagVideo:!1,_flagLoaded:!1,_flagRepeat:!1,_flagOffset:!1,_flagScale:!1,_src:"",_image:null,_loaded:!1,_repeat:"no-repeat",_scale:1,_offset:null,clone:function(){return new h(this.src)},toObject:function(){return{src:this.src,image:this.image}},_update:function(){if(this._flagSrc||this._flagImage||this._flagVideo)if(this.trigger(c.Events.change),this._flagSrc||this._flagImage)this.loaded=
+!1,h.load(this,k.bind(function(){this.loaded=!0;this.trigger(c.Events.change).trigger(c.Events.load)},this));this._image&&4<=this._image.readyState&&(this._flagVideo=!0);return this},flagReset:function(){this._flagSrc=this._flagImage=this._flagLoaded=this._flagVideo=this._flagScale=this._flagOffset=!1;return this}});h.MakeObservable(h.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.Path,l=c.Rectangle,h=c.Sprite=function(d,e,a,g,h,f){m.call(this,[new c.Anchor,new c.Anchor,new c.Anchor,new c.Anchor],!0);this.noStroke();this.noFill();d instanceof c.Texture?this.texture=d:k.isString(d)&&(this.texture=new c.Texture(d));this._update();this.translation.set(e||0,a||0);k.isNumber(g)&&(this.columns=g);k.isNumber(h)&&(this.rows=h);k.isNumber(f)&&(this.frameRate=f)};k.extend(h,{Properties:["texture","columns","rows","frameRate","index"],MakeObservable:function(d){l.MakeObservable(d);
+k.each(h.Properties,c.Utils.defineProperty,d)}});k.extend(h.prototype,l.prototype,{_flagTexture:!1,_flagColumns:!1,_flagRows:!1,_flagFrameRate:!1,flagIndex:!1,_amount:1,_duration:0,_startTime:0,_playing:!1,_firstFrame:0,_lastFrame:0,_loop:!0,_texture:null,_columns:1,_rows:1,_frameRate:0,_index:0,play:function(c,e,a){this._playing=!0;this._firstFrame=0;this._lastFrame=this.amount-1;this._startTime=k.performance.now();k.isNumber(c)&&(this._firstFrame=c);k.isNumber(e)&&(this._lastFrame=e);k.isFunction(a)?
+this._onLastFrame=a:delete this._onLastFrame;this._index!==this._firstFrame&&(this._startTime-=1E3*Math.abs(this._index-this._firstFrame)/this._frameRate);return this},pause:function(){this._playing=!1;return this},stop:function(){this._playing=!1;this._index=0;return this},clone:function(c){c=c||this.parent;var d=new h(this.texture,this.translation.x,this.translation.y,this.columns,this.rows,this.frameRate);this.playing&&(d.play(this._firstFrame,this._lastFrame),d._loop=this._loop);c&&c.add(d);return d},
+_update:function(){var c=this._texture,e=this._columns,a=this._rows;if(this._flagColumns||this._flagRows)this._amount=this._columns*this._rows;this._flagFrameRate&&(this._duration=1E3*this._amount/this._frameRate);this._flagTexture&&(this.fill=this._texture);if(this._texture.loaded){var g=c.image.width;var h=c.image.height;var f=g/e;a=h/a;var m=this._amount;this.width!==f&&(this.width=f);this.height!==a&&(this.height=a);if(this._playing&&0<this._frameRate){k.isNaN(this._lastFrame)&&(this._lastFrame=
+m-1);m=k.performance.now()-this._startTime;var v=this._lastFrame+1;var B=1E3*(v-this._firstFrame)/this._frameRate;m=this._loop?m%B:Math.min(m,B);m=k.lerp(this._firstFrame,v,m/B);m=Math.floor(m);m!==this._index&&(this._index=m,m>=this._lastFrame-1&&this._onLastFrame&&this._onLastFrame())}f=this._index%e*-f+(g-f)/2;e=-a*Math.floor(this._index/e)+(h-a)/2;f!==c.offset.x&&(c.offset.x=f);e!==c.offset.y&&(c.offset.y=e)}l.prototype._update.call(this);return this},flagReset:function(){this._flagTexture=this._flagColumns=
+this._flagRows=this._flagFrameRate=!1;l.prototype.flagReset.call(this);return this}});h.MakeObservable(h.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){var k=c.Utils,m=c.Path,l=c.Rectangle,h=c.ImageSequence=function(d,e,a,g){m.call(this,[new c.Anchor,new c.Anchor,new c.Anchor,new c.Anchor],!0);this._renderer.flagTextures=k.bind(h.FlagTextures,this);this._renderer.bindTextures=k.bind(h.BindTextures,this);this._renderer.unbindTextures=k.bind(h.UnbindTextures,this);this.noStroke();this.noFill();this.textures=k.map(d,h.GenerateTexture,this);this._update();this.translation.set(e||0,a||0);k.isNumber(g)?this.frameRate=g:this.frameRate=h.DefaultFrameRate};
+k.extend(h,{Properties:["frameRate","index"],DefaultFrameRate:30,FlagTextures:function(){this._flagTextures=!0},BindTextures:function(d){for(var e=d.length;e--;)d[e].bind(c.Events.change,this._renderer.flagTextures);this._renderer.flagTextures()},UnbindTextures:function(d){for(var e=d.length;e--;)d[e].unbind(c.Events.change,this._renderer.flagTextures);this._renderer.flagTextures()},MakeObservable:function(d){l.MakeObservable(d);k.each(h.Properties,c.Utils.defineProperty,d);Object.defineProperty(d,
+"textures",{enumerable:!0,get:function(){return this._textures},set:function(d){var a=this._renderer.bindTextures,e=this._renderer.unbindTextures;this._textures&&this._textures.unbind(c.Events.insert,a).unbind(c.Events.remove,e);this._textures=new c.Utils.Collection((d||[]).slice(0));this._textures.bind(c.Events.insert,a).bind(c.Events.remove,e);a(this._textures)}})},GenerateTexture:function(d){if(d instanceof c.Texture)return d;if(k.isString(d))return new c.Texture(d)}});k.extend(h.prototype,l.prototype,
+{_flagTextures:!1,_flagFrameRate:!1,_flagIndex:!1,_amount:1,_duration:0,_index:0,_startTime:0,_playing:!1,_firstFrame:0,_lastFrame:0,_loop:!0,_textures:null,_frameRate:0,play:function(c,e,a){this._playing=!0;this._firstFrame=0;this._lastFrame=this.amount-1;this._startTime=k.performance.now();k.isNumber(c)&&(this._firstFrame=c);k.isNumber(e)&&(this._lastFrame=e);k.isFunction(a)?this._onLastFrame=a:delete this._onLastFrame;this._index!==this._firstFrame&&(this._startTime-=1E3*Math.abs(this._index-this._firstFrame)/
+this._frameRate);return this},pause:function(){this._playing=!1;return this},stop:function(){this._playing=!1;this._index=0;return this},clone:function(c){c=c||this.parent;var d=new h(this.textures,this.translation.x,this.translation.y,this.frameRate);d._loop=this._loop;this._playing&&d.play();c&&c.add(d);return d},_update:function(){var d=this._textures;this._flagTextures&&(this._amount=d.length);this._flagFrameRate&&(this._duration=1E3*this._amount/this._frameRate);if(this._playing&&0<this._frameRate){var e=
+this._amount;k.isNaN(this._lastFrame)&&(this._lastFrame=e-1);e=k.performance.now()-this._startTime;var a=this._lastFrame+1;var g=1E3*(a-this._firstFrame)/this._frameRate;e=this._loop?e%g:Math.min(e,g);e=k.lerp(this._firstFrame,a,e/g);e=Math.floor(e);e!==this._index&&(this._index=e,a=d[this._index],a.loaded&&(d=a.image.width,g=a.image.height,this.width!==d&&(this.width=d),this.height!==g&&(this.height=g),this.fill=a,e>=this._lastFrame-1&&this._onLastFrame&&this._onLastFrame()))}else!this._flagIndex&&
+this.fill instanceof c.Texture||(a=d[this._index],a.loaded&&(d=a.image.width,g=a.image.height,this.width!==d&&(this.width=d),this.height!==g&&(this.height=g)),this.fill=a);l.prototype._update.call(this);return this},flagReset:function(){this._flagTextures=this._flagFrameRate=!1;l.prototype.flagReset.call(this);return this}});h.MakeObservable(h.prototype)})(("undefined"!==typeof global?global:this).Two);
+(function(c){function k(a,c){var d=a.parent;if(d===c)this.additions.push(a),this._flagAdditions=!0;else{if(d&&d.children.ids[a.id]){var e=h.indexOf(d.children,a);d.children.splice(e,1);e=h.indexOf(d.additions,a);0<=e?d.additions.splice(e,1):(d.subtractions.push(a),d._flagSubtractions=!0)}c?(a.parent=c,this.additions.push(a),this._flagAdditions=!0):(e=h.indexOf(this.additions,a),0<=e?this.additions.splice(e,1):(this.subtractions.push(a),this._flagSubtractions=!0),delete a.parent)}}var m=Math.min,l=
+Math.max,h=c.Utils,d=function(){c.Utils.Collection.apply(this,arguments);Object.defineProperty(this,"_events",{value:{},enumerable:!1});this.ids={};this.on(c.Events.insert,this.attach);this.on(c.Events.remove,this.detach);d.prototype.attach.apply(this,arguments)};d.prototype=new c.Utils.Collection;d.prototype.constructor=d;h.extend(d.prototype,{attach:function(a){for(var c=0;c<a.length;c++)this.ids[a[c].id]=a[c];return this},detach:function(a){for(var c=0;c<a.length;c++)delete this.ids[a[c].id];return this}});
+var e=c.Group=function(){c.Shape.call(this,!0);this._renderer.type="group";this.additions=[];this.subtractions=[];this.children=arguments};h.extend(e,{Children:d,InsertChildren:function(a){for(var c=0;c<a.length;c++)k.call(this,a[c],this)},RemoveChildren:function(a){for(var c=0;c<a.length;c++)k.call(this,a[c])},OrderChildren:function(a){this._flagOrder=!0},MakeObservable:function(a){var g=c.Path.Properties.slice(0),k=h.indexOf(g,"opacity");0<=k&&(g.splice(k,1),Object.defineProperty(a,"opacity",{enumerable:!0,
+get:function(){return this._opacity},set:function(a){this._flagOpacity=this._opacity!=a;this._opacity=a}}));c.Shape.MakeObservable(a);e.MakeGetterSetters(a,g);Object.defineProperty(a,"children",{enumerable:!0,get:function(){return this._children},set:function(a){var g=h.bind(e.InsertChildren,this),f=h.bind(e.RemoveChildren,this),k=h.bind(e.OrderChildren,this);this._children&&this._children.unbind();this._children=new d(a);this._children.bind(c.Events.insert,g);this._children.bind(c.Events.remove,
+f);this._children.bind(c.Events.order,k)}});Object.defineProperty(a,"mask",{enumerable:!0,get:function(){return this._mask},set:function(a){this._mask=a;this._flagMask=!0;a.clip||(a.clip=!0)}})},MakeGetterSetters:function(a,c){h.isArray(c)||(c=[c]);h.each(c,function(c){e.MakeGetterSetter(a,c)})},MakeGetterSetter:function(a,c){var d="_"+c;Object.defineProperty(a,c,{enumerable:!0,get:function(){return this[d]},set:function(a){this[d]=a;h.each(this.children,function(d){d[c]=a})}})}});h.extend(e.prototype,
+c.Shape.prototype,{_flagAdditions:!1,_flagSubtractions:!1,_flagOrder:!1,_flagOpacity:!0,_flagMask:!1,_fill:"#fff",_stroke:"#000",_linewidth:1,_opacity:1,_visible:!0,_cap:"round",_join:"round",_miter:4,_closed:!0,_curved:!1,_automatic:!0,_beginning:0,_ending:1,_mask:null,clone:function(a){a=a||this.parent;var c=new e,d=h.map(this.children,function(a){return a.clone(c)});c.add(d);c.opacity=this.opacity;this.mask&&(c.mask=this.mask);c.translation.copy(this.translation);c.rotation=this.rotation;c.scale=
+this.scale;a&&a.add(c);return c},toObject:function(){var a={children:[],translation:this.translation.toObject(),rotation:this.rotation,scale:this.scale,opacity:this.opacity,mask:this.mask?this.mask.toObject():null};h.each(this.children,function(c,d){a.children[d]=c.toObject()},this);return a},corner:function(){var a=this.getBoundingClientRect(!0),c={x:a.left,y:a.top};this.children.forEach(function(a){a.translation.subSelf(c)});return this},center:function(){var a=this.getBoundingClientRect(!0);a.centroid=
+{x:a.left+a.width/2,y:a.top+a.height/2};this.children.forEach(function(c){c.isShape&&c.translation.subSelf(a.centroid)});return this},getById:function(a){var c=function(a,d){if(a.id===d)return a;if(a.children)for(var e=a.children.length;e--;){var f=c(a.children[e],d);if(f)return f}};return c(this,a)||null},getByClassName:function(a){var c=[],d=function(a,e){-1!=a.classList.indexOf(e)?c.push(a):a.children&&a.children.forEach(function(a){d(a,e)});return c};return d(this,a)},getByType:function(a){var d=
+[],e=function(a,g){for(var f in a.children)a.children[f]instanceof g?d.push(a.children[f]):a.children[f]instanceof c.Group&&e(a.children[f],g);return d};return e(this,a)},add:function(a){a=a instanceof Array?a.slice():h.toArray(arguments);for(var c=0;c<a.length;c++)a[c]&&a[c].id&&this.children.push(a[c]);return this},remove:function(a){var c=this.parent;if(0>=arguments.length&&c)return c.remove(this),this;a=a instanceof Array?a.slice():h.toArray(arguments);for(c=0;c<a.length;c++)a[c]&&this.children.ids[a[c].id]&&
+this.children.splice(h.indexOf(this.children,a[c]),1);return this},getBoundingClientRect:function(a){var c;this._update(!0);var d=Infinity,e=-Infinity,k=Infinity,v=-Infinity;this.children.forEach(function(f){/(linear-gradient|radial-gradient|gradient)/.test(f._renderer.type)||(c=f.getBoundingClientRect(a),h.isNumber(c.top)&&h.isNumber(c.left)&&h.isNumber(c.right)&&h.isNumber(c.bottom)&&(k=m(c.top,k),d=m(c.left,d),e=l(c.right,e),v=l(c.bottom,v)))},this);return{top:k,left:d,right:e,bottom:v,width:e-
+d,height:v-k}},noFill:function(){this.children.forEach(function(a){a.noFill()});return this},noStroke:function(){this.children.forEach(function(a){a.noStroke()});return this},subdivide:function(){var a=arguments;this.children.forEach(function(c){c.subdivide.apply(c,a)});return this},flagReset:function(){this._flagAdditions&&(this.additions.length=0,this._flagAdditions=!1);this._flagSubtractions&&(this.subtractions.length=0,this._flagSubtractions=!1);this._flagOrder=this._flagMask=this._flagOpacity=
+!1;c.Shape.prototype.flagReset.call(this);return this}});e.MakeObservable(e.prototype)})(("undefined"!==typeof global?global:this).Two);
diff --git a/doc/user_guides.md b/doc/user_guides.md
new file mode 100644
index 000000000..832761363
--- /dev/null
+++ b/doc/user_guides.md
@@ -0,0 +1,9 @@
+# User Guides {#user_guides}
+
+- @subpage user_guides_common
+- @subpage iscsi
+- @subpage nvmf
+- @subpage vhost
+- @subpage bdev
+- @subpage blobfs
+- @subpage jsonrpc
diff --git a/doc/user_guides_common.md b/doc/user_guides_common.md
new file mode 100644
index 000000000..25ab260fd
--- /dev/null
+++ b/doc/user_guides_common.md
@@ -0,0 +1,89 @@
+# Configuring SPDK Applications {#user_guides_common}
+
+# Overview {#user_guides_common_overview}
+
+This guide covers topics common to all applications that leverage SPDK's application framework.
+
+## Command Line Parameters {#common_cmd_line_args}
+
+The SPDK application framework defines a set of base command line flags for all applications that use it. Specific applications may implement additional flags.
+
+Param    | Type     | Default                | Description
+-------- | -------- | ---------------------- | -----------
+-c       | string   |                        | @ref cmd_arg_config_file
+-d       | flag     | false                  | disable coredump file creation
+-e       | integer  | 0x0                    | tracepoint group hexadecimal mask for SPDK trace buffers
+-g       | flag     | false                  | force creating just one hugetlbfs file
+-h       | flag     | false                  | show all available parameters and exit
+-i       | integer  | process PID            | shared memory ID
+-m       | CPU mask | 0x1                    | application @ref cpu_mask
+-n       | integer  | all channels           | number of memory channels used for DPDK
+-p       | integer  | first core in CPU mask | master (primary) core for DPDK
+-q       | flag     | false                  | disable notice level logging to `stderr`
+-r       | string   | /var/tmp/spdk.sock     | RPC listen address
+-s       | integer  | all hugepage memory    | memory size in MB for DPDK
+-u       | flag     | false                  | @ref cmd_arg_disable_pci_access.
+-w       | flag     | false                  | @ref cmd_arg_deferred_initialization
+-B       | B:D:F    |                        | @ref cmd_arg_pci_blacklist_whitelist.
+-W       | B:D:F    |                        | @ref cmd_arg_pci_blacklist_whitelist.
+-L       | string   |                        | @ref cmd_arg_debug_log_flags
+-f       | string   |                        | save pid to file under given path
+
+### Configuration file {#cmd_arg_config_file}
+
+Historically, the SPDK application framework was configured using a configuration file. This is still supported, but is
+considered deprecated in favor of JSON RPC configuration. See @ref jsonrpc for details.
+
+Note that `-c` and `-w` cannot be used at the same time.
+
+### Deferred initialization {#cmd_arg_deferred_initialization}
+
+SPDK applications progress through a set of states, including `STARTUP` and `RUNTIME`.
+
+If `-w` parameter is provided SPDK will pause just before starting subsystem initialization. This state is called `STARTUP`.
+The JSON RPC server is ready but list of commands is limited to only those that are needed to set application global parameters.
+Those parameters can't be changed after SPDK application enters `RUNTIME` state. When client finishes preconfiguring SPDK subsystems
+it needs to issue @ref rpc_start_subsystem_init RPC command to continue initialization process. After `rpc_start_subsystem_init`
+returns `true` the SPDK will enter `RUNTIME` state and list of available commands will change again. From now on SPDK is ready
+for further configuration.
+
+To know what RPC methods are valid in current state issue `get_rpc_methods` with parameter `current` set to `true`.
+
+For more details see @ref jsonrpc documentation.
+
+### Disable PCI access {#cmd_arg_disable_pci_access}
+
+If SPDK is run with PCI access disabled it won't detect any PCI devices, including NVMe, IOAT, NICs etc. Also VFIO and UIO
+kernel modules are not needed anymore.
+
+### PCI address blacklist and whitelist {#cmd_arg_pci_blacklist_whitelist}
+
+Note that `-B` and `-W` cannot be used at the same time.
+
+If blacklist is used all devices with provided PCI address will be ignored. If whitelist is used only those
+devices will be probed. You can used `-B` or `-W` more than once to add more than one device to list.
+
+### Debug log flags {#cmd_arg_debug_log_flags}
+
+Use comma separated list of flags or use `-L all` to enable all debug flags. Run SPDK application with `-h` to get a list
+of all valid flags. Debug flags are only available in debug builds of SPDK.
+
+## CPU mask {#cpu_mask}
+
+Whenever the `CPU mask` is mentioned it is a string in one of the following formats:
+
+- Case insensitive hexadecimal string with or without "0x" prefix.
+- Comma separated list of CPUs or list of CPU ranges. Use '-' to define range.
+
+
+### Example
+
+The following CPU masks are equal and correspond to CPUs 0, 1, 2, 8, 9, 10, 11 and 12:
+
+~~~
+0x1f07
+0x1F07
+1f07
+[0,1,2,8-12]
+[0, 1, 2, 8, 9, 10, 11, 12]
+~~~
diff --git a/doc/vhost.md b/doc/vhost.md
index b7748dacd..bde1c1c35 100644
--- a/doc/vhost.md
+++ b/doc/vhost.md
@@ -15,46 +15,32 @@
 
 A vhost target provides a local storage service as a process running on a local machine.
 It is capable of exposing virtualized block devices to QEMU instances or other arbitrary
-processes. These processes communicate with the vhost target using the
-[virtio protocol](https://wiki.libvirt.org/page/Virtio), a standardized protocol for
-paravirtualized devices.
+processes.
+
+The following diagram presents how QEMU-based VM communicates with SPDK Vhost-SCSI device.
+
+![QEMU/SPDK vhost data flow](img/qemu_vhost_data_flow.svg)
+
+The diagram, and the vhost protocol itself is described in @ref vhost_processing doc.
 
 SPDK provides an accelerated vhost target by applying the same user space and polling
-techniques as other components in SPDK.  Since SPDK is polling for virtio submissions,
-it can signal the virtio driver to skip notifications on submission.  This avoids VMEXITs on I/O
-submission and can significantly reduce CPU usage in the guest VM on heavy I/O workloads.
-
-The following diagram presents how QEMU-based VM communicates with an SPDK vhost device.
-
-    +-------QEMU-VM--------+             +---------------SPDK-vhost-------------+
-    |                      |             |                                      |
-    |  +----------------+  |             |  +--------------------------------+  |
-    |  |                |  |             |  |                                |  |
-    |  |  Virtio-SCSI   |  |  eventfd    |  |               +-------------+  |  |
-    |  |  Linux driver  |  |  interrupt  |  |  Virtio-SCSI  |             |  |  |
-    |  |                |  <----------------+  device       |  NVMe disk  |  |  |
-    |  +--------^-------+  |             |  |               |             |  |  |
-    |           |          |             |  |               +-------^-----+  |  |
-    +----------------------+             |  |                       |        |  |
-                |                        |  +----------^---------------------+  |
-                |                        |             |            |           |
-                |                        +--------------------------------------+
-                |                                      |            |
-                |                              polling |            | DMA
-                |                                      |            |
-    +-----------v----Shared hugepage memory------------+------------------------+
-    |                                                               |           |
-    |  +----------------------------------+-------------------------v--------+  |
-    +  |            Virtqueues            |              Buffers             |  |
-    |  +----------------------------------+----------------------------------+  |
-    |                                                                           |
-    +---------------------------------------------------------------------------+
+techniques as other components in SPDK.  Since SPDK is polling for vhost submissions,
+it can signal the VM to skip notifications on submission.  This avoids VMEXITs on I/O
+submission and can significantly reduce CPU usage in the VM on heavy I/O workloads.
 
 # Prerequisites {#vhost_prereqs}
 
 This guide assumes the SPDK has been built according to the instructions in @ref
 getting_started.  The SPDK vhost target is built with the default configure options.
 
+## Vhost Command Line Parameters {#vhost_cmd_line_args}
+
+Additional command line flags are available for Vhost target.
+
+Param    | Type     | Default                | Description
+-------- | -------- | ---------------------- | -----------
+-S       | string   | $PWD                   | directory where UNIX domain sockets will be created
+
 ## Supported Guest Operating Systems
 
 The guest OS must contain virtio-scsi or virtio-blk drivers.  Most Linux and FreeBSD
@@ -125,7 +111,7 @@ For vhost-blk, bdevs are exposed directly as block devices in the guest OS and a
 not associated at all with SCSI.
 
 SPDK supports several different types of storage backends, including NVMe,
-Linux AIO, malloc ramdisk and Ceph RBD.  Refer to @ref bdev_getting_started for
+Linux AIO, malloc ramdisk and Ceph RBD.  Refer to @ref bdev for
 additional information on configuring SPDK storage backends.
 
 This guide will use a malloc bdev (ramdisk) named Malloc0. The following RPC
@@ -135,7 +121,7 @@ will create a 64MB malloc bdev with 512-byte block size.
 scripts/rpc.py construct_malloc_bdev 64 512 -b Malloc0
 ~~~
 
-## Create a virtio device {#vhost_vdev_create}
+## Create a vhost device {#vhost_vdev_create}
 
 ### Vhost-SCSI
 
@@ -163,7 +149,7 @@ scripts/rpc.py add_vhost_scsi_lun vhost.0 0 Malloc0
 To remove a bdev from a vhost-scsi controller use the following RPC:
 
 ~~~{.sh}
-scripts/rpc.py remove_vhost_scsi_dev vhost.0 0
+scripts/rpc.py remove_vhost_scsi_target vhost.0 0
 ~~~
 
 ### Vhost-BLK
@@ -401,7 +387,7 @@ Just like hot-attach, the hot-detach is done by simply removing bdev from a cont
 when QEMU VM is already started.
 
 ~~~{.sh}
-scripts/rpc.py remove_vhost_scsi_dev vhost.0 0
+scripts/rpc.py remove_vhost_scsi_target vhost.0 0
 ~~~
 
 Removing an entire bdev will hot-detach it from a controller as well.
diff --git a/doc/vhost_processing.md b/doc/vhost_processing.md
new file mode 100644
index 000000000..ea9a586d4
--- /dev/null
+++ b/doc/vhost_processing.md
@@ -0,0 +1,166 @@
+# Vhost processing {#vhost_processing}
+
+# Table of Contents {#vhost_processing_toc}
+
+- @ref vhost_processing_intro
+- @ref vhost_processing_qemu
+- @ref vhost_processing_init
+- @ref vhost_processing_io_path
+
+# Introduction {#vhost_processing_intro}
+
+This document is intended to provide an overall high level insight into how
+Vhost works behind the scenes. It assumes you're already familiar with the
+basics of virtqueues and vrings from the
+[VIRTIO protocol](http://docs.oasis-open.org/virtio/virtio/v1.0/virtio-v1.0.html).
+Code snippets used in this document might have been simplified for the sake
+of readability and should not be used as an API or implementation reference.
+
+vhost is a protocol for devices accessible via inter-process communication.
+It uses the same virtqueue and vring layout for I/O transport as VIRTIO to
+allow direct mapping to Virtio devices. The initial vhost implementation is
+a part of the Linux kernel and uses ioctl interface to communicate with
+userspace applications. What makes it possible for SPDK to expose a vhost
+device is Vhost-user protocol.
+
+The [Vhost-user specification](https://git.qemu.org/?p=qemu.git;a=blob_plain;f=docs/interop/vhost-user.txt;hb=HEAD)
+describes the protocol as follows:
+
+```
+[Vhost-user protocol] is aiming to complement the ioctl interface used to
+control the vhost implementation in the Linux kernel. It implements the control
+plane needed to establish virtqueue sharing with a user space process on the
+same host. It uses communication over a Unix domain socket to share file
+descriptors in the ancillary data of the message.
+
+The protocol defines 2 sides of the communication, master and slave. Master is
+the application that shares its virtqueues, in our case QEMU. Slave is the
+consumer of the virtqueues.
+
+In the current implementation QEMU is the Master, and the Slave is intended to
+be a software Ethernet switch running in user space, such as Snabbswitch.
+
+Master and slave can be either a client (i.e. connecting) or server (listening)
+in the socket communication.
+```
+
+SPDK vhost is a Vhost-user slave server. It exposes Unix domain sockets and
+allows external applications to connect.
+
+# QEMU {#vhost_processing_qemu}
+
+One of major Vhost-user use cases is networking (DPDK) or storage (SPDK)
+offload in QEMU. The following diagram presents how QEMU-based VM
+communicates with SPDK Vhost-SCSI device.
+
+![QEMU/SPDK vhost data flow](img/qemu_vhost_data_flow.svg)
+
+The irqfd mechanism isn't described in this document, as it KVM/QEMU-specific.
+Briefly speaking, doing an eventfd_write on the callfd descriptor will
+directly interrupt the guest because of irqfd.
+
+# Device initialization {#vhost_processing_init}
+
+All initialization and management information is exchanged via the Vhost-user
+messages. The connection always starts with the feature negotiation. Both
+the Master and the Slave exposes a list of their implemented features. Most
+of these features are implementation-related, but also regard e.g. multiqueue
+support or live migration. A feature will be used only if both sides support
+it.
+
+After the negotiatiation Vhost-user driver shares its memory, so that the vhost
+device (SPDK) can access it directly. The memory can be fragmented into multiple
+physically-discontiguous regions, although Vhost-user specification enforces
+a limit on their number (currently 8). The driver sends a single message with
+the following data for each region:
+ * file descriptor - for mmap
+ * user address - for memory translations in Vhost-user messages (e.g.
+   translating vring addresses)
+ * guest address - for buffers addresses translations in vrings (for QEMU this
+   is a physical address inside the guest)
+ * user offset - positive offset for the mmap
+ * size
+
+The Master will send new memory regions after each memory change - usually
+hotplug/hotremove. The previous mappings will be removed.
+
+Drivers may also request a device config, consisting of e.g. disk geometry.
+Vhost-SCSI drivers, however, don't need implement this functionality
+as they use common SCSI I/O to inquiry the underlying disk(s).
+
+Afterwards, the driver requests the number of maximum supported queues and
+starts sending virtqueue data, which consists of:
+ * unique virtqueue id
+ * index of the last processed vring descriptor
+ * vring addresses (from user address space)
+ * call descriptor (for interrupting the driver after I/O completions)
+ * kick descriptor (to listen for I/O requests - unused by SPDK)
+
+If multiqueue feature has been negotiated, the driver has to send a specific
+*ENABLE* message for each extra queue it wants to be polled. Other queues are
+polled as soon as they're initialized.
+
+# I/O path {#vhost_processing_io_path}
+
+The Master sends I/O by allocating proper buffers in shared memory, filling
+the request data, and putting guest addresses of those buffers into virtqueues.
+
+A Virtio-Block request looks as follows.
+
+```
+struct virtio_blk_req {
+        uint32_t type; // READ, WRITE, FLUSH (read-only)
+        uint64_t offset; // offset in the disk (read-only)
+        struct iovec buffers[]; // scatter-gatter list (read/write)
+        uint8_t status; // I/O completion status (write-only)
+};
+```
+And a Virtio-SCSI request as follows.
+
+```
+struct virtio_scsi_req_cmd {
+  struct virtio_scsi_cmd_req *req; // request data (read-only)
+  struct iovec read_only_buffers[]; // scatter-gatter list for WRITE I/Os
+  struct virtio_scsi_cmd_resp *resp; // response data (write-only)
+  struct iovec write_only_buffers[]; // scatter-gatter list for READ I/Os
+}
+```
+
+Virtqueue generally consists of an array of descriptors and each I/O needs
+to be converted into a chain of such descriptors. A descriptor can be
+either readable or writable, so each I/O request must consist of at least two
+descriptors (request + response).
+
+
+```
+struct virtq_desc {
+        /* Address (guest-physical). */
+        le64 addr;
+        /* Length. */
+        le32 len;
+
+/* This marks a buffer as continuing via the next field. */
+#define VIRTQ_DESC_F_NEXT   1
+/* This marks a buffer as device write-only (otherwise device read-only). */
+#define VIRTQ_DESC_F_WRITE     2
+        /* The flags as indicated above. */
+        le16 flags;
+        /* Next field if flags & NEXT */
+        le16 next;
+};
+```
+
+The device after polling this descriptor chain needs to translate and transform
+it back into the original request struct. It needs to know the request layout
+up-front, so each device backend (Vhost-Block/SCSI) has its own implementation
+for polling virtqueues. For each descriptor, the device performs a lookup in
+the Vhost-user memory region table and goes through a gpa_to_vva translation
+(guest physical address to vhost virtual address). SPDK enforces the request
+and response data to be contained within a single memory region. I/O buffers
+do not have such limitations and SPDK may automatically perform additional
+iovec splitting and gpa_to_vva translations if required. After forming request
+structs, SPDK forwards such I/O to the underlying drive and polls for the
+completion. Once I/O completes, SPDK vhost fills the response buffer with
+proper data and interrupts the guest by doing an eventfd_write on the call
+descriptor for proper virtqueue. There are multiple interrupt coalescing
+features involved, but they won't be discussed in this document.
diff --git a/dpdkbuild/Makefile b/dpdkbuild/Makefile
index cc611156b..f81bd3e54 100644
--- a/dpdkbuild/Makefile
+++ b/dpdkbuild/Makefile
@@ -36,6 +36,32 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
 .PHONY: all clean install
 
+IPSEC_OPTS=SHARED=n
+INTEL_IPSEC_MB_LIB=
+CRYPTO_ENABLED=n
+
+ifeq ($(CONFIG_CRYPTO),y)
+ifeq ($(TARGET_MACHINE),x86_64)
+ifneq ($(wildcard $(SPDK_ROOT_DIR)/intel-ipsec-mb/README),)
+INTEL_IPSEC_MB_LIB=$(SPDK_ROOT_DIR)/intel-ipsec-mb/libIPSec_MB.a
+IPSEC_MB_CFLAGS = -fPIC
+CRYPTO_ENABLED = y
+DPDK_OPTS += AESNI_MULTI_BUFFER_LIB_PATH=$(SPDK_ROOT_DIR)/intel-ipsec-mb
+DPDK_OPTS += CONFIG_RTE_LIBRTE_PMD_AESNI_MB=y
+DPDK_OPTS += CONFIG_RTE_LIBRTE_CRYPTODEV=y
+DPDK_OPTS += CONFIG_RTE_LIBRTE_REORDER=y
+DPDK_OPTS += CONFIG_RTE_LIBRTE_KVARGS=y
+endif
+endif
+endif
+
+ifeq ($(CRYPTO_ENABLED),n)
+DPDK_OPTS += CONFIG_RTE_LIBRTE_PMD_AESNI_MB=n
+DPDK_OPTS += CONFIG_RTE_LIBRTE_CRYPTODEV=n
+DPDK_OPTS += CONFIG_RTE_LIBRTE_REORDER=n
+DPDK_OPTS += CONFIG_RTE_LIBRTE_KVARGS=n
+endif
+
 ifeq ($(TARGET_MACHINE),aarch64)
 DPDK_CONFIG := arm64-armv8a
 else
@@ -54,16 +80,17 @@ endif
 
 ifeq ($(CC_TYPE),clang)
 DPDK_CONFIG := $(DPDK_CONFIG)-clang
+IPSEC_CC := clang
 else
 DPDK_CONFIG := $(DPDK_CONFIG)-gcc
+IPSEC_CC := gcc
 endif
 
-ifeq ($(CONFIG_FIO_PLUGIN),y)
 DPDK_CFLAGS = -fPIC
-endif
 
 ifeq ($(CONFIG_DEBUG),y)
 DPDK_CFLAGS += -O0 -g
+IPSEC_OPTS += DEBUG=y
 endif
 
 ifeq ($(CONFIG_WERROR),y)
@@ -72,13 +99,20 @@ else
 DPDK_CFLAGS += -Wno-error
 endif
 
-$(SPDK_ROOT_DIR)/dpdk/build:
-	$(Q)$(MAKE) -C $(SPDK_ROOT_DIR)/dpdk config T=$(DPDK_CONFIG)
+$(SPDK_ROOT_DIR)/dpdk/build: $(INTEL_IPSEC_MB_LIB)
+	$(Q)$(MAKE) -C $(SPDK_ROOT_DIR)/dpdk config T=$(DPDK_CONFIG) $(DPDK_OPTS)
 
-all: $(SPDK_ROOT_DIR)/dpdk/build
-	$(Q)$(MAKE) -C $(SPDK_ROOT_DIR)/dpdk/build EXTRA_CFLAGS="$(DPDK_CFLAGS)" MAKEFLAGS="T=$(DPDK_CONFIG) -j$(NPROC)"
+all: $(SPDK_ROOT_DIR)/dpdk/build $(INTEL_IPSEC_MB_LIB)
+	$(Q)$(MAKE) -C $(SPDK_ROOT_DIR)/dpdk/build EXTRA_CFLAGS="$(DPDK_CFLAGS)" MAKEFLAGS="T=$(DPDK_CONFIG) -j$(NPROC)" $(DPDK_OPTS)
+
+ifeq ($(CONFIG_CRYPTO),y)
+$(SPDK_ROOT_DIR)/intel-ipsec-mb/libIPSec_MB.a:
+	$(Q)$(MAKE) -C $(SPDK_ROOT_DIR)/intel-ipsec-mb EXTRA_CFLAGS="$(IPSEC_MB_CFLAGS)" $(IPSEC_OPTS) MAKEFLAGS="j$(NPROC)" CC=$(IPSEC_CC)
+endif
 
 clean:
-	$(Q)rm -rf $(SPDK_ROOT_DIR)/dpdk/build
+	$(Q)rm -rf $(SPDK_ROOT_DIR)/dpdk/build; \
+	rm -rf $(SPDK_ROOT_DIR)/intel-ipsec-mb/obj/*; \
+	rm -rf $(SPDK_ROOT_DIR)/intel-ipsec-mb/libIPSec_MB.a
 
 install: all
diff --git a/etc/spdk/iscsi.conf.in b/etc/spdk/iscsi.conf.in
index a2b0cd84c..2935dc767 100644
--- a/etc/spdk/iscsi.conf.in
+++ b/etc/spdk/iscsi.conf.in
@@ -29,6 +29,15 @@
   # Set to 0xFFFFFFFFFFFFFFFF to enable all tracepoint groups.
   #TpointGroupMask 0x0
 
+# Users may activate entries in this section to override default values for
+# global parameters in the block device (bdev) subsystem.
+[Bdev]
+  # Number of spdk_bdev_io structures allocated in the global bdev subsystem pool.
+  #BdevIoPoolSize 65536
+
+  # Maximum number of spdk_bdev_io structures to cache per thread.
+  #BdevIoCacheSize 256
+
 [iSCSI]
   # node name (not include optional part)
   # Users can optionally change this to fit their environment.
@@ -121,9 +130,10 @@
 
 # Users may change this section to create a different number or size of
 #  malloc LUNs.
-# If the system has hardware DMA engine, it will use an IOAT
-# (i.e. Crystal Beach DMA) channel to do the copy instead of memcpy.
-# Of course, users can disable offload even it is available.
+# If the system has hardware DMA engine, it can use an IOAT
+# (i.e. Crystal Beach DMA) channel to do the copy instead of memcpy
+# by specifying "Enable Yes" in [Ioat] section.
+# Offload is disabled by default even it is available.
 [Malloc]
   # Number of Malloc targets
   NumberOfLuns 3
@@ -132,11 +142,12 @@
   # Block size. Default is 512 bytes.
   BlockSize 4096
 
-# Users may not want to use offload even it is available.
+# Users can use offload by specifying "Enable Yes" in this section
+# if it is available.
 # Users may use the whitelist to initialize specified devices, IDS
 #  uses BUS:DEVICE.FUNCTION to identify each Ioat channel.
 [Ioat]
-  Disable Yes
+  Enable No
   Whitelist 00:04.0
   Whitelist 00:04.1
 
diff --git a/etc/spdk/nvmf.conf.in b/etc/spdk/nvmf.conf.in
index 835229f6d..512dd1be8 100644
--- a/etc/spdk/nvmf.conf.in
+++ b/etc/spdk/nvmf.conf.in
@@ -20,6 +20,21 @@
   # Set to 0xFFFFFFFFFFFFFFFF to enable all tracepoint groups.
   #TpointGroupMask 0x0
 
+  # PciBlacklist and PciWhitelist cannot be used at the same time
+  #PciBlacklist 0000:01:00.0
+  #PciBlacklist 0000:02:00.0
+  #PciWhitelist 0000:03:00.0
+  #PciWhitelist 0000:04:00.0
+
+# Users may activate entries in this section to override default values for
+# global parameters in the block device (bdev) subsystem.
+[Bdev]
+  # Number of spdk_bdev_io structures allocated in the global bdev subsystem pool.
+  #BdevIoPoolSize 65536
+
+  # Maximum number of spdk_bdev_io structures to cache per thread.
+  #BdevIoCacheSize 256
+
 # Users may change this section to create a different number or size of
 #  malloc LUNs.
 # This will generate 8 LUNs with a malloc-allocated backend.
@@ -127,9 +142,9 @@
 #   The user must specify a bdev name for each namespace, and may optionally
 #   specify a namespace ID. If nsid is omitted, the namespace will be
 #   assigned the next available NSID. The NSID must be unique within the
-#   subsystem.
+#   subsystem. An optional namespace UUID may also be specified.
 #   Syntax:
-#     Namespace <bdev_name> [<nsid>]
+#     Namespace <bdev_name> [<nsid> [<uuid>]]
 
 # Namespaces backed by physical NVMe devices
 [Subsystem1]
diff --git a/etc/spdk/rocksdb.conf.in b/etc/spdk/rocksdb.conf.in
index 004609987..928d09788 100644
--- a/etc/spdk/rocksdb.conf.in
+++ b/etc/spdk/rocksdb.conf.in
@@ -17,6 +17,6 @@
   #ReactorMask 0x1
 
 [Ioat]
-  Disable Yes
+  Enable No
 
 # [Nvme] section will get appended here by scripts/gen_nvme.sh.
diff --git a/etc/spdk/vhost.conf.in b/etc/spdk/vhost.conf.in
index b7f1b8ec5..261e58918 100644
--- a/etc/spdk/vhost.conf.in
+++ b/etc/spdk/vhost.conf.in
@@ -29,11 +29,22 @@
   # Set to 0xFFFFFFFFFFFFFFFF to enable all tracepoint groups.
   #TpointGroupMask 0x0
 
+# Users may activate entries in this section to override default values for
+# global parameters in the block device (bdev) subsystem.
+[Bdev]
+  # Number of spdk_bdev_io structures allocated in the global bdev subsystem pool.
+  #BdevIoPoolSize 65536
+
+  # Maximum number of spdk_bdev_io structures to cache per thread.
+  #BdevIoCacheSize 256
+
 # Users may not want to use offload even it is available.
+# Users can use offload by specifying "Enable Yes" in this section
+# if it is available.
 # Users may use the whitelist to initialize specified devices, IDS
 #  uses BUS:DEVICE.FUNCTION to identify each Ioat channel.
 [Ioat]
-  Disable Yes
+  Enable No
   #Whitelist 00:04.0
   #Whitelist 00:04.1
 
@@ -51,9 +62,10 @@
 
 # Users may change this section to create a different number or size of
 #  malloc LUNs.
-# If the system has hardware DMA engine, it will use an IOAT
-# (i.e. Crystal Beach DMA) channel to do the copy instead of memcpy.
-# Of course, users can disable offload even it is available.
+# If the system has hardware DMA engine, it can use an IOAT
+# (i.e. Crystal Beach DMA) channel to do the copy instead of memcpy
+# by specifying "Enable Yes" in [Ioat] section.
+# Offload is disabled by default even it is available.
 [Malloc]
   # Number of Malloc targets
   NumberOfLuns 3
@@ -109,13 +121,13 @@
   Name vhost.0
   # Assign devices from backend
   # Use the first malloc device
-  Dev 0 Malloc0
+  Target 0 Malloc0
   # Use the first AIO device
-  #Dev 1 AIO0
+  #Target 1 AIO0
   # Use the frist Nvme device
-  #Dev 2 Nvme0n1
+  #Target 2 Nvme0n1
   # Use the third partition from second Nvme device
-  #Dev 3 Nvme1n1p2
+  #Target 3 Nvme1n1p2
 
   # Start the poller for this vhost controller on one of the cores in
   #  this cpumask.  By default, it not specified, will use any core in the
@@ -124,7 +136,7 @@
 
 #[VhostScsi1]
 #  Name vhost.1
-#  Dev 0 AIO1
+#  Target 0 AIO1
 #  Cpumask 0x1
 
 #[VhostBlk0]
diff --git a/examples/bdev/Makefile b/examples/bdev/Makefile
index e0083d202..dc1f52213 100644
--- a/examples/bdev/Makefile
+++ b/examples/bdev/Makefile
@@ -35,6 +35,7 @@ SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
 DIRS-$(CONFIG_FIO_PLUGIN) = fio_plugin
+DIRS-y += hello_world
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/examples/bdev/fio_plugin/Makefile b/examples/bdev/fio_plugin/Makefile
index e47fadfa2..4f16751bb 100644
--- a/examples/bdev/fio_plugin/Makefile
+++ b/examples/bdev/fio_plugin/Makefile
@@ -43,7 +43,7 @@ C_SRCS = fio_plugin.c
 CFLAGS += -I$(FIO_SOURCE_DIR)
 LDFLAGS += -shared -rdynamic
 
-SPDK_LIB_LIST +=  util bdev conf copy rpc jsonrpc json log
+SPDK_LIB_LIST +=  thread util bdev conf copy rpc jsonrpc json log
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
diff --git a/examples/bdev/fio_plugin/fio_plugin.c b/examples/bdev/fio_plugin/fio_plugin.c
index 60f775fd5..6244ee8a4 100644
--- a/examples/bdev/fio_plugin/fio_plugin.c
+++ b/examples/bdev/fio_plugin/fio_plugin.c
@@ -37,7 +37,7 @@
 #include "spdk/copy_engine.h"
 #include "spdk/conf.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 #include "spdk/string.h"
 #include "spdk/queue.h"
@@ -95,6 +95,7 @@ struct spdk_fio_thread {
 };
 
 static struct spdk_fio_thread *g_init_thread = NULL;
+static pthread_t g_init_thread_id = 0;
 static bool g_spdk_env_initialized = false;
 
 static int spdk_fio_init(struct thread_data *td);
@@ -207,6 +208,36 @@ spdk_fio_init_thread(struct thread_data *td)
 	return 0;
 }
 
+static void *
+spdk_init_thread_poll(void *arg)
+{
+	struct spdk_fio_thread *thread = arg;
+	int oldstate;
+	int rc;
+
+	/* Loop until the thread is cancelled */
+	while (true) {
+		rc = pthread_setcancelstate(PTHREAD_CANCEL_DISABLE, &oldstate);
+		if (rc != 0) {
+			SPDK_ERRLOG("Unable to set cancel state disabled on g_init_thread (%d): %s\n",
+				    rc, spdk_strerror(rc));
+		}
+
+		spdk_fio_poll_thread(thread);
+
+		rc = pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &oldstate);
+		if (rc != 0) {
+			SPDK_ERRLOG("Unable to set cancel state enabled on g_init_thread (%d): %s\n",
+				    rc, spdk_strerror(rc));
+		}
+
+		/* This is a pthread cancellation point and cannot be removed. */
+		sleep(1);
+	}
+
+	return NULL;
+}
+
 static int
 spdk_fio_init_env(struct thread_data *td)
 {
@@ -288,6 +319,16 @@ spdk_fio_init_env(struct thread_data *td)
 		count = spdk_fio_poll_thread(fio_thread);
 	} while (count > 0);
 
+	/*
+	 * Spawn a thread to continue polling this thread
+	 * occasionally.
+	 */
+
+	rc = pthread_create(&g_init_thread_id, NULL, &spdk_init_thread_poll, fio_thread);
+	if (rc != 0) {
+		SPDK_ERRLOG("Unable to spawn thread to poll admin queue. It won't be polled.\n");
+	}
+
 	return 0;
 }
 
@@ -489,7 +530,13 @@ spdk_fio_completion_cb(struct spdk_bdev_io *bdev_io,
 	spdk_bdev_free_io(bdev_io);
 }
 
-static int
+#if FIO_IOOPS_VERSION >= 24
+typedef enum fio_q_status fio_q_status_t;
+#else
+typedef int fio_q_status_t;
+#endif
+
+static fio_q_status_t
 spdk_fio_queue(struct thread_data *td, struct io_u *io_u)
 {
 	int rc = 1;
@@ -694,6 +741,10 @@ spdk_fio_finish_env(void)
 	/* the same thread that called spdk_fio_init_env */
 	fio_thread = g_init_thread;
 
+	if (pthread_cancel(g_init_thread_id) == 0) {
+		pthread_join(g_init_thread_id, NULL);
+	}
+
 	spdk_bdev_finish(spdk_fio_module_finish_done, &done);
 
 	do {
diff --git a/examples/bdev/hello_world/.gitignore b/examples/bdev/hello_world/.gitignore
new file mode 100644
index 000000000..7bdf93936
--- /dev/null
+++ b/examples/bdev/hello_world/.gitignore
@@ -0,0 +1 @@
+hello_bdev
diff --git a/examples/bdev/hello_world/Makefile b/examples/bdev/hello_world/Makefile
new file mode 100644
index 000000000..dacc1b81b
--- /dev/null
+++ b/examples/bdev/hello_world/Makefile
@@ -0,0 +1,56 @@
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.modules.mk
+
+APP = hello_bdev
+
+C_SRCS := hello_bdev.c
+
+SPDK_LIB_LIST = event_bdev event_copy
+SPDK_LIB_LIST += bdev copy event thread util conf trace log jsonrpc json rpc
+
+LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS) $(SOCK_MODULES_LINKER_ARGS)
+LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
+
+all : $(APP)
+	@:
+
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+	$(LINK_C)
+
+clean :
+	$(CLEAN_C) $(APP)
+
+include $(SPDK_ROOT_DIR)/mk/spdk.deps.mk
diff --git a/examples/bdev/hello_world/bdev.conf b/examples/bdev/hello_world/bdev.conf
new file mode 100644
index 000000000..c8504b017
--- /dev/null
+++ b/examples/bdev/hello_world/bdev.conf
@@ -0,0 +1,5 @@
+[Passthru]
+  PT Malloc1 PT0
+[Malloc]
+  NumberOfLuns 2
+  LunSizeInMB  16
diff --git a/examples/bdev/hello_world/hello_bdev.c b/examples/bdev/hello_world/hello_bdev.c
new file mode 100644
index 000000000..d9f1be1d6
--- /dev/null
+++ b/examples/bdev/hello_world/hello_bdev.c
@@ -0,0 +1,259 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/stdinc.h"
+#include "spdk/thread.h"
+#include "spdk/bdev.h"
+#include "spdk/env.h"
+#include "spdk/event.h"
+#include "spdk/log.h"
+#include "spdk/string.h"
+#include "spdk/bdev_module.h"
+
+static char *g_bdev_name = "Malloc0";
+
+/*
+ * We'll use this struct to gather housekeeping hello_context to pass between
+ * our events and callbacks.
+ */
+struct hello_context_t {
+	struct spdk_bdev *bdev;
+	struct spdk_bdev_desc *bdev_desc;
+	struct spdk_io_channel *bdev_io_channel;
+	char *buff;
+	char *bdev_name;
+};
+
+/*
+ * Usage function for printing parameters that are specific to this application
+ */
+static void
+hello_bdev_usage(void)
+{
+	printf(" -b bdev name\n");
+}
+
+/*
+ * This function is called to parse the parameters that are specific to this application
+ */
+static void hello_bdev_parse_arg(int ch, char *arg)
+{
+	switch (ch) {
+	case 'b':
+		g_bdev_name = arg;
+		break;
+	}
+}
+
+/*
+ * Callback function for read io completion.
+ */
+static void
+read_complete(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+{
+	struct hello_context_t *hello_context = cb_arg;
+
+	if (success) {
+		SPDK_NOTICELOG("Read string from bdev : %s\n", hello_context->buff);
+	} else {
+		SPDK_ERRLOG("bdev io read error\n");
+	}
+
+	/* Complete the bdev io and close the channel */
+	spdk_bdev_free_io(bdev_io);
+	spdk_put_io_channel(hello_context->bdev_io_channel);
+	spdk_bdev_close(hello_context->bdev_desc);
+	SPDK_NOTICELOG("Stopping app\n");
+	spdk_app_stop(success ? 0 : -1);
+}
+
+/*
+ * Callback function for write io completion.
+ */
+static void
+write_complete(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+{
+	struct hello_context_t *hello_context = cb_arg;
+	int rc;
+	uint32_t blk_size;
+
+	/* Complete the I/O */
+	spdk_bdev_free_io(bdev_io);
+
+	if (success) {
+		SPDK_NOTICELOG("bdev io write completed successfully\n");
+	} else {
+		SPDK_ERRLOG("bdev io write error: %d\n", EIO);
+		spdk_put_io_channel(hello_context->bdev_io_channel);
+		spdk_bdev_close(hello_context->bdev_desc);
+		spdk_app_stop(-1);
+		return;
+	}
+
+	/* Zero the buffer so that we can use it for reading */
+	blk_size = spdk_bdev_get_block_size(hello_context->bdev);
+	memset(hello_context->buff, 0, blk_size);
+
+	SPDK_NOTICELOG("Reading io\n");
+	rc = spdk_bdev_read(hello_context->bdev_desc, hello_context->bdev_io_channel,
+			    hello_context->buff, 0, blk_size, read_complete, hello_context);
+
+	if (rc) {
+		SPDK_ERRLOG("%s error while reading from bdev: %d\n", spdk_strerror(-rc), rc);
+		spdk_put_io_channel(hello_context->bdev_io_channel);
+		spdk_bdev_close(hello_context->bdev_desc);
+		spdk_app_stop(-1);
+		return;
+	}
+}
+
+/*
+ * Our initial event that kicks off everything from main().
+ */
+static void
+hello_start(void *arg1, void *arg2)
+{
+	struct hello_context_t *hello_context = arg1;
+	uint32_t blk_size, buf_align;
+	int rc = 0;
+	hello_context->bdev = NULL;
+	hello_context->bdev_desc = NULL;
+
+	SPDK_NOTICELOG("Successfully started the application\n");
+
+	/*
+	 * Get the bdev. There can be many bdevs configured in
+	 * in the configuration file but this application will only
+	 * use the one input by the user at runtime so we get it via its name.
+	 */
+	hello_context->bdev = spdk_bdev_get_by_name(hello_context->bdev_name);
+	if (hello_context->bdev == NULL) {
+		SPDK_ERRLOG("Could not find the bdev: %s\n", hello_context->bdev_name);
+		spdk_app_stop(-1);
+		return;
+	}
+
+	/*
+	 * Open the bdev by calling spdk_bdev_open()
+	 * The function will return a descriptor
+	 */
+	SPDK_NOTICELOG("Opening the bdev %s\n", hello_context->bdev_name);
+	rc = spdk_bdev_open(hello_context->bdev, true, NULL, NULL, &hello_context->bdev_desc);
+	if (rc) {
+		SPDK_ERRLOG("Could not open bdev: %s\n", hello_context->bdev_name);
+		spdk_app_stop(-1);
+		return;
+	}
+
+	SPDK_NOTICELOG("Opening io channel\n");
+	/* Open I/O channel */
+	hello_context->bdev_io_channel = spdk_bdev_get_io_channel(hello_context->bdev_desc);
+	if (hello_context->bdev_io_channel == NULL) {
+		SPDK_ERRLOG("Could not create bdev I/O channel!!\n");
+		spdk_bdev_close(hello_context->bdev_desc);
+		spdk_app_stop(-1);
+		return;
+	}
+
+	/* Allocate memory for the write buffer.
+	 * Initialize the write buffer with the string "Hello World!"
+	 */
+	blk_size = spdk_bdev_get_block_size(hello_context->bdev);
+	buf_align = spdk_bdev_get_buf_align(hello_context->bdev);
+	hello_context->buff = spdk_dma_zmalloc(blk_size, buf_align, NULL);
+	if (!hello_context->buff) {
+		SPDK_ERRLOG("Failed to allocate buffer\n");
+		spdk_put_io_channel(hello_context->bdev_io_channel);
+		spdk_bdev_close(hello_context->bdev_desc);
+		spdk_app_stop(-1);
+		return;
+	}
+	snprintf(hello_context->buff, blk_size, "%s", "Hello World!\n");
+
+	SPDK_NOTICELOG("Writing to the bdev\n");
+	rc = spdk_bdev_write(hello_context->bdev_desc, hello_context->bdev_io_channel,
+			     hello_context->buff, 0, blk_size, write_complete, hello_context);
+	if (rc) {
+		SPDK_ERRLOG("%s error while writing to bdev: %d\n", spdk_strerror(-rc), rc);
+		spdk_bdev_close(hello_context->bdev_desc);
+		spdk_put_io_channel(hello_context->bdev_io_channel);
+		spdk_app_stop(-1);
+		return;
+	}
+}
+
+int
+main(int argc, char **argv)
+{
+	struct spdk_app_opts opts = {};
+	int rc = 0;
+	struct hello_context_t hello_context = {};
+
+	/* Set default values in opts structure. */
+	spdk_app_opts_init(&opts);
+	opts.name = "hello_bdev";
+	opts.config_file = "bdev.conf";
+
+	/*
+	 * The user can provide the config file and bdev name at run time.
+	 * For example, to use Malloc0 in file bdev.conf run with params
+	 * ./hello_bdev -c bdev.conf -b Malloc0
+	 * To use passthru bdev PT0 run with params
+	 * ./hello_bdev -c bdev.conf -b PT0
+	 * If none of the parameters are provide the application will use the
+	 * default parameters(-c bdev.conf -b Malloc0).
+	 */
+	if ((rc = spdk_app_parse_args(argc, argv, &opts, "b:", hello_bdev_parse_arg,
+				      hello_bdev_usage)) != SPDK_APP_PARSE_ARGS_SUCCESS) {
+		exit(rc);
+	}
+	hello_context.bdev_name = g_bdev_name;
+
+	/*
+	 * spdk_app_start() will block running hello_start() until
+	 * spdk_app_stop() is called by someone (not simply when
+	 * hello_start() returns), or if an error occurs during
+	 * spdk_app_start() before hello_start() runs.
+	 */
+	rc = spdk_app_start(&opts, hello_start, &hello_context, NULL);
+	if (rc) {
+		SPDK_ERRLOG("ERROR starting application\n");
+	}
+
+	/* When the app stops, free up memory that we allocated. */
+	spdk_dma_free(hello_context.buff);
+
+	/* Gracefully close out all of the SPDK subsystems. */
+	spdk_app_fini();
+	return rc;
+}
diff --git a/examples/blob/cli/Makefile b/examples/blob/cli/Makefile
index 5f5817850..7796c40f1 100644
--- a/examples/blob/cli/Makefile
+++ b/examples/blob/cli/Makefile
@@ -39,16 +39,16 @@ APP = blobcli
 C_SRCS := blobcli.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event util conf trace \
+SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event thread util conf trace \
 		log jsonrpc json rpc
 
-LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_NO_LVOL_MODULES_LINKER_ARGS)
+LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_NO_LVOL_MODULES_LINKER_ARGS) $(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_NO_LVOL_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(COPY_MODULES_FILES) $(BLOCKDEV_NO_LVOL_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/examples/blob/cli/blobcli.c b/examples/blob/cli/blobcli.c
index be370629a..9cba85de2 100644
--- a/examples/blob/cli/blobcli.c
+++ b/examples/blob/cli/blobcli.c
@@ -41,6 +41,7 @@
 #include "spdk/log.h"
 #include "spdk/version.h"
 #include "spdk/string.h"
+#include "spdk/uuid.h"
 
 /*
  * The following is not a public header file, but the CLI does expose
@@ -80,6 +81,7 @@ enum cli_action_type {
 	CLI_LIST_BDEVS,
 	CLI_LIST_BLOBS,
 	CLI_INIT_BS,
+	CLI_DUMP_BS,
 	CLI_SHELL_EXIT,
 	CLI_HELP,
 };
@@ -147,6 +149,7 @@ print_cmds(void)
 	printf("\nCommands include:\n");
 	printf("\t-b bdev - name of the block device to use (example: Nvme0n1)\n");
 	printf("\t-d <blobid> filename - dump contents of a blob to a file\n");
+	printf("\t-D - dump metadata contents of an existing blobstore\n");
 	printf("\t-f <blobid> value - fill a blob with a decimal value\n");
 	printf("\t-h - this help screen\n");
 	printf("\t-i - initialize a blobstore\n");
@@ -958,6 +961,77 @@ init_bs(struct cli_context_t *cli_context)
 		     cli_context);
 }
 
+static void
+spdk_bsdump_done(void *arg, int bserrno)
+{
+	struct cli_context_t *cli_context = arg;
+
+	if (cli_context->cli_mode == CLI_MODE_CMD) {
+		spdk_app_stop(0);
+	} else {
+		cli_context->action = CLI_NONE;
+		cli_start(cli_context, NULL);
+	}
+}
+
+static void
+bsdump_print_xattr(FILE *fp, const char *bstype, const char *name, const void *value,
+		   size_t value_len)
+{
+	if (strncmp(bstype, "BLOBFS", SPDK_BLOBSTORE_TYPE_LENGTH) == 0) {
+		if (strcmp(name, "name") == 0) {
+			fprintf(fp, "%.*s", (int)value_len, (char *)value);
+		} else if (strcmp(name, "length") == 0 && value_len == sizeof(uint64_t)) {
+			uint64_t length;
+
+			memcpy(&length, value, sizeof(length));
+			fprintf(fp, "%" PRIu64, length);
+		} else {
+			fprintf(fp, "?");
+		}
+	} else if (strncmp(bstype, "LVOLSTORE", SPDK_BLOBSTORE_TYPE_LENGTH) == 0) {
+		if (strcmp(name, "name") == 0) {
+			fprintf(fp, "%s", (char *)value);
+		} else if (strcmp(name, "uuid") == 0 && value_len == sizeof(struct spdk_uuid)) {
+			char uuid[SPDK_UUID_STRING_LEN];
+
+			spdk_uuid_fmt_lower(uuid, sizeof(uuid), (struct spdk_uuid *)value);
+			fprintf(fp, "%s", uuid);
+		} else {
+			fprintf(fp, "?");
+		}
+	} else {
+		fprintf(fp, "?");
+	}
+}
+
+/*
+ * Dump metadata of an existing blobstore in a human-readable format.
+ */
+static void
+dump_bs(struct cli_context_t *cli_context)
+{
+	struct spdk_bdev *bdev = NULL;
+
+	bdev = spdk_bdev_get_by_name(cli_context->bdev_name);
+	if (bdev == NULL) {
+		printf("Could not find a bdev\n");
+		spdk_app_stop(-1);
+		return;
+	}
+	printf("Init blobstore using bdev Product Name: %s\n",
+	       spdk_bdev_get_product_name(bdev));
+
+	cli_context->bs_dev = spdk_bdev_create_bs_dev(bdev, NULL, NULL);
+	if (cli_context->bs_dev == NULL) {
+		printf("Could not create blob bdev!!\n");
+		spdk_app_stop(-1);
+		return;
+	}
+
+	spdk_bs_dump(cli_context->bs_dev, stdout, bsdump_print_xattr, spdk_bsdump_done, cli_context);
+}
+
 /*
  * Common cmd/option parser for command and shell modes.
  */
@@ -968,7 +1042,7 @@ cmd_parser(int argc, char **argv, struct cli_context_t *cli_context)
 	int cmd_chosen = 0;
 	char resp;
 
-	while ((op = getopt(argc, argv, "b:c:d:f:hil:m:n:p:r:s:ST:Xx:")) != -1) {
+	while ((op = getopt(argc, argv, "b:c:d:f:hil:m:n:p:r:s:DST:Xx:")) != -1) {
 		switch (op) {
 		case 'b':
 			if (strcmp(cli_context->bdev_name, "") == 0) {
@@ -985,6 +1059,10 @@ cmd_parser(int argc, char **argv, struct cli_context_t *cli_context)
 				usage(cli_context, "ERROR: -c option not valid during shell mode.\n");
 			}
 			break;
+		case 'D':
+			cmd_chosen++;
+			cli_context->action = CLI_DUMP_BS;
+			break;
 		case 'd':
 			if (argv[optind] != NULL) {
 				cmd_chosen++;
@@ -1381,6 +1459,9 @@ cli_start(void *arg1, void *arg2)
 	case CLI_INIT_BS:
 		init_bs(cli_context);
 		break;
+	case CLI_DUMP_BS:
+		dump_bs(cli_context);
+		break;
 	case CLI_LIST_BDEVS:
 		list_bdevs(cli_context);
 		break;
diff --git a/examples/blob/hello_world/Makefile b/examples/blob/hello_world/Makefile
index fc7660ad4..7c567fcb0 100644
--- a/examples/blob/hello_world/Makefile
+++ b/examples/blob/hello_world/Makefile
@@ -39,16 +39,16 @@ APP = hello_blob
 C_SRCS := hello_blob.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event util conf trace \
+SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event thread util conf trace \
 		log jsonrpc json rpc
 
-LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS)
+LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS) $(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(COPY_MODULES_FILES) $(BLOCKDEV_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/examples/ioat/Makefile b/examples/ioat/Makefile
index 882bf8c91..d4d62b91e 100644
--- a/examples/ioat/Makefile
+++ b/examples/ioat/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y += perf verify kperf
+DIRS-y += perf verify
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/examples/ioat/kperf/.gitignore b/examples/ioat/kperf/.gitignore
deleted file mode 100644
index bc25a0bd3..000000000
--- a/examples/ioat/kperf/.gitignore
+++ /dev/null
@@ -1 +0,0 @@
-ioat_kperf
diff --git a/examples/ioat/kperf/README b/examples/ioat/kperf/README
deleted file mode 100644
index 76f7b76a2..000000000
--- a/examples/ioat/kperf/README
+++ /dev/null
@@ -1,46 +0,0 @@
-IOAT Kernel Driver Test Tool
-============================
-
-For the purpose to make performance comparison with user space IOAT
-driver, we developed the test tool based on IOAT kernel driver, the
-test tool contains 2 components: kernel test module and user space
-application. The kernel test module allocated one kernel thread for
-each DMA channel, and the kernel thread did not pin to specified
-CPU cores, but ensure all the thread run in the same NUMA socket
-with DMA channel, and the user space application communicated
-with kernel test module via sysfs interface.
-
-Building & Usage
-================
-
-1. Compile and load the kernel test module first.
-
-    modprobe -v ioatdma
-    ./scripts/build_kmod.sh build && insmod dmaperf.ko
-
-2. Run the test application.
-
-    Parameters:
-    [-h usage]
-    [-n number of DMA channels]
-    [-q queue depth, per DMA channel]
-    [-s [n^2] transfer size, per descriptor]
-    [-t total [n^2] data to tranfer, per DMA channel]
-
-    For example: ./ioat_kperf -n 4 -q 128 -s 12 -t 32
-
-    Total 4 Channels, Queue_Depth 128, Transfer Size 4096 Bytes, Total Transfer Size 4 GB
-    Running I/O . . . .
-    Channel 0 Performance Data 1414 MB/s
-    Channel 1 Performance Data 1413 MB/s
-    Channel 2 Performance Data 1413 MB/s
-    Channel 3 Performance Data 1415 MB/s
-    Total Channel Performance Data 5655 MB/s
-
-3. Cleanup
-    ./scripts/build_kmod.sh clean
-
-OS Support
-==========
-We have tested several Linux distributions, currently Fedora 21/22 with kernel
-version >= 3.17 are supported.
diff --git a/examples/ioat/kperf/ioat_kperf.c b/examples/ioat/kperf/ioat_kperf.c
deleted file mode 100644
index 08f549e41..000000000
--- a/examples/ioat/kperf/ioat_kperf.c
+++ /dev/null
@@ -1,361 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright (c) Intel Corporation.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "spdk/stdinc.h"
-
-#define ioat_max(a,b) (((a)>(b))?(a):(b))
-
-static int
-check_modules(char *driver_name)
-{
-	FILE *fd;
-	const char *proc_modules = "/proc/modules";
-	char buffer[256];
-
-	fd = fopen(proc_modules, "r");
-	if (!fd) {
-		return -1;
-	}
-
-	while (fgets(buffer, sizeof(buffer), fd)) {
-		if (strstr(buffer, driver_name) == NULL) {
-			continue;
-		} else {
-			fclose(fd);
-			return 0;
-		}
-	}
-	fclose(fd);
-
-	return -1;
-}
-
-static int
-get_u32_from_file(const char *sysfs_file, uint32_t *value)
-{
-	FILE *f;
-	char buf[BUFSIZ];
-
-	f = fopen(sysfs_file, "r");
-	if (f == NULL) {
-		return -1;
-	}
-
-	if (fgets(buf, sizeof(buf), f) != NULL) {
-		*value = strtoul(buf, NULL, 10);
-	}
-
-	fclose(f);
-
-	return 0;
-}
-
-static int
-get_str_from_file(const char *sysfs_file, char *buf, int len)
-{
-	FILE *f;
-
-	f = fopen(sysfs_file, "r");
-	if (f == NULL) {
-		return -1;
-	}
-
-	if (fgets(buf, len, f) != NULL) {
-		fclose(f);
-		return 0;
-	}
-
-	fclose(f);
-	return -1;
-}
-
-static int
-put_u32_to_file(const char *sysfs_file, uint32_t value)
-{
-	FILE *f;
-	int n;
-	char buf[BUFSIZ];
-
-	f = fopen(sysfs_file, "w");
-	if (f == NULL) {
-		return -1;
-	}
-
-	n = snprintf(buf, sizeof(buf), "%ul", value);
-	if ((n < 0) || (n >= (int)sizeof(buf))) {
-		fclose(f);
-		return -1;
-	}
-
-	if (fwrite(buf, n, 1, f) == 0) {
-		fclose(f);
-		return -1;
-	}
-
-	fclose(f);
-	return 0;
-}
-
-static int
-get_u64_from_file(const char *sysfs_file, uint64_t *value)
-{
-	FILE *f;
-	char buf[BUFSIZ];
-
-	f = fopen(sysfs_file, "r");
-	if (f == NULL) {
-		return -1;
-	}
-
-	if (fgets(buf, sizeof(buf), f) != NULL) {
-		*value = strtoull(buf, NULL, 10);
-	}
-
-	fclose(f);
-
-	return 0;
-}
-
-static int
-get_dma_channel_count(void)
-{
-	int count = 0;
-	struct dirent *e;
-	DIR *dir;
-	char *str;
-
-	dir = opendir("/sys/bus/pci/drivers/ioatdma");
-	if (dir == NULL) {
-		return 0;
-	}
-
-	while ((e = readdir(dir)) != NULL) {
-		str = strstr(e->d_name, ":");
-		if (str != NULL) {
-			count++;
-		}
-	}
-	closedir(dir);
-
-	return count;
-}
-
-static void
-usage(char *program_name)
-{
-	printf("%s options\n", program_name);
-	printf("\t[-h usage]\n");
-	printf("\t[-n number of DMA channels]\n");
-	printf("\t[-q queue depth, per DMA channel]\n");
-	printf("\t[-s [n^2] transfer size, per descriptor]\n");
-	printf("\t[-t total [n^2] data to tranfer, per DMA channel]\n");
-}
-
-int main(int argc, char *argv[])
-{
-	int op;
-	int rc;
-	char buf[BUFSIZ];
-	uint32_t count = 0;
-	uint32_t i, threads = 0;
-	uint32_t ring_size, queue_depth = 0;
-	uint32_t transfer_size, order = 0;
-	uint64_t total_size, copied = 0;
-	uint64_t elapsed_time = 0;
-	uint64_t total_time = 0;
-	uint64_t perf, total_copied = 0;
-	char channel[1024];
-
-	if (check_modules("ioatdma")) {
-		fprintf(stderr, "Ioat driver not loaded,"
-			" run `modprobe -v ioatdma` first\n");
-		return -1;
-	}
-	if (check_modules("dmaperf")) {
-		fprintf(stderr, "Kernel Ioat test driver not loaded,"
-			" run `insmod dmaperf.ko` in the kmod directory\n");
-		return -1;
-	}
-	count = get_dma_channel_count();
-	if (!count) {
-		fprintf(stderr, "No DMA channel found\n");
-		return -1;
-	}
-
-	ring_size = 1UL << 16;
-
-	while ((op = getopt(argc, argv, "hn:q:s:t:")) != -1) {
-		switch (op) {
-		case 'n':
-			threads = atoi(optarg);
-			if (threads > count) {
-				fprintf(stderr, "Error: Total channel count %u\n", count);
-				return -1;
-			}
-			rc = put_u32_to_file("/sys/kernel/debug/dmaperf/dmaperf/threads", threads);
-			if (rc < 0) {
-				fprintf(stderr, "Cannot set dma channels\n");
-				return -1;
-			}
-			break;
-		case 'q':
-			queue_depth = atoi(optarg);
-			if (queue_depth > ring_size) {
-				fprintf(stderr, "Max Ioat DMA ring size %d\n", ring_size);
-				return -1;
-			}
-			rc = put_u32_to_file("/sys/kernel/debug/dmaperf/dmaperf/queue_depth", queue_depth);
-			if (rc < 0) {
-				fprintf(stderr, "Cannot set queue depth\n");
-				return -1;
-			}
-			break;
-		case 's':
-			order = atoi(optarg);
-			rc = put_u32_to_file("/sys/kernel/debug/dmaperf/dmaperf/transfer_size_order", order);
-			if (rc < 0) {
-				fprintf(stderr, "Cannot set descriptor transfer size order\n");
-				return -1;
-			}
-			break;
-		case 't':
-			order = atoi(optarg);
-			rc = put_u32_to_file("/sys/kernel/debug/dmaperf/dmaperf/total_size_order", order);
-			if (rc < 0) {
-				fprintf(stderr, "Cannot set channel total transfer size order\n");
-				return -1;
-			}
-			break;
-		case 'h' :
-			usage(argv[0]);
-			exit(0);
-		default:
-			usage(argv[0]);
-			exit(1);
-		}
-	}
-
-	/* get driver configuration */
-	rc = get_u32_from_file("/sys/kernel/debug/dmaperf/dmaperf/transfer_size_order",
-			       &order);
-	if (rc < 0) {
-		fprintf(stderr, "Cannot get channel descriptor transfer size\n");
-		return -1;
-	}
-	transfer_size = 1UL << order;
-
-	rc = get_u32_from_file("/sys/kernel/debug/dmaperf/dmaperf/total_size_order",
-			       &order);
-	if (rc < 0) {
-		fprintf(stderr, "Cannot get channel total transfer size\n");
-		return -1;
-	}
-	total_size = 1ULL << order;
-
-	rc = get_u32_from_file("/sys/kernel/debug/dmaperf/dmaperf/threads",
-			       &threads);
-	if (rc < 0) {
-		fprintf(stderr, "Cannot get dma channel threads\n");
-		return -1;
-	}
-
-	rc = get_u32_from_file("/sys/kernel/debug/dmaperf/dmaperf/queue_depth",
-			       &queue_depth);
-	if (rc < 0) {
-		fprintf(stderr, "Cannot get queue depth\n");
-		return -1;
-	}
-
-	fprintf(stdout,
-		"Total %d Channels, Queue_Depth %d, Transfer Size %d Bytes, Total Transfer Size %"PRIu64" GB\n",
-		threads, queue_depth, transfer_size, total_size >> 30ULL);
-
-	/* run the channels */
-	rc = put_u32_to_file("/sys/kernel/debug/dmaperf/dmaperf/run", 1);
-	if (rc < 0) {
-		fprintf(stderr, "Cannot run the channels\n");
-		return -1;
-	}
-
-	fprintf(stdout, "Running I/O ");
-	fflush(stdout);
-	memset(buf, 0, BUFSIZ);
-	/* wait all the channels to be idle */
-	do {
-		fprintf(stdout, ". ");
-		fflush(stdout);
-		sleep(1);
-
-		if (strstr(buf, "idle") != NULL) {
-			fprintf(stdout, "\n");
-			fflush(stdout);
-			sleep(1);
-			break;
-		}
-	} while (!get_str_from_file("/sys/kernel/debug/dmaperf/dmaperf/status", buf, BUFSIZ));
-
-	/* collect each channel performance data */
-
-	for (i = 0; i < threads; i++) {
-		/* total data transfer length for the DMA channel in Bytes */
-		snprintf(channel, sizeof(channel), "/sys/kernel/debug/dmaperf/dmaperf/thread_%u/copied", i);
-		rc = get_u64_from_file(channel, &copied);
-		if (rc < 0) {
-			fprintf(stderr, "Cannot get channel copied data\n");
-			return -1;
-		}
-		/* time in microseconds for total data transfer length */
-		snprintf(channel, sizeof(channel), "/sys/kernel/debug/dmaperf/dmaperf/thread_%u/elapsed_time", i);
-		/* elapsed_time is in microsecond */
-		rc = get_u64_from_file(channel, &elapsed_time);
-		if (rc < 0) {
-			fprintf(stderr, "Cannot get channel elapsed time\n");
-			return -1;
-		}
-		assert(elapsed_time != 0);
-		perf = (copied * 1000 * 1000) / (elapsed_time * 1024 * 1024);
-		total_copied += copied;
-		total_time = ioat_max(elapsed_time, total_time);
-		fprintf(stdout, "Channel %d Bandwidth %"PRIu64" MiB/s\n",
-			i, perf);
-	}
-
-	if (total_time && threads) {
-		fprintf(stdout, "Total Channel Bandwidth: %"PRIu64" MiB/s\n",
-			total_copied / total_time);
-		fprintf(stdout, "Average Bandwidth Per Channel: %"PRIu64" MiB/s\n",
-			(total_copied * 1000 * 1000) / (total_time * threads * 1024 * 1024));
-	}
-
-	return 0;
-}
diff --git a/examples/ioat/kperf/kmod/.gitignore b/examples/ioat/kperf/kmod/.gitignore
deleted file mode 100644
index 1602fff22..000000000
--- a/examples/ioat/kperf/kmod/.gitignore
+++ /dev/null
@@ -1,5 +0,0 @@
-.cache.mk
-.tmp_versions
-dmaperf.mod.c
-modules.order
-Module.symvers
diff --git a/examples/ioat/kperf/kmod/dmaperf.c b/examples/ioat/kperf/kmod/dmaperf.c
deleted file mode 100644
index 430adde00..000000000
--- a/examples/ioat/kperf/kmod/dmaperf.c
+++ /dev/null
@@ -1,704 +0,0 @@
-/*
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- *   redistributing this file, you may do so under either license.
- *
- *   GPL LICENSE SUMMARY
- *
- *   Copyright (c) Intel Corporation.
- *   All rights reserved.
- *
- *   This program is free software; you can redistribute it and/or modify
- *   it under the terms of version 2 of the GNU General Public License as
- *   published by the Free Software Foundation.
- *
- *   BSD LICENSE
- *
- *   Copyright (c) Intel Corporation.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copy
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- *   PCIe DMA Perf Linux driver
- */
-
-#include <linux/init.h>
-#include <linux/kernel.h>
-#include <linux/wait.h>
-#include <linux/module.h>
-#include <linux/kthread.h>
-#include <linux/time.h>
-#include <linux/timer.h>
-#include <linux/dma-mapping.h>
-#include <linux/pci.h>
-#include <linux/slab.h>
-#include <linux/spinlock.h>
-#include <linux/debugfs.h>
-#include <linux/dmaengine.h>
-#include <linux/delay.h>
-#include <linux/printk.h>
-#include <linux/nodemask.h>
-
-#define DRIVER_NAME		"dma_perf"
-#define DRIVER_DESCRIPTION	"PCIe DMA Performance Measurement Tool"
-
-#define DRIVER_LICENSE		"Dual BSD/GPL"
-#define DRIVER_VERSION		"1.0"
-#define DRIVER_AUTHOR		"Dave Jiang <dave.jiang@intel.com>"
-
-#define MAX_THREADS		32
-#define MAX_TEST_SIZE		1024 * 1024	/* 1M */
-#define DMA_CHANNELS_PER_NODE	8
-
-MODULE_LICENSE(DRIVER_LICENSE);
-MODULE_VERSION(DRIVER_VERSION);
-MODULE_AUTHOR(DRIVER_AUTHOR);
-MODULE_AUTHOR("Changpeng Liu <changpeng.liu@intel.com>");
-MODULE_DESCRIPTION(DRIVER_DESCRIPTION);
-
-static struct dentry *perf_debugfs_dir;
-static struct perf_ctx *g_perf = NULL;
-
-static unsigned int seg_order = 12; /* 4K */
-static unsigned int queue_depth = 256;
-static unsigned int run_order = 32; /* 4G */
-
-struct perf_mw {
-	size_t		buf_size;
-	void		*virt_addr;
-};
-
-struct perf_ctx;
-
-struct pthr_ctx {
-	struct dentry		*debugfs_thr_dir;
-	struct dentry		*debugfs_copied;
-	struct dentry		*debugfs_elapsed_time;
-	struct device		*dev;
-	int			node;
-	wait_queue_head_t	wq;
-	struct perf_mw		mw;
-	struct task_struct	*thread;
-	struct perf_ctx		*perf;
-	atomic_t		dma_sync;
-	struct dma_chan		*dma_chan;
-	int			dma_up;
-	int			dma_down;
-	int			dma_prep_err;
-	u64			copied;
-	u64			elapsed_time;
-};
-
-struct perf_ctx {
-	spinlock_t		db_lock;
-	struct dentry		*debugfs_node_dir;
-	struct dentry		*debugfs_run;
-	struct dentry		*debugfs_threads;
-	struct dentry		*debugfs_queue_depth;
-	struct dentry		*debugfs_transfer_size_order;
-	struct dentry		*debugfs_total_size_order;
-	struct dentry		*debugfs_status;
-	u8			numa_nodes;
-	u8			perf_threads;
-	bool			run;
-	struct pthr_ctx		pthr_ctx[MAX_THREADS];
-	atomic_t		tsync;
-};
-
-static void perf_free_mw(struct pthr_ctx *pctx);
-static int perf_set_mw(struct pthr_ctx *pctx, size_t size);
-
-static void perf_copy_callback(void *data)
-{
-	struct pthr_ctx *pctx = data;
-
-	atomic_dec(&pctx->dma_sync);
-	pctx->dma_down++;
-
-	wake_up(&pctx->wq);
-}
-
-static ssize_t perf_copy(struct pthr_ctx *pctx, char *dst,
-			 char *src, size_t size)
-{
-	struct dma_async_tx_descriptor *txd;
-	struct dma_chan *chan = pctx->dma_chan;
-	struct dma_device *device;
-	struct dmaengine_unmap_data *unmap;
-	dma_cookie_t cookie;
-	size_t src_off, dst_off;
-	int retries = 0;
-
-	if (!chan) {
-		printk("DMA engine does not exist\n");
-		return -EINVAL;
-	}
-
-	device = chan->device;
-	src_off = (size_t)src & ~PAGE_MASK;
-	dst_off = (size_t)dst & ~PAGE_MASK;
-
-	if (!is_dma_copy_aligned(device, src_off, dst_off, size)) {
-		return -ENODEV;
-	}
-
-	unmap = dmaengine_get_unmap_data(device->dev, 2, GFP_NOWAIT);
-	if (!unmap) {
-		return -ENOMEM;
-	}
-
-	unmap->len = size;
-	unmap->addr[0] = dma_map_page(device->dev, virt_to_page(src),
-				      src_off, size, DMA_TO_DEVICE);
-	if (dma_mapping_error(device->dev, unmap->addr[0])) {
-		goto err_get_unmap;
-	}
-
-	unmap->to_cnt = 1;
-
-	unmap->addr[1] = dma_map_page(device->dev, virt_to_page(dst),
-				      dst_off, size, DMA_FROM_DEVICE);
-	if (dma_mapping_error(device->dev, unmap->addr[1])) {
-		goto err_get_unmap;
-	}
-	unmap->from_cnt = 1;
-
-dma_prep_retry:
-	txd = device->device_prep_dma_memcpy(chan, unmap->addr[1],
-					     unmap->addr[0],
-					     size, DMA_PREP_INTERRUPT);
-	if (!txd) {
-		if (retries++ > 20) {
-			pctx->dma_prep_err++;
-			goto err_get_unmap;
-		} else {
-			set_current_state(TASK_INTERRUPTIBLE);
-			schedule_timeout(50);
-			goto dma_prep_retry;
-		}
-	}
-
-	txd->callback = perf_copy_callback;
-	txd->callback_param = pctx;
-	dma_set_unmap(txd, unmap);
-
-	cookie = dmaengine_submit(txd);
-	if (dma_submit_error(cookie)) {
-		goto err_set_unmap;
-	}
-
-	atomic_inc(&pctx->dma_sync);
-
-	pctx->dma_up++;
-	dma_async_issue_pending(chan);
-
-	return size;
-
-err_set_unmap:
-	dmaengine_unmap_put(unmap);
-err_get_unmap:
-	dmaengine_unmap_put(unmap);
-	return 0;
-}
-
-static int perf_move_data(struct pthr_ctx *pctx, char *dst, char *src,
-			  u64 buf_size, u64 win_size, u64 total)
-{
-	int chunks, total_chunks, i;
-	int copied_chunks = 0;
-	u64 result;
-	char *tmp = dst;
-	u64 perf, diff_us;
-	ktime_t kstart, kstop, kdiff;
-
-	chunks = win_size / buf_size;
-	total_chunks = total / buf_size;
-
-	printk("%s: chunks: %d total_chunks: %d\n", current->comm, chunks, total_chunks);
-
-	kstart = ktime_get();
-
-	for (i = 0; i < total_chunks; i++) {
-
-		wait_event_interruptible(pctx->wq, atomic_read(&pctx->dma_sync) < queue_depth);
-
-		result = perf_copy(pctx, tmp, src, buf_size);
-		pctx->copied += result;
-		copied_chunks++;
-		if (copied_chunks == chunks) {
-			tmp = dst;
-			copied_chunks = 0;
-		} else {
-			tmp += buf_size;
-		}
-	}
-
-	printk("%s: All DMA descriptors submitted\n", current->comm);
-
-	/* FIXME: need a timeout here eventually */
-	while (atomic_read(&pctx->dma_sync) != 0) {
-		msleep(1);
-	}
-
-	pr_info("%s: dma_up: %d  dma_down: %d dma_prep_err: %d\n",
-		current->comm, pctx->dma_up, pctx->dma_down,
-		pctx->dma_prep_err);
-
-	kstop = ktime_get();
-	kdiff = ktime_sub(kstop, kstart);
-	diff_us = ktime_to_us(kdiff);
-
-	pr_info("%s: copied %Lu bytes\n", current->comm, pctx->copied);
-
-	pr_info("%s: lasted %Lu usecs\n", current->comm, diff_us);
-
-	perf = pctx->copied / diff_us;
-
-	pr_info("%s: MBytes/s: %Lu\n", current->comm, perf);
-
-	pctx->elapsed_time = diff_us;
-
-	return 0;
-}
-
-static bool perf_dma_filter_fn(struct dma_chan *chan, void *node)
-{
-	return dev_to_node(&chan->dev->device) == (int)(unsigned long)node;
-}
-
-static int dma_perf_thread(void *data)
-{
-	struct pthr_ctx *pctx = data;
-	struct perf_ctx *perf = pctx->perf;
-	struct perf_mw *mw = &pctx->mw;
-	char *dst;
-	u64 win_size, buf_size, total;
-	void *src;
-	int rc, node;
-	struct dma_chan *dma_chan = NULL;
-
-	pr_info("kthread %s starting...\n", current->comm);
-
-	node = pctx->node;
-
-	if (!pctx->dma_chan) {
-		dma_cap_mask_t dma_mask;
-
-		dma_cap_zero(dma_mask);
-		dma_cap_set(DMA_MEMCPY, dma_mask);
-		dma_chan = dma_request_channel(dma_mask, perf_dma_filter_fn,
-					       (void *)(unsigned long)node);
-		if (!dma_chan) {
-			pr_warn("%s: cannot acquire DMA channel, quitting\n",
-				current->comm);
-			return -ENODEV;
-		}
-		pctx->dma_chan = dma_chan;
-		pctx->dev = dma_chan->device->dev;
-	}
-
-	src = kmalloc_node(MAX_TEST_SIZE, GFP_KERNEL, node);
-	if (!src) {
-		rc = -ENOMEM;
-		goto err;
-	}
-
-	rc = perf_set_mw(pctx, MAX_TEST_SIZE);
-	if (rc < 0) {
-		pr_err("%s: set mw failed\n", current->comm);
-		rc = -ENXIO;
-		goto err;
-	}
-
-	win_size = mw->buf_size;
-	buf_size = 1ULL << seg_order;
-	total = 1ULL << run_order;
-
-	if (buf_size > MAX_TEST_SIZE) {
-		buf_size = MAX_TEST_SIZE;
-	}
-
-	dst = (char *)mw->virt_addr;
-
-	atomic_inc(&perf->tsync);
-	while (atomic_read(&perf->tsync) != perf->perf_threads) {
-		schedule();
-	}
-
-	rc = perf_move_data(pctx, dst, src, buf_size, win_size, total);
-
-	atomic_dec(&perf->tsync);
-
-	if (rc < 0) {
-		pr_err("%s: failed\n", current->comm);
-		rc = -ENXIO;
-		goto err;
-	}
-
-	return 0;
-
-err:
-	if (src) {
-		kfree(src);
-	}
-
-	if (dma_chan) {
-		dma_release_channel(dma_chan);
-		pctx->dma_chan = NULL;
-	}
-
-	return rc;
-}
-
-static void perf_free_mw(struct pthr_ctx *pctx)
-{
-	struct perf_mw *mw = &pctx->mw;
-
-	if (!mw->virt_addr) {
-		return;
-	}
-
-	kfree(mw->virt_addr);
-	mw->buf_size = 0;
-	mw->virt_addr = NULL;
-}
-
-static int perf_set_mw(struct pthr_ctx *pctx, size_t size)
-{
-	struct perf_mw *mw = &pctx->mw;
-
-	if (!size) {
-		return -EINVAL;
-	}
-
-	mw->buf_size = size;
-
-	mw->virt_addr = kmalloc_node(size, GFP_KERNEL, pctx->node);
-
-	if (!mw->virt_addr) {
-		mw->buf_size = 0;
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-static ssize_t debugfs_run_read(struct file *filp, char __user *ubuf,
-				size_t count, loff_t *offp)
-{
-	struct perf_ctx *perf = filp->private_data;
-	char *buf;
-	ssize_t ret, out_offset;
-
-	if (!perf) {
-		return 0;
-	}
-
-	buf = kmalloc(64, GFP_KERNEL);
-	out_offset = snprintf(buf, 64, "%d\n", perf->run);
-	ret = simple_read_from_buffer(ubuf, count, offp, buf, out_offset);
-	kfree(buf);
-
-	return ret;
-}
-
-static ssize_t debugfs_run_write(struct file *filp, const char __user *ubuf,
-				 size_t count, loff_t *offp)
-{
-	struct perf_ctx *perf = filp->private_data;
-	int node, i;
-
-	if (perf->perf_threads == 0) {
-		return 0;
-	}
-
-	if (atomic_read(&perf->tsync) == 0) {
-		perf->run = false;
-	}
-
-	if (perf->run == true) {
-		/* lets stop the threads */
-		perf->run = false;
-		for (i = 0; i < MAX_THREADS; i++) {
-			if (perf->pthr_ctx[i].thread) {
-				kthread_stop(perf->pthr_ctx[i].thread);
-				perf->pthr_ctx[i].thread = NULL;
-			} else {
-				break;
-			}
-		}
-	} else {
-		perf->run = true;
-
-		if (perf->perf_threads > MAX_THREADS) {
-			perf->perf_threads = MAX_THREADS;
-			pr_info("Reset total threads to: %u\n", MAX_THREADS);
-		}
-
-		/* no greater than 1M */
-		if (seg_order > 20) {
-			seg_order = 20;
-			pr_info("Fix seg_order to %u\n", seg_order);
-		}
-
-		if (run_order < seg_order) {
-			run_order = seg_order;
-			pr_info("Fix run_order to %u\n", run_order);
-		}
-
-		/* launch kernel thread */
-		for (i = 0; i < perf->perf_threads; i++) {
-			struct pthr_ctx *pctx;
-
-			pctx = &perf->pthr_ctx[i];
-			atomic_set(&pctx->dma_sync, 0);
-			pctx->perf = perf;
-			pctx->elapsed_time = 0;
-			pctx->copied = 0;
-
-			init_waitqueue_head(&pctx->wq);
-
-			/* NUMA socket node */
-			pctx->node = i / DMA_CHANNELS_PER_NODE;
-			node = pctx->node;
-
-			pctx->thread =
-				kthread_create_on_node(dma_perf_thread,
-						       (void *)pctx,
-						       node, "dma_perf %d", i);
-			if (pctx->thread) {
-				wake_up_process(pctx->thread);
-			} else {
-				perf->run = false;
-				for (i = 0; i < MAX_THREADS; i++) {
-					if (pctx->thread) {
-						kthread_stop(pctx->thread);
-						pctx->thread = NULL;
-					} else {
-						break;
-					}
-				}
-			}
-
-			if (perf->run == false) {
-				return -ENXIO;
-			}
-		}
-
-	}
-
-	return count;
-}
-
-static const struct file_operations dma_perf_debugfs_run = {
-	.owner = THIS_MODULE,
-	.open = simple_open,
-	.read = debugfs_run_read,
-	.write = debugfs_run_write,
-};
-
-static ssize_t debugfs_status_read(struct file *filp, char __user *ubuf,
-				   size_t count, loff_t *offp)
-{
-	struct perf_ctx *perf = filp->private_data;
-	char *buf;
-	ssize_t ret, out_offset;
-
-	if (!perf) {
-		return 0;
-	}
-
-	buf = kmalloc(64, GFP_KERNEL);
-	out_offset = snprintf(buf, 64, "%s\n", atomic_read(&perf->tsync) ? "running" : "idle");
-	ret = simple_read_from_buffer(ubuf, count, offp, buf, out_offset);
-	kfree(buf);
-
-	return ret;
-}
-
-static const struct file_operations dma_perf_debugfs_status = {
-	.owner = THIS_MODULE,
-	.open = simple_open,
-	.read = debugfs_status_read,
-};
-
-static int perf_debugfs_setup(struct perf_ctx *perf)
-{
-
-	int i;
-	char temp_name[64];
-
-	if (!perf_debugfs_dir) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_node_dir = debugfs_create_dir("dmaperf",
-				 perf_debugfs_dir);
-	if (!perf->debugfs_node_dir) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_run = debugfs_create_file("run", S_IRUSR | S_IWUSR,
-						perf->debugfs_node_dir, perf,
-						&dma_perf_debugfs_run);
-	if (!perf->debugfs_run) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_status = debugfs_create_file("status", S_IRUSR,
-			       perf->debugfs_node_dir, perf,
-			       &dma_perf_debugfs_status);
-	if (!perf->debugfs_status) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_threads = debugfs_create_u8("threads", S_IRUSR | S_IWUSR,
-				perf->debugfs_node_dir,
-				&perf->perf_threads);
-	if (!perf->debugfs_threads) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_queue_depth = debugfs_create_u32("queue_depth", S_IRUSR | S_IWUSR,
-				    perf->debugfs_node_dir,
-				    &queue_depth);
-	if (!perf->debugfs_queue_depth) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_transfer_size_order = debugfs_create_u32("transfer_size_order", S_IRUSR | S_IWUSR,
-					    perf->debugfs_node_dir,
-					    &seg_order);
-	if (!perf->debugfs_transfer_size_order) {
-		return -ENODEV;
-	}
-
-	perf->debugfs_total_size_order = debugfs_create_u32("total_size_order", S_IRUSR | S_IWUSR,
-					 perf->debugfs_node_dir,
-					 &run_order);
-	if (!perf->debugfs_total_size_order) {
-		return -ENODEV;
-	}
-
-	for (i = 0; i < MAX_THREADS; i++) {
-		struct pthr_ctx *pctx = &perf->pthr_ctx[i];
-		snprintf(temp_name, sizeof(temp_name), "thread_%d", i);
-
-		pctx->debugfs_thr_dir = debugfs_create_dir(temp_name, perf->debugfs_node_dir);
-		if (!pctx->debugfs_thr_dir) {
-			return -ENODEV;
-		}
-
-		pctx->debugfs_copied = debugfs_create_u64("copied", S_IRUSR,
-				       pctx->debugfs_thr_dir,
-				       &pctx->copied);
-		if (!pctx->debugfs_copied) {
-			return -ENODEV;
-		}
-
-		pctx->debugfs_elapsed_time = debugfs_create_u64("elapsed_time", S_IRUSR,
-					     pctx->debugfs_thr_dir,
-					     &pctx->elapsed_time);
-		if (!pctx->debugfs_elapsed_time) {
-			return -ENODEV;
-		}
-	}
-
-	return 0;
-}
-
-static int perf_probe(void)
-{
-	struct perf_ctx *perf;
-	int rc = 0;
-
-	perf = kzalloc_node(sizeof(*perf), GFP_KERNEL, 0);
-	if (!perf) {
-		rc = -ENOMEM;
-		goto err_perf;
-	}
-
-	perf->numa_nodes = num_online_nodes();
-	perf->perf_threads = 1;
-	atomic_set(&perf->tsync, 0);
-	perf->run = false;
-	spin_lock_init(&perf->db_lock);
-
-	if (debugfs_initialized() && !perf_debugfs_dir) {
-		perf_debugfs_dir = debugfs_create_dir(KBUILD_MODNAME, NULL);
-		if (!perf_debugfs_dir) {
-			goto err_ctx;
-		}
-
-		rc = perf_debugfs_setup(perf);
-		if (rc) {
-			goto err_ctx;
-		}
-	}
-
-	g_perf = perf;
-	return 0;
-
-err_ctx:
-	kfree(perf);
-err_perf:
-	return rc;
-}
-
-static void perf_remove(void)
-{
-	int i;
-	struct perf_ctx *perf = g_perf;
-
-	if (perf_debugfs_dir) {
-		debugfs_remove_recursive(perf_debugfs_dir);
-		perf_debugfs_dir = NULL;
-	}
-
-	for (i = 0; i < MAX_THREADS; i++) {
-		struct pthr_ctx *pctx = &perf->pthr_ctx[i];
-		if (pctx->dma_chan) {
-			dma_release_channel(pctx->dma_chan);
-		}
-		perf_free_mw(pctx);
-	}
-
-	kfree(perf);
-}
-
-static int __init perf_init_module(void)
-{
-	printk("DMA Performance Test Init\n");
-	return perf_probe();
-}
-module_init(perf_init_module);
-
-static void __exit perf_exit_module(void)
-{
-	printk("DMA Performance Test Exit\n");
-	perf_remove();
-}
-module_exit(perf_exit_module);
diff --git a/examples/ioat/perf/Makefile b/examples/ioat/perf/Makefile
index 55de07d3e..518a35072 100644
--- a/examples/ioat/perf/Makefile
+++ b/examples/ioat/perf/Makefile
@@ -39,7 +39,7 @@ APP = perf
 
 C_SRCS := perf.c
 
-SPDK_LIB_LIST = ioat util log
+SPDK_LIB_LIST = ioat thread util log
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/examples/ioat/verify/Makefile b/examples/ioat/verify/Makefile
index de3276f42..d7a7b0b2c 100644
--- a/examples/ioat/verify/Makefile
+++ b/examples/ioat/verify/Makefile
@@ -39,7 +39,7 @@ APP = verify
 
 C_SRCS := verify.c
 
-SPDK_LIB_LIST = ioat util log
+SPDK_LIB_LIST = ioat thread util log
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/examples/ioat/verify/verify.c b/examples/ioat/verify/verify.c
index 66c9b8c77..ba462323c 100644
--- a/examples/ioat/verify/verify.c
+++ b/examples/ioat/verify/verify.c
@@ -37,6 +37,7 @@
 #include "spdk/env.h"
 #include "spdk/queue.h"
 #include "spdk/string.h"
+#include "spdk/util.h"
 
 #define SRC_BUFFER_SIZE (512*1024)
 
@@ -125,33 +126,33 @@ ioat_exit(void)
 static void prepare_ioat_task(struct thread_entry *thread_entry, struct ioat_task *ioat_task)
 {
 	int len;
-	int src_offset;
-	int dst_offset;
-	int num_ddwords;
+	uintptr_t src_offset;
+	uintptr_t dst_offset;
 	uint64_t fill_pattern;
 
 	if (ioat_task->type == IOAT_FILL_TYPE) {
 		fill_pattern = rand_r(&seed);
 		fill_pattern = fill_pattern << 32 | rand_r(&seed);
 
-		/* ensure that the length of memset block is 8 Bytes aligned */
-		num_ddwords = (rand_r(&seed) % SRC_BUFFER_SIZE) / 8;
-		len = num_ddwords * 8;
-		if (len < 8) {
-			len = 8;
-		}
-		dst_offset = rand_r(&seed) % (SRC_BUFFER_SIZE - len);
+		/* Ensure that the length of memset block is 8 Bytes aligned.
+		 * In case the buffer crosses hugepage boundary and must be split,
+		 * we also need to ensure 8 byte address alignment. We do it
+		 * unconditionally to keep things simple.
+		 */
+		len = 8 + ((rand_r(&seed) % (SRC_BUFFER_SIZE - 16)) & ~0x7);
+		dst_offset = 8 + rand_r(&seed) % (SRC_BUFFER_SIZE - 8 - len);
 		ioat_task->fill_pattern = fill_pattern;
+		ioat_task->dst = (void *)(((uintptr_t)ioat_task->buffer + dst_offset) & ~0x7);
 	} else {
 		src_offset = rand_r(&seed) % SRC_BUFFER_SIZE;
 		len = rand_r(&seed) % (SRC_BUFFER_SIZE - src_offset);
 		dst_offset = rand_r(&seed) % (SRC_BUFFER_SIZE - len);
 
 		memset(ioat_task->buffer, 0, SRC_BUFFER_SIZE);
-		ioat_task->src =  g_src + src_offset;
+		ioat_task->src = (void *)((uintptr_t)g_src + src_offset);
+		ioat_task->dst = (void *)((uintptr_t)ioat_task->buffer + dst_offset);
 	}
 	ioat_task->len = len;
-	ioat_task->dst = ioat_task->buffer + dst_offset;
 	ioat_task->thread_entry = thread_entry;
 }
 
@@ -425,7 +426,7 @@ dump_result(struct thread_entry *threads, uint32_t num_threads)
 		total_completed += t->fill_completed;
 		total_failed += t->xfer_failed;
 		total_failed += t->fill_failed;
-		if (t->xfer_completed || t->xfer_failed)
+		if (total_completed || total_failed)
 			printf("lcore = %d, copy success = %ld, copy failed = %ld, fill success = %ld, fill failed = %ld\n",
 			       t->lcore_id, t->xfer_completed, t->xfer_failed, t->fill_completed, t->fill_failed);
 	}
diff --git a/examples/nvme/fio_plugin/README.md b/examples/nvme/fio_plugin/README.md
index bcc0aba18..2c5332828 100644
--- a/examples/nvme/fio_plugin/README.md
+++ b/examples/nvme/fio_plugin/README.md
@@ -78,3 +78,20 @@ FIO test, the performance is worse than SPDK perf (also using one CPU core) agai
 multiple jobs for FIO test, the performance of FIO is similiar with SPDK perf. After analyzing this phenomenon, we
 think that is caused by the FIO architecture. Mainly FIO can scale with multiple threads (i.e., using CPU cores),
 but it is not good to use one thread against many I/O devices.
+
+# End-to-end Data Protection (Optional)
+
+Running with PI setting, following settings steps are required.
+First, format device namespace with proper PI setting. For example:
+
+    nvme format /dev/nvme0n1 -l 1 -i 1 -p 0 -m 1
+
+In fio configure file, add PRACT and set PRCHK by flags(GUARD|REFTAG|APPTAG) properly. For example:
+
+    pi_act=0
+    pi_chk=GUARD
+
+Blocksize should be set as the sum of data and metadata. For example, if data blocksize is 512 Byte, host generated
+PI metadata is 8 Byte, then blocksize in fio configure file should be 520 Byte:
+
+    bs=520
diff --git a/examples/nvme/fio_plugin/fio_plugin.c b/examples/nvme/fio_plugin/fio_plugin.c
index 18974daa0..5bbcf1ab8 100644
--- a/examples/nvme/fio_plugin/fio_plugin.c
+++ b/examples/nvme/fio_plugin/fio_plugin.c
@@ -37,21 +37,29 @@
 #include "spdk/env.h"
 #include "spdk/string.h"
 #include "spdk/log.h"
+#include "spdk/endian.h"
+#include "spdk/crc16.h"
 
 #include "config-host.h"
 #include "fio.h"
 #include "optgroup.h"
 
 #define NVME_IO_ALIGN		4096
+#define FIO_NVME_PI_APPTAG	0x1234
 
 static bool spdk_env_initialized;
 static int spdk_enable_sgl = 0;
+static uint32_t spdk_pract_flag;
+static uint32_t spdk_prchk_flags;
 
 struct spdk_fio_options {
 	void	*pad;	/* off1 used in option descriptions may not be 0 */
 	int	mem_size;
 	int	shm_id;
 	int	enable_sgl;
+	char	*hostnqn;
+	int	pi_act;
+	char	*pi_chk;
 };
 
 struct spdk_fio_request {
@@ -59,6 +67,10 @@ struct spdk_fio_request {
 	/** Offset in current iovec, fio only uses 1 vector */
 	uint32_t iov_offset;
 
+	/** Application tag and its mask for NVMe PI */
+	uint16_t		appmask;
+	uint16_t		apptag;
+
 	struct spdk_fio_thread	*fio_thread;
 };
 
@@ -71,6 +83,7 @@ struct spdk_fio_ctrlr {
 
 static struct spdk_fio_ctrlr *ctrlr_g;
 static int td_count;
+static pthread_t g_ctrlr_thread_id = 0;
 static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
 static bool g_error;
 
@@ -78,6 +91,8 @@ struct spdk_fio_qpair {
 	struct fio_file		*f;
 	struct spdk_nvme_qpair	*qpair;
 	struct spdk_nvme_ns	*ns;
+	uint32_t		io_flags;
+	bool			do_nvme_pi;
 	struct spdk_fio_qpair	*next;
 	struct spdk_fio_ctrlr	*fio_ctrlr;
 };
@@ -95,10 +110,55 @@ struct spdk_fio_thread {
 
 };
 
+static void *
+spdk_fio_poll_ctrlrs(void *arg)
+{
+	struct spdk_fio_ctrlr *fio_ctrlr;
+	int oldstate;
+	int rc;
+
+	/* Loop until the thread is cancelled */
+	while (true) {
+		rc = pthread_setcancelstate(PTHREAD_CANCEL_DISABLE, &oldstate);
+		if (rc != 0) {
+			SPDK_ERRLOG("Unable to set cancel state disabled on g_init_thread (%d): %s\n",
+				    rc, spdk_strerror(rc));
+		}
+
+		pthread_mutex_lock(&mutex);
+		fio_ctrlr = ctrlr_g;
+
+		while (fio_ctrlr) {
+			spdk_nvme_ctrlr_process_admin_completions(fio_ctrlr->ctrlr);
+			fio_ctrlr = fio_ctrlr->next;
+		}
+
+		pthread_mutex_unlock(&mutex);
+
+		rc = pthread_setcancelstate(PTHREAD_CANCEL_ENABLE, &oldstate);
+		if (rc != 0) {
+			SPDK_ERRLOG("Unable to set cancel state enabled on g_init_thread (%d): %s\n",
+				    rc, spdk_strerror(rc));
+		}
+
+		/* This is a pthread cancellation point and cannot be removed. */
+		sleep(1);
+	}
+
+	return NULL;
+}
+
 static bool
 probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	 struct spdk_nvme_ctrlr_opts *opts)
 {
+	struct thread_data	*td = cb_ctx;
+	struct spdk_fio_options *fio_options = td->eo;
+
+	if (fio_options->hostnqn) {
+		snprintf(opts->hostnqn, sizeof(opts->hostnqn), "%s", fio_options->hostnqn);
+	}
+
 	return true;
 }
 
@@ -117,6 +177,45 @@ get_fio_ctrlr(const struct spdk_nvme_transport_id *trid)
 	return NULL;
 }
 
+static bool
+fio_do_nvme_pi_check(struct spdk_fio_qpair *fio_qpair)
+{
+	struct spdk_nvme_ns	*ns = NULL;
+	const struct spdk_nvme_ns_data *nsdata;
+
+	ns = fio_qpair->ns;
+	nsdata = spdk_nvme_ns_get_data(ns);
+
+	if (!spdk_nvme_ns_supports_extended_lba(ns)) {
+		return false;
+	}
+
+	if (spdk_nvme_ns_get_pi_type(ns) ==
+	    SPDK_NVME_FMT_NVM_PROTECTION_DISABLE) {
+		return false;
+	}
+
+	/* PI locates at the first 8 bytes of metadata,
+	 * doesn't support now
+	 */
+	if (nsdata->dps.md_start) {
+		return false;
+	}
+
+	/* Controller performs PI setup and check */
+	if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRACT) {
+		return false;
+	}
+
+	/* Type3 don't support REFTAG */
+	if (spdk_nvme_ns_get_pi_type(ns) ==
+	    SPDK_NVME_FMT_NVM_PROTECTION_TYPE3) {
+		return false;
+	}
+
+	return true;
+}
+
 static void
 attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	  struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_ctrlr_opts *opts)
@@ -202,6 +301,12 @@ attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	fio_qpair->next = fio_thread->fio_qpair;
 	fio_thread->fio_qpair = fio_qpair;
 
+	if (spdk_nvme_ns_get_flags(ns) & SPDK_NVME_NS_DPS_PI_SUPPORTED) {
+		fio_qpair->io_flags = spdk_pract_flag | spdk_prchk_flags;
+	}
+
+	fio_qpair->do_nvme_pi = fio_do_nvme_pi_check(fio_qpair);
+
 	f->real_file_size = spdk_nvme_ns_get_size(fio_qpair->ns);
 	if (f->real_file_size <= 0) {
 		g_error = true;
@@ -213,6 +318,23 @@ attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	fio_file_set_size_known(f);
 }
 
+static void parse_prchk_flags(const char *prchk_str)
+{
+	if (!prchk_str) {
+		return;
+	}
+
+	if (strstr(prchk_str, "GUARD") != NULL) {
+		spdk_prchk_flags = SPDK_NVME_IO_FLAGS_PRCHK_GUARD;
+	}
+	if (strstr(prchk_str, "REFTAG") != NULL) {
+		spdk_prchk_flags |= SPDK_NVME_IO_FLAGS_PRCHK_REFTAG;
+	}
+	if (strstr(prchk_str, "APPTAG") != NULL) {
+		spdk_prchk_flags |= SPDK_NVME_IO_FLAGS_PRCHK_APPTAG;
+	}
+}
+
 /* Called once at initialization. This is responsible for gathering the size of
  * each "file", which in our case are in the form
  * 'key=value [key=value] ... ns=value'
@@ -254,6 +376,8 @@ static int spdk_fio_setup(struct thread_data *td)
 		opts.mem_size = fio_options->mem_size;
 		opts.shm_id = fio_options->shm_id;
 		spdk_enable_sgl = fio_options->enable_sgl;
+		spdk_pract_flag = fio_options->pi_act;
+		parse_prchk_flags(fio_options->pi_chk);
 		if (spdk_env_init(&opts) < 0) {
 			SPDK_ERRLOG("Unable to initialize SPDK env\n");
 			free(fio_thread->iocq);
@@ -264,6 +388,12 @@ static int spdk_fio_setup(struct thread_data *td)
 		}
 		spdk_env_initialized = true;
 		spdk_unaffinitize_thread();
+
+		/* Spawn a thread to continue polling the controllers */
+		rc = pthread_create(&g_ctrlr_thread_id, NULL, &spdk_fio_poll_ctrlrs, NULL);
+		if (rc != 0) {
+			SPDK_ERRLOG("Unable to spawn a thread to poll admin queues. They won't be polled.\n");
+		}
 	}
 
 	for_each_file(td, f, i) {
@@ -381,11 +511,119 @@ static void spdk_fio_io_u_free(struct thread_data *td, struct io_u *io_u)
 	}
 }
 
+static void
+fio_extended_lba_setup_pi(struct spdk_fio_qpair *fio_qpair, struct io_u *io_u)
+{
+	struct spdk_nvme_ns	*ns = NULL;
+	struct spdk_fio_request *fio_req = io_u->engine_data;
+	struct spdk_nvme_protection_info *pi;
+	uint16_t crc16;
+	uint32_t i, md_size, sector_size, pi_offset, extended_lba_size, lba_count;
+	uint64_t lba;
+
+	ns = fio_qpair->ns;
+
+	sector_size = spdk_nvme_ns_get_sector_size(ns);
+	md_size = spdk_nvme_ns_get_md_size(ns);
+	extended_lba_size = sector_size + md_size;
+	lba = io_u->offset / extended_lba_size;
+	lba_count = io_u->xfer_buflen / extended_lba_size;
+
+	if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_APPTAG) {
+		/* Let's use number of lbas for application tag */
+		fio_req->appmask = 0xffff;
+		fio_req->apptag = FIO_NVME_PI_APPTAG;
+	}
+
+	for (i = 0; i < lba_count; i++) {
+		pi_offset = (extended_lba_size * (i + 1)) - 8;
+		pi = (struct spdk_nvme_protection_info *)(io_u->buf + pi_offset);
+		memset(pi, 0, sizeof(*pi));
+
+		if (io_u->ddir == DDIR_WRITE) {
+			if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_GUARD) {
+				/* CRC buffer should not include PI */
+				crc16 = spdk_crc16_t10dif(io_u->buf + extended_lba_size * i,
+							  extended_lba_size - 8);
+				to_be16(&pi->guard, crc16);
+			}
+			if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_APPTAG) {
+				/* Let's use number of lbas for application tag */
+				to_be16(&pi->app_tag, FIO_NVME_PI_APPTAG);
+			}
+			if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_REFTAG) {
+				to_be32(&pi->ref_tag, (uint32_t)lba + i);
+			}
+		}
+	}
+}
+
+static void
+fio_extended_lba_verify_pi(struct spdk_fio_qpair *fio_qpair, struct io_u *io_u)
+{
+	struct spdk_nvme_ns	*ns = NULL;
+	struct spdk_nvme_protection_info *pi;
+	uint16_t crc16, guard, app_tag;
+	uint32_t i, md_size, sector_size, pi_offset, extended_lba_size, ref_tag, lba_count;
+	uint64_t lba;
+
+	ns = fio_qpair->ns;
+	sector_size = spdk_nvme_ns_get_sector_size(ns);
+	md_size = spdk_nvme_ns_get_md_size(ns);
+	extended_lba_size = sector_size + md_size;
+	lba = io_u->offset / extended_lba_size;
+	lba_count = io_u->xfer_buflen / extended_lba_size;
+
+	for (i = 0; i < lba_count; i++) {
+		pi_offset = (extended_lba_size * (i + 1)) - 8;
+		pi = (struct spdk_nvme_protection_info *)(io_u->buf + pi_offset);
+
+		if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_GUARD) {
+			/* CRC buffer should not include last 8 bytes of PI */
+			crc16 = spdk_crc16_t10dif(io_u->buf + extended_lba_size * i,
+						  extended_lba_size - 8);
+			to_be16(&guard, crc16);
+			if (pi->guard != guard) {
+				fprintf(stdout, "Get Guard Error LBA 0x%16.16"PRIx64","
+					" Expected 0x%04x but returned with 0x%04x,"
+					" may read the LBA without write it first\n",
+					lba + i, guard, pi->guard);
+			}
+
+		}
+		if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_APPTAG) {
+			/* Previously we used the number of lbas as
+			 * application tag for writes
+			 */
+			to_be16(&app_tag, FIO_NVME_PI_APPTAG);
+			if (pi->app_tag != app_tag) {
+				fprintf(stdout, "Get Application Tag Error LBA 0x%16.16"PRIx64","
+					" Expected 0x%04x but returned with 0x%04x,"
+					" may read the LBA without write it first\n",
+					lba + i, app_tag, pi->app_tag);
+			}
+		}
+		if (fio_qpair->io_flags & SPDK_NVME_IO_FLAGS_PRCHK_REFTAG) {
+			to_be32(&ref_tag, (uint32_t)lba + i);
+			if (pi->ref_tag != ref_tag) {
+				fprintf(stdout, "Get Reference Tag Error LBA 0x%16.16"PRIx64","
+					" Expected 0x%08x but returned with 0x%08x,"
+					" may read the LBA without write it first\n",
+					lba + i, ref_tag, pi->ref_tag);
+			}
+		}
+	}
+}
+
 static void spdk_fio_completion_cb(void *ctx, const struct spdk_nvme_cpl *cpl)
 {
 	struct spdk_fio_request		*fio_req = ctx;
 	struct spdk_fio_thread		*fio_thread = fio_req->fio_thread;
 
+	if (fio_thread->fio_qpair->do_nvme_pi) {
+		fio_extended_lba_verify_pi(fio_thread->fio_qpair, fio_req->io);
+	}
+
 	assert(fio_thread->iocq_count < fio_thread->iocq_size);
 	fio_thread->iocq[fio_thread->iocq_count++] = fio_req->io;
 }
@@ -416,7 +654,14 @@ spdk_nvme_io_next_sge(void *ref, void **address, uint32_t *length)
 	return 0;
 }
 
-static int spdk_fio_queue(struct thread_data *td, struct io_u *io_u)
+#if FIO_IOOPS_VERSION >= 24
+typedef enum fio_q_status fio_q_status_t;
+#else
+typedef int fio_q_status_t;
+#endif
+
+static fio_q_status_t
+spdk_fio_queue(struct thread_data *td, struct io_u *io_u)
 {
 	int rc = 1;
 	struct spdk_fio_thread	*fio_thread = td->io_ops_data;
@@ -444,25 +689,34 @@ static int spdk_fio_queue(struct thread_data *td, struct io_u *io_u)
 	lba = io_u->offset / block_size;
 	lba_count = io_u->xfer_buflen / block_size;
 
+	// TODO: considering situations that fio will randomize and verify io_u
+	if (fio_qpair->do_nvme_pi) {
+		fio_extended_lba_setup_pi(fio_qpair, io_u);
+	}
+
 	switch (io_u->ddir) {
 	case DDIR_READ:
 		if (!spdk_enable_sgl) {
-			rc = spdk_nvme_ns_cmd_read(ns, fio_qpair->qpair, io_u->buf, lba, lba_count,
-						   spdk_fio_completion_cb, fio_req, 0);
+			rc = spdk_nvme_ns_cmd_read_with_md(ns, fio_qpair->qpair, io_u->buf, NULL, lba, lba_count,
+							   spdk_fio_completion_cb, fio_req,
+							   fio_qpair->io_flags, fio_req->appmask, fio_req->apptag);
 		} else {
-			rc = spdk_nvme_ns_cmd_readv(ns, fio_qpair->qpair, lba,
-						    lba_count, spdk_fio_completion_cb, fio_req, 0,
-						    spdk_nvme_io_reset_sgl, spdk_nvme_io_next_sge);
+			rc = spdk_nvme_ns_cmd_readv_with_md(ns, fio_qpair->qpair, lba,
+							    lba_count, spdk_fio_completion_cb, fio_req, fio_qpair->io_flags,
+							    spdk_nvme_io_reset_sgl, spdk_nvme_io_next_sge, NULL,
+							    fio_req->appmask, fio_req->apptag);
 		}
 		break;
 	case DDIR_WRITE:
 		if (!spdk_enable_sgl) {
-			rc = spdk_nvme_ns_cmd_write(ns, fio_qpair->qpair, io_u->buf, lba, lba_count,
-						    spdk_fio_completion_cb, fio_req, 0);
+			rc = spdk_nvme_ns_cmd_write_with_md(ns, fio_qpair->qpair, io_u->buf, NULL, lba, lba_count,
+							    spdk_fio_completion_cb, fio_req,
+							    fio_qpair->io_flags, fio_req->appmask, fio_req->apptag);
 		} else {
-			rc = spdk_nvme_ns_cmd_writev(ns, fio_qpair->qpair, lba,
-						     lba_count, spdk_fio_completion_cb, fio_req, 0,
-						     spdk_nvme_io_reset_sgl, spdk_nvme_io_next_sge);
+			rc = spdk_nvme_ns_cmd_writev_with_md(ns, fio_qpair->qpair, lba,
+							     lba_count, spdk_fio_completion_cb, fio_req, fio_qpair->io_flags,
+							     spdk_nvme_io_reset_sgl, spdk_nvme_io_next_sge, NULL,
+							     fio_req->appmask, fio_req->apptag);
 		}
 		break;
 	default:
@@ -566,6 +820,10 @@ static void spdk_fio_cleanup(struct thread_data *td)
 
 	free(fio_thread);
 
+	if (pthread_cancel(g_ctrlr_thread_id) == 0) {
+		pthread_join(g_ctrlr_thread_id, NULL);
+	}
+
 	pthread_mutex_lock(&mutex);
 	td_count--;
 	if (td_count == 0) {
@@ -612,6 +870,35 @@ static struct fio_option options[] = {
 		.category	= FIO_OPT_C_ENGINE,
 		.group		= FIO_OPT_G_INVALID,
 	},
+	{
+		.name		= "hostnqn",
+		.lname		= "Host NQN to use when connecting to controllers.",
+		.type		= FIO_OPT_STR_STORE,
+		.off1		= offsetof(struct spdk_fio_options, hostnqn),
+		.help		= "Host NQN",
+		.category	= FIO_OPT_C_ENGINE,
+		.group		= FIO_OPT_G_INVALID,
+	},
+	{
+		.name		= "pi_act",
+		.lname		= "Protection Information Action",
+		.type		= FIO_OPT_INT,
+		.off1		= offsetof(struct spdk_fio_options, pi_act),
+		.def		= "1",
+		.help		= "Protection Information Action bit (pi_act=1 or pi_act=0)",
+		.category	= FIO_OPT_C_ENGINE,
+		.group		= FIO_OPT_G_INVALID,
+	},
+	{
+		.name		= "pi_chk",
+		.lname		= "Protection Information Check(GUARD|REFTAG|APPTAG)",
+		.type		= FIO_OPT_STR_STORE,
+		.off1		= offsetof(struct spdk_fio_options, pi_chk),
+		.def		= NULL,
+		.help		= "Control of Protection Information Checking (pi_chk=GUARD|REFTAG|APPTAG)",
+		.category	= FIO_OPT_C_ENGINE,
+		.group		= FIO_OPT_G_INVALID,
+	},
 	{
 		.name		= NULL,
 	},
diff --git a/examples/nvme/identify/identify.c b/examples/nvme/identify/identify.c
index 709586de2..c6fb20e70 100644
--- a/examples/nvme/identify/identify.c
+++ b/examples/nvme/identify/identify.c
@@ -823,7 +823,7 @@ print_controller(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_transport
 	       cap.bits.nssrs ? "Supported" : "Not Supported");
 	printf("Command Sets Supported\n");
 	printf("  NVM Command Set:                     %s\n",
-	       cap.bits.css_nvm ? "Supported" : "Not Supported");
+	       cap.bits.css & SPDK_NVME_CAP_CSS_NVM ? "Supported" : "Not Supported");
 	printf("Boot Partition:                        %s\n",
 	       cap.bits.bps ? "Supported" : "Not Supported");
 	printf("Memory Page Size Minimum:              %" PRIu64 " bytes\n",
@@ -944,6 +944,8 @@ print_controller(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_transport
 	       cdata->sgls.metadata_address ? "Supported" : "Not Supported");
 	printf("  SGL Offset:                %s\n",
 	       cdata->sgls.sgl_offset ? "Supported" : "Not Supported");
+	printf("  Transport SGL Data Block:  %s\n",
+	       cdata->sgls.transport_sgl ? "Supported" : "Not Supported");
 	printf("\n");
 
 	printf("Firmware Slot Information\n");
@@ -1103,12 +1105,12 @@ print_controller(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_transport
 		       health_page.critical_warning.bits.read_only ? "Yes" : "No");
 		printf("  Volatile Memory Backup:    %s\n",
 		       health_page.critical_warning.bits.volatile_memory_backup ? "WARNING" : "OK");
-		printf("Current Temperature:         %u Kelvin (%u Celsius)\n",
+		printf("Current Temperature:         %u Kelvin (%d Celsius)\n",
 		       health_page.temperature,
-		       health_page.temperature - 273);
-		printf("Temperature Threshold:       %u Kelvin (%u Celsius)\n",
+		       (int)health_page.temperature - 273);
+		printf("Temperature Threshold:       %u Kelvin (%d Celsius)\n",
 		       features[SPDK_NVME_FEAT_TEMPERATURE_THRESHOLD].result,
-		       features[SPDK_NVME_FEAT_TEMPERATURE_THRESHOLD].result - 273);
+		       (int)features[SPDK_NVME_FEAT_TEMPERATURE_THRESHOLD].result - 273);
 		printf("Available Spare:             %u%%\n", health_page.available_spare);
 		printf("Available Spare Threshold:   %u%%\n", health_page.available_spare_threshold);
 		printf("Life Percentage Used:        %u%%\n", health_page.percentage_used);
@@ -1146,9 +1148,9 @@ print_controller(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_transport
 		printf("Critical Temperature Time:   %u minutes\n", health_page.critical_temp_time);
 		for (i = 0; i < 8; i++) {
 			if (health_page.temp_sensor[i] != 0) {
-				printf("Temperature Sensor %d:        %u Kelvin (%u Celsius)\n",
+				printf("Temperature Sensor %d:        %u Kelvin (%d Celsius)\n",
 				       i + 1, health_page.temp_sensor[i],
-				       health_page.temp_sensor[i] - 273);
+				       (int)health_page.temp_sensor[i] - 273);
 			}
 		}
 		printf("\n");
@@ -1169,13 +1171,13 @@ print_controller(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_transport
 		printf("==================================\n");
 		printf("Minimum Thermal Management Temperature:  ");
 		if (cdata->mntmt) {
-			printf("%u Kelvin (%u Celsius)\n", cdata->mntmt, cdata->mntmt - 273);
+			printf("%u Kelvin (%d Celsius)\n", cdata->mntmt, (int)cdata->mntmt - 273);
 		} else {
 			printf("Not Reported\n");
 		}
 		printf("Maximum Thermal Managment Temperature:   ");
 		if (cdata->mxtmt) {
-			printf("%u Kelvin (%u Celsius)\n", cdata->mxtmt, cdata->mxtmt - 273);
+			printf("%u Kelvin (%d Celsius)\n", cdata->mxtmt, (int)cdata->mxtmt - 273);
 		} else {
 			printf("Not Reported\n");
 		}
@@ -1437,7 +1439,7 @@ usage(const char *program_name)
 	printf("     subnqn      Subsystem NQN (default: %s)\n", SPDK_NVMF_DISCOVERY_NQN);
 	printf("    Example: -r 'trtype:RDMA adrfam:IPv4 traddr:192.168.100.8 trsvcid:4420'\n");
 
-	spdk_tracelog_usage(stdout, "-t");
+	spdk_tracelog_usage(stdout, "-L");
 
 	printf(" -i         shared memory group ID\n");
 	printf(" -p         core number in decimal to run this application which started from 0\n");
@@ -1455,7 +1457,7 @@ parse_args(int argc, char **argv)
 	g_trid.trtype = SPDK_NVME_TRANSPORT_PCIE;
 	snprintf(g_trid.subnqn, sizeof(g_trid.subnqn), "%s", SPDK_NVMF_DISCOVERY_NQN);
 
-	while ((op = getopt(argc, argv, "d:i:p:r:t:xH")) != -1) {
+	while ((op = getopt(argc, argv, "d:i:p:r:xHL:")) != -1) {
 		switch (op) {
 		case 'd':
 			g_dpdk_mem = atoi(optarg);
@@ -1477,7 +1479,10 @@ parse_args(int argc, char **argv)
 				return 1;
 			}
 			break;
-		case 't':
+		case 'x':
+			g_hex_dump = true;
+			break;
+		case 'L':
 			rc = spdk_log_set_trace_flag(optarg);
 			if (rc < 0) {
 				fprintf(stderr, "unknown flag\n");
@@ -1486,15 +1491,13 @@ parse_args(int argc, char **argv)
 			}
 			spdk_log_set_print_level(SPDK_LOG_DEBUG);
 #ifndef DEBUG
-			fprintf(stderr, "%s must be rebuilt with CONFIG_DEBUG=y for -t flag.\n",
+			fprintf(stderr, "%s must be rebuilt with CONFIG_DEBUG=y for -L flag.\n",
 				argv[0]);
 			usage(argv[0]);
 			return 0;
 #endif
 			break;
-		case 'x':
-			g_hex_dump = true;
-			break;
+
 		case 'H':
 		default:
 			usage(argv[0]);
diff --git a/examples/nvme/perf/README.md b/examples/nvme/perf/README.md
new file mode 100644
index 000000000..e5ec38d12
--- /dev/null
+++ b/examples/nvme/perf/README.md
@@ -0,0 +1,5 @@
+# Compiling perf on FreeBSD
+
+To use perf test on FreeBSD over NVMe-oF, explicitly link userspace library of HBA. For example, on a setup with Mellanox HBA,
+
+	LIBS += -lmlx5
diff --git a/go/spdk.go b/go/spdk.go
new file mode 100644
index 000000000..44ee7b569
--- /dev/null
+++ b/go/spdk.go
@@ -0,0 +1,50 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// spdk might one day provide Go bindings for the SPDK RPC API.
+// At the moment all that it does is allowing a Go project
+// to vendor in the SPDK source code via dep with this
+// in Gopkg.toml:
+//
+// required = ["github.com/spdk/spdk/go"]
+//
+// [prune]
+//  go-tests = true
+//  unused-packages = true
+//
+//  [[prune.project]]
+//    name = "github.com/spdk/spdk"
+//    go-tests = false
+//    unused-packages = false
+
+package spdk
diff --git a/include/spdk/barrier.h b/include/spdk/barrier.h
index a5f83916e..d4665a2f2 100644
--- a/include/spdk/barrier.h
+++ b/include/spdk/barrier.h
@@ -60,6 +60,18 @@ extern "C" {
 #error Unknown architecture
 #endif
 
+/** Read memory barrier */
+#ifdef __PPC64__
+#define spdk_rmb()	__asm volatile("sync" ::: "memory")
+#elif defined(__aarch64__)
+#define spdk_rmb()	__asm volatile("dsb lt" ::: "memory")
+#elif defined(__i386__) || defined(__x86_64__)
+#define spdk_rmb()	__asm volatile("lfence" ::: "memory")
+#else
+#define spdk_rmb()
+#error Unknown architecture
+#endif
+
 /** Full read/write memory barrier */
 #ifdef __PPC64__
 #define spdk_mb()	__asm volatile("sync" ::: "memory")
diff --git a/include/spdk/base64.h b/include/spdk/base64.h
new file mode 100644
index 000000000..c158c2316
--- /dev/null
+++ b/include/spdk/base64.h
@@ -0,0 +1,138 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * \file
+ * Base64 utility functions
+ */
+
+#ifndef SPDK_BASE64_H
+#define SPDK_BASE64_H
+
+#include "spdk/stdinc.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/**
+ * Following the Base64 part in RFC4648:
+ * https://tools.ietf.org/html/rfc4648.html
+ */
+
+/**
+ * Calculate strlen of encoded Base64 string based on raw buffer length.
+ *
+ * \param raw_len Length of raw buffer.
+ * \return Encoded Base64 string length, excluding the terminating null byte ('\0').
+ */
+static inline size_t spdk_base64_get_encoded_strlen(size_t raw_len)
+{
+	return (raw_len + 2) / 3 * 4;
+}
+
+/**
+ * Calculate length of raw buffer based on strlen of encoded Base64.
+ *
+ * \param encoded_strlen Length of enocded Base64 string, excluding terminating null byte ('\0').
+ * \return Length of raw buffer.
+ */
+static inline size_t spdk_base64_get_decoded_len(size_t encoded_strlen)
+{
+	/* text_strlen and raw_len should be (4n,3n), (4n+2, 3n+1) or (4n+3, 3n+2) */
+	return encoded_strlen / 4 * 3 + ((encoded_strlen % 4 + 1) / 2);
+}
+
+/**
+ * Base 64 Encoding with Standard Base64 Alphabet defined in RFC4684.
+ *
+ * \param dst Buffer address of encoded Base64 string. Its length should be enough
+ * to contain Base64 string and the terminating null byte ('\0'), so it needs to be at
+ * least as long as 1 + spdk_base64_get_encoded_strlen(src_len).
+ * \param src Raw data buffer to be encoded.
+ * \param src_len Length of raw data buffer.
+ *
+ * \return 0 on success.
+ * \return -EINVAL if dst or src is NULL, or binary_len <= 0.
+ */
+int spdk_base64_encode(char *dst, const void *src, size_t src_len);
+
+/**
+ * Base 64 Encoding with URL and Filename Safe Alphabet.
+ *
+ * \param dst Buffer address of encoded Base64 string. Its length should be enough
+ * to contain Base64 string and the terminating null byte ('\0'), so it needs to be at
+ * least as long as 1 + spdk_base64_get_encoded_strlen(src_len).
+ * \param src Raw data buffer to be encoded.
+ * \param src_len Length of raw data buffer.
+ *
+ * \return 0 on success.
+ * \return -EINVAL if dst or src is NULL, or binary_len <= 0.
+ */
+int spdk_base64_urlsafe_encode(char *dst, const void *src, size_t src_len);
+
+/**
+ * Base 64 Decoding with Standard Base64 Alphabet defined in RFC4684.
+ *
+ * \param dst Buffer address of decoded raw data. Its length should be enough
+ * to contain decoded raw data, so it needs to be at least as long as
+ * spdk_base64_get_decoded_len(encoded_strlen).
+ * \param dst_len Output parameter for the length of actual decoded raw data.
+ * If NULL, the actual decoded length won't be returned.
+ * \param src Data buffer for base64 string to be decoded.
+ *
+ * \return 0 on success.
+ * \return -EINVAL if dst or src is NULL, or content of src is illegal.
+ */
+int spdk_base64_decode(void *dst, size_t *dst_len, const char *src);
+
+/**
+ * Base 64 Decoding with URL and Filename Safe Alphabet.
+ *
+ * \param dst Buffer address of decoded raw data. Its length should be enough
+ * to contain decoded raw data, so it needs to be at least as long as
+ * spdk_base64_get_decoded_len(encoded_strlen).
+ * \param dst_len Output parameter for the length of actual decoded raw data.
+ * If NULL, the actual decoded length won't be returned.
+ * \param src Data buffer for base64 string to be decoded.
+ *
+ * \return 0 on success.
+ * \return -EINVAL if dst or src is NULL, or content of src is illegal.
+ */
+int spdk_base64_urlsafe_decode(void *dst, size_t *dst_len, const char *src);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* SPDK_BASE64_H */
diff --git a/include/spdk/bdev.h b/include/spdk/bdev.h
index 4bdbce5f6..dfe454132 100644
--- a/include/spdk/bdev.h
+++ b/include/spdk/bdev.h
@@ -44,6 +44,7 @@
 #include "spdk/scsi_spec.h"
 #include "spdk/nvme_spec.h"
 #include "spdk/json.h"
+#include "spdk/queue.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -52,6 +53,11 @@ extern "C" {
 #define SPDK_BDEV_SMALL_BUF_MAX_SIZE 8192
 #define SPDK_BDEV_LARGE_BUF_MAX_SIZE (64 * 1024)
 
+/**
+ * Block device remove callback.
+ *
+ * \param remove_ctx Context for the removed block device.
+ */
 typedef void (*spdk_bdev_remove_cb_t)(void *remove_ctx);
 
 /**
@@ -104,9 +110,9 @@ enum spdk_bdev_io_type {
  * Block device completion callback.
  *
  * \param bdev_io Block device I/O that has completed.
- * \param success true if I/O completed successfully or false if it failed; additional error
- *                information may be retrieved from bdev_io by calling
- *                spdk_bdev_io_get_nvme_status() or spdk_bdev_io_get_scsi_status().
+ * \param success True if I/O completed successfully or false if it failed;
+ * additional error information may be retrieved from bdev_io by calling
+ * spdk_bdev_io_get_nvme_status() or spdk_bdev_io_get_scsi_status().
  * \param cb_arg Callback argument specified when bdev_io was submitted.
  */
 typedef void (*spdk_bdev_io_completion_cb)(struct spdk_bdev_io *bdev_io,
@@ -123,8 +129,31 @@ struct spdk_bdev_io_stat {
 	uint64_t ticks_rate;
 };
 
+struct spdk_bdev_opts {
+	uint32_t bdev_io_pool_size;
+	uint32_t bdev_io_cache_size;
+};
+
+void spdk_bdev_get_opts(struct spdk_bdev_opts *opts);
+
+int spdk_bdev_set_opts(struct spdk_bdev_opts *opts);
+
+/**
+ * Block device initialization callback.
+ *
+ * \param cb_arg Callback argument.
+ * \param rc 0 if block device initialized successfully or negative errno if it failed.
+ */
 typedef void (*spdk_bdev_init_cb)(void *cb_arg, int rc);
+
+/**
+ * Block device finish callback.
+ *
+ * \param cb_arg Callback argument.
+ */
 typedef void (*spdk_bdev_fini_cb)(void *cb_arg);
+typedef void (*spdk_bdev_get_device_stat_cb)(struct spdk_bdev *bdev,
+		struct spdk_bdev_io_stat *stat, void *cb_arg, int rc);
 
 /**
  * Initialize block device modules.
@@ -308,7 +337,18 @@ uint64_t spdk_bdev_get_num_blocks(const struct spdk_bdev *bdev);
  *
  * Return 0 for no QoS enforced on the queried block device.
  */
-uint64_t spdk_bdev_get_qos_ios_per_sec(const struct spdk_bdev *bdev);
+uint64_t spdk_bdev_get_qos_ios_per_sec(struct spdk_bdev *bdev);
+
+/**
+ * Set an IOPS-based quality of service rate limit on a bdev.
+ *
+ * \param bdev Block device.
+ * \param ios_per_sec I/O per second limit.
+ * \param cb_fn Callback function to be called when the QoS limit has been updated.
+ * \param cb_arg Argument to pass to cb_fn.
+ */
+void spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
+				  void (*cb_fn)(void *cb_arg, int status), void *cb_arg);
 
 /**
  * Get minimum I/O buffer address alignment for a bdev.
@@ -349,6 +389,48 @@ bool spdk_bdev_has_write_cache(const struct spdk_bdev *bdev);
  */
 const struct spdk_uuid *spdk_bdev_get_uuid(const struct spdk_bdev *bdev);
 
+/**
+ * Get the most recently measured queue depth from a bdev.
+ *
+ * The reported queue depth is the aggregate of outstanding I/O
+ * across all open channels associated with this bdev.
+ *
+ * \param bdev Block device to query.
+ *
+ * \return The most recent queue depth measurement for the bdev.
+ * If tracking is not enabled, the function will return UINT64_MAX
+ * It is also possible to receive UINT64_MAX after enabling tracking
+ * but before the first period has expired.
+ */
+uint64_t
+spdk_bdev_get_qd(const struct spdk_bdev *bdev);
+
+/**
+ * Get the queue depth polling period.
+ *
+ * The return value of this function is only valid if the bdev's
+ * queue depth tracking status is set to true.
+ *
+ * \param bdev Block device to query.
+ *
+ * \return The period at which this bdev's gueue depth is being refreshed.
+ */
+uint64_t
+spdk_bdev_get_qd_sampling_period(const struct spdk_bdev *bdev);
+
+/**
+ * Enable or disable queue depth sampling for this bdev.
+ *
+ * Enables queue depth sampling when period is greater than 0. Disables it when the period
+ * is equal to zero. The resulting queue depth is stored in the spdk_bdev object as
+ * measured_queue_depth.
+ *
+ * \param bdev Block device on which to enable queue depth tracking.
+ * \param period The period at which to poll this bdev's queue depth. If this is set
+ * to zero, polling will be disabled.
+ */
+void spdk_bdev_set_qd_sampling_period(struct spdk_bdev *bdev, uint64_t period);
+
 /**
  * Obtain an I/O channel for the block device opened by the specified
  * descriptor. I/O channels are bound to threads, so the resulting I/O
@@ -361,9 +443,19 @@ const struct spdk_uuid *spdk_bdev_get_uuid(const struct spdk_bdev *bdev);
  */
 struct spdk_io_channel *spdk_bdev_get_io_channel(struct spdk_bdev_desc *desc);
 
+/**
+ * \defgroup bdev_io_submit_functions bdev I/O Submit Functions
+ *
+ * These functions submit a new I/O request to a bdev.  The I/O request will
+ *  be represented by an spdk_bdev_io structure allocated from a global pool.
+ *  These functions will return -ENOMEM if the spdk_bdev_io pool is empty.
+ */
+
 /**
  * Submit a read request to the bdev on the given channel.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param buf Data buffer to read into.
@@ -375,6 +467,8 @@ struct spdk_io_channel *spdk_bdev_get_io_channel(struct spdk_bdev_desc *desc);
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
  */
 int spdk_bdev_read(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		   void *buf, uint64_t offset, uint64_t nbytes,
@@ -383,6 +477,8 @@ int spdk_bdev_read(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 /**
  * Submit a read request to the bdev on the given channel.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param buf Data buffer to read into.
@@ -394,6 +490,8 @@ int spdk_bdev_read(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
  */
 int spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			  void *buf, uint64_t offset_blocks, uint64_t num_blocks,
@@ -406,6 +504,8 @@ int spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *c
  * data and may not be able to directly transfer into the buffers provided. In
  * this case, the request may fail.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param iov A scatter gather list of buffers to be read into.
@@ -418,6 +518,8 @@ int spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *c
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
  */
 int spdk_bdev_readv(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		    struct iovec *iov, int iovcnt,
@@ -431,6 +533,8 @@ int spdk_bdev_readv(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * data and may not be able to directly transfer into the buffers provided. In
  * this case, the request may fail.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param iov A scatter gather list of buffers to be read into.
@@ -443,6 +547,8 @@ int spdk_bdev_readv(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
  */
 int spdk_bdev_readv_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			   struct iovec *iov, int iovcnt,
@@ -452,6 +558,8 @@ int spdk_bdev_readv_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
 /**
  * Submit a write request to the bdev on the given channel.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param buf Data buffer to written from.
@@ -463,6 +571,9 @@ int spdk_bdev_readv_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_write(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		    void *buf, uint64_t offset, uint64_t nbytes,
@@ -471,6 +582,8 @@ int spdk_bdev_write(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 /**
  * Submit a write request to the bdev on the given channel.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param buf Data buffer to written from.
@@ -482,6 +595,9 @@ int spdk_bdev_write(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			   void *buf, uint64_t offset_blocks, uint64_t num_blocks,
@@ -494,6 +610,8 @@ int spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * data and may not be able to directly transfer out of the buffers provided. In
  * this case, the request may fail.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param iov A scatter gather list of buffers to be written from.
@@ -506,6 +624,9 @@ int spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_writev(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		     struct iovec *iov, int iovcnt,
@@ -519,6 +640,8 @@ int spdk_bdev_writev(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * data and may not be able to directly transfer out of the buffers provided. In
  * this case, the request may fail.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param iov A scatter gather list of buffers to be written from.
@@ -531,6 +654,9 @@ int spdk_bdev_writev(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_writev_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			    struct iovec *iov, int iovcnt,
@@ -541,6 +667,8 @@ int spdk_bdev_writev_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel
  * Submit a write zeroes request to the bdev on the given channel. This command
  *  ensures that all bytes in the specified range are set to 00h
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset The offset, in bytes, from the start of the block device.
@@ -551,6 +679,9 @@ int spdk_bdev_writev_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_write_zeroes(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			   uint64_t offset, uint64_t len,
@@ -560,6 +691,8 @@ int spdk_bdev_write_zeroes(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * Submit a write zeroes request to the bdev on the given channel. This command
  *  ensures that all bytes in the specified range are set to 00h
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset_blocks The offset, in blocks, from the start of the block device.
@@ -570,6 +703,9 @@ int spdk_bdev_write_zeroes(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 				  uint64_t offset_blocks, uint64_t num_blocks,
@@ -580,6 +716,8 @@ int spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_ch
  * deallocate. This notifies the device that the data in the blocks described is no
  * longer valid. Reading blocks that have been unmapped results in indeterminate data.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset The offset, in bytes, from the start of the block device.
@@ -590,6 +728,9 @@ int spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_ch
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_unmap(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		    uint64_t offset, uint64_t nbytes,
@@ -600,6 +741,8 @@ int spdk_bdev_unmap(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * deallocate. This notifies the device that the data in the blocks described is no
  * longer valid. Reading blocks that have been unmapped results in indeterminate data.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset_blocks The offset, in blocks, from the start of the block device.
@@ -610,6 +753,9 @@ int spdk_bdev_unmap(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_unmap_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			   uint64_t offset_blocks, uint64_t num_blocks,
@@ -620,6 +766,8 @@ int spdk_bdev_unmap_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * caches, data is not guaranteed to be persistent until the completion of a flush
  * request. Call spdk_bdev_has_write_cache() to check if the bdev has a volatile cache.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset The offset, in bytes, from the start of the block device.
@@ -630,6 +778,9 @@ int spdk_bdev_unmap_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset and/or nbytes are not aligned or out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_flush(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		    uint64_t offset, uint64_t length,
@@ -640,6 +791,8 @@ int spdk_bdev_flush(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * caches, data is not guaranteed to be persistent until the completion of a flush
  * request. Call spdk_bdev_has_write_cache() to check if the bdev has a volatile cache.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param offset_blocks The offset, in blocks, from the start of the block device.
@@ -650,6 +803,9 @@ int spdk_bdev_flush(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -EINVAL - offset_blocks and/or num_blocks are out of range
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_flush_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			   uint64_t offset_blocks, uint64_t num_blocks,
@@ -658,6 +814,8 @@ int spdk_bdev_flush_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
 /**
  * Submit a reset request to the bdev on the given channel.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param cb Called when the request is complete.
@@ -666,21 +824,11 @@ int spdk_bdev_flush_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
  */
 int spdk_bdev_reset(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		    spdk_bdev_io_completion_cb cb, void *cb_arg);
 
-/**
- * Set an IOPS-based quality of service rate limit on a bdev.
- *
- * \param bdev Block device.
- * \param ios_per_sec I/O per second limit.
- * \param cb_fn Callback function to be called when the QoS limit has been updated.
- * \param cb_arg Argument to pass to cb_fn.
- */
-void spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
-				  void (*cb_fn)(void *cb_arg, int status), void *cb_arg);
-
 /**
  * Submit an NVMe Admin command to the bdev. This passes directly through
  * the block layer to the device. Support for NVMe passthru is optional,
@@ -689,6 +837,8 @@ void spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
  * The SGL/PRP will be automated generated based on the given buffer,
  * so that portion of the command may be left empty.
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * \param desc Block device descriptor.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param cmd The raw NVMe command. Must be an admin command.
@@ -700,6 +850,8 @@ void spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_nvme_admin_passthru(struct spdk_bdev_desc *desc,
 				  struct spdk_io_channel *ch,
@@ -712,6 +864,8 @@ int spdk_bdev_nvme_admin_passthru(struct spdk_bdev_desc *desc,
  * the block layer to the device. Support for NVMe passthru is optional,
  * indicated by calling spdk_bdev_io_type_supported().
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * The SGL/PRP will be automated generated based on the given buffer,
  * so that portion of the command may be left empty. Also, the namespace
  * id (nsid) will be populated automatically.
@@ -727,6 +881,8 @@ int spdk_bdev_nvme_admin_passthru(struct spdk_bdev_desc *desc,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_nvme_io_passthru(struct spdk_bdev_desc *bdev_desc,
 			       struct spdk_io_channel *ch,
@@ -739,11 +895,13 @@ int spdk_bdev_nvme_io_passthru(struct spdk_bdev_desc *bdev_desc,
  * the block layer to the device. Support for NVMe passthru is optional,
  * indicated by calling spdk_bdev_io_type_supported().
  *
+ * \ingroup bdev_io_submit_functions
+ *
  * The SGL/PRP will be automated generated based on the given buffer,
  * so that portion of the command may be left empty. Also, the namespace
  * id (nsid) will be populated automatically.
  *
- * \param bdev Block device
+ * \param bdev_desc Block device descriptor
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
  * \param cmd The raw NVMe command. Must be in the NVM command set.
  * \param buf Data buffer to written from.
@@ -756,6 +914,8 @@ int spdk_bdev_nvme_io_passthru(struct spdk_bdev_desc *bdev_desc,
  * \return 0 on success. On success, the callback will always
  * be called (even if the request ultimately failed). Return
  * negated errno on failure, in which case the callback will not be called.
+ *   * -ENOMEM - spdk_bdev_io buffer cannot be allocated
+ *   * -EBADF - desc not open for writing
  */
 int spdk_bdev_nvme_io_passthru_md(struct spdk_bdev_desc *bdev_desc,
 				  struct spdk_io_channel *ch,
@@ -764,18 +924,63 @@ int spdk_bdev_nvme_io_passthru_md(struct spdk_bdev_desc *bdev_desc,
 				  spdk_bdev_io_completion_cb cb, void *cb_arg);
 
 /**
- * Free an I/O request. This should be called after the callback for the I/O has
- * been called and notifies the bdev layer that memory may now be released.
+ * Free an I/O request. This should only be called after the completion callback
+ * for the I/O has been called and notifies the bdev layer that memory may now
+ * be released.
  *
  * \param bdev_io I/O request.
+ */
+void spdk_bdev_free_io(struct spdk_bdev_io *bdev_io);
+
+/**
+ * Block device I/O wait callback
+ *
+ * Callback function to notify when an spdk_bdev_io structure is available
+ * to satisfy a call to one of the @ref bdev_io_submit_functions.
+ */
+typedef void (*spdk_bdev_io_wait_cb)(void *cb_arg);
+
+/**
+ * Structure to register a callback when an spdk_bdev_io becomes available.
+ */
+struct spdk_bdev_io_wait_entry {
+	struct spdk_bdev			*bdev;
+	spdk_bdev_io_wait_cb			cb_fn;
+	void					*cb_arg;
+	TAILQ_ENTRY(spdk_bdev_io_wait_entry)	link;
+};
+
+/**
+ * Add an entry into the calling thread's queue to be notified when an
+ * spdk_bdev_io becomes available.
+ *
+ * When one of the @ref bdev_io_submit_functions returns -ENOMEM, it means
+ * the spdk_bdev_io buffer pool has no available buffers. This function may
+ * be called to register a callback to be notified when a buffer becomes
+ * available on the calling thread.
+ *
+ * The callback function will always be called on the same thread as this
+ * function was called.
+ *
+ * This function must only be called immediately after one of the
+ * @ref bdev_io_submit_functions returns -ENOMEM.
+ *
+ * \param bdev Block device.  The block device that the caller will submit
+ *             an I/O to when the callback is invoked.  Must match the bdev
+ *             member in the entry parameter.
+ * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
+ * \param entry Data structure allocated by the caller specifying the callback
+ *              function and argument.
  *
- * \return -1 on failure, 0 on success.
+ * \return 0 on success.
+ *         -EINVAL if bdev parameter does not match bdev member in entry
+ *         -EINVAL if an spdk_bdev_io structure was available on this thread.
  */
-int spdk_bdev_free_io(struct spdk_bdev_io *bdev_io);
+int spdk_bdev_queue_io_wait(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
+			    struct spdk_bdev_io_wait_entry *entry);
 
 /**
- * Return I/O statistics for this channel. After returning stats, zero out
- * the current state of the statistics.
+ * Return I/O statistics for this channel.
  *
  * \param bdev Block device.
  * \param ch I/O channel. Obtained by calling spdk_bdev_get_io_channel().
@@ -785,6 +990,19 @@ int spdk_bdev_free_io(struct spdk_bdev_io *bdev_io);
 void spdk_bdev_get_io_stat(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
 			   struct spdk_bdev_io_stat *stat);
 
+
+/**
+ * Return I/O statistics for this bdev. All the required information will be passed
+ * via the callback function.
+ *
+ * \param bdev Block device to query.
+ * \param stat Structure for aggregating collected statistics.  Passed as argument to cb.
+ * \param cb Called when this operation completes.
+ * \param cb_arg Argument passed to callback function.
+ */
+void spdk_bdev_get_device_stat(struct spdk_bdev *bdev, struct spdk_bdev_io_stat *stat,
+			       spdk_bdev_get_device_stat_cb cb, void *cb_arg);
+
 /**
  * Get the status of bdev_io as an NVMe status code.
  *
diff --git a/include/spdk_internal/bdev.h b/include/spdk/bdev_module.h
similarity index 50%
rename from include/spdk_internal/bdev.h
rename to include/spdk/bdev_module.h
index 9988d4d2e..568e5b85a 100644
--- a/include/spdk_internal/bdev.h
+++ b/include/spdk/bdev_module.h
@@ -34,48 +34,22 @@
 
 /** \file
  * Block Device Module Interface
+ *
+ * For information on how to write a bdev module, see @ref bdev_module.
  */
 
-#ifndef SPDK_INTERNAL_BDEV_H
-#define SPDK_INTERNAL_BDEV_H
+#ifndef SPDK_BDEV_MODULE_H
+#define SPDK_BDEV_MODULE_H
 
 #include "spdk/stdinc.h"
 
 #include "spdk/bdev.h"
 #include "spdk/queue.h"
 #include "spdk/scsi_spec.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
+#include "spdk/util.h"
 #include "spdk/uuid.h"
 
-/** \page block_backend_modules Block Device Backend Modules
- *
- * To implement a backend block device driver, a number of functions
- * dictated by struct spdk_bdev_fn_table must be provided.
- *
- * The module should register itself using SPDK_BDEV_MODULE_REGISTER to
- * define the parameters for the module.
- *
- * <hr>
- *
- * In the module initialization code, the config file sections can be parsed to
- * acquire custom configuration parameters. For example, if the config file has
- * a section such as below:
- * <blockquote><pre>
- * [MyBE]
- * MyParam 1234
- * </pre></blockquote>
- *
- * The value can be extracted as the example below:
- * <blockquote><pre>
- * struct spdk_conf_section *sp = spdk_conf_find_section(NULL, "MyBe");
- * int my_param = spdk_conf_section_get_intval(sp, "MyParam");
- * </pre></blockquote>
- *
- * The backend initialization routine also need to create "disks". A virtual
- * representation of each LUN must be constructed. Mainly a struct spdk_bdev
- * must be passed to the bdev database via spdk_bdev_register().
- */
-
 /** Block device module */
 struct spdk_bdev_module {
 	/**
@@ -126,19 +100,19 @@ struct spdk_bdev_module {
 	int (*get_ctx_size)(void);
 
 	/**
-	 * Notification that a bdev should be examined by a virtual bdev module.
+	 * First notification that a bdev should be examined by a virtual bdev module.
 	 * Virtual bdev modules may use this to examine newly-added bdevs and automatically
-	 * create their own vbdevs.
+	 * create their own vbdevs, but no I/O to device can be send to bdev at this point.
+	 * Only vbdevs based on config files can be created here.
 	 */
-	void (*examine)(struct spdk_bdev *bdev);
+	void (*examine_config)(struct spdk_bdev *bdev);
 
 	/**
-	 * Count of bdev inits/examinations in progress. Used by generic bdev
-	 * layer and must not be modified by bdev modules.
-	 *
-	 * \note Used internally by bdev subsystem, don't change this value in bdev module.
+	 * Second notification that a bdev should be examined by a virtual bdev module.
+	 * Virtual bdev modules may use this to examine newly-added bdevs and automatically
+	 * create their own vbdevs. This callback may use I/O operations end finish asynchronously.
 	 */
-	uint32_t action_in_progress;
+	void (*examine_disk)(struct spdk_bdev *bdev);
 
 	/**
 	 * Denotes if the module_init function may complete asynchronously. If set to true,
@@ -154,7 +128,21 @@ struct spdk_bdev_module {
 	 */
 	bool async_fini;
 
-	TAILQ_ENTRY(spdk_bdev_module) tailq;
+	/**
+	 * Fields that are used by the internal bdev subsystem. Bdev modules
+	 *  must not read or write to these fields.
+	 */
+	struct __bdev_module_internal_fields {
+		/**
+		 * Count of bdev inits/examinations in progress. Used by generic bdev
+		 * layer and must not be modified by bdev modules.
+		 *
+		 * \note Used internally by bdev subsystem, don't change this value in bdev module.
+		 */
+		uint32_t action_in_progress;
+
+		TAILQ_ENTRY(spdk_bdev_module) tailq;
+	} internal;
 };
 
 typedef void (*spdk_bdev_unregister_cb)(void *cb_arg, int rc);
@@ -240,49 +228,15 @@ struct spdk_bdev {
 	/** Unique product name for this kind of block device. */
 	char *product_name;
 
+	/** write cache enabled, not used at the moment */
+	int write_cache;
+
 	/** Size in bytes of a logical block for the backend */
 	uint32_t blocklen;
 
 	/** Number of blocks */
 	uint64_t blockcnt;
 
-	/** Number of active channels on this bdev except the QoS bdev channel */
-	uint32_t channel_count;
-
-	/** Quality of service parameters */
-	struct spdk_bdev_qos {
-		/** True if QoS is enabled */
-		bool enabled;
-
-		/** True if the state of the QoS is being modified */
-		bool mod_in_progress;
-
-		/** Rate limit, in I/O per second */
-		uint64_t rate_limit;
-
-		/** The channel that all I/O are funneled through */
-		struct spdk_bdev_channel *ch;
-
-		/** The thread on which the poller is running. */
-		struct spdk_thread *thread;
-
-		/** Queue of I/O waiting to be issued. */
-		bdev_io_tailq_t queued;
-
-		/** Maximum allowed IOs to be issued in one timeslice (e.g., 1ms) and
-		 *  only valid for the master channel which manages the outstanding IOs. */
-		uint64_t max_ios_per_timeslice;
-
-		/** Submitted IO in one timeslice (e.g., 1ms) */
-		uint64_t io_submitted_this_timeslice;
-
-		/** Polller that processes queued I/O commands each time slice. */
-		struct spdk_poller *poller;
-	} qos;
-
-	/** write cache enabled, not used at the moment */
-	int write_cache;
-
 	/**
 	 * This is used to make sure buffers are sector aligned.
 	 * This causes double buffering on writes.
@@ -309,104 +263,79 @@ struct spdk_bdev {
 	/** function table for all LUN ops */
 	const struct spdk_bdev_fn_table *fn_table;
 
-	/** Mutex protecting claimed */
-	pthread_mutex_t mutex;
-
-	/** The bdev status */
-	enum spdk_bdev_status status;
-
-	/** The array of block devices that this block device is built on top of (if any). */
-	struct spdk_bdev **base_bdevs;
-	size_t base_bdevs_cnt;
-
-
 	/** The array of virtual block devices built on top of this block device. */
 	struct spdk_bdev **vbdevs;
 	size_t vbdevs_cnt;
 
-	/**
-	 * Pointer to the module that has claimed this bdev for purposes of creating virtual
-	 *  bdevs on top of it.  Set to NULL if the bdev has not been claimed.
+	/** Fields that are used internally by the bdev subsystem.  Bdev modules
+	 *  must not read or write to these fields.
 	 */
-	struct spdk_bdev_module *claim_module;
+	struct __bdev_internal_fields {
+		/** Quality of service parameters */
+		struct spdk_bdev_qos *qos;
 
-	/** Callback function that will be called after bdev destruct is completed. */
-	spdk_bdev_unregister_cb	unregister_cb;
+		/** True if the state of the QoS is being modified */
+		bool qos_mod_in_progress;
 
-	/** Unregister call context */
-	void *unregister_ctx;
+		/** Mutex protecting claimed */
+		pthread_mutex_t mutex;
 
-	/** List of open descriptors for this block device. */
-	TAILQ_HEAD(, spdk_bdev_desc) open_descs;
+		/** The bdev status */
+		enum spdk_bdev_status status;
 
-	TAILQ_ENTRY(spdk_bdev) link;
+		/** The array of block devices that this block device is built on top of (if any). */
+		struct spdk_bdev **base_bdevs;
+		size_t base_bdevs_cnt;
 
-	/** points to a reset bdev_io if one is in progress. */
-	struct spdk_bdev_io *reset_in_progress;
-};
+		/**
+		 * Pointer to the module that has claimed this bdev for purposes of creating virtual
+		 *  bdevs on top of it.  Set to NULL if the bdev has not been claimed.
+		 */
+		struct spdk_bdev_module *claim_module;
 
-typedef void (*spdk_bdev_io_get_buf_cb)(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io);
+		/** Callback function that will be called after bdev destruct is completed. */
+		spdk_bdev_unregister_cb	unregister_cb;
 
-struct spdk_bdev_io {
-	/** The block device that this I/O belongs to. */
-	struct spdk_bdev *bdev;
+		/** Unregister call context */
+		void *unregister_ctx;
 
-	/** The bdev I/O channel that this was handled on. */
-	struct spdk_bdev_channel *ch;
+		/** List of open descriptors for this block device. */
+		TAILQ_HEAD(, spdk_bdev_desc) open_descs;
 
-	/** The bdev I/O channel that this was submitted on. */
-	struct spdk_bdev_channel *io_submit_ch;
+		TAILQ_ENTRY(spdk_bdev) link;
 
-	/** User function that will be called when this completes */
-	spdk_bdev_io_completion_cb cb;
+		/** points to a reset bdev_io if one is in progress. */
+		struct spdk_bdev_io *reset_in_progress;
 
-	/** Context that will be passed to the completion callback */
-	void *caller_ctx;
+		/** poller for tracking the queue_depth of a device, NULL if not tracking */
+		struct spdk_poller *qd_poller;
 
-	/** Current tsc at submit time. Used to calculate latency at completion. */
-	uint64_t submit_tsc;
+		/** period at which we poll for queue depth information */
+		uint64_t period;
 
-	/**
-	 * Set to true while the bdev module submit_request function is in progress.
-	 *
-	 * This is used to decide whether spdk_bdev_io_complete() can complete the I/O directly
-	 * or if completion must be deferred via an event.
-	 */
-	bool in_submit_request;
+		/** used to aggregate queue depth while iterating across the bdev's open channels */
+		uint64_t temporary_queue_depth;
 
-	/** Status for the IO */
-	int8_t status;
+		/** queue depth as calculated the last time the telemetry poller checked. */
+		uint64_t measured_queue_depth;
 
-	/** Error information from a device */
-	union {
-		/** Only valid when status is SPDK_BDEV_IO_STATUS_NVME_ERROR */
-		struct {
-			/** NVMe status code type */
-			uint8_t sct;
-			/** NVMe status code */
-			uint8_t sc;
-		} nvme;
-		/** Only valid when status is SPDK_BDEV_IO_STATUS_SCSI_ERROR */
-		struct {
-			/** SCSI status code */
-			uint8_t sc;
-			/** SCSI sense key */
-			uint8_t sk;
-			/** SCSI additional sense code */
-			uint8_t asc;
-			/** SCSI additional sense code qualifier */
-			uint8_t ascq;
-		} scsi;
-	} error;
+	} internal;
+};
+
+typedef void (*spdk_bdev_io_get_buf_cb)(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io);
+
+struct spdk_bdev_io {
+	/** The block device that this I/O belongs to. */
+	struct spdk_bdev *bdev;
 
 	/** Enumerated value representing the I/O type. */
 	uint8_t type;
 
+	/** A single iovec element for use by this bdev_io. */
+	struct iovec iov;
+
 	union {
 		struct {
-			/** For basic IO case, use our own iovec element. */
-			struct iovec iov;
-
 			/** For SG buffer cases, array of iovecs to transfer. */
 			struct iovec *iovs;
 
@@ -450,24 +379,78 @@ struct spdk_bdev_io {
 		} nvme_passthru;
 	} u;
 
-	/** bdev allocated memory associated with this request */
-	void *buf;
-
-	/** requested size of the buffer associated with this I/O */
-	uint64_t buf_len;
-
-	/** Callback for when buf is allocated */
-	spdk_bdev_io_get_buf_cb get_buf_cb;
-
-	/** Entry to the list need_buf of struct spdk_bdev. */
-	STAILQ_ENTRY(spdk_bdev_io) buf_link;
-
-	/** Member used for linking child I/Os together. */
-	TAILQ_ENTRY(spdk_bdev_io) link;
-
 	/** It may be used by modules to put the bdev_io into its own list. */
 	TAILQ_ENTRY(spdk_bdev_io) module_link;
 
+	/**
+	 *  Fields that are used internally by the bdev subsystem.  Bdev modules
+	 *  must not read or write to these fields.
+	 */
+	struct __bdev_io_internal_fields {
+		/** The bdev I/O channel that this was handled on. */
+		struct spdk_bdev_channel *ch;
+
+		/** The bdev I/O channel that this was submitted on. */
+		struct spdk_bdev_channel *io_submit_ch;
+
+		/** User function that will be called when this completes */
+		spdk_bdev_io_completion_cb cb;
+
+		/** Context that will be passed to the completion callback */
+		void *caller_ctx;
+
+		/** Current tsc at submit time. Used to calculate latency at completion. */
+		uint64_t submit_tsc;
+
+		/** Error information from a device */
+		union {
+			/** Only valid when status is SPDK_BDEV_IO_STATUS_NVME_ERROR */
+			struct {
+				/** NVMe status code type */
+				uint8_t sct;
+				/** NVMe status code */
+				uint8_t sc;
+			} nvme;
+			/** Only valid when status is SPDK_BDEV_IO_STATUS_SCSI_ERROR */
+			struct {
+				/** SCSI status code */
+				uint8_t sc;
+				/** SCSI sense key */
+				uint8_t sk;
+				/** SCSI additional sense code */
+				uint8_t asc;
+				/** SCSI additional sense code qualifier */
+				uint8_t ascq;
+			} scsi;
+		} error;
+
+		/**
+		 * Set to true while the bdev module submit_request function is in progress.
+		 *
+		 * This is used to decide whether spdk_bdev_io_complete() can complete the I/O directly
+		 * or if completion must be deferred via an event.
+		 */
+		bool in_submit_request;
+
+		/** Status for the IO */
+		int8_t status;
+
+		/** bdev allocated memory associated with this request */
+		void *buf;
+
+		/** requested size of the buffer associated with this I/O */
+		uint64_t buf_len;
+
+		/** Callback for when buf is allocated */
+		spdk_bdev_io_get_buf_cb get_buf_cb;
+
+		/** Member used for linking child I/Os together. */
+		TAILQ_ENTRY(spdk_bdev_io) link;
+
+		/** Entry to the list need_buf of struct spdk_bdev. */
+		STAILQ_ENTRY(spdk_bdev_io) buf_link;
+	} internal;
+
 	/**
 	 * Per I/O context for use by the bdev module.
 	 */
@@ -476,17 +459,103 @@ struct spdk_bdev_io {
 	/* No members may be added after driver_ctx! */
 };
 
+/**
+ * Register a new bdev.
+ *
+ * \param bdev Block device to register.
+ *
+ * \return 0 on success.
+ * \return -EINVAL if the bdev name is NULL.
+ * \return -EEXIST if a bdev or bdev alias with the same name already exists.
+ */
 int spdk_bdev_register(struct spdk_bdev *bdev);
+
+/**
+ * Unregister a bdev
+ *
+ * \param bdev Block device to unregister.
+ * \param cb_fn Callback function to be called when the unregister is complete.
+ * \param cb_arg Argument to be supplied to cb_fn
+ */
 void spdk_bdev_unregister(struct spdk_bdev *bdev, spdk_bdev_unregister_cb cb_fn, void *cb_arg);
+
+/**
+ * Invokes the unregister callback of a bdev backing a virtual bdev.
+ *
+ * A Bdev with an asynchronous destruct path should return 1 from its
+ * destruct function and call this function at the conclusion of that path.
+ * Bdevs with synchronous destruct paths should return 0 from their destruct
+ * path.
+ *
+ * \param bdev Block device that was destroyed.
+ * \param bdeverrno Error code returned from bdev's destruct callback.
+ */
 void spdk_bdev_destruct_done(struct spdk_bdev *bdev, int bdeverrno);
+
+/**
+ * Register a virtual bdev.
+ *
+ * \param vbdev Virtual bdev to register.
+ * \param base_bdevs Array of bdevs upon which this vbdev is based.
+ * \param base_bdev_count Number of bdevs in base_bdevs.
+ *
+ * \return 0 on success
+ * \return -EINVAL if the bdev name is NULL.
+ * \return -EEXIST if the bdev already exists.
+ * \return -ENOMEM if allocation of the base_bdevs array or the base bdevs vbdevs array fails.
+ */
 int spdk_vbdev_register(struct spdk_bdev *vbdev, struct spdk_bdev **base_bdevs,
 			int base_bdev_count);
 
+/**
+ * Indicate to the bdev layer that the module is done examining a bdev.
+ *
+ * To be called synchronously or asynchronously in response to the
+ * module's examine function being called.
+ *
+ * \param module Pointer to the module completing the examination.
+ */
 void spdk_bdev_module_examine_done(struct spdk_bdev_module *module);
+
+/**
+ * Indicate to the bdev layer that the module is done initializing.
+ *
+ * To be called synchronously or asynchronously in response to the
+ * module_init function being called.
+ *
+ * \param module Pointer to the module completing the initialization.
+ */
 void spdk_bdev_module_init_done(struct spdk_bdev_module *module);
+
+/**
+ * Indicate to the bdev layer that the module is done cleaning up.
+ *
+ * To be called either synchronously or asynchronously
+ * in response to the module_fini function being called.
+ *
+ */
 void spdk_bdev_module_finish_done(void);
+
+/**
+ * Called by a bdev module to lay exclusive write claim to a bdev.
+ *
+ * Also upgrades that bdev's descriptor to have write access.
+ *
+ * \param bdev Block device to be claimed.
+ * \param desc Descriptor for the above block device.
+ * \param module Bdev module attempting to claim bdev.
+ *
+ * \return 0 on success
+ * \return -EPERM if the bdev is already claimed by another module.
+ */
 int spdk_bdev_module_claim_bdev(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
 				struct spdk_bdev_module *module);
+
+/**
+ * Called to release a write claim on a block device.
+ *
+ * \param bdev Block device to be released.
+ */
 void spdk_bdev_module_release_bdev(struct spdk_bdev *bdev);
 
 /**
@@ -496,7 +565,6 @@ void spdk_bdev_module_release_bdev(struct spdk_bdev *bdev);
  * \param bdev Block device to query.
  * \param alias Alias to be added to list.
  *
- * Return codes
  * \return 0 on success
  * \return -EEXIST if alias already exists as name or alias on any bdev
  * \return -ENOMEM if memory cannot be allocated to store alias
@@ -538,6 +606,26 @@ const struct spdk_bdev_aliases_list *spdk_bdev_get_aliases(const struct spdk_bde
  */
 void spdk_bdev_io_get_buf(struct spdk_bdev_io *bdev_io, spdk_bdev_io_get_buf_cb cb, uint64_t len);
 
+/**
+ * Set the given buffer as the data buffer described by this bdev_io.
+ *
+ * The portion of the buffer used may be adjusted for memory alignement
+ * purposes.
+ *
+ * \param bdev_io I/O to set the buffer on.
+ * \param buf The buffer to set as the active data buffer.
+ * \param len The length of the buffer.
+ *
+ * \return The usable size of the buffer, after adjustments of alignment.
+ */
+size_t spdk_bdev_io_set_buf(struct spdk_bdev_io *bdev_io, void *buf, size_t len);
+
+/**
+ * Complete a bdev_io
+ *
+ * \param bdev_io I/O to complete.
+ * \param status The I/O completion status.
+ */
 void spdk_bdev_io_complete(struct spdk_bdev_io *bdev_io,
 			   enum spdk_bdev_io_status status);
 
@@ -582,9 +670,27 @@ struct spdk_thread *spdk_bdev_io_get_thread(struct spdk_bdev_io *bdev_io);
  */
 int spdk_bdev_notify_blockcnt_change(struct spdk_bdev *bdev, uint64_t size);
 
+/**
+ * Translates NVMe status codes to SCSI status information.
+ *
+ * The codes are stored in the user supplied integers.
+ *
+ * \param bdev_io I/O containing status codes to translate.
+ * \param sc SCSI Status Code will be stored here.
+ * \param sk SCSI Sense Key will be stored here.
+ * \param asc SCSI Additional Sense Code will be stored here.
+ * \param ascq SCSI Additional Sense Code Qualifier will be stored here.
+ */
 void spdk_scsi_nvme_translate(const struct spdk_bdev_io *bdev_io,
 			      int *sc, int *sk, int *asc, int *ascq);
 
+/**
+ * Add the given module to the list of registered modules.
+ * This function should be invoked by referencing the macro
+ * SPDK_BDEV_MODULE_REGISTER in the module c file.
+ *
+ * \param bdev_module Module to be added.
+ */
 void spdk_bdev_module_list_add(struct spdk_bdev_module *bdev_module);
 
 /**
@@ -598,33 +704,68 @@ struct spdk_bdev_module *spdk_bdev_module_list_find(const char *name);
 static inline struct spdk_bdev_io *
 spdk_bdev_io_from_ctx(void *ctx)
 {
-	return (struct spdk_bdev_io *)
-	       ((uintptr_t)ctx - offsetof(struct spdk_bdev_io, driver_ctx));
+	return SPDK_CONTAINEROF(ctx, struct spdk_bdev_io, driver_ctx);
 }
 
 struct spdk_bdev_part_base;
 
-typedef void (*spdk_bdev_part_base_free_fn)(struct spdk_bdev_part_base *base);
-
-struct spdk_bdev_part_base {
-	struct spdk_bdev		*bdev;
-	struct spdk_bdev_desc		*desc;
-	uint32_t			ref;
-	uint32_t			channel_size;
-	spdk_bdev_part_base_free_fn	base_free_fn;
-	bool				claimed;
-	struct spdk_bdev_module		*module;
-	struct spdk_bdev_fn_table	*fn_table;
-	struct bdev_part_tailq		*tailq;
-	spdk_io_channel_create_cb	ch_create_cb;
-	spdk_io_channel_destroy_cb	ch_destroy_cb;
-};
+/**
+ * Returns a pointer to the spdk_bdev associated with an spdk_bdev_part_base
+ *
+ * \param part_base A pointer to an spdk_bdev_part_base object.
+ *
+ * \return A pointer to the base's spdk_bdev struct.
+ */
+struct spdk_bdev *spdk_bdev_part_base_get_bdev(struct spdk_bdev_part_base *part_base);
+
+/**
+ * Returns a pointer to the spdk_bdev_descriptor associated with an spdk_bdev_part_base
+ *
+ * \param part_base A pointer to an spdk_bdev_part_base object.
+ *
+ * \return A pointer to the base's spdk_bdev_desc struct.
+ */
+struct spdk_bdev_desc *spdk_bdev_part_base_get_desc(struct spdk_bdev_part_base *part_base);
+
+/**
+ * Returns a pointer to the tailq associated with an spdk_bdev_part_base
+ *
+ * \param part_base A pointer to an spdk_bdev_part_base object.
+ *
+ * \return The head of a tailq of spdk_bdev_part structs registered to the base's module.
+ */
+struct bdev_part_tailq *spdk_bdev_part_base_get_tailq(struct spdk_bdev_part_base *part_base);
+
+/**
+ * Returns a pointer to the module level context associated with an spdk_bdev_part_base
+ *
+ * \param part_base A pointer to an spdk_bdev_part_base object.
+ *
+ * \return A pointer to the module level context registered with the base in spdk_bdev_part_base_construct.
+ */
+void *spdk_bdev_part_base_get_ctx(struct spdk_bdev_part_base *part_base);
+
+typedef void (*spdk_bdev_part_base_free_fn)(void *ctx);
 
 struct spdk_bdev_part {
-	struct spdk_bdev		bdev;
-	struct spdk_bdev_part_base	*base;
-	uint64_t			offset_blocks;
+	/* Entry into the module's global list of bdev parts */
 	TAILQ_ENTRY(spdk_bdev_part)	tailq;
+
+	/**
+	 * Fields that are used internally by part.c These fields should only
+	 * be accessed from a module using any pertinent get and set methods.
+	 */
+	struct bdev_part_internal_fields {
+
+		/* This part's corresponding bdev object. Not to be confused with the base bdev */
+		struct spdk_bdev		bdev;
+
+		/* The base to which this part belongs */
+		struct spdk_bdev_part_base	*base;
+
+		/* number of blocks from the start of the base bdev to the start of this part */
+		uint64_t			offset_blocks;
+	} internal;
 };
 
 struct spdk_bdev_part_channel {
@@ -634,23 +775,128 @@ struct spdk_bdev_part_channel {
 
 typedef TAILQ_HEAD(bdev_part_tailq, spdk_bdev_part)	SPDK_BDEV_PART_TAILQ;
 
+/**
+ * Free the base corresponding to one or more spdk_bdev_part.
+ *
+ * \param base The base to free.
+ */
 void spdk_bdev_part_base_free(struct spdk_bdev_part_base *base);
+
+/**
+ * Free an spdk_bdev_part context.
+ *
+ * \param part The part to free.
+ *
+ * \return 1 always. To indicate that the operation is asynchronous.
+ */
 int spdk_bdev_part_free(struct spdk_bdev_part *part);
+
+/**
+ * Calls spdk_bdev_unregister on the bdev for each part associated with base_bdev.
+ *
+ * \param base_bdev The spdk_bdev upon which an spdk_bdev-part_base is built
+ * \param tailq The list of spdk_bdev_part bdevs associated with this base bdev.
+ */
 void spdk_bdev_part_base_hotremove(struct spdk_bdev *base_bdev, struct bdev_part_tailq *tailq);
-int spdk_bdev_part_base_construct(struct spdk_bdev_part_base *base, struct spdk_bdev *bdev,
-				  spdk_bdev_remove_cb_t remove_cb,
-				  struct spdk_bdev_module *module,
-				  struct spdk_bdev_fn_table *fn_table,
-				  struct bdev_part_tailq *tailq,
-				  spdk_bdev_part_base_free_fn free_fn,
-				  uint32_t channel_size,
-				  spdk_io_channel_create_cb ch_create_cb,
-				  spdk_io_channel_destroy_cb ch_destroy_cb);
+
+/**
+ * Construct a new spdk_bdev_part_base on top of the provided bdev.
+ *
+ * \param bdev The spdk_bdev upon which this base will be built.
+ * \param remove_cb Function to be called upon hotremove of the bdev.
+ * \param module The module to which this bdev base belongs.
+ * \param fn_table Function table for communicating with the bdev backend.
+ * \param tailq The head of the list of all spdk_bdev_part structures registered to this base's module.
+ * \param free_fn User provided function to free base related context upon bdev removal or shutdown.
+ * \param ctx Module specific context for this bdev part base.
+ * \param channel_size Channel size in bytes.
+ * \param ch_create_cb Called after a new channel is allocated.
+ * \param ch_destroy_cb Called upon channel deletion.
+ *
+ * \return 0 on success
+ * \return -1 if the underlying bdev cannot be opened.
+ */
+struct spdk_bdev_part_base *spdk_bdev_part_base_construct(struct spdk_bdev *bdev,
+		spdk_bdev_remove_cb_t remove_cb,
+		struct spdk_bdev_module *module,
+		struct spdk_bdev_fn_table *fn_table,
+		struct bdev_part_tailq *tailq,
+		spdk_bdev_part_base_free_fn free_fn,
+		void *ctx,
+		uint32_t channel_size,
+		spdk_io_channel_create_cb ch_create_cb,
+		spdk_io_channel_destroy_cb ch_destroy_cb);
+
+/**
+ * Create a logical spdk_bdev_part on top of a base.
+ *
+ * \param part The part object allocated by the user.
+ * \param base The base from which to create the part.
+ * \param name The name of the new spdk_bdev_part.
+ * \param offset_blocks The offset into the base bdev at which this part begins.
+ * \param num_blocks The number of blocks that this part will span.
+ * \param product_name Unique name for this type of block device.
+ *
+ * \return 0 on success.
+ * \return -1 if the bases underlying bdev cannot be claimed by the current module.
+ */
 int spdk_bdev_part_construct(struct spdk_bdev_part *part, struct spdk_bdev_part_base *base,
 			     char *name, uint64_t offset_blocks, uint64_t num_blocks,
 			     char *product_name);
+
+/**
+ * Forwards I/O from an spdk_bdev_part to the underlying base bdev.
+ *
+ * This function will apply the offset_blocks the user provided to
+ * spdk_bdev_part_construct to the I/O. The user should not manually
+ * apply this offset before submitting any I/O through this function.
+ *
+ * \param ch The I/O channel associated with the spdk_bdev_part.
+ * \param bdev_io The I/O to be submitted to the underlying bdev.
+ */
 void spdk_bdev_part_submit_request(struct spdk_bdev_part_channel *ch, struct spdk_bdev_io *bdev_io);
 
+/**
+ * Return a pointer to this part's spdk_bdev.
+ *
+ * \param part An spdk_bdev_part object.
+ *
+ * \return A pointer to this part's spdk_bdev object.
+ */
+struct spdk_bdev *spdk_bdev_part_get_bdev(struct spdk_bdev_part *part);
+
+/**
+ * Return a pointer to this part's base.
+ *
+ * \param part An spdk_bdev_part object.
+ *
+ * \return A pointer to this part's spdk_bdev_part_base object.
+ */
+struct spdk_bdev_part_base *spdk_bdev_part_get_base(struct spdk_bdev_part *part);
+
+/**
+ * Return a pointer to this part's base bdev.
+ *
+ * The return value of this function is equivalent to calling
+ * spdk_bdev_part_base_get_bdev on this part's base.
+ *
+ * \param part An spdk_bdev_part object.
+ *
+ * \return A pointer to the bdev belonging to this part's base.
+ */
+struct spdk_bdev *spdk_bdev_part_get_base_bdev(struct spdk_bdev_part *part);
+
+/**
+ * Return this part's offset from the beginning of the base bdev.
+ *
+ * This function should not be called in the I/O path. Any block
+ * translations to I/O will be handled in spdk_bdev_part_submit_request.
+ *
+ * \param part An spdk_bdev_part object.
+ *
+ * \return the block offset of this part from it's underlying bdev.
+ */
+uint64_t spdk_bdev_part_get_offset_blocks(struct spdk_bdev_part *part);
 
 /*
  * Macro used to register module for later initialization.
@@ -673,4 +919,4 @@ void spdk_bdev_part_submit_request(struct spdk_bdev_part_channel *ch, struct spd
  */
 #define SPDK_BDEV_MODULE_REGISTER_FN_NAME_(line) spdk_bdev_module_register_ ## line
 
-#endif /* SPDK_INTERNAL_BDEV_H */
+#endif /* SPDK_BDEV_MODULE_H */
diff --git a/include/spdk/bit_array.h b/include/spdk/bit_array.h
index b73919b91..fb28a0f93 100644
--- a/include/spdk/bit_array.h
+++ b/include/spdk/bit_array.h
@@ -155,6 +155,24 @@ uint32_t spdk_bit_array_find_first_set(const struct spdk_bit_array *ba, uint32_t
  */
 uint32_t spdk_bit_array_find_first_clear(const struct spdk_bit_array *ba, uint32_t start_bit_index);
 
+/**
+ * Count the number of set bits in the array.
+ *
+ * \param ba The bit array to search.
+ *
+ * \return the number of bits set in the array.
+ */
+uint32_t spdk_bit_array_count_set(const struct spdk_bit_array *ba);
+
+/**
+ * Count the number of cleared bits in the array.
+ *
+ * \param ba The bit array to search.
+ *
+ * \return the number of bits cleared in the array.
+ */
+uint32_t spdk_bit_array_count_clear(const struct spdk_bit_array *ba);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/blob.h b/include/spdk/blob.h
index bc5757b7d..4c97c2b61 100644
--- a/include/spdk/blob.h
+++ b/include/spdk/blob.h
@@ -75,17 +75,57 @@ struct spdk_io_channel;
 struct spdk_blob;
 struct spdk_xattr_names;
 
+/**
+ * Blobstore operation completion callback.
+ *
+ * \param cb_arg Callback argument.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_bs_op_complete)(void *cb_arg, int bserrno);
+
+/**
+ * Blobstore operation completion callback with handle.
+ *
+ * \param cb_arg Callback argument.
+ * \param bs Handle to a blobstore.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_bs_op_with_handle_complete)(void *cb_arg, struct spdk_blob_store *bs,
 		int bserrno);
+
+/**
+ * Blob operation completion callback.
+ *
+ * \param cb_arg Callback argument.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_blob_op_complete)(void *cb_arg, int bserrno);
+
+/**
+ * Blob operation completion callback with blob ID.
+ *
+ * \param cb_arg Callback argument.
+ * \param blobid Blob ID.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_blob_op_with_id_complete)(void *cb_arg, spdk_blob_id blobid, int bserrno);
-typedef void (*spdk_blob_op_with_handle_complete)(void *cb_arg, struct spdk_blob *blb, int bserrno);
 
+/**
+ * Blob operation completion callback with handle.
+ *
+ * \param cb_arg Callback argument.
+ * \param bs Handle to a blob.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
+typedef void (*spdk_blob_op_with_handle_complete)(void *cb_arg, struct spdk_blob *blb, int bserrno);
 
-/* Calls to function pointers of this type must obey all of the normal
-   rules for channels. The channel passed to this completion must match
-   the channel the operation was initiated on. */
+/**
+ * Blobstore device completion callback.
+ *
+ * \param channel I/O channel the operation was initiated on.
+ * \param cb_arg Callback argument.
+ * \param bserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_bs_dev_cpl)(struct spdk_io_channel *channel,
 				void *cb_arg, int bserrno);
 
@@ -198,6 +238,20 @@ void spdk_bs_load(struct spdk_bs_dev *dev, struct spdk_bs_opts *opts,
 void spdk_bs_init(struct spdk_bs_dev *dev, struct spdk_bs_opts *opts,
 		  spdk_bs_op_with_handle_complete cb_fn, void *cb_arg);
 
+typedef void (*spdk_bs_dump_print_xattr)(FILE *fp, const char *bstype, const char *name,
+		const void *value, size_t value_length);
+
+/**
+ * Dump a blobstore's metadata to a given FILE in human-readable format.
+ *
+ * \param dev Blobstore block device.
+ * \param fp FILE pointer to dump the metadata contents.
+ * \param print_xattr_fn Callback function to interpret external xattrs.
+ * \param cb_fn Called when the dump is complete.
+ * \param cb_arg Argument passed to function cb_fn.
+ */
+void spdk_bs_dump(struct spdk_bs_dev *dev, FILE *fp, spdk_bs_dump_print_xattr print_xattr_fn,
+		  spdk_bs_op_complete cb_fn, void *cb_arg);
 /**
  * Destroy the blobstore.
  *
@@ -467,6 +521,39 @@ bool spdk_blob_is_thin_provisioned(struct spdk_blob *blob);
 void spdk_bs_delete_blob(struct spdk_blob_store *bs, spdk_blob_id blobid,
 			 spdk_blob_op_complete cb_fn, void *cb_arg);
 
+/**
+ * Allocate all clusters in this blob. Data for allocated clusters is copied
+ * from backing blob(s) if they exist.
+ *
+ * This call removes all dependencies on any backing blobs.
+ *
+ * \param bs blobstore.
+ * \param channel IO channel used to inflate blob.
+ * \param blobid The id of the blob to inflate.
+ * \param cb_fn Called when the operation is complete.
+ * \param cb_arg Argument passed to function cb_fn.
+ */
+void spdk_bs_inflate_blob(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+			  spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg);
+
+/**
+ * Remove dependency on parent blob.
+ *
+ * This call allocates and copies data for any clusters that are allocated in
+ * the parent blob, and decouples parent updating dependencies of blob to
+ * its ancestor.
+ *
+ * If blob have no parent -EINVAL error is reported.
+ *
+ * \param bs blobstore.
+ * \param channel IO channel used to inflate blob.
+ * \param blobid The id of the blob.
+ * \param cb_fn Called when the operation is complete.
+ * \param cb_arg Argument passed to function cb_fn.
+ */
+void spdk_bs_blob_decouple_parent(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+				  spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg);
+
 /**
  * Open a blob from the given blobstore.
  *
@@ -481,6 +568,7 @@ void spdk_bs_open_blob(struct spdk_blob_store *bs, spdk_blob_id blobid,
 /**
  * Resize a blob to 'sz' clusters. These changes are not persisted to disk until
  * spdk_bs_md_sync_blob() is called.
+ * If called before previous resize finish, it will fail with errno -EBUSY
  *
  * \param blob Blob to resize.
  * \param sz The new number of clusters.
@@ -627,29 +715,6 @@ void spdk_blob_io_unmap(struct spdk_blob *blob, struct spdk_io_channel *channel,
 void spdk_blob_io_write_zeroes(struct spdk_blob *blob, struct spdk_io_channel *channel,
 			       uint64_t offset, uint64_t length, spdk_blob_op_complete cb_fn, void *cb_arg);
 
-/*
- * The following spdk_bs_io prefixed functions are deprecated in favor of their corresponding spdk_blob_io
- * function above.
- */
-void spdk_bs_io_write_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   void *payload, uint64_t offset, uint64_t length,
-			   spdk_blob_op_complete cb_fn, void *cb_arg) __attribute__((deprecated));
-void spdk_bs_io_read_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			  void *payload, uint64_t offset, uint64_t length,
-			  spdk_blob_op_complete cb_fn, void *cb_arg) __attribute__((deprecated));
-void spdk_bs_io_writev_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			    struct iovec *iov, int iovcnt, uint64_t offset, uint64_t length,
-			    spdk_blob_op_complete cb_fn, void *cb_arg) __attribute__((deprecated));
-void spdk_bs_io_readv_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   struct iovec *iov, int iovcnt, uint64_t offset, uint64_t length,
-			   spdk_blob_op_complete cb_fn, void *cb_arg) __attribute__((deprecated));
-void spdk_bs_io_unmap_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   uint64_t offset, uint64_t length,
-			   spdk_blob_op_complete cb_fn, void *cb_arg)  __attribute__((deprecated));
-void spdk_bs_io_write_zeroes_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-				  uint64_t offset, uint64_t length,
-				  spdk_blob_op_complete cb_fn, void *cb_arg)  __attribute__((deprecated));
-
 /**
  * Get the first blob of the blobstore. The obtained blob will be passed to
  * the callback function.
diff --git a/include/spdk/blobfs.h b/include/spdk/blobfs.h
index 16bec8489..d3aba0c8e 100644
--- a/include/spdk/blobfs.h
+++ b/include/spdk/blobfs.h
@@ -62,16 +62,60 @@ struct spdk_file_stat {
 	uint64_t	size;
 };
 
+/**
+ * Filesystem operation completion callback with handle.
+ *
+ * \param ctx Context for the operation.
+ * \param fs Handle to a blobfs.
+ * \param fserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_fs_op_with_handle_complete)(void *ctx, struct spdk_filesystem *fs,
 		int fserrno);
+
+/**
+ * File operation completion callback with handle.
+ *
+ * \param ctx Context for the operation.
+ * \param f Handle to a file.
+ * \param fserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_file_op_with_handle_complete)(void *ctx, struct spdk_file *f, int fserrno);
 typedef spdk_bs_op_complete spdk_fs_op_complete;
 
+/**
+ * File operation completion callback.
+ *
+ * \param ctx Context for the operation.
+ * \param fserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_file_op_complete)(void *ctx, int fserrno);
+
+/**
+ * File stat operation completion callback.
+ *
+ * \param ctx Context for the operation.
+ * \param stat Handle to the stat about the file.
+ * \param fserrno 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_file_stat_op_complete)(void *ctx, struct spdk_file_stat *stat, int fserrno);
 
-typedef void (*fs_request_fn)(void *);
-typedef void (*fs_send_request_fn)(fs_request_fn, void *);
+/**
+ * Function for a request of file system.
+ *
+ * \param arg Argument to the request function.
+ */
+typedef void (*fs_request_fn)(void *arg);
+
+/**
+ * Function for sending request.
+ *
+ * This function will be invoked any time when the filesystem wants to pass a
+ * message to the main dispatch thread.
+ *
+ * \param fs_request_fn A pointer to the request function.
+ * \param arg Argument to the request function.
+ */
+typedef void (*fs_send_request_fn)(fs_request_fn, void *arg);
 
 /**
  * Initialize a spdk_blobfs_opts structure to the default option values.
diff --git a/include/spdk/copy_engine.h b/include/spdk/copy_engine.h
index 9f9ba346e..06dc15604 100644
--- a/include/spdk/copy_engine.h
+++ b/include/spdk/copy_engine.h
@@ -44,7 +44,19 @@
 extern "C" {
 #endif
 
+/**
+ * Copy operation callback.
+ *
+ * \param ref 'copy_req' passed to the corresponding spdk_copy_submit() call.
+ * \param status 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_copy_completion_cb)(void *ref, int status);
+
+/**
+ * Copy engine finish callback.
+ *
+ * \param cb_arg Callback argument.
+ */
 typedef void (*spdk_copy_fini_cb)(void *cb_arg);
 
 struct spdk_io_channel;
diff --git a/include/spdk/cpuset.h b/include/spdk/cpuset.h
index 75bd5755d..d59305714 100644
--- a/include/spdk/cpuset.h
+++ b/include/spdk/cpuset.h
@@ -138,7 +138,7 @@ uint32_t spdk_cpuset_count(const struct spdk_cpuset *set);
 /**
  * Convert a CPU set to hex string.
  *
- * \param CPU set.
+ * \param set CPU set.
  *
  * \return a pointer to hexadecimal representation of CPU set. Buffer to store a
  * string is dynamically allocated internally and freed with CPU set object.
diff --git a/include/spdk/env.h b/include/spdk/env.h
index bf6ba459c..43c01980e 100644
--- a/include/spdk/env.h
+++ b/include/spdk/env.h
@@ -58,6 +58,14 @@ extern "C" {
  */
 #define SPDK_MALLOC_SHARE  0x02
 
+#define SPDK_MAX_MEMZONE_NAME_LEN 32
+#define SPDK_MAX_MEMPOOL_NAME_LEN 29
+
+/**
+ * Memzone flags
+ */
+#define SPDK_MEMZONE_NO_IOVA_CONTIG 0x00100000 /**< no iova contiguity */
+
 struct spdk_pci_device;
 
 /**
@@ -72,6 +80,10 @@ struct spdk_env_opts {
 	int			mem_size;
 	bool			no_pci;
 	bool			hugepage_single_segments;
+	bool			unlink_hugepage;
+	size_t			num_pci_addr;
+	struct spdk_pci_addr	*pci_blacklist;
+	struct spdk_pci_addr	*pci_whitelist;
 
 	/** Opaque context for use of the env implementation. */
 	void			*env_context;
@@ -91,6 +103,7 @@ struct spdk_env_opts {
  * \param socket_id Socket ID to allocate memory on, or SPDK_ENV_SOCKET_ID_ANY
  * for any socket.
  * \param flags Combination of SPDK_MALLOC flags (\ref SPDK_MALLOC_DMA, \ref SPDK_MALLOC_SHARE).
+ * At least one flag must be specified.
  *
  * \return a pointer to the allocated memory buffer.
  */
@@ -246,6 +259,22 @@ void spdk_dma_free(void *buf);
  */
 void *spdk_memzone_reserve(const char *name, size_t len, int socket_id, unsigned flags);
 
+/**
+ * Reserve a named, process shared memory zone with the given size, socket_id,
+ * flags and alignment.
+ *
+ * \param name Name to set for this memory zone.
+ * \param len Length in bytes.
+ * \param socket_id Socket ID to allocate memory on, or SPDK_ENV_SOCKET_ID_ANY
+ * for any socket.
+ * \param flags Flags to set for this memory zone.
+ * \param align Alignment for resulting memzone. Must be a power of 2.
+ *
+ * \return a pointer to the allocated memory address on success, or NULL on failure.
+ */
+void *spdk_memzone_reserve_aligned(const char *name, size_t len, int socket_id,
+				   unsigned flags, unsigned align);
+
 /**
  * Lookup the memory zone identified by the given name.
  *
@@ -366,7 +395,7 @@ void spdk_mempool_put(struct spdk_mempool *mp, void *ele);
  * \param ele_arr Array of the elements to put.
  * \param count Count of elements to put.
  */
-void spdk_mempool_put_bulk(struct spdk_mempool *mp, void *const *ele_arr, size_t count);
+void spdk_mempool_put_bulk(struct spdk_mempool *mp, void **ele_arr, size_t count);
 
 /**
  * Get the number of entries in the memory pool.
@@ -597,17 +626,6 @@ int spdk_pci_ioat_enumerate(spdk_pci_enum_cb enum_cb, void *enum_ctx);
  */
 int spdk_pci_virtio_enumerate(spdk_pci_enum_cb enum_cb, void *enum_ctx);
 
-/**
- * Get PCI device from the given address.
- *
- * \param pci_addr A pointer to the PCI address struct.
- *
- * \return a pointer to the PCI device or NULL if no devide is found at the given
- * address.
- */
-struct spdk_pci_device *spdk_pci_get_device(struct spdk_pci_addr *pci_addr)
-__attribute__((deprecated));
-
 /**
  * Get a mapping of the virtual address to the BAR of the PCI device.
  *
@@ -1014,10 +1032,12 @@ int spdk_mem_map_clear_translation(struct spdk_mem_map *map, uint64_t vaddr, uin
  *
  * \param map Memory map.
  * \param vaddr Virtual address.
+ * \param size Size of memory region.
  *
- * \return the translation of 2MB hugepage mapping.
+ * \return the translation of vaddr stored in the map, or default_translation
+ * as specified in spdk_mem_map_alloc() if vaddr is not present in the map.
  */
-uint64_t spdk_mem_map_translate(const struct spdk_mem_map *map, uint64_t vaddr);
+uint64_t spdk_mem_map_translate(const struct spdk_mem_map *map, uint64_t vaddr, uint64_t size);
 
 /**
  * Register the specified memory region for address translation.
@@ -1038,7 +1058,7 @@ int spdk_mem_register(void *vaddr, size_t len);
  * are completed or cancelled before calling this function.
  *
  * \param vaddr Virtual address to unregister.
- * \param leng Length in bytes of the vaddr.
+ * \param len Length in bytes of the vaddr.
  *
  * \return 0 on success, negative errno on failure.
  */
diff --git a/include/spdk/event.h b/include/spdk/event.h
index fdcf86edb..08ccf07a1 100644
--- a/include/spdk/event.h
+++ b/include/spdk/event.h
@@ -51,6 +51,12 @@
 extern "C" {
 #endif
 
+/**
+ * Event handler function.
+ *
+ * \param arg1 Argument 1.
+ * \param arg2 Argument 2.
+ */
 typedef void (*spdk_event_fn)(void *arg1, void *arg2);
 
 /**
@@ -63,8 +69,17 @@ struct spdk_event;
  */
 struct spdk_poller;
 
+/**
+ * Callback function for customized shutdown handling of application.
+ */
 typedef void (*spdk_app_shutdown_cb)(void);
-typedef void (*spdk_sighandler_t)(int);
+
+/**
+ * Signal handler fucntion.
+ *
+ * \param signal Signal number.
+ */
+typedef void (*spdk_sighandler_t)(int signal);
 
 #define SPDK_DEFAULT_RPC_ADDR "/var/tmp/spdk.sock"
 
@@ -89,7 +104,11 @@ struct spdk_app_opts {
 	int			mem_size;
 	bool			no_pci;
 	bool			hugepage_single_segments;
+	bool			unlink_hugepage;
 	enum spdk_log_level	print_level;
+	size_t			num_pci_addr;
+	struct spdk_pci_addr	*pci_blacklist;
+	struct spdk_pci_addr	*pci_whitelist;
 
 	/* The maximum latency allowed when passing an event
 	 * from one core to another. A value of 0
@@ -97,6 +116,17 @@ struct spdk_app_opts {
 	 * specified in microseconds.
 	 */
 	uint64_t		max_delay_us;
+
+	/* Wait for the associated RPC before initializing subsystems
+	 * when this flag is enabled.
+	 */
+	bool			delay_subsystem_init;
+};
+
+struct spdk_reactor_tsc_stats {
+	uint64_t busy_tsc;
+	uint64_t idle_tsc;
+	uint64_t unknown_tsc;
 };
 
 /**
@@ -186,7 +216,7 @@ int spdk_app_parse_core_mask(const char *mask, struct spdk_cpuset *cpumask);
  */
 struct spdk_cpuset *spdk_app_get_core_mask(void);
 
-#define SPDK_APP_GETOPT_STRING "c:de:ghi:m:n:p:qr:s:t:u"
+#define SPDK_APP_GETOPT_STRING "c:de:ghi:m:n:p:qr:s:uwB:L:RW:"
 
 enum spdk_app_parse_args_rvals {
 	SPDK_APP_PARSE_ARGS_HELP = 0,
@@ -213,6 +243,13 @@ spdk_app_parse_args_rvals_t spdk_app_parse_args(int argc, char **argv,
 		struct spdk_app_opts *opts, const char *getopt_str,
 		void (*parse)(int ch, char *arg), void (*usage)(void));
 
+/**
+ * Print usage strings for common SPDK command line options.
+ *
+ * May only be called after spdk_app_parse_args().
+ */
+void spdk_app_usage(void);
+
 /**
  * Allocate an event to be passed to spdk_event_call().
  *
@@ -247,6 +284,15 @@ void spdk_reactor_enable_context_switch_monitor(bool enabled);
  */
 bool spdk_reactor_context_switch_monitor_enabled(void);
 
+/**
+ * Get tsc stats from a given reactor
+ * Copy cumulative reactor tsc values to user's tsc_stats structure.
+ *
+ * \param tsc_stats User's tsc_stats structure.
+ * \param core_id Get tsc data on this Reactor core id.
+ */
+int spdk_reactor_get_tsc_stats(struct spdk_reactor_tsc_stats *tsc_stats, uint32_t core_id);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/io_channel.h b/include/spdk/io_channel.h
index 7dc6be88c..71ddb90a4 100644
--- a/include/spdk/io_channel.h
+++ b/include/spdk/io_channel.h
@@ -38,312 +38,11 @@
 #ifndef SPDK_IO_CHANNEL_H_
 #define SPDK_IO_CHANNEL_H_
 
-#include "spdk/stdinc.h"
-
-#include "spdk/queue.h"
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-struct spdk_thread;
-struct spdk_io_channel_iter;
-struct spdk_poller;
-
-typedef void (*spdk_thread_fn)(void *ctx);
-typedef void (*spdk_thread_pass_msg)(spdk_thread_fn fn, void *ctx,
-				     void *thread_ctx);
-
-/**
- * Callback function for a poller.
- *
- * \param ctx Context passed as arg to spdk_poller_register()
- * \return 0 to indicate that polling took place but no events were found;
- *         positive to indicate that polling took place and some events were processed;
- *         negative if the poller does not provide spin-wait information.
- */
-typedef int (*spdk_poller_fn)(void *ctx);
-typedef struct spdk_poller *(*spdk_start_poller)(void *thread_ctx,
-		spdk_poller_fn fn,
-		void *arg,
-		uint64_t period_microseconds);
-typedef void (*spdk_stop_poller)(struct spdk_poller *poller, void *thread_ctx);
-
-typedef int (*spdk_io_channel_create_cb)(void *io_device, void *ctx_buf);
-typedef void (*spdk_io_channel_destroy_cb)(void *io_device, void *ctx_buf);
-
-typedef void (*spdk_io_device_unregister_cb)(void *io_device);
-
-typedef void (*spdk_channel_msg)(struct spdk_io_channel_iter *i);
-typedef void (*spdk_channel_for_each_cpl)(struct spdk_io_channel_iter *i, int status);
-
-/**
- * \brief Represents a per-thread channel for accessing an I/O device.
- *
- * An I/O device may be a physical entity (i.e. NVMe controller) or a software
- *  entity (i.e. a blobstore).
- *
- * This structure is not part of the API - all accesses should be done through
- *  spdk_io_channel function calls.
- */
-struct spdk_io_channel {
-	struct spdk_thread		*thread;
-	struct io_device		*dev;
-	uint32_t			ref;
-	TAILQ_ENTRY(spdk_io_channel)	tailq;
-	spdk_io_channel_destroy_cb	destroy_cb;
-
-	/*
-	 * Modules will allocate extra memory off the end of this structure
-	 *  to store references to hardware-specific references (i.e. NVMe queue
-	 *  pairs, or references to child device spdk_io_channels (i.e.
-	 *  virtual bdevs).
-	 */
-};
-
-/**
- * Initializes the calling thread for I/O channel allocation.
- *
- * \param msg_fn A function that may be called from any thread and is passed a function
- * pointer (spdk_thread_fn) that must be called on the same thread that spdk_allocate_thread
- * was called from.
- * \param start_poller_fn Function to be called to start a poller for the thread.
- * \param stop_poller_fn Function to be called to stop a poller for the thread.
- * \param thread_ctx Context that will be passed to fn, start_poller_fn and spdk_stop_poller.
- * \param name Human-readable name for the thread; can be retrieved with spdk_thread_get_name().
- * The string is copied, so the pointed-to data only needs to be valid during the
- * spdk_allocate_thread() call. May be NULL to specify no name.
- *
- * \return a pointer to the allocated thread on success or NULL on failure..
- */
-struct spdk_thread *spdk_allocate_thread(spdk_thread_pass_msg msg_fn,
-		spdk_start_poller start_poller_fn,
-		spdk_stop_poller stop_poller_fn,
-		void *thread_ctx,
-		const char *name);
-
-/**
- * Release any resources related to the calling thread for I/O channel allocation.
- *
- * All I/O channel references related to the calling thread must be released using
- * spdk_put_io_channel() prior to calling this function.
- */
-void spdk_free_thread(void);
-
-/**
- * Get a handle to the current thread.
- *
- * This handle may be passed to other threads and used as the target of
- * spdk_thread_send_msg().
- *
- * \sa spdk_io_channel_get_thread()
- *
- * \return a pointer to the current thread on success or NULL on failure.
- */
-struct spdk_thread *spdk_get_thread(void);
-
-/**
- * Get a thread's name.
- *
- * \param thread Thread to query.
- *
- * \return the name of the thread.
- */
-const char *spdk_thread_get_name(const struct spdk_thread *thread);
-
-/**
- * Send a message to the given thread.
- *
- * The message may be sent asynchronously - i.e. spdk_thread_send_msg may return
- * prior to `fn` being called.
- *
- * \param thread The target thread.
- * \param fn This function will be called on the given thread.
- * \param ctx This context will be passed to fn when called.
- */
-void spdk_thread_send_msg(const struct spdk_thread *thread, spdk_thread_fn fn, void *ctx);
-
-/**
- * Send a message to each thread, serially.
- *
- * The message is sent asynchronously - i.e. spdk_for_each_thread will return
- * prior to `fn` being called on each thread.
- *
- * \param fn This is the function that will be called on each thread.
- * \param ctx This context will be passed to fn when called.
- * \param cpl This will be called on the originating thread after `fn` has been
- * called on each thread.
- */
-void spdk_for_each_thread(spdk_thread_fn fn, void *ctx, spdk_thread_fn cpl);
-
-/**
- * Register a poller on the current thread.
- *
- * The poller can be unregistered by calling spdk_poller_unregister().
- *
- * \param fn This function will be called every `period_microseconds`.
- * \param arg Argument passed to fn.
- * \param period_microseconds How often to call `fn`. If 0, call `fn` as often
- *  as possible.
- *
- * \return a pointer to the poller registered on the current thread on success
- * or NULL on failure.
- */
-struct spdk_poller *spdk_poller_register(spdk_poller_fn fn,
-		void *arg,
-		uint64_t period_microseconds);
-
-/**
- * Unregister a poller on the current thread.
- *
- * \param ppoller The poller to unregister.
- */
-void spdk_poller_unregister(struct spdk_poller **ppoller);
-
-/**
- * Register the opaque io_device context as an I/O device.
- *
- * After an I/O device is registered, it can return I/O channels using the
- * spdk_get_io_channel() function.
- *
- * \param io_device The pointer to io_device context.
- * \param create_cb Callback function invoked to allocate any resources required
- * for a new I/O channel.
- * \param destroy_cb Callback function invoked to release the resources for an
- * I/O channel.
- * \param ctx_size The size of the context buffer allocated to store references
- * to allocated I/O channel resources.
- */
-void spdk_io_device_register(void *io_device, spdk_io_channel_create_cb create_cb,
-			     spdk_io_channel_destroy_cb destroy_cb, uint32_t ctx_size);
-
-/**
- * Unregister the opaque io_device context as an I/O device.
- *
- * The actual unregistration might be deferred until all active I/O channels are
- * destroyed.
- *
- * \param io_device The pointer to io_device context.
- * \param unregister_cb An optional callback function invoked to release any
- * references to this I/O device.
- */
-void spdk_io_device_unregister(void *io_device, spdk_io_device_unregister_cb unregister_cb);
-
-/**
- * Get an I/O channel for the specified io_device to be used by the calling thread.
- *
- * The io_device context pointer specified must have previously been registered
- * using spdk_io_device_register(). If an existing I/O channel does not exist
- * yet for the given io_device on the calling thread, it will allocate an I/O
- * channel and invoke the create_cb function pointer specified in spdk_io_device_register().
- * If an I/O channel already exists for the given io_device on the calling thread,
- * its reference is returned rather than creating a new I/O channel.
- *
- * \param io_device The pointer to io_device context.
- *
- * \return a pointer to the I/O channel for this device on success or NULL on failure.
- */
-struct spdk_io_channel *spdk_get_io_channel(void *io_device);
-
-/**
- * Release a reference to an I/O channel. This happens asynchronously.
- *
- * Actual release will happen on the same thread that called spdk_get_io_channel()
- * for the specified I/O channel. If this releases the last reference to the
- * I/O channel, The destroy_cb function specified in spdk_io_device_register()
- * will be invoked to release any associated resources.
- *
- * \param ch I/O channel to release a reference.
- */
-void spdk_put_io_channel(struct spdk_io_channel *ch);
-
-/**
- * Get the context buffer associated with an I/O channel.
- *
- * \param ch I/O channel.
- *
- * \return a pointer to the context buffer.
- */
-static inline void *
-spdk_io_channel_get_ctx(struct spdk_io_channel *ch)
-{
-	return (uint8_t *)ch + sizeof(*ch);
-}
-
-/**
- * Get I/O channel from the context buffer. This is the inverse of
- * spdk_io_channel_get_ctx().
- *
- * \param ctx The pointer to the context buffer.
- *
- * \return a pointer to the I/O channel associated with the context buffer.
- */
-struct spdk_io_channel *spdk_io_channel_from_ctx(void *ctx);
-
-/**
- * Get the thread associated with an I/O channel.
- *
- * \param ch I/O channel.
- *
- * \return a pointer to the thread associated with the I/O channel
- */
-struct spdk_thread *spdk_io_channel_get_thread(struct spdk_io_channel *ch);
-
-/**
- * Call 'fn' on each channel associated with io_device.
- *
- * This happens asynchronously, so fn may be called after spdk_for_each_channel
- * returns. 'fn' will be called for each channel serially, such that two calls
- * to 'fn' will not overlap in time. After 'fn' has been called, call
- * spdk_for_each_channel_continue() to continue iterating.
- *
- * \param io_device 'fn' will be called on each channel associated with this io_device.
- * \param fn Called on the appropriate thread for each channel associated with io_device.
- * \param ctx Context buffer registered to spdk_io_channel_iter that can be obatined
- * form the function spdk_io_channel_iter_get_ctx().
- * \param cpl Called on the thread that spdk_for_each_channel was initially called
- * from when 'fn' has been called on each channel.
- */
-void spdk_for_each_channel(void *io_device, spdk_channel_msg fn, void *ctx,
-			   spdk_channel_for_each_cpl cpl);
-
-/**
- * Get io_device from the I/O channel iterator.
- *
- * \param i I/O channel iterator.
- *
- * \return a pointer to the io_device.
- */
-void *spdk_io_channel_iter_get_io_device(struct spdk_io_channel_iter *i);
-
-/**
- * Get I/O channel from the I/O channel iterator.
- *
- * \param i I/O channel iterator.
- *
- * \return a pointer to the I/O channel.
- */
-struct spdk_io_channel *spdk_io_channel_iter_get_channel(struct spdk_io_channel_iter *i);
-
-/**
- * Get context buffer from the I/O channel iterator.
- *
- * \param i I/O channel iterator.
- *
- * \return a pointer to the context buffer.
- */
-void *spdk_io_channel_iter_get_ctx(struct spdk_io_channel_iter *i);
-
-/**
- * Helper function to iterate all channels for spdk_for_each_channel().
- *
- * \param i I/O channel iterator.
- * \param status Status for the I/O channel iterator.
+/*
+ * This file has been renamed to thread.h. Please update
+ * include paths.
  */
-void spdk_for_each_channel_continue(struct spdk_io_channel_iter *i, int status);
 
-#ifdef __cplusplus
-}
-#endif
+#include "spdk/thread.h"
 
 #endif /* SPDK_IO_CHANNEL_H_ */
diff --git a/include/spdk/json.h b/include/spdk/json.h
index cd76c5e90..62db4439c 100644
--- a/include/spdk/json.h
+++ b/include/spdk/json.h
@@ -147,6 +147,7 @@ int spdk_json_decode_array(const struct spdk_json_val *values, spdk_json_decode_
 			   void *out, size_t max_size, size_t *out_size, size_t stride);
 
 int spdk_json_decode_bool(const struct spdk_json_val *val, void *out);
+int spdk_json_decode_uint16(const struct spdk_json_val *val, void *out);
 int spdk_json_decode_int32(const struct spdk_json_val *val, void *out);
 int spdk_json_decode_uint32(const struct spdk_json_val *val, void *out);
 int spdk_json_decode_uint64(const struct spdk_json_val *val, void *out);
@@ -181,6 +182,7 @@ bool spdk_json_strequal(const struct spdk_json_val *val, const char *str);
  */
 char *spdk_json_strdup(const struct spdk_json_val *val);
 
+int spdk_json_number_to_uint16(const struct spdk_json_val *val, uint16_t *num);
 int spdk_json_number_to_int32(const struct spdk_json_val *val, int32_t *num);
 int spdk_json_number_to_uint32(const struct spdk_json_val *val, uint32_t *num);
 int spdk_json_number_to_uint64(const struct spdk_json_val *val, uint64_t *num);
diff --git a/include/spdk/jsonrpc.h b/include/spdk/jsonrpc.h
index fa62341ac..282497316 100644
--- a/include/spdk/jsonrpc.h
+++ b/include/spdk/jsonrpc.h
@@ -47,12 +47,20 @@
 extern "C" {
 #endif
 
+/* Defined error codes in JSON-RPC specification 2.0 */
 #define SPDK_JSONRPC_ERROR_PARSE_ERROR		-32700
 #define SPDK_JSONRPC_ERROR_INVALID_REQUEST	-32600
 #define SPDK_JSONRPC_ERROR_METHOD_NOT_FOUND	-32601
 #define SPDK_JSONRPC_ERROR_INVALID_PARAMS	-32602
 #define SPDK_JSONRPC_ERROR_INTERNAL_ERROR	-32603
 
+/* Custom error codes in SPDK
+
+ * Error codes from and including -32768 to -32000 are reserved for
+ * predefined errors, hence custom error codes must be outside of the range.
+ */
+#define SPDK_JSONRPC_ERROR_INVALID_STATE	-1
+
 struct spdk_jsonrpc_server;
 struct spdk_jsonrpc_request;
 
diff --git a/include/spdk/log.h b/include/spdk/log.h
index 59eaa70a1..e098dfd18 100644
--- a/include/spdk/log.h
+++ b/include/spdk/log.h
@@ -144,7 +144,7 @@ int spdk_log_set_trace_flag(const char *flag);
 /**
  * Clear a trace flag.
  *
- * \flag Trace flag to clear.
+ * \param flag Trace flag to clear.
  *
  * \return 0 on success, -1 on failure.
  */
diff --git a/include/spdk/lvol.h b/include/spdk/lvol.h
index 224a2c63a..d14a38496 100644
--- a/include/spdk/lvol.h
+++ b/include/spdk/lvol.h
@@ -61,13 +61,15 @@ struct spdk_lvs_opts {
 };
 
 /**
- * \brief Initialize an spdk_lvs_opts structure to the defaults.
- * \param opts
+ * Initialize an spdk_lvs_opts structure to the defaults.
+ *
+ * \param opts Pointer to the spdk_lvs_opts structure to initialize.
  */
 void spdk_lvs_opts_init(struct spdk_lvs_opts *opts);
 
 /**
- * \brief Callback definition for lvolstore operations, including handle to lvs
+ * Callback definition for lvolstore operations, including handle to lvs.
+ *
  * \param cb_arg Custom arguments
  * \param lvol_store Handle to lvol_store or NULL when lvserrno is set
  * \param lvserrno Error
@@ -76,7 +78,8 @@ typedef void (*spdk_lvs_op_with_handle_complete)(void *cb_arg, struct spdk_lvol_
 		int lvserrno);
 
 /**
- * \brief Callback definition for lvolstore operations without handle
+ * Callback definition for lvolstore operations without handle.
+ *
  * \param cb_arg Custom arguments
  * \param lvserrno Error
  */
@@ -84,7 +87,8 @@ typedef void (*spdk_lvs_op_complete)(void *cb_arg, int lvserrno);
 
 
 /**
- * \brief Callback definition for lvol operations with handle to lvol
+ * Callback definition for lvol operations with handle to lvol.
+ *
  * \param cb_arg Custom arguments
  * \param lvol Handle to lvol or NULL when lvserrno is set
  * \param lvolerrno Error
@@ -93,133 +97,178 @@ typedef void (*spdk_lvol_op_with_handle_complete)(void *cb_arg, struct spdk_lvol
 		int lvolerrno);
 
 /**
- * \brief Callback definition for lvol operations without handle to lvol
+ * Callback definition for lvol operations without handle to lvol.
+ *
  * \param cb_arg Custom arguments
  * \param lvolerrno Error
  */
 typedef void (*spdk_lvol_op_complete)(void *cb_arg, int lvolerrno);
 
 /**
- * \brief Initialize lvolstore on given bs_bdev.
+ * Initialize lvolstore on given bs_bdev.
  *
- * bs_dev can be created on bdev by using spdk_bdev_create_bs_dev()
- * Refer to blobstore documention for more details.
+ * \param bs_dev This is created on the given bdev by using spdk_bdev_create_bs_dev()
+ * beforehand.
+ * \param o Options for lvolstore.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  *
- * \param o Options for lvolstore
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
- * \return error
+ * \return 0 on success, negative errno on failure.
  */
 int spdk_lvs_init(struct spdk_bs_dev *bs_dev, struct spdk_lvs_opts *o,
 		  spdk_lvs_op_with_handle_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Renames given lvolstore.
+ * Rename the given lvolstore.
  *
- * \param lvs Pointer to lvolstore
- * \param new_name New name of lvs
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * \param lvs Pointer to lvolstore.
+ * \param new_name New name of lvs.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void spdk_lvs_rename(struct spdk_lvol_store *lvs, const char *new_name,
 		     spdk_lvs_op_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Unloads lvolstore
+ * Unload lvolstore.
  *
  * All lvols have to be closed beforehand, when doing unload.
  *
- * \param lvol_store Handle to lvolstore
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
- * \return error
+ * \param lvol_store Handle to lvolstore.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
+ *
+ * \return 0 on success, negative errno on failure.
  */
 int spdk_lvs_unload(struct spdk_lvol_store *lvol_store,
 		    spdk_lvs_op_complete cb_fn, void *cb_arg);
+
 /**
- * \brief Destroy lvolstore
+ * Destroy lvolstore.
  *
  * All lvols have to be closed beforehand, when doing destroy.
  *
- * \param lvol_store Handle to lvolstore
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
- * \return error
+ * \param lvol_store Handle to lvolstore.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
+ *
+ * \return 0 on success, negative errno on failure.
  */
 int spdk_lvs_destroy(struct spdk_lvol_store *lvol_store,
 		     spdk_lvs_op_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Create lvol on given lvolstore with specified size
- * \param lvs Handle to lvolstore
- * \param name Name of lvol
- * \param sz size of lvol in bytes
- * \param thin_provisioned Enables thin provisioning
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
- * \return error
+ * Create lvol on given lvolstore with specified size.
+ *
+ * \param lvs Handle to lvolstore.
+ * \param name Name of lvol.
+ * \param sz size of lvol in bytes.
+ * \param thin_provisioned Enables thin provisioning.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
+ *
+ * \return 0 on success, negative errno on failure.
  */
 int spdk_lvol_create(struct spdk_lvol_store *lvs, const char *name, uint64_t sz,
 		     bool thin_provisioned, spdk_lvol_op_with_handle_complete cb_fn, void *cb_arg);
 /**
- * \brief Create snapshot of given lvol
- * \param lvol Handle to lvol
- * \param snapshot_name Name of created snapshot
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * Create snapshot of given lvol.
+ *
+ * \param lvol Handle to lvol.
+ * \param snapshot_name Name of created snapshot.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void spdk_lvol_create_snapshot(struct spdk_lvol *lvol, const char *snapshot_name,
 			       spdk_lvol_op_with_handle_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Create clone of given snapshot
- * \param lvol Handle to lvol snapshot
- * \param clone_name Name of created clone
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * Create clone of given snapshot.
+ *
+ * \param lvol Handle to lvol snapshot.
+ * \param clone_name Name of created clone.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void spdk_lvol_create_clone(struct spdk_lvol *lvol, const char *clone_name,
 			    spdk_lvol_op_with_handle_complete cb_fn, void *cb_arg);
 
-
 /**
- * \brief Renames lvol with new_name.
- * \param lvol Handle to lvol
- * \param new_name new name for lvol
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * Rename lvol with new_name.
+ *
+ * \param lvol Handle to lvol.
+ * \param new_name new name for lvol.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void
 spdk_lvol_rename(struct spdk_lvol *lvol, const char *new_name,
 		 spdk_lvol_op_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Closes lvol and removes information about lvol from its lvolstore.
- * \param lvol Handle to lvol
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * Close lvol and remove information about lvol from its lvolstore.
+ *
+ * \param lvol Handle to lvol.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void spdk_lvol_destroy(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Closes lvol, but information is kept on lvolstore.
- * \param lvol Handle to lvol
- * \param cb_fn Completion callback
- * \param cb_arg Completion callback custom arguments
+ * Close lvol, but information is kept on lvolstore.
+ *
+ * \param lvol Handle to lvol.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
  */
 void spdk_lvol_close(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg);
 
 /**
- * \brief Return IO channel of bdev associated with specified lvol.
- * \param lvol Handle to lvol
- * \return IO channel
+ * Get I/O channel of bdev associated with specified lvol.
+ *
+ * \param lvol Handle to lvol.
+ *
+ * \return a pointer to the I/O channel.
  */
 struct spdk_io_channel *spdk_lvol_get_io_channel(struct spdk_lvol *lvol);
 
+/**
+ * Load lvolstore from the given blobstore device.
+ *
+ * \param bs_dev Pointer to the blobstore device.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
+ */
 void spdk_lvs_load(struct spdk_bs_dev *bs_dev, spdk_lvs_op_with_handle_complete cb_fn,
 		   void *cb_arg);
+
+/**
+ * Open a lvol.
+ *
+ * \param lvol Handle to lvol.
+ * \param cb_fn Completion callback.
+ * \param cb_arg Completion callback custom arguments.
+ */
 void spdk_lvol_open(struct spdk_lvol *lvol, spdk_lvol_op_with_handle_complete cb_fn, void *cb_arg);
 
+/**
+ * Inflate lvol
+ *
+ * \param lvol Handle to lvol
+ * \param cb_fn Completion callback
+ * \param cb_arg Completion callback custom arguments
+ */
+void spdk_lvol_inflate(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg);
+
+/**
+ * Decouple parent of lvol
+ *
+ * \param lvol Handle to lvol
+ * \param cb_fn Completion callback
+ * \param cb_arg Completion callback custom arguments
+ */
+void spdk_lvol_decouple_parent(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/nvme.h b/include/spdk/nvme.h
index 500f96f8a..9f0f2fee0 100644
--- a/include/spdk/nvme.h
+++ b/include/spdk/nvme.h
@@ -53,11 +53,13 @@ extern int32_t		spdk_nvme_retry_count;
 
 
 
-/** \brief Opaque handle to a controller. Returned by \ref spdk_nvme_probe()'s attach_cb. */
+/**
+ * Opaque handle to a controller. Returned by spdk_nvme_probe()'s attach_cb.
+ */
 struct spdk_nvme_ctrlr;
 
 /**
- * \brief NVMe controller initialization options.
+ * NVMe controller initialization options.
  *
  * A pointer to this structure will be provided for each probe callback from spdk_nvme_probe() to
  * allow the user to request non-default options, and the actual options enabled on the controller
@@ -144,10 +146,19 @@ struct spdk_nvme_ctrlr_opts {
 	 * Set to all zeroes to specify that no host ID should be provided to the controller.
 	 */
 	uint8_t extended_host_id[16];
+
+	/**
+	 * The I/O command set to select.
+	 *
+	 * If the requested command set is not supported, the controller
+	 * initialization process will not proceed. By default, the NVM
+	 * command set is used.
+	 */
+	enum spdk_nvme_cc_css command_set;
 };
 
 /**
- * \brief Get the default options for the creation of a specific NVMe controller.
+ * Get the default options for the creation of a specific NVMe controller.
  *
  * \param[out] opts Will be filled with the default option.
  * \param opts_size Must be set to sizeof(struct spdk_nvme_ctrlr_opts).
@@ -174,6 +185,11 @@ enum spdk_nvme_transport_type {
 	 * RDMA Transport (RoCE, iWARP, etc.)
 	 */
 	SPDK_NVME_TRANSPORT_RDMA = SPDK_NVMF_TRTYPE_RDMA,
+
+	/**
+	 * Fibre Channel (FC) Transport
+	 */
+	SPDK_NVME_TRANSPORT_FC = SPDK_NVMF_TRTYPE_FC,
 };
 
 /**
@@ -201,14 +217,16 @@ struct spdk_nvme_transport_id {
 	 * Transport address of the NVMe-oF endpoint. For transports which use IP
 	 * addressing (e.g. RDMA), this should be an IP address. For PCIe, this
 	 * can either be a zero length string (the whole bus) or a PCI address
-	 * in the format DDDD:BB:DD.FF or DDDD.BB.DD.FF
+	 * in the format DDDD:BB:DD.FF or DDDD.BB.DD.FF. For FC the string is
+	 * formatted as: nn-0xWWNN:pn-0xWWPN” where a)WWN isthe Node_Name of the
+	 * target NVMe_Port and b)WWPN is the N_Port_Name of the target NVMe_Port.
 	 */
 	char traddr[SPDK_NVMF_TRADDR_MAX_LEN + 1];
 
 	/**
 	 * Transport service id of the NVMe-oF endpoint.  For transports which use
 	 * IP addressing (e.g. RDMA), this field shoud be the port number. For PCIe,
-	 * this is always a zero length string.
+	 * and FC this is always a zero length string.
 	 */
 	char trsvcid[SPDK_NVMF_TRSVCID_MAX_LEN + 1];
 
@@ -223,21 +241,23 @@ struct spdk_nvme_transport_id {
  *
  * \param trid Output transport ID structure (must be allocated and initialized by caller).
  * \param str Input string representation of a transport ID to parse.
- * \return 0 if parsing was successful and trid is filled out, or negated errno values on failure.
  *
- * str must be a zero-terminated C string containing one or more key:value pairs separated by
- * whitespace.
+ * str must be a zero-terminated C string containing one or more key:value pairs
+ * separated by whitespace.
  *
  * Key          | Value
  * ------------ | -----
  * trtype       | Transport type (e.g. PCIe, RDMA)
  * adrfam       | Address family (e.g. IPv4, IPv6)
- * traddr       | Transport address (e.g. 0000:04:00.0 for PCIe or 192.168.100.8 for RDMA)
+ * traddr       | Transport address (e.g. 0000:04:00.0 for PCIe, 192.168.100.8 for RDMA, or WWN for FC)
  * trsvcid      | Transport service identifier (e.g. 4420)
  * subnqn       | Subsystem NQN
  *
- * Unspecified fields of trid are left unmodified, so the caller must initialize trid (for example,
- * memset() to 0) before calling this function.
+ * Unspecified fields of trid are left unmodified, so the caller must initialize
+ * trid (for example, memset() to 0) before calling this function.
+ *
+ * \return 0 if parsing was successful and trid is filled out, or negated errno
+ * values on failure.
  */
 int spdk_nvme_transport_id_parse(struct spdk_nvme_transport_id *trid, const char *str);
 
@@ -245,8 +265,10 @@ int spdk_nvme_transport_id_parse(struct spdk_nvme_transport_id *trid, const char
  * Parse the string representation of a transport ID tranport type.
  *
  * \param trtype Output transport type (allocated by caller).
- * \param str Input string representation of transport type (e.g. "PCIe", "RDMA")
- * \return 0 if parsing was successful and trtype is filled out, or negated errno values on failure.
+ * \param str Input string representation of transport type (e.g. "PCIe", "RDMA").
+ *
+ * \return 0 if parsing was successful and trtype is filled out, or negated errno
+ * values on failure.
  */
 int spdk_nvme_transport_id_parse_trtype(enum spdk_nvme_transport_type *trtype, const char *str);
 
@@ -254,7 +276,8 @@ int spdk_nvme_transport_id_parse_trtype(enum spdk_nvme_transport_type *trtype, c
  * Look up the string representation of a transport ID transport type.
  *
  * \param trtype Transport type to convert.
- * \return Static string constant describing trtype, or NULL if trtype not found.
+ *
+ * \return static string constant describing trtype, or NULL if trtype not found.
  */
 const char *spdk_nvme_transport_id_trtype_str(enum spdk_nvme_transport_type trtype);
 
@@ -262,7 +285,8 @@ const char *spdk_nvme_transport_id_trtype_str(enum spdk_nvme_transport_type trty
  * Look up the string representation of a transport ID address family.
  *
  * \param adrfam Address family to convert.
- * \return Static string constant describing adrfam, or NULL if adrmfam not found.
+ *
+ * \return static string constant describing adrfam, or NULL if adrmfam not found.
  */
 const char *spdk_nvme_transport_id_adrfam_str(enum spdk_nvmf_adrfam adrfam);
 
@@ -270,31 +294,36 @@ const char *spdk_nvme_transport_id_adrfam_str(enum spdk_nvmf_adrfam adrfam);
  * Parse the string representation of a tranport ID address family.
  *
  * \param adrfam Output address family (allocated by caller).
- * \param str Input string representation of address family (e.g. "IPv4", "IPv6")
- * \return 0 if parsing was successful and adrfam is filled out, or negated errno values on failure.
+ * \param str Input string representation of address family (e.g. "IPv4", "IPv6").
+ *
+ * \return 0 if parsing was successful and adrfam is filled out, or negated errno
+ * values on failure.
  */
 int spdk_nvme_transport_id_parse_adrfam(enum spdk_nvmf_adrfam *adrfam, const char *str);
 
 /**
  * Compare two transport IDs.
  *
- * \param trid1 First transport ID to compare.
- * \param trid2 Second transport ID to compare.
+ * The result of this function may be used to sort transport IDs in a consistent
+ * order; however, the comparison result is not guaranteed to be consistent across
+ * library versions.
  *
- * \return 0 if trid1 == trid2, less than 0 if trid1 < trid2, greater than 0 if trid1 > trid2.
+ * This function uses a case-insensitive comparison for string fields, but it does
+ * not otherwise normalize the transport ID. It is the caller's responsibility to
+ * provide the transport IDs in a consistent format.
  *
- * The result of this function may be used to sort transport IDs in a consistent order; however,
- * the comparison result is not guaranteed to be consistent across library versions.
+ * \param trid1 First transport ID to compare.
+ * \param trid2 Second transport ID to compare.
  *
- * This function uses a case-insensitive comparison for string fields, but it does not otherwise
- * normalize the transport ID. It is the caller's responsibility to provide the transport IDs in
- * a consistent format.
+ * \return 0 if trid1 == trid2, less than 0 if trid1 < trid2, greater than 0 if
+ * trid1 > trid2.
  */
 int spdk_nvme_transport_id_compare(const struct spdk_nvme_transport_id *trid1,
 				   const struct spdk_nvme_transport_id *trid2);
 
 /**
- * Determine whether the NVMe library can handle a specific NVMe over Fabrics transport type.
+ * Determine whether the NVMe library can handle a specific NVMe over Fabrics
+ * transport type.
  *
  * \param trtype NVMe over Fabrics transport type to check.
  *
@@ -305,65 +334,80 @@ bool spdk_nvme_transport_available(enum spdk_nvme_transport_type trtype);
 /**
  * Callback for spdk_nvme_probe() enumeration.
  *
- * \param opts NVMe controller initialization options.  This structure will be populated with the
- * default values on entry, and the user callback may update any options to request a different
- * value.  The controller may not support all requested parameters, so the final values will be
- * provided during the attach callback.
+ * \param cb_ctx Opaque value passed to spdk_nvme_probe().
+ * \param trid NVMe transport identifier.
+ * \param opts NVMe controller initialization options. This structure will be
+ * populated with the default values on entry, and the user callback may update
+ * any options to request a different value. The controller may not support all
+ * requested parameters, so the final values will be provided during the attach
+ * callback.
+ *
  * \return true to attach to this device.
  */
 typedef bool (*spdk_nvme_probe_cb)(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 				   struct spdk_nvme_ctrlr_opts *opts);
 
 /**
- * Callback for spdk_nvme_probe() to report a device that has been attached to the userspace NVMe driver.
+ * Callback for spdk_nvme_attach() to report a device that has been attached to
+ * the userspace NVMe driver.
  *
- * \param opts NVMe controller initialization options that were actually used.  Options may differ
- * from the requested options from the probe call depending on what the controller supports.
+ * \param cb_ctx Opaque value passed to spdk_nvme_attach_cb().
+ * \param trid NVMe transport identifier.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param opts NVMe controller initialization options that were actually used.
+ * Options may differ from the requested options from the attach call depending
+ * on what the controller supports.
  */
 typedef void (*spdk_nvme_attach_cb)(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 				    struct spdk_nvme_ctrlr *ctrlr,
 				    const struct spdk_nvme_ctrlr_opts *opts);
 
 /**
- * Callback for spdk_nvme_probe() to report that a device attached to the userspace NVMe driver
- * has been removed from the system.
+ * Callback for spdk_nvme_remove() to report that a device attached to the userspace
+ * NVMe driver has been removed from the system.
  *
  * The controller will remain in a failed state (any new I/O submitted will fail).
  *
  * The controller must be detached from the userspace driver by calling spdk_nvme_detach()
- * once the controller is no longer in use.  It is up to the library user to ensure that
- * no other threads are using the controller before calling spdk_nvme_detach().
+ * once the controller is no longer in use. It is up to the library user to ensure
+ * that no other threads are using the controller before calling spdk_nvme_detach().
  *
+ * \param cb_ctx Opaque value passed to spdk_nvme_remove_cb().
  * \param ctrlr NVMe controller instance that was removed.
  */
 typedef void (*spdk_nvme_remove_cb)(void *cb_ctx, struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Enumerate the bus indicated by the transport ID and attach the userspace NVMe driver
- * to each device found if desired.
+ * Enumerate the bus indicated by the transport ID and attach the userspace NVMe
+ * driver to each device found if desired.
  *
- * \param trid The transport ID indicating which bus to enumerate. If the trtype is PCIe or trid is NULL,
- * this will scan the local PCIe bus. If the trtype is RDMA, the traddr and trsvcid must point at the
- * location of an NVMe-oF discovery service.
- * \param cb_ctx Opaque value which will be passed back in cb_ctx parameter of the callbacks.
- * \param probe_cb will be called once per NVMe device found in the system.
- * \param attach_cb will be called for devices for which probe_cb returned true once that NVMe
- * controller has been attached to the userspace driver.
- * \param remove_cb will be called for devices that were attached in a previous spdk_nvme_probe()
- * call but are no longer attached to the system. Optional; specify NULL if removal notices are not
- * desired.
- *
- * This function is not thread safe and should only be called from one thread at a time while no
- * other threads are actively using any NVMe devices.
+ * This function is not thread safe and should only be called from one thread at
+ * a time while no other threads are actively using any NVMe devices.
  *
- * If called from a secondary process, only devices that have been attached to the userspace driver
- * in the primary process will be probed.
+ * If called from a secondary process, only devices that have been attached to
+ * the userspace driver in the primary process will be probed.
  *
- * If called more than once, only devices that are not already attached to the SPDK NVMe driver
- * will be reported.
+ * If called more than once, only devices that are not already attached to the
+ * SPDK NVMe driver will be reported.
  *
  * To stop using the the controller and release its associated resources,
- * call \ref spdk_nvme_detach with the spdk_nvme_ctrlr instance from the attach_cb() function.
+ * call spdk_nvme_detach() with the spdk_nvme_ctrlr instance from the attach_cb()
+ * function.
+ *
+ * \param trid The transport ID indicating which bus to enumerate. If the trtype
+ * is PCIe or trid is NULL, this will scan the local PCIe bus. If the trtype is
+ * RDMA, the traddr and trsvcid must point at the location of an NVMe-oF discovery
+ * service.
+ * \param cb_ctx Opaque value which will be passed back in cb_ctx parameter of
+ * the callbacks.
+ * \param probe_cb will be called once per NVMe device found in the system.
+ * \param attach_cb will be called for devices for which probe_cb returned true
+ * once that NVMe controller has been attached to the userspace driver.
+ * \param remove_cb will be called for devices that were attached in a previous
+ * spdk_nvme_probe() call but are no longer attached to the system. Optional;
+ * specify NULL if removal notices are not desired.
+ *
+ * \return 0 on success, -1 on failure.
  */
 int spdk_nvme_probe(const struct spdk_nvme_transport_id *trid,
 		    void *cb_ctx,
@@ -372,184 +416,265 @@ int spdk_nvme_probe(const struct spdk_nvme_transport_id *trid,
 		    spdk_nvme_remove_cb remove_cb);
 
 /**
- * \brief Connect the NVMe driver to the device located at the given transport ID.
+ * Connect the NVMe driver to the device located at the given transport ID.
  *
- * \param trid The transport ID indicating which device to connect. If the trtype is PCIe, this will
- * connect the local PCIe bus. If the trtype is RDMA, the traddr and trsvcid must point at the
- * location of an NVMe-oF service.
- * \param opts NVMe controller initialization options. Default values will be used if the user does
- * not specify the options. The controller may not support all requested parameters.
- * \param opts_size Must be set to sizeof(struct spdk_nvme_ctrlr_opts), or 0 if opts is NULL.
+ * This function is not thread safe and should only be called from one thread at
+ * a time while no other threads are actively using this NVMe device.
  *
- * \return pointer to the connected NVMe controller or NULL if there is any failure.
+ * If called from a secondary process, only the device that has been attached to
+ * the userspace driver in the primary process will be connected.
  *
- * This function is not thread safe and should only be called from one thread at a time while no
- * other threads are actively using this NVMe device.
+ * If connecting to multiple controllers, it is suggested to use spdk_nvme_probe()
+ * and filter the requested controllers with the probe callback. For PCIe controllers,
+ * spdk_nvme_probe() will be more efficient since the controller resets will happen
+ * in parallel.
  *
- * If called from a secondary process, only the device that has been attached to the userspace driver
- * in the primary process will be connected.
+ * To stop using the the controller and release its associated resources, call
+ * spdk_nvme_detach() with the spdk_nvme_ctrlr instance returned by this function.
  *
- * If connecting to multiple controllers, it is suggested to use spdk_nvme_probe() and filter the
- * requested controllers with the probe callback. For PCIe controllers, spdk_nvme_probe() will be
- * more efficient since the controller resets will happen in parallel.
+ * \param trid The transport ID indicating which device to connect. If the trtype
+ * is PCIe, this will connect the local PCIe bus. If the trtype is RDMA, the traddr
+ * and trsvcid must point at the location of an NVMe-oF service.
+ * \param opts NVMe controller initialization options. Default values will be used
+ * if the user does not specify the options. The controller may not support all
+ * requested parameters.
+ * \param opts_size Must be set to sizeof(struct spdk_nvme_ctrlr_opts), or 0 if
+ * opts is NULL.
+ *
+ * \return pointer to the connected NVMe controller or NULL if there is any failure.
  *
- * To stop using the the controller and release its associated resources,
- * call \ref spdk_nvme_detach with the spdk_nvme_ctrlr instance returned by this function.
  */
 struct spdk_nvme_ctrlr *spdk_nvme_connect(const struct spdk_nvme_transport_id *trid,
 		const struct spdk_nvme_ctrlr_opts *opts,
 		size_t opts_size);
 
 /**
- * \brief Detaches specified device returned by \ref spdk_nvme_probe()'s attach_cb from the NVMe driver.
+ * Detach specified device returned by spdk_nvme_probe()'s attach_cb from the
+ * NVMe driver.
  *
  * On success, the spdk_nvme_ctrlr handle is no longer valid.
  *
  * This function should be called from a single thread while no other threads
  * are actively using the NVMe device.
  *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return 0 on success, -1 on failure.
  */
 int spdk_nvme_detach(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Perform a full hardware reset of the NVMe controller.
+ * Perform a full hardware reset of the NVMe controller.
  *
  * This function should be called from a single thread while no other threads
  * are actively using the NVMe device.
  *
- * Any pointers returned from spdk_nvme_ctrlr_get_ns() and spdk_nvme_ns_get_data() may be invalidated
- * by calling this function.  The number of namespaces as returned by spdk_nvme_ctrlr_get_num_ns() may
- * also change.
+ * Any pointers returned from spdk_nvme_ctrlr_get_ns() and spdk_nvme_ns_get_data()
+ * may be invalidated by calling this function. The number of namespaces as returned
+ * by spdk_nvme_ctrlr_get_num_ns() may also change.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return 0 on success, -1 on failure.
  */
 int spdk_nvme_ctrlr_reset(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the identify controller data as defined by the NVMe specification.
+ * Get the identify controller data as defined by the NVMe specification.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ctrlr Opaque handle to NVMe controller.
  *
+ * \return pointer to the identify controller data.
  */
 const struct spdk_nvme_ctrlr_data *spdk_nvme_ctrlr_get_data(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the NVMe controller CSTS (Status) register.
+ * Get the NVMe controller CSTS (Status) register.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return the NVMe controller CSTS (Status) register.
  */
 union spdk_nvme_csts_register spdk_nvme_ctrlr_get_regs_csts(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the NVMe controller CAP (Capabilities) register.
+ * Get the NVMe controller CAP (Capabilities) register.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return the NVMe controller CAP (Capabilities) register.
  */
 union spdk_nvme_cap_register spdk_nvme_ctrlr_get_regs_cap(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the NVMe controller VS (Version) register.
+ * Get the NVMe controller VS (Version) register.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return the NVMe controller VS (Version) register.
  */
 union spdk_nvme_vs_register spdk_nvme_ctrlr_get_regs_vs(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the number of namespaces for the given NVMe controller.
+ * Get the number of namespaces for the given NVMe controller.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the
+ * controller is attached to the SPDK NVMe driver.
  *
  * This is equivalent to calling spdk_nvme_ctrlr_get_data() to get the
  * spdk_nvme_ctrlr_data and then reading the nn field.
  *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return the number of namespaces.
  */
 uint32_t spdk_nvme_ctrlr_get_num_ns(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Get the PCI device of a given NVMe controller.
+ * Get the PCI device of a given NVMe controller.
  *
- * \return PCI device of the NVMe controller, or NULL if not available.
+ * This only works for local (PCIe-attached) NVMe controllers; other transports
+ * will return NULL.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
  *
- * This only works for local (PCIe-attached) NVMe controllers; other transports will return NULL.
+ * \return PCI device of the NVMe controller, or NULL if not available.
  */
 struct spdk_pci_device *spdk_nvme_ctrlr_get_pci_device(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Return true if nsid is an active ns for the given NVMe controller.
+ * Get the maximum data transfer size of a given NVMe controller.
+ *
+ * \return Maximum data transfer size of the NVMe controller in bytes.
+ *
+ * The I/O command helper functions, such as spdk_nvme_ns_cmd_read(), will split
+ * large I/Os automatically; however, it is up to the user to obey this limit for
+ * commands submitted with the raw command functions, such as spdk_nvme_ctrlr_cmd_io_raw().
+ */
+uint32_t spdk_nvme_ctrlr_get_max_xfer_size(const struct spdk_nvme_ctrlr *ctrlr);
+
+/**
+ * Check whether the nsid is an active nv for the given NVMe controller.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param nsid Namespace id.
  *
+ * \return true if nsid is an active ns, or false otherwise.
  */
 bool spdk_nvme_ctrlr_is_active_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid);
 
 /**
- * \brief Return the nsid of the first active namespace, 0 if there are no active namespaces.
+ * Get the nsid of the first active namespace.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return the nsid of the first active namespace, 0 if there are no active namespaces.
  */
 uint32_t spdk_nvme_ctrlr_get_first_active_ns(struct spdk_nvme_ctrlr *ctrlr);
 
 /**
- * \brief Return a next active namespace given the previous ns id, 0 when there are no more active namespaces.
+ * Get next active namespace given the previous nsid.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param prev_nsid Namespace id.
  *
+ * \return a next active namespace given the previous nsid, 0 when there are no
+ * more active namespaces.
  */
 uint32_t spdk_nvme_ctrlr_get_next_active_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t prev_nsid);
 
 /**
- * \brief Determine if a particular log page is supported by the given NVMe controller.
+ * Determine if a particular log page is supported by the given NVMe controller.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \sa spdk_nvme_ctrlr_cmd_get_log_page().
  *
- * \sa spdk_nvme_ctrlr_cmd_get_log_page()
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param log_page Log page to query.
+ *
+ * \return true if supported, or false otherwise.
  */
 bool spdk_nvme_ctrlr_is_log_page_supported(struct spdk_nvme_ctrlr *ctrlr, uint8_t log_page);
 
 /**
- * \brief Determine if a particular feature is supported by the given NVMe controller.
+ * Determine if a particular feature is supported by the given NVMe controller.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \sa spdk_nvme_ctrlr_cmd_get_feature().
  *
- * \sa spdk_nvme_ctrlr_cmd_get_feature()
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param feature_code Feature to query.
+ *
+ * \return true if supported, or false otherwise.
  */
 bool spdk_nvme_ctrlr_is_feature_supported(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature_code);
 
 /**
  * Signature for callback function invoked when a command is completed.
  *
- * The spdk_nvme_cpl parameter contains the completion status.
+ * \param spdk_nvme_cpl Completion queue entry that coontains the completion status.
  */
 typedef void (*spdk_nvme_cmd_cb)(void *, const struct spdk_nvme_cpl *);
 
 /**
- * Signature for callback function invoked when an asynchronous error
- *  request command is completed.
+ * Signature for callback function invoked when an asynchronous error request
+ * command is completed.
  *
- * The aer_cb_arg parameter is set to the context specified by
- *  spdk_nvme_register_aer_callback().
- * The spdk_nvme_cpl parameter contains the completion status of the
- *  asynchronous event request that was completed.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param aer_cb_arg Context specified by spdk_nvme_register_aer_callback().
+ * \param spdk_nvme_cpl Completion queue entry that contains the completion status
+ * of the asynchronous event request that was completed.
  */
 typedef void (*spdk_nvme_aer_cb)(void *aer_cb_arg,
 				 const struct spdk_nvme_cpl *);
 
+/**
+ * Register callback function invoked when an AER command is completed for the
+ * given NVMe controller.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param aer_cb_fn Callback function invoked when an asynchronous error request
+ * command is completed.
+ * \param aer_cb_arg Argument passed to callback function.
+ */
 void spdk_nvme_ctrlr_register_aer_callback(struct spdk_nvme_ctrlr *ctrlr,
 		spdk_nvme_aer_cb aer_cb_fn,
 		void *aer_cb_arg);
 
 /**
- * \brief Opaque handle to a queue pair.
+ * Opaque handle to a queue pair.
  *
  * I/O queue pairs may be allocated using spdk_nvme_ctrlr_alloc_io_qpair().
  */
 struct spdk_nvme_qpair;
 
 /**
- * Signature for the callback function invoked when a timeout is
- * detected on a request.
- * For timeouts detected on the admin queue pair, the qpair returned
- * here will be NULL.
+ * Signature for the callback function invoked when a timeout is detected on a
+ * request.
+ *
+ * For timeouts detected on the admin queue pair, the qpair returned here will
+ * be NULL.
+ *
+ * \param cb_arg Argument passed to callback funciton.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param qpair Opaque handle to a queue pair.
+ * \param cid Command ID.
  */
 typedef void (*spdk_nvme_timeout_cb)(void *cb_arg,
 				     struct spdk_nvme_ctrlr *ctrlr,
@@ -557,21 +682,21 @@ typedef void (*spdk_nvme_timeout_cb)(void *cb_arg,
 				     uint16_t cid);
 
 /**
- * \brief Register for timeout callback on a controller.
+ * Register for timeout callback on a controller.
  *
  * The application can choose to register for timeout callback or not register
  * for timeout callback.
  *
  * \param ctrlr NVMe controller on which to monitor for timeout.
- * \param timeout_sec Timeout value in seconds.
- * \param cb_fn A function pointer that points to the callback function
+ * \param timeout_us Timeout value in microseconds.
+ * \param cb_fn A function pointer that points to the callback function.
  * \param cb_arg Argument to the callback function.
  */
 void spdk_nvme_ctrlr_register_timeout_callback(struct spdk_nvme_ctrlr *ctrlr,
-		uint32_t timeout_sec, spdk_nvme_timeout_cb cb_fn, void *cb_arg);
+		uint64_t timeout_us, spdk_nvme_timeout_cb cb_fn, void *cb_arg);
 
 /**
- * \brief NVMe I/O queue pair initialization options.
+ * NVMe I/O queue pair initialization options.
  *
  * These options may be passed to spdk_nvme_ctrlr_alloc_io_qpair() to configure queue pair
  * options at queue creation time.
@@ -598,18 +723,19 @@ struct spdk_nvme_io_qpair_opts {
 	 *
 	 * This should be at least as large as io_queue_size.
 	 *
-	 * A single I/O may allocate more than one request, since splitting may be necessary to
-	 * conform to the device's maximum transfer size, PRP list compatibility requirements,
-	 * or driver-assisted striping.
+	 * A single I/O may allocate more than one request, since splitting may be
+	 * necessary to conform to the device's maximum transfer size, PRP list
+	 * compatibility requirements, or driver-assisted striping.
 	 */
 	uint32_t io_queue_requests;
 };
 
 /**
- * \brief Get the default options for I/O qpair creation for a specific NVMe controller.
+ * Get the default options for I/O qpair creation for a specific NVMe controller.
  *
  * \param ctrlr NVMe controller to retrieve the defaults from.
- * \param[out] opts Will be filled with the default options for spdk_nvme_ctrlr_alloc_io_qpair().
+ * \param[out] opts Will be filled with the default options for
+ * spdk_nvme_ctrlr_alloc_io_qpair().
  * \param opts_size Must be set to sizeof(struct spdk_nvme_io_qpair_opts).
  */
 void spdk_nvme_ctrlr_get_default_io_qpair_opts(struct spdk_nvme_ctrlr *ctrlr,
@@ -617,27 +743,34 @@ void spdk_nvme_ctrlr_get_default_io_qpair_opts(struct spdk_nvme_ctrlr *ctrlr,
 		size_t opts_size);
 
 /**
- * \brief Allocate an I/O queue pair (submission and completion queue).
+ * Allocate an I/O queue pair (submission and completion queue).
  *
- * Each queue pair should only be used from a single thread at a time (mutual exclusion must be
- * enforced by the user).
+ * Each queue pair should only be used from a single thread at a time (mutual
+ * exclusion must be enforced by the user).
  *
  * \param ctrlr NVMe controller for which to allocate the I/O queue pair.
- * \param opts I/O qpair creation options, or NULL to use the defaults as returned by
- *             spdk_nvme_ctrlr_alloc_io_qpair().
- * \param opts_size Must be set to sizeof(struct spdk_nvme_io_qpair_opts), or 0 if opts is NULL.
+ * \param opts I/O qpair creation options, or NULL to use the defaults as returned
+ * by spdk_nvme_ctrlr_alloc_io_qpair().
+ * \param opts_size Must be set to sizeof(struct spdk_nvme_io_qpair_opts), or 0
+ * if opts is NULL.
+ *
+ * \return a pointer to the allocated I/O queue pair.
  */
 struct spdk_nvme_qpair *spdk_nvme_ctrlr_alloc_io_qpair(struct spdk_nvme_ctrlr *ctrlr,
 		const struct spdk_nvme_io_qpair_opts *opts,
 		size_t opts_size);
 
 /**
- * \brief Free an I/O queue pair that was allocated by spdk_nvme_ctrlr_alloc_io_qpair().
+ * Free an I/O queue pair that was allocated by spdk_nvme_ctrlr_alloc_io_qpair().
+ *
+ * \param qpair I/O queue pair to free.
+ *
+ * \return 0 on success, -1 on failure.
  */
 int spdk_nvme_ctrlr_free_io_qpair(struct spdk_nvme_qpair *qpair);
 
 /**
- * \brief Send the given NVM I/O command to the NVMe controller.
+ * Send the given NVM I/O command to the NVMe controller.
  *
  * This is a low level interface for submitting I/O commands directly. Prefer
  * the spdk_nvme_ns_cmd_* functions instead. The validity of the command will
@@ -647,7 +780,18 @@ int spdk_nvme_ctrlr_free_io_qpair(struct spdk_nvme_qpair *qpair);
  * list/SGL or the CID. The driver will handle both of those for you.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param qpair I/O qpair to submit command.
+ * \param cmd NVM I/O command to submit.
+ * \param buf Virtual memory address of a single physically contiguous buffer.
+ * \param len Size of buffer.
+ * \param cb_fn Callback function invoked when the I/O command completes.
+ * \param cb_arg Argument passed to callback function.
+ *
+ * \return 0 on success, negated errno on failure.
  */
 int spdk_nvme_ctrlr_cmd_io_raw(struct spdk_nvme_ctrlr *ctrlr,
 			       struct spdk_nvme_qpair *qpair,
@@ -656,7 +800,7 @@ int spdk_nvme_ctrlr_cmd_io_raw(struct spdk_nvme_ctrlr *ctrlr,
 			       spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Send the given NVM I/O command with metadata to the NVMe controller.
+ * Send the given NVM I/O command with metadata to the NVMe controller.
  *
  * This is a low level interface for submitting I/O commands directly. Prefer
  * the spdk_nvme_ns_cmd_* functions instead. The validity of the command will
@@ -666,7 +810,20 @@ int spdk_nvme_ctrlr_cmd_io_raw(struct spdk_nvme_ctrlr *ctrlr,
  * list/SGL or the CID. The driver will handle both of those for you.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param qpair I/O qpair to submit command.
+ * \param cmd NVM I/O command to submit.
+ * \param buf Virtual memory address of a single physically contiguous buffer.
+ * \param len Size of buffer.
+ * \param md_buf Virtual memory address of a single physically contiguous metadata
+ * buffer.
+ * \param cb_fn Callback function invoked when the I/O command completes.
+ * \param cb_arg Argument passed to callback function.
+ *
+ * \return 0 on success, negated errno on failure.
  */
 int spdk_nvme_ctrlr_cmd_io_raw_with_md(struct spdk_nvme_ctrlr *ctrlr,
 				       struct spdk_nvme_qpair *qpair,
@@ -675,33 +832,34 @@ int spdk_nvme_ctrlr_cmd_io_raw_with_md(struct spdk_nvme_ctrlr *ctrlr,
 				       spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Process any outstanding completions for I/O submitted on a queue pair.
+ * Process any outstanding completions for I/O submitted on a queue pair.
  *
- * This call is non-blocking, i.e. it only
- * processes completions that are ready at the time of this function call. It does not
- * wait for outstanding commands to finish.
+ * This call is non-blocking, i.e. it only processes completions that are ready
+ * at the time of this function call. It does not wait for outstanding commands
+ * to finish.
  *
- * For each completed command, the request's callback function will
- *  be called if specified as non-NULL when the request was submitted.
+ * For each completed command, the request's callback function will be called if
+ * specified as non-NULL when the request was submitted.
  *
- * \param qpair Queue pair to check for completions.
- * \param max_completions Limit the number of completions to be processed in one call, or 0
- * for unlimited.
+ * The caller must ensure that each queue pair is only used from one thread at a
+ * time.
  *
- * \return Number of completions processed (may be 0) or negative on error.
+ * This function may be called at any point while the controller is attached to
+ * the SPDK NVMe driver.
  *
  * \sa spdk_nvme_cmd_cb
  *
- * This function may be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param qpair Queue pair to check for completions.
+ * \param max_completions Limit the number of completions to be processed in one
+ * call, or 0 for unlimited.
  *
- * The caller must ensure that each queue pair is only used from one thread at a time.
+ * \return number of completions processed (may be 0) or negated on error.
  */
 int32_t spdk_nvme_qpair_process_completions(struct spdk_nvme_qpair *qpair,
 		uint32_t max_completions);
 
 /**
- * \brief Send the given admin command to the NVMe controller.
+ * Send the given admin command to the NVMe controller.
  *
  * This is a low level interface for submitting admin commands directly. Prefer
  * the spdk_nvme_ctrlr_cmd_* functions instead. The validity of the command will
@@ -710,11 +868,20 @@ int32_t spdk_nvme_qpair_process_completions(struct spdk_nvme_qpair *qpair,
  * When constructing the nvme_command it is not necessary to fill out the PRP
  * list/SGL or the CID. The driver will handle both of those for you.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion
  * of commands submitted through this function.
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param cmd NVM admin command to submit.
+ * \param buf Virtual memory address of a single physically contiguous buffer.
+ * \param len Size of buffer.
+ * \param cb_fn Callback function invoked when the admin command completes.
+ * \param cb_arg Argument passed to callback function.
+ *
+ * \return 0 on success, negated errno on failure.
  */
 int spdk_nvme_ctrlr_cmd_admin_raw(struct spdk_nvme_ctrlr *ctrlr,
 				  struct spdk_nvme_cmd *cmd,
@@ -722,60 +889,71 @@ int spdk_nvme_ctrlr_cmd_admin_raw(struct spdk_nvme_ctrlr *ctrlr,
 				  spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Process any outstanding completions for admin commands.
+ * Process any outstanding completions for admin commands.
  *
  * This will process completions for admin commands submitted on any thread.
  *
  * This call is non-blocking, i.e. it only processes completions that are ready
- * at the time of this function call. It does not wait for outstanding commands to
- * finish.
+ * at the time of this function call. It does not wait for outstanding commands
+ * to finish.
  *
- * \return Number of completions processed (may be 0) or negative on error.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ctrlr Opaque handle to NVMe controller.
+ *
+ * \return number of completions processed (may be 0) or negated on error.
  */
 int32_t spdk_nvme_ctrlr_process_admin_completions(struct spdk_nvme_ctrlr *ctrlr);
 
 
-/** \brief Opaque handle to a namespace. Obtained by calling spdk_nvme_ctrlr_get_ns(). */
+/**
+ * Opaque handle to a namespace. Obtained by calling spdk_nvme_ctrlr_get_ns().
+ */
 struct spdk_nvme_ns;
 
 /**
- * \brief Get a handle to a namespace for the given controller.
+ * Get a handle to a namespace for the given controller.
+ *
+ * Namespaces are numbered from 1 to the total number of namespaces. There will
+ * never be any gaps in the numbering. The number of namespaces is obtained by
+ * calling spdk_nvme_ctrlr_get_num_ns().
  *
- * Namespaces are numbered from 1 to the total number of namespaces. There will never
- * be any gaps in the numbering. The number of namespaces is obtained by calling
- * spdk_nvme_ctrlr_get_num_ns().
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ctrlr Opaque handle to NVMe controller.
+ * \param ns_id Namespace id.
+ *
+ * \return a pointer to the namespace.
  */
 struct spdk_nvme_ns *spdk_nvme_ctrlr_get_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t ns_id);
 
 /**
- * \brief Get a specific log page from the NVMe controller.
+ * Get a specific log page from the NVMe controller.
  *
- * \param ctrlr NVMe controller to query.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
+ *
+ * \sa spdk_nvme_ctrlr_is_log_page_supported()
+ *
+ * \param ctrlr Opaque handle to NVMe controller.
  * \param log_page The log page identifier.
- * \param nsid Depending on the log page, this may be 0, a namespace identifier, or SPDK_NVME_GLOBAL_NS_TAG.
+ * \param nsid Depending on the log page, this may be 0, a namespace identifier,
+ * or SPDK_NVME_GLOBAL_NS_TAG.
  * \param payload The pointer to the payload buffer.
  * \param payload_size The size of payload buffer.
- * \param offset Offset in bytes within the log page to start retrieving log page data.
- *               May only be non-zero if the controller supports extended data for Get Log Page
- *               as reported in the controller data log page attributes.
+ * \param offset Offset in bytes within the log page to start retrieving log page
+ * data. May only be non-zero if the controller supports extended data for Get Log
+ * Page as reported in the controller data log page attributes.
  * \param cb_fn Callback function to invoke when the log page has been retrieved.
  * \param cb_arg Argument to pass to the callback function.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
- *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
- *
- * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
- * of commands submitted through this function.
- *
- * \sa spdk_nvme_ctrlr_is_log_page_supported()
+ * \return 0 if successfully submitted, negated errno if resources could not be
+ * allocated for this request.
  */
 int spdk_nvme_ctrlr_cmd_get_log_page(struct spdk_nvme_ctrlr *ctrlr,
 				     uint8_t log_page, uint32_t nsid,
@@ -784,18 +962,18 @@ int spdk_nvme_ctrlr_cmd_get_log_page(struct spdk_nvme_ctrlr *ctrlr,
 				     spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Abort a specific previously-submitted NVMe command.
+ * Abort a specific previously-submitted NVMe command.
+ *
+ * \sa spdk_nvme_ctrlr_register_timeout_callback()
  *
  * \param ctrlr NVMe controller to which the command was submitted.
- * \param qpair NVMe queue pair to which the command was submitted.
- *              For admin commands, pass NULL for the qpair.
+ * \param qpair NVMe queue pair to which the command was submitted. For admin
+ *  commands, pass NULL for the qpair.
  * \param cid Command ID of the command to abort.
  * \param cb_fn Callback function to invoke when the abort has completed.
- * \param cb_arg Argument to pass to the callback function.\
+ * \param cb_arg Argument to pass to the callback function.
  *
  * \return 0 if successfully submitted, negated errno value otherwise.
- *
- * \sa spdk_nvme_ctrlr_register_timeout_callback()
  */
 int spdk_nvme_ctrlr_cmd_abort(struct spdk_nvme_ctrlr *ctrlr,
 			      struct spdk_nvme_qpair *qpair,
@@ -804,7 +982,15 @@ int spdk_nvme_ctrlr_cmd_abort(struct spdk_nvme_ctrlr *ctrlr,
 			      void *cb_arg);
 
 /**
- * \brief Set specific feature for the given NVMe controller.
+ * Set specific feature for the given NVMe controller.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
+ *
+ * \sa spdk_nvme_ctrlr_cmd_get_feature().
  *
  * \param ctrlr NVMe controller to manipulate.
  * \param feature The feature identifier.
@@ -815,23 +1001,43 @@ int spdk_nvme_ctrlr_cmd_abort(struct spdk_nvme_ctrlr *ctrlr,
  * \param cb_fn Callback function to invoke when the feature has been set.
  * \param cb_arg Argument to pass to the callback function.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
+ * \return 0 if successfully submitted, negated errno if resources could not be
+ * allocated for this request.
+ */
+int spdk_nvme_ctrlr_cmd_set_feature(struct spdk_nvme_ctrlr *ctrlr,
+				    uint8_t feature, uint32_t cdw11, uint32_t cdw12,
+				    void *payload, uint32_t payload_size,
+				    spdk_nvme_cmd_cb cb_fn, void *cb_arg);
+
+/**
+ * Get specific feature from given NVMe controller.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
  *
- * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
- * of commands submitted through this function.
+ * \sa spdk_nvme_ctrlr_cmd_set_feature()
  *
- * \sa spdk_nvme_ctrlr_cmd_get_feature()
+ * \param ctrlr NVMe controller to query.
+ * \param feature The feature identifier.
+ * \param cdw11 as defined by the specification for this command.
+ * \param payload The pointer to the payload buffer.
+ * \param payload_size The size of payload buffer.
+ * \param cb_fn Callback function to invoke when the feature has been retrieved.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request.
  */
-int spdk_nvme_ctrlr_cmd_set_feature(struct spdk_nvme_ctrlr *ctrlr,
-				    uint8_t feature, uint32_t cdw11, uint32_t cdw12,
+int spdk_nvme_ctrlr_cmd_get_feature(struct spdk_nvme_ctrlr *ctrlr,
+				    uint8_t feature, uint32_t cdw11,
 				    void *payload, uint32_t payload_size,
 				    spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Get specific feature from given NVMe controller.
+ * Get specific feature from given NVMe controller.
  *
  * \param ctrlr NVMe controller to query.
  * \param feature The feature identifier.
@@ -840,251 +1046,341 @@ int spdk_nvme_ctrlr_cmd_set_feature(struct spdk_nvme_ctrlr *ctrlr,
  * \param payload_size The size of payload buffer.
  * \param cb_fn Callback function to invoke when the feature has been retrieved.
  * \param cb_arg Argument to pass to the callback function.
+ * \param ns_id The namespace identifier.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
  * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
  * of commands submitted through this function.
  *
- * \sa spdk_nvme_ctrlr_cmd_set_feature()
+ * \sa spdk_nvme_ctrlr_cmd_set_feature_ns()
  */
-int spdk_nvme_ctrlr_cmd_get_feature(struct spdk_nvme_ctrlr *ctrlr,
-				    uint8_t feature, uint32_t cdw11,
-				    void *payload, uint32_t payload_size,
-				    spdk_nvme_cmd_cb cb_fn, void *cb_arg);
+int spdk_nvme_ctrlr_cmd_get_feature_ns(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
+				       uint32_t cdw11, void *payload, uint32_t payload_size,
+				       spdk_nvme_cmd_cb cb_fn, void *cb_arg, uint32_t ns_id);
 
 /**
- * \brief Attach the specified namespace to controllers.
+ * Set specific feature for the given NVMe controller and namespace ID.
  *
- * \param ctrlr NVMe controller to use for command submission.
- * \param nsid Namespace identifier for namespace to attach.
- * \param payload The pointer to the controller list.
+ * \param ctrlr NVMe controller to manipulate.
+ * \param feature The feature identifier.
+ * \param cdw11 as defined by the specification for this command.
+ * \param cdw12 as defined by the specification for this command.
+ * \param payload The pointer to the payload buffer.
+ * \param payload_size The size of payload buffer.
+ * \param cb_fn Callback function to invoke when the feature has been set.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param ns_id The namespace identifier.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request.
  *
- * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
  * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
  * of commands submitted through this function.
+ *
+ * \sa spdk_nvme_ctrlr_cmd_get_feature_ns()
  */
-int spdk_nvme_ctrlr_attach_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
-			      struct spdk_nvme_ctrlr_list *payload);
+int spdk_nvme_ctrlr_cmd_set_feature_ns(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
+				       uint32_t cdw11, uint32_t cdw12, void *payload,
+				       uint32_t payload_size, spdk_nvme_cmd_cb cb_fn,
+				       void *cb_arg, uint32_t ns_id);
 
 /**
- * \brief Detach the specified namespace from controllers.
+ * Attach the specified namespace to controllers.
+ *
+ * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ *
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
  *
  * \param ctrlr NVMe controller to use for command submission.
- * \param nsid Namespace ID to detach.
+ * \param nsid Namespace identifier for namespace to attach.
  * \param payload The pointer to the controller list.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request.
+ */
+int spdk_nvme_ctrlr_attach_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
+			      struct spdk_nvme_ctrlr_list *payload);
+
+/**
+ * Detach the specified namespace from controllers.
  *
  * This function is thread safe and can be called at any point after spdk_nvme_probe().
  *
- * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
- * of commands submitted through this function.
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
+ *
+ * \param ctrlr NVMe controller to use for command submission.
+ * \param nsid Namespace ID to detach.
+ * \param payload The pointer to the controller list.
+ *
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request
  */
 int spdk_nvme_ctrlr_detach_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
 			      struct spdk_nvme_ctrlr_list *payload);
 
 /**
- * \brief Create a namespace.
+ * Create a namespace.
+ *
+ * This function is thread safe and can be called at any point after spdk_nvme_probe().
  *
  * \param ctrlr NVMe controller to create namespace on.
  * \param payload The pointer to the NVMe namespace data.
  *
  * \return Namespace ID (>= 1) if successfully created, or 0 if the request failed.
- *
- * This function is thread safe and can be called at any point after spdk_nvme_probe().
  */
 uint32_t spdk_nvme_ctrlr_create_ns(struct spdk_nvme_ctrlr *ctrlr,
 				   struct spdk_nvme_ns_data *payload);
 
 /**
- * \brief Delete a namespace.
+ * Delete a namespace.
  *
- * \param ctrlr NVMe controller to delete namespace from.
- * \param nsid The namespace identifier.
+ * This function is thread safe and can be called at any point after spdk_nvme_probe().
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
+ * Call spdk_nvme_ctrlr_process_admin_completions() to poll for completion of
+ * commands submitted through this function.
  *
- * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ * \param ctrlr NVMe controller to delete namespace from.
+ * \param nsid The namespace identifier.
  *
- * Call \ref spdk_nvme_ctrlr_process_admin_completions() to poll for completion
- * of commands submitted through this function.
+ * \return 0 if successfully submitted, negated errno if resources could not be
+ * allocated
+ * for this request
  */
 int spdk_nvme_ctrlr_delete_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid);
 
 /**
- * \brief Format NVM.
+ * Format NVM.
  *
  * This function requests a low-level format of the media.
  *
+ * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ *
  * \param ctrlr NVMe controller to format.
- * \param nsid The namespace identifier.  May be SPDK_NVME_GLOBAL_NS_TAG to format all namespaces.
+ * \param nsid The namespace identifier. May be SPDK_NVME_GLOBAL_NS_TAG to format
+ * all namespaces.
  * \param format The format information for the command.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request
- *
- * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ * \return 0 if successfully submitted, negated errno if resources could not be
+ * allocated for this request
  */
 int spdk_nvme_ctrlr_format(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
 			   struct spdk_nvme_format *format);
 
 /**
- * \brief Download a new firmware image.
+ * Download a new firmware image.
+ *
+ * This function is thread safe and can be called at any point after spdk_nvme_probe().
  *
+ * \param ctrlr NVMe controller to perform firmware operation on.
  * \param payload The data buffer for the firmware image.
  * \param size The data size will be downloaded.
  * \param slot The slot that the firmware image will be committed to.
  * \param commit_action The action to perform when firmware is committed.
- * \param completion_status output parameter. Contains the completion status of the firmware commit operation.
+ * \param completion_status output parameter. Contains the completion status of
+ * the firmware commit operation.
  *
- * \return 0 if successfully submitted, ENOMEM if resources could not be allocated for this request,
- * -1 if the size is not multiple of 4.
- *
- * This function is thread safe and can be called at any point after spdk_nvme_probe().
+ * \return 0 if successfully submitted, ENOMEM if resources could not be allocated
+ * for this request, -1 if the size is not multiple of 4.
  */
 int spdk_nvme_ctrlr_update_firmware(struct spdk_nvme_ctrlr *ctrlr, void *payload, uint32_t size,
 				    int slot, enum spdk_nvme_fw_commit_action commit_action,
 				    struct spdk_nvme_status *completion_status);
 
 /**
- * \brief Allocate an I/O buffer from the controller memory buffer (Experimental).
+ * Allocate an I/O buffer from the controller memory buffer (Experimental).
+ *
+ * This function allocates registered memory which belongs to the Controller
+ * Memory Buffer (CMB) of the specified NVMe controller. Note that the CMB has
+ * to support the WDS and RDS capabilities for the allocation to be successful.
+ * Also, due to vtophys contraints the CMB must be at least 4MiB in size. Free
+ * memory allocated with this function using spdk_nvme_ctrlr_free_cmb_io_buffer().
  *
  * \param ctrlr Controller from which to allocate memory buffer.
  * \param size Size of buffer to allocate in bytes.
  *
- * \return Pointer to controller memory buffer allocation, or NULL if allocation was not possible.
- *
- * This function allocates registered memory which belongs to the
- * Controller Memory Buffer (CMB) of the specified NVMe
- * controller. Note that the CMB has to support the WDS and RDS
- * capabilities for the allocation to be successful. Also, due to
- * vtophys contraints the CMB must be at least 4MiB in size. Free
- * memory allocated with this function using
- * spdk_nvme_ctrlr_free_cmb_io_buffer().
+ * \return Pointer to controller memory buffer allocation, or NULL if allocation
+ * was not possible.
  */
 void *spdk_nvme_ctrlr_alloc_cmb_io_buffer(struct spdk_nvme_ctrlr *ctrlr, size_t size);
 
 /**
- * \brief Free a controller memory I/O buffer (Experimental).
+ * Free a controller memory I/O buffer (Experimental).
+ *
+ * Note this function is currently a NOP which is one reason why this and
+ * spdk_nvme_ctrlr_alloc_cmb_io_buffer() are currently marked as experimental.
  *
  * \param ctrlr Controller from which the buffer was allocated.
  * \param buf Buffer previously allocated by spdk_nvme_ctrlr_alloc_cmb_io_buffer().
  * \param size Size of buf in bytes.
- *
- * Note this function is currently a NOP which is not a good thing and
- * is one reason why this and spdk_nvme_ctrlr_alloc_cmb_io_buffer()
- * are currently marked as experimental.
  */
 void spdk_nvme_ctrlr_free_cmb_io_buffer(struct spdk_nvme_ctrlr *ctrlr, void *buf, size_t size);
 
 /**
- * \brief Get the identify namespace data as defined by the NVMe specification.
+ * Get the identify namespace data as defined by the NVMe specification.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ns Namespace.
+ *
+ * \return a pointer to the namespace data.
  */
 const struct spdk_nvme_ns_data *spdk_nvme_ns_get_data(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the namespace id (index number) from the given namespace handle.
+ * Get the namespace id (index number) from the given namespace handle.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \return namespace id.
  */
 uint32_t spdk_nvme_ns_get_id(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the Controller with which this namespace is associated.
+ * Get the controller with which this namespace is associated.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace.
+ *
+ * \return a pointer to the controller.
  */
 struct spdk_nvme_ctrlr *spdk_nvme_ns_get_ctrlr(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Determine whether a namespace is active.
+ * Determine whether a namespace is active.
  *
  * Inactive namespaces cannot be the target of I/O commands.
+ *
+ * \param ns Namespace to query.
+ *
+ * \return true if active, or false if inactive.
  */
 bool spdk_nvme_ns_is_active(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the maximum transfer size, in bytes, for an I/O sent to the given namespace.
+ * Get the maximum transfer size, in bytes, for an I/O sent to the given namespace.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \return the maximum transfer size in bytes.
  */
 uint32_t spdk_nvme_ns_get_max_io_xfer_size(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the sector size, in bytes, of the given namespace.
+ * Get the sector size, in bytes, of the given namespace.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * /return the sector size in bytes.
  */
 uint32_t spdk_nvme_ns_get_sector_size(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the number of sectors for the given namespace.
+ * Get the number of sectors for the given namespace.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \return the number of sectors.
  */
 uint64_t spdk_nvme_ns_get_num_sectors(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the size, in bytes, of the given namespace.
+ * Get the size, in bytes, of the given namespace.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
+ *
+ * \return the size of the given namespace in bytes.
  */
 uint64_t spdk_nvme_ns_get_size(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the end-to-end data protection information type of the given namespace.
+ * Get the end-to-end data protection information type of the given namespace.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ns Namespace to query.
+ *
+ * \return the end-to-end data protection information type.
  */
 enum spdk_nvme_pi_type spdk_nvme_ns_get_pi_type(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the metadata size, in bytes, of the given namespace.
+ * Get the metadata size, in bytes, of the given namespace.
+ *
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * \param ns Namespace to query.
+ *
+ * \return the metadata size of the given namespace in bytes.
  */
 uint32_t spdk_nvme_ns_get_md_size(struct spdk_nvme_ns *ns);
 
 /**
- * \brief True if the namespace can support extended LBA when end-to-end data protection enabled.
+ * Check whether if the namespace can support extended LBA when end-to-end data
+ * protection enabled.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
+ *
+ * \return true if the namespace can support extended LBA when end-to-end data
+ * protection enabled, or false otherwise.
  */
 bool spdk_nvme_ns_supports_extended_lba(struct spdk_nvme_ns *ns);
 
 /**
- * \brief Determine the value returned when reading deallocated blocks.
+ * Determine the value returned when reading deallocated blocks.
+ *
+ * If deallocated blocks return 0, the deallocate command can be used as a more
+ * efficient alternative to the write_zeroes command, especially for large requests.
+ *
+ * \param ns Namespace.
  *
- * If deallocated blocks return 0, the deallocate command can be used as a more efficient alternative
- * to the write_zeroes command, especially for large requests.
+ * \return the logical block read value.
  */
 enum spdk_nvme_dealloc_logical_block_read_value spdk_nvme_ns_get_dealloc_logical_block_read_value(
 	struct spdk_nvme_ns *ns);
 
 /**
- * \brief Get the optimal I/O boundary, in blocks, for the given namespace.
+ * Get the optimal I/O boundary, in blocks, for the given namespace.
  *
- * \return Optimal granularity of I/O commands, in blocks, or 0 if no optimal granularity is reported.
+ * Read and write commands should not cross the optimal I/O boundary for best
+ * performance.
  *
- * Read and write commands should not cross the optimal I/O boundary for best performance.
+ * \param ns Namespace to query.
+ *
+ * \return Optimal granularity of I/O commands, in blocks, or 0 if no optimal
+ * granularity is reported.
  */
 uint32_t spdk_nvme_ns_get_optimal_io_boundary(struct spdk_nvme_ns *ns);
 
@@ -1093,7 +1389,7 @@ uint32_t spdk_nvme_ns_get_optimal_io_boundary(struct spdk_nvme_ns *ns);
  *
  * \param ns Namespace to query.
  *
- * \return Pointer to namespace UUID, or NULL if ns does not have a UUID.
+ * \return a pointer to namespace UUID, or NULL if ns does not have a UUID.
  */
 const struct spdk_uuid *spdk_nvme_ns_get_uuid(const struct spdk_nvme_ns *ns);
 
@@ -1112,19 +1408,24 @@ enum spdk_nvme_ns_flags {
 };
 
 /**
- * \brief Get the flags for the given namespace.
+ * Get the flags for the given namespace.
  *
  * See spdk_nvme_ns_flags for the possible flags returned.
  *
- * This function is thread safe and can be called at any point while the controller is attached to
- *  the SPDK NVMe driver.
+ * This function is thread safe and can be called at any point while the controller
+ * is attached to the SPDK NVMe driver.
+ *
+ * \param ns Namespace to query.
+ *
+ * \return the flags for the given namespace.
  */
 uint32_t spdk_nvme_ns_get_flags(struct spdk_nvme_ns *ns);
 
 /**
  * Restart the SGL walk to the specified offset when the command has scattered payloads.
  *
- * The cb_arg parameter is the value passed to readv/writev.
+ * \param cb_arg Argument passed to readv/writev.
+ * \param offset Offset for SGL.
  */
 typedef void (*spdk_nvme_req_reset_sgl_cb)(void *cb_arg, uint32_t offset);
 
@@ -1132,55 +1433,58 @@ typedef void (*spdk_nvme_req_reset_sgl_cb)(void *cb_arg, uint32_t offset);
  * Fill out *address and *length with the current SGL entry and advance to the next
  * entry for the next time the callback is invoked.
  *
- * The cb_arg parameter is the value passed to readv/writev.
- * The address parameter contains the virtual address of this segment.
- * The length parameter contains the length of this physical segment.
  * The described segment must be physically contiguous.
+ *
+ * \param cb_arg Argument passed to readv/writev.
+ * \param address Virtual address of this segment.
+ * \param length Length of this physical segment.
  */
 typedef int (*spdk_nvme_req_next_sge_cb)(void *cb_arg, void **address, uint32_t *length);
 
 /**
- * \brief Submits a write I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the write I/O
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param lba starting LBA to write the data
- * \param lba_count length (in sectors) for the write operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined by the SPDK_NVME_IO_FLAGS_* entries
- *			in spdk/nvme_spec.h, for this I/O.
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a write I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the write I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the data payload.
+ * \param lba Starting LBA to write the data.
+ * \param lba_count Length (in sectors) for the write operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined by the SPDK_NVME_IO_FLAGS_* entries in
+ * spdk/nvme_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request
  */
 int spdk_nvme_ns_cmd_write(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair, void *payload,
 			   uint64_t lba, uint32_t lba_count, spdk_nvme_cmd_cb cb_fn,
 			   void *cb_arg, uint32_t io_flags);
 
 /**
- * \brief Submits a write I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the write I/O
- * \param qpair I/O queue pair to submit the request
- * \param lba starting LBA to write the data
- * \param lba_count length (in sectors) for the write operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- * \param reset_sgl_fn callback function to reset scattered payload
- * \param next_sge_fn callback function to iterate each scattered
- * payload memory segment
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a write I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the write I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param lba Starting LBA to write the data.
+ * \param lba_count Length (in sectors) for the write operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ * \param reset_sgl_fn Callback function to reset scattered payload.
+ * \param next_sge_fn Callback function to iterate each scattered payload memory
+ * segment.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_writev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 			    uint64_t lba, uint32_t lba_count,
@@ -1189,27 +1493,60 @@ int spdk_nvme_ns_cmd_writev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpa
 			    spdk_nvme_req_next_sge_cb next_sge_fn);
 
 /**
- * \brief Submits a write I/O to the specified NVMe namespace.
+ * Submit a write I/O to the specified NVMe namespace.
+ *
+ * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
  *
  * \param ns NVMe namespace to submit the write I/O
  * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param metadata virtual address pointer to the metadata payload, the length
- *	           of metadata is specified by spdk_nvme_ns_get_md_size()
  * \param lba starting LBA to write the data
  * \param lba_count length (in sectors) for the write operation
  * \param cb_fn callback function to invoke when the I/O is completed
  * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined by the SPDK_NVME_IO_FLAGS_* entries
- *			in spdk/nvme_spec.h, for this I/O.
+ * \param io_flags set flags, defined in nvme_spec.h, for this I/O
+ * \param reset_sgl_fn callback function to reset scattered payload
+ * \param next_sge_fn callback function to iterate each scattered
+ * payload memory segment
+ * \param metadata virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size()
  * \param apptag_mask application tag mask.
  * \param apptag application tag to use end-to-end protection information.
  *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request structure
+ * cannot be allocated for the I/O request.
+ */
+int spdk_nvme_ns_cmd_writev_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
+				    uint64_t lba, uint32_t lba_count,
+				    spdk_nvme_cmd_cb cb_fn, void *cb_arg, uint32_t io_flags,
+				    spdk_nvme_req_reset_sgl_cb reset_sgl_fn,
+				    spdk_nvme_req_next_sge_cb next_sge_fn, void *metadata,
+				    uint16_t apptag_mask, uint16_t apptag);
+
+/**
+ * Submit a write I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the write I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the data payload.
+ * \param metadata Virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size().
+ * \param lba Starting LBA to write the data.
+ * \param lba_count Length (in sectors) for the write operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined by the SPDK_NVME_IO_FLAGS_* entries in
+ * spdk/nvme_spec.h, for this I/O.
+ * \param apptag_mask Application tag mask.
+ * \param apptag Application tag to use end-to-end protection information.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_write_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 				   void *payload, void *metadata,
@@ -1218,22 +1555,23 @@ int spdk_nvme_ns_cmd_write_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpa
 				   uint16_t apptag_mask, uint16_t apptag);
 
 /**
- * \brief Submits a write zeroes I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the write zeroes I/O
- * \param qpair I/O queue pair to submit the request
- * \param lba starting LBA for this command
- * \param lba_count length (in sectors) for the write zero operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined by the SPDK_NVME_IO_FLAGS_* entries
- *			in spdk/nvme_spec.h, for this I/O.
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a write zeroes I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the write zeroes I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param lba Starting LBA for this command.
+ * \param lba_count Length (in sectors) for the write zero operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined by the SPDK_NVME_IO_FLAGS_* entries in
+ * spdk/nvme_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_write_zeroes(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 				  uint64_t lba, uint32_t lba_count,
@@ -1243,44 +1581,46 @@ int spdk_nvme_ns_cmd_write_zeroes(struct spdk_nvme_ns *ns, struct spdk_nvme_qpai
 /**
  * \brief Submits a read I/O to the specified NVMe namespace.
  *
- * \param ns NVMe namespace to submit the read I/O
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param lba starting LBA to read the data
- * \param lba_count length (in sectors) for the read operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
- *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the read I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the data payload.
+ * \param lba Starting LBA to read the data.
+ * \param lba_count Length (in sectors) for the read operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_read(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair, void *payload,
 			  uint64_t lba, uint32_t lba_count, spdk_nvme_cmd_cb cb_fn,
 			  void *cb_arg, uint32_t io_flags);
 
 /**
- * \brief Submits a read I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the read I/O
- * \param qpair I/O queue pair to submit the request
- * \param lba starting LBA to read the data
- * \param lba_count length (in sectors) for the read operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- * \param reset_sgl_fn callback function to reset scattered payload
- * \param next_sge_fn callback function to iterate each scattered
- * payload memory segment
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a read I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the read I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param lba Starting LBA to read the data.
+ * \param lba_count Length (in sectors) for the read operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ * \param reset_sgl_fn Callback function to reset scattered payload.
+ * \param next_sge_fn Callback function to iterate each scattered payload memory
+ * segment.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_readv(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 			   uint64_t lba, uint32_t lba_count,
@@ -1289,18 +1629,20 @@ int spdk_nvme_ns_cmd_readv(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpai
 			   spdk_nvme_req_next_sge_cb next_sge_fn);
 
 /**
- * \brief Submits a read I/O to the specified NVMe namespace.
+ * Submit a read I/O to the specified NVMe namespace.
  *
  * \param ns NVMe namespace to submit the read I/O
  * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param metadata virtual address pointer to the metadata payload, the length
- *	           of metadata is specified by spdk_nvme_ns_get_md_size()
  * \param lba starting LBA to read the data
  * \param lba_count length (in sectors) for the read operation
  * \param cb_fn callback function to invoke when the I/O is completed
  * \param cb_arg argument to pass to the callback function
  * \param io_flags set flags, defined in nvme_spec.h, for this I/O
+ * \param reset_sgl_fn callback function to reset scattered payload
+ * \param next_sge_fn callback function to iterate each scattered
+ * payload memory segment
+ * \param metadata virtual address pointer to the metadata payload, the length
+ *	           of metadata is specified by spdk_nvme_ns_get_md_size()
  * \param apptag_mask application tag mask.
  * \param apptag application tag to use end-to-end protection information.
  *
@@ -1310,6 +1652,32 @@ int spdk_nvme_ns_cmd_readv(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpai
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
  * The user must ensure that only one thread submits I/O on a given qpair at any given time.
  */
+int spdk_nvme_ns_cmd_readv_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
+				   uint64_t lba, uint32_t lba_count,
+				   spdk_nvme_cmd_cb cb_fn, void *cb_arg, uint32_t io_flags,
+				   spdk_nvme_req_reset_sgl_cb reset_sgl_fn,
+				   spdk_nvme_req_next_sge_cb next_sge_fn, void *metadata,
+				   uint16_t apptag_mask, uint16_t apptag);
+
+/**
+ * Submits a read I/O to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the read I/O
+ * \param qpair I/O queue pair to submit the request
+ * \param payload virtual address pointer to the data payload
+ * \param metadata virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size().
+ * \param lba starting LBA to read the data.
+ * \param lba_count Length (in sectors) for the read operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ * \param apptag_mask Application tag mask.
+ * \param apptag Application tag to use end-to-end protection information.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
+ */
 int spdk_nvme_ns_cmd_read_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 				  void *payload, void *metadata,
 				  uint64_t lba, uint32_t lba_count, spdk_nvme_cmd_cb cb_fn,
@@ -1317,29 +1685,31 @@ int spdk_nvme_ns_cmd_read_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpai
 				  uint16_t apptag_mask, uint16_t apptag);
 
 /**
- * \brief Submits a data set management request to the specified NVMe namespace. Data set
- *        management operations are designed to optimize interaction with the block
- *        translation layer inside the device. The most common type of operation is
- *        deallocate, which is often referred to as TRIM or UNMAP.
+ * Submit a data set management request to the specified NVMe namespace. Data set
+ * management operations are designed to optimize interaction with the block
+ * translation layer inside the device. The most common type of operation is
+ * deallocate, which is often referred to as TRIM or UNMAP.
+ *
+ * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * This is a convenience wrapper that will automatically allocate and construct
+ * the correct data buffers. Therefore, ranges does not need to be allocated from
+ * pinned memory and can be placed on the stack. If a higher performance, zero-copy
+ * version of DSM is required, simply build and submit a raw command using
+ * spdk_nvme_ctrlr_cmd_io_raw().
  *
  * \param ns NVMe namespace to submit the DSM request
- * \param type A bit field constructed from \ref enum spdk_nvme_dsm_attribute.
+ * \param type A bit field constructed from \ref spdk_nvme_dsm_attribute.
  * \param qpair I/O queue pair to submit the request
- * \param ranges An array of \ref spdk_nvme_dsm_range elements describing
- *		 the LBAs to operate on.
+ * \param ranges An array of \ref spdk_nvme_dsm_range elements describing the LBAs
+ * to operate on.
  * \param num_ranges The number of elements in the ranges array.
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
+ * \param cb_fn Callback function to invoke when the I/O is completed
+ * \param cb_arg Argument to pass to the callback function
  *
  * \return 0 if successfully submitted, negated POSIX errno values otherwise.
- *
- * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
- *
- * This is a convenience wrapper that will automatically allocate and construct the correct
- * data buffers. Therefore, ranges does not need to be allocated from pinned memory and
- * can be placed on the stack. If a higher performance, zero-copy version of DSM is
- * required, simply build and submit a raw command using spdk_nvme_ctrlr_cmd_io_raw().
  */
 int spdk_nvme_ns_cmd_dataset_management(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 					uint32_t type,
@@ -1349,39 +1719,41 @@ int spdk_nvme_ns_cmd_dataset_management(struct spdk_nvme_ns *ns, struct spdk_nvm
 					void *cb_arg);
 
 /**
- * \brief Submits a flush request to the specified NVMe namespace.
+ * Submit a flush request to the specified NVMe namespace.
  *
- * \param ns NVMe namespace to submit the flush request
- * \param qpair I/O queue pair to submit the request
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
+ * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
  *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * \param ns NVMe namespace to submit the flush request.
+ * \param qpair I/O queue pair to submit the request.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
  *
- * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_flush(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 			   spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Submits a reservation register to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the reservation register request
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the reservation register data
- * \param ignore_key '1' the current reservation key check is disabled
- * \param action specifies the registration action
- * \param cptpl change the Persist Through Power Loss state
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a reservation register to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the reservation register request.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the reservation register data.
+ * \param ignore_key '1' the current reservation key check is disabled.
+ * \param action Specifies the registration action.
+ * \param cptpl Change the Persist Through Power Loss state.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_reservation_register(struct spdk_nvme_ns *ns,
 		struct spdk_nvme_qpair *qpair,
@@ -1392,22 +1764,23 @@ int spdk_nvme_ns_cmd_reservation_register(struct spdk_nvme_ns *ns,
 		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Submits a reservation release to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the reservation release request
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to current reservation key
- * \param ignore_key '1' the current reservation key check is disabled
- * \param action specifies the reservation release action
- * \param type reservation type for the namespace
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submits a reservation release to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the reservation release request.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to current reservation key.
+ * \param ignore_key '1' the current reservation key check is disabled.
+ * \param action Specifies the reservation release action.
+ * \param type Reservation type for the namespace.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_reservation_release(struct spdk_nvme_ns *ns,
 		struct spdk_nvme_qpair *qpair,
@@ -1418,22 +1791,23 @@ int spdk_nvme_ns_cmd_reservation_release(struct spdk_nvme_ns *ns,
 		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Submits a reservation acquire to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the reservation acquire request
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to reservation acquire data
- * \param ignore_key '1' the current reservation key check is disabled
- * \param action specifies the reservation acquire action
- * \param type reservation type for the namespace
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submits a reservation acquire to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the reservation acquire request.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to reservation acquire data.
+ * \param ignore_key '1' the current reservation key check is disabled.
+ * \param action Specifies the reservation acquire action.
+ * \param type Reservation type for the namespace.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_reservation_acquire(struct spdk_nvme_ns *ns,
 		struct spdk_nvme_qpair *qpair,
@@ -1444,20 +1818,21 @@ int spdk_nvme_ns_cmd_reservation_acquire(struct spdk_nvme_ns *ns,
 		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Submits a reservation report to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the reservation report request
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer for reservation status data
- * \param len length bytes for reservation status data structure
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a reservation report to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the reservation report request.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer for reservation status data.
+ * \param len Length bytes for reservation status data structure.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_reservation_report(struct spdk_nvme_ns *ns,
 					struct spdk_nvme_qpair *qpair,
@@ -1465,46 +1840,48 @@ int spdk_nvme_ns_cmd_reservation_report(struct spdk_nvme_ns *ns,
 					spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 
 /**
- * \brief Submits a compare I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the compare I/O
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param lba starting LBA to compare the data
- * \param lba_count length (in sectors) for the compare operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a compare I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the compare I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the data payload.
+ * \param lba Starting LBA to compare the data.
+ * \param lba_count Length (in sectors) for the compare operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_compare(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair, void *payload,
 			     uint64_t lba, uint32_t lba_count, spdk_nvme_cmd_cb cb_fn,
 			     void *cb_arg, uint32_t io_flags);
 
 /**
- * \brief Submits a compare I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the compare I/O
- * \param qpair I/O queue pair to submit the request
- * \param lba starting LBA to compare the data
- * \param lba_count length (in sectors) for the compare operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- * \param reset_sgl_fn callback function to reset scattered payload
- * \param next_sge_fn callback function to iterate each scattered
- * payload memory segment
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a compare I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the compare I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param lba Starting LBA to compare the data.
+ * \param lba_count Length (in sectors) for the compare operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ * \param reset_sgl_fn Callback function to reset scattered payload.
+ * \param next_sge_fn Callback function to iterate each scattered payload memory
+ * segment.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_comparev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 			      uint64_t lba, uint32_t lba_count,
@@ -1513,26 +1890,27 @@ int spdk_nvme_ns_cmd_comparev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *q
 			      spdk_nvme_req_next_sge_cb next_sge_fn);
 
 /**
- * \brief Submits a compare I/O to the specified NVMe namespace.
- *
- * \param ns NVMe namespace to submit the compare I/O
- * \param qpair I/O queue pair to submit the request
- * \param payload virtual address pointer to the data payload
- * \param metadata virtual address pointer to the metadata payload, the length
- *	           of metadata is specified by spdk_nvme_ns_get_md_size()
- * \param lba starting LBA to compare the data
- * \param lba_count length (in sectors) for the compare operation
- * \param cb_fn callback function to invoke when the I/O is completed
- * \param cb_arg argument to pass to the callback function
- * \param io_flags set flags, defined in nvme_spec.h, for this I/O
- * \param apptag_mask application tag mask.
- * \param apptag application tag to use end-to-end protection information.
- *
- * \return 0 if successfully submitted, ENOMEM if an nvme_request
- *	     structure cannot be allocated for the I/O request
+ * Submit a compare I/O to the specified NVMe namespace.
  *
  * The command is submitted to a qpair allocated by spdk_nvme_ctrlr_alloc_io_qpair().
- * The user must ensure that only one thread submits I/O on a given qpair at any given time.
+ * The user must ensure that only one thread submits I/O on a given qpair at any
+ * given time.
+ *
+ * \param ns NVMe namespace to submit the compare I/O.
+ * \param qpair I/O queue pair to submit the request.
+ * \param payload Virtual address pointer to the data payload.
+ * \param metadata Virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size().
+ * \param lba Starting LBA to compare the data.
+ * \param lba_count Length (in sectors) for the compare operation.
+ * \param cb_fn Callback function to invoke when the I/O is completed.
+ * \param cb_arg Argument to pass to the callback function.
+ * \param io_flags Set flags, defined in nvme_spec.h, for this I/O.
+ * \param apptag_mask Application tag mask.
+ * \param apptag Application tag to use end-to-end protection information.
+ *
+ * \return 0 if successfully submitted, negated errno if an nvme_request structure
+ * cannot be allocated for the I/O request.
  */
 int spdk_nvme_ns_cmd_compare_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 				     void *payload, void *metadata,
@@ -1540,6 +1918,54 @@ int spdk_nvme_ns_cmd_compare_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_q
 				     void *cb_arg, uint32_t io_flags,
 				     uint16_t apptag_mask, uint16_t apptag);
 
+/**
+ * \brief Inject an error for the next request with a given opcode.
+ *
+ * \param ctrlr NVMe controller.
+ * \param qpair I/O queue pair to add the error command,
+ *              NULL for Admin queue pair.
+ * \param opc Opcode for Admin or I/O commands.
+ * \param do_not_submit True if matching requests should not be submitted
+ *                      to the controller, but instead completed manually
+ *                      after timeout_in_us has expired.  False if matching
+ *                      requests should be submitted to the controller and
+ *                      have their completion status modified after the
+ *                      controller completes the request.
+ * \param timeout_in_us Wait specified microseconds when do_not_submit is true.
+ * \param err_count Number of matching requests to inject errors.
+ * \param sct Status code type.
+ * \param sc Status code.
+ *
+ * \return 0 if successfully enabled, ENOMEM if an error command
+ *	     structure cannot be allocated.
+ *
+ * The function can be called multiple times to inject errors for different
+ * commands.  If the opcode matches an existing entry, the existing entry
+ * will be updated with the values specified.
+ */
+int spdk_nvme_qpair_add_cmd_error_injection(struct spdk_nvme_ctrlr *ctrlr,
+		struct spdk_nvme_qpair *qpair,
+		uint8_t opc,
+		bool do_not_submit,
+		uint64_t timeout_in_us,
+		uint32_t err_count,
+		uint8_t sct, uint8_t sc);
+
+/**
+ * \brief Clear the specified NVMe command with error status.
+ *
+ * \param ctrlr NVMe controller.
+ * \param qpair I/O queue pair to remove the error command,
+ * \            NULL for Admin queue pair.
+ * \param opc Opcode for Admin or I/O commands.
+ *
+ * The function will remove specified command in the error list.
+ */
+void spdk_nvme_qpair_remove_cmd_error_injection(struct spdk_nvme_ctrlr *ctrlr,
+		struct spdk_nvme_qpair *qpair,
+		uint8_t opc);
+
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/nvme_ocssd.h b/include/spdk/nvme_ocssd.h
new file mode 100644
index 000000000..a4f853048
--- /dev/null
+++ b/include/spdk/nvme_ocssd.h
@@ -0,0 +1,227 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * \file
+ * NVMe driver public API extension for Open-Channel
+ */
+
+#ifndef SPDK_NVME_OCSSD_H
+#define SPDK_NVME_OCSSD_H
+
+#include "spdk/stdinc.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "spdk/nvme.h"
+#include "spdk/nvme_ocssd_spec.h"
+
+/**
+ * \brief Determine if OpenChannel is supported by the given NVMe controller.
+ * \param ctrlr NVMe controller to check.
+ *
+ * \return true if support OpenChannel
+ */
+bool spdk_nvme_ctrlr_is_ocssd_supported(struct spdk_nvme_ctrlr *ctrlr);
+
+/**
+ * \brief Identify geometry of the given namespace.
+ * \param ctrlr NVMe controller to query.
+ * \param nsid Id of the given namesapce.
+ * \param payload The pointer to the payload buffer.
+ * \param payload_size The size of payload buffer. Shall be multiple of 4K.
+ * \param cb_fn Callback function to invoke when the feature has been retrieved.
+ * \param cb_arg Argument to pass to the callback function.
+ *
+ * \return 0 if successfully submitted, ENOMEM if resources could not be
+ * allocated for this request, EINVAL if wrong payload size.
+ *
+ */
+int spdk_nvme_ocssd_ctrlr_cmd_geometry(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
+				       void *payload, uint32_t payload_size,
+				       spdk_nvme_cmd_cb cb_fn, void *cb_arg);
+
+/**
+ * \brief Submits a vector reset command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param lba_list an array of LBAs for processing.
+ * LBAs must correspond to the start of chunks to reset.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in lba_list
+ * \param chunk_info an array of chunk info on DMA-able memory
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_reset(struct spdk_nvme_ns *ns,
+					struct spdk_nvme_qpair *qpair,
+					uint64_t *lba_list, uint32_t num_lbas,
+					struct spdk_ocssd_chunk_information *chunk_info,
+					spdk_nvme_cmd_cb cb_fn, void *cb_arg);
+
+/**
+ * \brief Submits a vector write command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param buffer virtual address pointer to the data payload
+ * \param lba_list an array of LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in lba_list
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ * \param io_flags set flags, defined by the SPDK_OCSSD_IO_FLAGS_* entries
+ * in spdk/nvme_ocssd_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_write(struct spdk_nvme_ns *ns,
+					struct spdk_nvme_qpair *qpair,
+					void *buffer,
+					uint64_t *lba_list, uint32_t num_lbas,
+					spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+					uint32_t io_flags);
+
+/**
+ * \brief Submits a vector write command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param buffer virtual address pointer to the data payload
+ * \param metadata virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size()
+ * \param lba_list an array of LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in lba_list
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ * \param io_flags set flags, defined by the SPDK_OCSSD_IO_FLAGS_* entries
+ * in spdk/nvme_ocssd_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_write_with_md(struct spdk_nvme_ns *ns,
+		struct spdk_nvme_qpair *qpair,
+		void *buffer, void *metadata,
+		uint64_t *lba_list, uint32_t num_lbas,
+		spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+		uint32_t io_flags);
+
+/**
+ * \brief Submits a vector read command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param buffer virtual address pointer to the data payload
+ * \param lba_list an array of LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in lba_list
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ * \param io_flags set flags, defined by the SPDK_OCSSD_IO_FLAGS_* entries
+ * in spdk/nvme_ocssd_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_read(struct spdk_nvme_ns *ns,
+				       struct spdk_nvme_qpair *qpair,
+				       void *buffer,
+				       uint64_t *lba_list, uint32_t num_lbas,
+				       spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				       uint32_t io_flags);
+
+/**
+ * \brief Submits a vector read command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param buffer virtual address pointer to the data payload
+ * \param metadata virtual address pointer to the metadata payload, the length
+ * of metadata is specified by spdk_nvme_ns_get_md_size()
+ * \param lba_list an array of LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in lba_list
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ * \param io_flags set flags, defined by the SPDK_OCSSD_IO_FLAGS_* entries
+ * in spdk/nvme_ocssd_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_read_with_md(struct spdk_nvme_ns *ns,
+		struct spdk_nvme_qpair *qpair,
+		void *buffer, void *metadata,
+		uint64_t *lba_list, uint32_t num_lbas,
+		spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+		uint32_t io_flags);
+
+/**
+ * \brief Submits a vector copy command to the specified NVMe namespace.
+ *
+ * \param ns NVMe namespace to submit the command
+ * \param qpair I/O queue pair to submit the request
+ * \param dst_lba_list an array of destination LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param src_lba_list an array of source LBAs for processing.
+ * Must be allocated through spdk_dma_malloc() or its variants
+ * \param num_lbas number of LBAs stored in src_lba_list and dst_lba_list
+ * \param cb_fn callback function to invoke when the I/O is completed
+ * \param cb_arg argument to pass to the callback function
+ * \param io_flags set flags, defined by the SPDK_OCSSD_IO_FLAGS_* entries
+ * in spdk/nvme_ocssd_spec.h, for this I/O.
+ *
+ * \return 0 if successfully submitted, ENOMEM if an nvme_request
+ *	     structure cannot be allocated for the I/O request
+ */
+int spdk_nvme_ocssd_ns_cmd_vector_copy(struct spdk_nvme_ns *ns,
+				       struct spdk_nvme_qpair *qpair,
+				       uint64_t *dst_lba_list, uint64_t *src_lba_list,
+				       uint32_t num_lbas,
+				       spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				       uint32_t io_flags);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/include/spdk/nvme_ocssd_spec.h b/include/spdk/nvme_ocssd_spec.h
new file mode 100644
index 000000000..42c66eb2d
--- /dev/null
+++ b/include/spdk/nvme_ocssd_spec.h
@@ -0,0 +1,313 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+ * \file
+ * Open-Channel specification definitions
+ */
+
+#ifndef SPDK_NVME_OCSSD_SPEC_H
+#define SPDK_NVME_OCSSD_SPEC_H
+
+#include "spdk/stdinc.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "spdk/assert.h"
+#include "spdk/nvme_spec.h"
+
+/** A maximum number of LBAs that can be issued by vector I/O commands */
+#define SPDK_NVME_OCSSD_MAX_LBAL_ENTRIES	64
+
+struct spdk_ocssd_dev_lba_fmt {
+	/**  Contiguous number of bits assigned to Group addressing */
+	uint8_t grp_len;
+
+	/** Contiguous number of bits assigned to PU addressing */
+	uint8_t pu_len;
+
+	/** Contiguous number of bits assigned to Chunk addressing */
+	uint8_t chk_len;
+
+	/** Contiguous number of bits assigned to logical blocks within Chunk */
+	uint8_t lbk_len;
+
+	uint8_t reserved[4];
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_ocssd_dev_lba_fmt) == 8, "Incorrect size");
+
+struct spdk_ocssd_geometry_data {
+	/** Major Version Number */
+	uint8_t		mjr;
+
+	/** Minor Version Number */
+	uint8_t		mnr;
+
+	uint8_t		reserved1[6];
+
+	/** LBA format */
+	struct spdk_ocssd_dev_lba_fmt	lbaf;
+
+	/** Media and Controller Capabilities */
+	struct {
+		/* Supports the Vector Chunk Copy I/O Command */
+		uint32_t	vec_chk_cpy	: 1;
+
+		/* Supports multiple resets when a chunk is in its free state */
+		uint32_t	multi_reset	: 1;
+
+		uint32_t	reserved	: 30;
+	} mccap;
+
+	uint8_t		reserved2[12];
+
+	/** Wear-level Index Delta Threshold */
+	uint8_t		wit;
+
+	uint8_t		reserved3[31];
+
+	/** Number of Groups */
+	uint16_t	num_grp;
+
+	/** Number of parallel units per group */
+	uint16_t	num_pu;
+
+	/** Number of chunks per parallel unit */
+	uint32_t	num_chk;
+
+	/** Chunk Size */
+	uint32_t	clba;
+
+	uint8_t		reserved4[52];
+
+	/** Minimum Write Size */
+	uint32_t	ws_min;
+
+	/** Optimal Write Size */
+	uint32_t	ws_opt;
+
+	/** Cache Minimum Write Size Units */
+	uint32_t	mw_cunits;
+
+	/** Maximum Open Chunks */
+	uint32_t	maxoc;
+
+	/** Maximum Open Chunks per PU */
+	uint32_t	maxocpu;
+
+	uint8_t		reserved5[44];
+
+	/** tRD Typical */
+	uint32_t	trdt;
+
+	/** tRD Max */
+	uint32_t	trdm;
+
+	/** tWR Typical */
+	uint32_t	twrt;
+
+	/** tWR Max */
+	uint32_t	twrm;
+
+	/** tCRS Typical */
+	uint32_t	tcrst;
+
+	/** tCRS Max */
+	uint32_t	tcrsm;
+
+	/** bytes 216-255: reserved for performance related metrics */
+	uint8_t		reserved6[40];
+
+	uint8_t		reserved7[3071 - 255];
+
+	/** bytes 3072-4095: Vendor Specific */
+	uint8_t		vs[4095 - 3071];
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_ocssd_geometry_data) == 4096, "Incorrect size");
+
+struct spdk_ocssd_chunk_information {
+	/** Chunk State */
+	struct {
+		/** if set to 1 chunk is free */
+		uint8_t free		: 1;
+
+		/** if set to 1 chunk is closed */
+		uint8_t closed		: 1;
+
+		/** if set to 1 chunk is open */
+		uint8_t open		: 1;
+
+		/** if set to 1 chunk is offline */
+		uint8_t offline		: 1;
+
+		uint8_t reserved	: 4;
+	} cs;
+
+	/** Chunk Type */
+	struct {
+		/** If set to 1 chunk must be written sequentially */
+		uint8_t seq_write		: 1;
+
+		/** If set to 1 chunk allows random writes */
+		uint8_t rnd_write		: 1;
+
+		uint8_t reserved1		: 2;
+
+		/**
+		 * If set to 1 chunk deviates from the chunk size reported
+		 * in identify geometry command.
+		 */
+		uint8_t size_deviate		: 1;
+
+		uint8_t reserved2		: 3;
+	} ct;
+
+	/** Wear-level Index */
+	uint8_t wli;
+
+	uint8_t reserved[5];
+
+	/** Starting LBA */
+	uint64_t slba;
+
+	/** Number of blocks in chunk */
+	uint64_t cnlb;
+
+	/** Write Pointer */
+	uint64_t wp;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_ocssd_chunk_information) == 32, "Incorrect size");
+
+/**
+ * Vector completion queue entry
+ */
+struct spdk_ocssd_vector_cpl {
+	/* dword 0,1 */
+	uint64_t		lba_status;	/* completion status bit array */
+
+	/* dword 2 */
+	uint16_t		sqhd;	/* submission queue head pointer */
+	uint16_t		sqid;	/* submission queue identifier */
+
+	/* dword 3 */
+	uint16_t		cid;	/* command identifier */
+	struct spdk_nvme_status	status;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_ocssd_vector_cpl) == 16, "Incorrect size");
+
+/**
+ * OCSSD admin command set opcodes
+ */
+enum spdk_ocssd_admin_opcode {
+	SPDK_OCSSD_OPC_GEOMETRY	= 0xE2
+};
+
+/**
+ * OCSSD I/O command set opcodes
+ */
+enum spdk_ocssd_io_opcode {
+	SPDK_OCSSD_OPC_VECTOR_RESET	= 0x90,
+	SPDK_OCSSD_OPC_VECTOR_WRITE	= 0x91,
+	SPDK_OCSSD_OPC_VECTOR_READ	= 0x92,
+	SPDK_OCSSD_OPC_VECTOR_COPY	= 0x93
+};
+
+/**
+ * Log page identifiers for SPDK_NVME_OPC_GET_LOG_PAGE
+ */
+enum spdk_ocssd_log_page {
+	/** Chunk Information */
+	SPDK_OCSSD_LOG_CHUNK_INFO	= 0xCA,
+};
+
+/**
+ * OCSSD feature identifiers
+ * Defines OCSSD specific features that may be configured with Set Features and
+ * retrieved with Get Features.
+ */
+enum spdk_ocssd_feat {
+	/**  Media Feedback feature identifier */
+	SPDK_OCSSD_FEAT_MEDIA_FEEDBACK	= 0xCA
+};
+
+/**
+ * OCSSD media error status codes extension.
+ * Additional error codes for status code type “2h” (media errors)
+ */
+enum spdk_ocssd_media_error_status_code {
+	/**
+	 * The chunk was either marked offline by the reset or the state
+	 * of the chunk is already offline.
+	 */
+	SPDK_OCSSD_SC_OFFLINE_CHUNK			= 0xC0,
+
+	/**
+	 * Invalid reset if chunk state is either “Free” or “Open”
+	 */
+	SPDK_OCSSD_SC_INVALID_RESET			= 0xC1,
+
+	/**
+	 * Write failed, chunk remains open.
+	 * Host should proceed to write to next write unit.
+	 */
+	SPDK_OCSSD_SC_WRITE_FAIL_WRITE_NEXT_UNIT	= 0xF0,
+
+	/**
+	 * The writes ended prematurely. The chunk state is set to closed.
+	 * The host can read up to the value of the write pointer.
+	 */
+	SPDK_OCSSD_SC_WRITE_FAIL_CHUNK_EARLY_CLOSE	= 0xF1,
+
+	/**
+	 * The write corresponds to a write out of order within an open
+	 * chunk or the write is to a closed or offline chunk.
+	 */
+	SPDK_OCSSD_SC_OUT_OF_ORDER_WRITE		= 0xF2,
+
+	/**
+	 * The data retrieved is nearing its limit for reading.
+	 * The limit is vendor specific, and only provides a hint
+	 * to the host that should refresh its data in the future.
+	 */
+	SPDK_OCSSD_SC_READ_HIGH_ECC			= 0xD0,
+};
+
+#define SPDK_OCSSD_IO_FLAGS_LIMITED_RETRY (1U << 31)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/include/spdk/nvme_spec.h b/include/spdk/nvme_spec.h
index 0658bfee7..6b180b3f5 100644
--- a/include/spdk/nvme_spec.h
+++ b/include/spdk/nvme_spec.h
@@ -96,9 +96,7 @@ union spdk_nvme_cap_register {
 		uint32_t nssrs		: 1;
 
 		/** command sets supported */
-		uint32_t css_nvm	: 1;
-
-		uint32_t css_reserved	: 7;
+		uint32_t css		: 8;
 
 		/** boot partition support */
 		uint32_t bps		: 1;
@@ -116,6 +114,17 @@ union spdk_nvme_cap_register {
 };
 SPDK_STATIC_ASSERT(sizeof(union spdk_nvme_cap_register) == 8, "Incorrect size");
 
+/**
+ * I/O Command Set Selected
+ *
+ * Only a single command set is defined as of NVMe 1.3 (NVM).
+ */
+enum spdk_nvme_cc_css {
+	SPDK_NVME_CC_CSS_NVM		= 0x0,	/**< NVM command set */
+};
+
+#define SPDK_NVME_CAP_CSS_NVM (1u << SPDK_NVME_CC_CSS_NVM) /**< NVM command set supported */
+
 union spdk_nvme_cc_register {
 	uint32_t	raw;
 	struct {
@@ -375,7 +384,8 @@ enum spdk_nvme_sgl_descriptor_type {
 	SPDK_NVME_SGL_TYPE_SEGMENT		= 0x2,
 	SPDK_NVME_SGL_TYPE_LAST_SEGMENT		= 0x3,
 	SPDK_NVME_SGL_TYPE_KEYED_DATA_BLOCK	= 0x4,
-	/* 0x5 - 0xE reserved */
+	SPDK_NVME_SGL_TYPE_TRANSPORT_DATA_BLOCK	= 0x5,
+	/* 0x6 - 0xE reserved */
 	SPDK_NVME_SGL_TYPE_VENDOR_SPECIFIC	= 0xF
 };
 
@@ -552,7 +562,8 @@ enum spdk_nvme_status_code_type {
 	SPDK_NVME_SCT_GENERIC		= 0x0,
 	SPDK_NVME_SCT_COMMAND_SPECIFIC	= 0x1,
 	SPDK_NVME_SCT_MEDIA_ERROR	= 0x2,
-	/* 0x3-0x6 - reserved */
+	SPDK_NVME_SCT_PATH		= 0x3,
+	/* 0x4-0x6 - reserved */
 	SPDK_NVME_SCT_VENDOR_SPECIFIC	= 0x7,
 };
 
@@ -659,6 +670,18 @@ enum spdk_nvme_media_error_status_code {
 	SPDK_NVME_SC_DEALLOCATED_OR_UNWRITTEN_BLOCK     = 0x87,
 };
 
+/**
+ * Path related status codes
+ */
+enum spdk_nvme_path_status_code {
+	SPDK_NVME_SC_INTERNAL_PATH_ERROR		= 0x00,
+
+	SPDK_NVME_SC_CONTROLLER_PATH_ERROR		= 0x60,
+
+	SPDK_NVME_SC_HOST_PATH_ERROR			= 0x70,
+	SPDK_NVME_SC_ABORTED_BY_HOST			= 0x71,
+};
+
 /**
  * Admin opcodes
  */
@@ -752,32 +775,58 @@ static inline enum spdk_nvme_data_transfer spdk_nvme_opc_get_data_transfer(uint8
 
 enum spdk_nvme_feat {
 	/* 0x00 - reserved */
+
+	/** cdw11 layout defined by \ref spdk_nvme_feat_arbitration */
 	SPDK_NVME_FEAT_ARBITRATION				= 0x01,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_power_management */
 	SPDK_NVME_FEAT_POWER_MANAGEMENT				= 0x02,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_lba_range_type */
 	SPDK_NVME_FEAT_LBA_RANGE_TYPE				= 0x03,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_temperature_threshold */
 	SPDK_NVME_FEAT_TEMPERATURE_THRESHOLD			= 0x04,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_error_recovery */
 	SPDK_NVME_FEAT_ERROR_RECOVERY				= 0x05,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_volatile_write_cache */
 	SPDK_NVME_FEAT_VOLATILE_WRITE_CACHE			= 0x06,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_number_of_queues */
 	SPDK_NVME_FEAT_NUMBER_OF_QUEUES				= 0x07,
 	SPDK_NVME_FEAT_INTERRUPT_COALESCING			= 0x08,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_interrupt_vector_configuration */
 	SPDK_NVME_FEAT_INTERRUPT_VECTOR_CONFIGURATION		= 0x09,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_write_atomicity */
 	SPDK_NVME_FEAT_WRITE_ATOMICITY				= 0x0A,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_async_event_configuration */
 	SPDK_NVME_FEAT_ASYNC_EVENT_CONFIGURATION		= 0x0B,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_autonomous_power_state_transition */
 	SPDK_NVME_FEAT_AUTONOMOUS_POWER_STATE_TRANSITION	= 0x0C,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_host_mem_buffer */
 	SPDK_NVME_FEAT_HOST_MEM_BUFFER				= 0x0D,
 	SPDK_NVME_FEAT_TIMESTAMP				= 0x0E,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_keep_alive_timer */
 	SPDK_NVME_FEAT_KEEP_ALIVE_TIMER				= 0x0F,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_host_controlled_thermal_management */
 	SPDK_NVME_FEAT_HOST_CONTROLLED_THERMAL_MANAGEMENT	= 0x10,
+	/** cdw11 layout defined by \ref spdk_nvme_feat_non_operational_power_state_config */
 	SPDK_NVME_FEAT_NON_OPERATIONAL_POWER_STATE_CONFIG	= 0x11,
 
+	/* 0x12-0x77 - reserved */
+
+	/* 0x78-0x7F - NVMe-MI features */
+
+	/** cdw11 layout defined by \ref spdk_nvme_feat_software_progress_marker */
 	SPDK_NVME_FEAT_SOFTWARE_PROGRESS_MARKER			= 0x80,
-	/* 0x81-0xBF - command set specific */
+
+	/** cdw11 layout defined by \ref spdk_nvme_feat_host_identifier */
 	SPDK_NVME_FEAT_HOST_IDENTIFIER				= 0x81,
 	SPDK_NVME_FEAT_HOST_RESERVE_MASK			= 0x82,
 	SPDK_NVME_FEAT_HOST_RESERVE_PERSIST			= 0x83,
+
+	/* 0x84-0xBF - command set specific (reserved) */
+
 	/* 0xC0-0xFF - vendor specific */
 };
 
+/** Bit set of attributes for DATASET MANAGEMENT commands. */
 enum spdk_nvme_dsm_attribute {
 	SPDK_NVME_DSM_ATTR_INTEGRAL_READ		= 0x1,
 	SPDK_NVME_DSM_ATTR_INTEGRAL_WRITE		= 0x2,
@@ -870,6 +919,20 @@ enum spdk_nvme_sgls_supported {
 	SPDK_NVME_SGLS_SUPPORTED_DWORD_ALIGNED		= 2,
 };
 
+/** Identify Controller data vwc.flush_broadcast values */
+enum spdk_nvme_flush_broadcast {
+	/** Support for NSID=FFFFFFFFh with Flush is not indicated. */
+	SPDK_NVME_FLUSH_BROADCAST_NOT_INDICATED		= 0,
+
+	/* 01b: Reserved */
+
+	/** Flush does not support NSID set to FFFFFFFFh. */
+	SPDK_NVME_FLUSH_BROADCAST_NOT_SUPPORTED		= 2,
+
+	/** Flush supports NSID set to FFFFFFFFh. */
+	SPDK_NVME_FLUSH_BROADCAST_SUPPORTED		= 3
+};
+
 struct __attribute__((packed)) spdk_nvme_ctrlr_data {
 	/* bytes 0-255: controller capabilities and features */
 
@@ -1174,7 +1237,8 @@ struct __attribute__((packed)) spdk_nvme_ctrlr_data {
 	/** volatile write cache */
 	struct {
 		uint8_t		present : 1;
-		uint8_t		reserved : 7;
+		uint8_t		flush_broadcast : 2;
+		uint8_t		reserved : 5;
 	} vwc;
 
 	/** atomic write unit normal */
@@ -1203,7 +1267,8 @@ struct __attribute__((packed)) spdk_nvme_ctrlr_data {
 		uint32_t	oversized_sgl : 1;
 		uint32_t	metadata_address : 1;
 		uint32_t	sgl_offset : 1;
-		uint32_t	reserved2: 11;
+		uint32_t	transport_sgl : 1;
+		uint32_t	reserved2 : 10;
 	} sgls;
 
 	uint8_t			reserved4[228];
@@ -1691,7 +1756,11 @@ struct spdk_nvme_error_information_entry {
 	uint64_t		lba;
 	uint32_t		nsid;
 	uint8_t			vendor_specific;
-	uint8_t			reserved[35];
+	uint8_t			trtype;
+	uint8_t			reserved30[2];
+	uint64_t		command_specific;
+	uint16_t		trtype_specific;
+	uint8_t			reserved42[22];
 };
 SPDK_STATIC_ASSERT(sizeof(struct spdk_nvme_error_information_entry) == 64, "Incorrect size");
 
diff --git a/include/spdk/nvmf.h b/include/spdk/nvmf.h
index 9f8a7f9a6..1f05d5c83 100644
--- a/include/spdk/nvmf.h
+++ b/include/spdk/nvmf.h
@@ -60,12 +60,15 @@ struct spdk_nvmf_request;
 struct spdk_nvmf_host;
 struct spdk_nvmf_listener;
 struct spdk_nvmf_poll_group;
+struct spdk_json_write_ctx;
 
 struct spdk_nvmf_tgt_opts {
 	uint16_t max_queue_depth;
 	uint16_t max_qpairs_per_ctrlr;
 	uint32_t in_capsule_data_size;
 	uint32_t max_io_size;
+	uint32_t max_subsystems;
+	uint32_t io_unit_size;
 };
 /**
  * Initialize the default value of opts.
@@ -83,13 +86,32 @@ void spdk_nvmf_tgt_opts_init(struct spdk_nvmf_tgt_opts *opts);
  */
 struct spdk_nvmf_tgt *spdk_nvmf_tgt_create(struct spdk_nvmf_tgt_opts *opts);
 
+typedef void (spdk_nvmf_tgt_destroy_done_fn)(void *ctx, int status);
+
 /**
  * Destroy an NVMe-oF target.
  *
  * \param tgt The target to destroy. This releases all resources.
+ * \param cb_fn A callback that will be called once the target is destroyed
+ * \param cb_arg A context argument passed to cb_fn.
+ */
+void spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt,
+			   spdk_nvmf_tgt_destroy_done_fn cb_fn,
+			   void *cb_arg);
+
+/**
+ * Write NVMe-oF target configuration into provided JSON context.
+ * \param w JSON write context
+ * \param tgt The NVMe-oF target
  */
-void spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt);
+void spdk_nvmf_tgt_write_config_json(struct spdk_json_write_ctx *w, struct spdk_nvmf_tgt *tgt);
 
+/**
+ * Function to be called once the target is listening.
+ *
+ * \param ctx Context argument passed to this function.
+ * \param status 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_nvmf_tgt_listen_done_fn)(void *ctx, int status);
 
 /**
@@ -112,6 +134,11 @@ void spdk_nvmf_tgt_listen(struct spdk_nvmf_tgt *tgt,
 			  spdk_nvmf_tgt_listen_done_fn cb_fn,
 			  void *cb_arg);
 
+/**
+ * Function to be called for each newly discovered qpair.
+ *
+ * \param qpair The newly discovered qpair.
+ */
 typedef void (*new_qpair_fn)(struct spdk_nvmf_qpair *qpair);
 
 /**
@@ -164,6 +191,21 @@ int spdk_nvmf_poll_group_add(struct spdk_nvmf_poll_group *group,
 int spdk_nvmf_poll_group_remove(struct spdk_nvmf_poll_group *group,
 				struct spdk_nvmf_qpair *qpair);
 
+typedef void (*nvmf_qpair_disconnect_cb)(void *ctx);
+
+/**
+ * Disconnect an NVMe-oF qpair
+ *
+ * \param qpair The NVMe-oF qpair to disconnect.
+ * \param cb_fn The function to call upon completion of the disconnect.
+ * \param ctx The context to pass to the callback function.
+ *
+ * \return 0 upon success.
+ * \return -ENOMEM if the function specific context could not be allocated.
+ */
+int spdk_nvmf_qpair_disconnect(struct spdk_nvmf_qpair *qpair, nvmf_qpair_disconnect_cb cb_fn,
+			       void *ctx);
+
 /**
  * Create an NVMe-oF subsystem.
  *
@@ -193,6 +235,13 @@ struct spdk_nvmf_subsystem *spdk_nvmf_subsystem_create(struct spdk_nvmf_tgt *tgt
  */
 void spdk_nvmf_subsystem_destroy(struct spdk_nvmf_subsystem *subsystem);
 
+/**
+ * Function to be called once the subsystem has changed state.
+ *
+ * \param subsytem NVMe-oF subsystem that has changed state.
+ * \param cb_arg Argument passed to callback function.
+ * \param status 0 if it completed successfully, or negative errno if it failed.
+ */
 typedef void (*spdk_nvmf_subsystem_state_change_done)(struct spdk_nvmf_subsystem *subsystem,
 		void *cb_arg, int status);
 
@@ -268,16 +317,17 @@ struct spdk_nvmf_subsystem *spdk_nvmf_tgt_find_subsystem(struct spdk_nvmf_tgt *t
  *
  * \param tgt The NVMe-oF target to iterate.
  *
- * \return a pointer to the NVMe-oF subsystem on success, or NULL on failure.
+ * \return a pointer to the first NVMe-oF subsystem on success, or NULL on failure.
  */
 struct spdk_nvmf_subsystem *spdk_nvmf_subsystem_get_first(struct spdk_nvmf_tgt *tgt);
 
 /**
  * Continue iterating over all known subsystems. If no additional subsystems, return NULL.
  *
- * \param tgt The NVMe-oF target to iterate.
+ * \param subsystem Previous subsystem returned from \ref spdk_nvmf_subsystem_get_first or
+ *                  \ref spdk_nvmf_subsystem_get_next.
  *
- * \return a pointer to the NVMe-oF subsystem on success, or NULL on failure.
+ * \return a pointer to the next NVMe-oF subsystem on success, or NULL on failure.
  */
 struct spdk_nvmf_subsystem *spdk_nvmf_subsystem_get_next(struct spdk_nvmf_subsystem *subsystem);
 
@@ -287,7 +337,7 @@ struct spdk_nvmf_subsystem *spdk_nvmf_subsystem_get_next(struct spdk_nvmf_subsys
  * May only be performed on subsystems in the PAUSED or INACTIVE states.
  *
  * \param subsystem Subsystem to add host to.
- * \param host_nqn The NQN for the host.
+ * \param hostnqn The NQN for the host.
  *
  * \return 0 on success, or negated errno value on failure.
  */
@@ -300,7 +350,7 @@ int spdk_nvmf_subsystem_add_host(struct spdk_nvmf_subsystem *subsystem,
  * May only be performed on subsystems in the PAUSED or INACTIVE states.
  *
  * \param subsystem Subsystem to remove host from.
- * \param host_nqn The NQN for the host.
+ * \param hostnqn The NQN for the host.
  *
  * \return 0 on success, or negated errno value on failure.
  */
@@ -542,6 +592,15 @@ struct spdk_nvmf_ns *spdk_nvmf_subsystem_get_next_ns(struct spdk_nvmf_subsystem
 struct spdk_nvmf_ns *spdk_nvmf_subsystem_get_ns(struct spdk_nvmf_subsystem *subsystem,
 		uint32_t nsid);
 
+/**
+ * Get the maximum number of namespaces allowed in a subsystem.
+ *
+ * \param subsystem Subsystem to query.
+ *
+ * \return Maximum number of namespaces allowed in the subsystem, or 0 for unlimited.
+ */
+uint32_t spdk_nvmf_subsystem_get_max_namespaces(const struct spdk_nvmf_subsystem *subsystem);
+
 /**
  * Get a namespace's NSID.
  *
@@ -608,20 +667,6 @@ const char *spdk_nvmf_subsystem_get_nqn(struct spdk_nvmf_subsystem *subsystem);
  */
 enum spdk_nvmf_subtype spdk_nvmf_subsystem_get_type(struct spdk_nvmf_subsystem *subsystem);
 
-/**
- * Handle the NVMe-oF request for connection.
- *
- * \param req NVMe-oF request to handle.
- */
-void spdk_nvmf_handle_connect(struct spdk_nvmf_request *req);
-
-/**
- * Disconnect the NVMe-oF controller.
- *
- * \param qpair The NVMe-oF qpair associated with the controller.
- */
-void spdk_nvmf_ctrlr_disconnect(struct spdk_nvmf_qpair *qpair);
-
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/nvmf_fc_spec.h b/include/spdk/nvmf_fc_spec.h
new file mode 100644
index 000000000..2a3435a70
--- /dev/null
+++ b/include/spdk/nvmf_fc_spec.h
@@ -0,0 +1,403 @@
+/*
+ *   BSD LICENSE
+ *
+ *   Copyright (c) 2018 Broadcom.  All Rights Reserved.
+ *   The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __NVMF_FC_SPEC_H__
+#define __NVMF_FC_SPEC_H__
+
+#include "spdk/env.h"
+#include "spdk/nvme.h"
+
+/*
+ * FC-NVMe Spec. Definitions
+ */
+
+#define FCNVME_R_CTL_CMD_REQ                   0x06
+#define FCNVME_R_CTL_DATA_OUT                  0x01
+#define FCNVME_R_CTL_CONFIRM                   0x03
+#define FCNVME_R_CTL_STATUS                    0x07
+#define FCNVME_R_CTL_ERSP_STATUS               0x08
+#define FCNVME_R_CTL_LS_REQUEST                0x32
+#define FCNVME_R_CTL_LS_RESPONSE               0x33
+#define FCNVME_R_CTL_BA_ABTS                   0x81
+
+#define FCNVME_F_CTL_END_SEQ                   0x080000
+#define FCNVME_F_CTL_SEQ_INIT                  0x010000
+
+/* END_SEQ | LAST_SEQ | Exchange Responder | SEQ init */
+#define FCNVME_F_CTL_RSP                       0x990000
+
+#define FCNVME_TYPE_BLS                        0x0
+#define FCNVME_TYPE_FC_EXCHANGE                0x08
+#define FCNVME_TYPE_NVMF_DATA                  0x28
+
+#define FCNVME_CMND_IU_FC_ID                   0x28
+#define FCNVME_CMND_IU_SCSI_ID                 0xFD
+
+#define FCNVME_CMND_IU_NODATA                  0x00
+#define FCNVME_CMND_IU_READ                    0x10
+#define FCNVME_CMND_IU_WRITE                   0x01
+
+/* BLS reject error codes */
+#define FCNVME_BLS_REJECT_UNABLE_TO_PERFORM    0x09
+#define FCNVME_BLS_REJECT_EXP_NOINFO           0x00
+#define FCNVME_BLS_REJECT_EXP_INVALID_OXID     0x03
+
+/*
+ * FC NVMe Link Services (LS) constants
+ */
+#define FCNVME_MAX_LS_REQ_SIZE                  1536
+#define FCNVME_MAX_LS_RSP_SIZE                  64
+
+#define FCNVME_LS_CA_CMD_MIN_LEN                592
+#define FCNVME_LS_CA_DESC_LIST_MIN_LEN          584
+#define FCNVME_LS_CA_DESC_MIN_LEN               576
+
+/* this value needs to be in sync with low level driver buffer size */
+#define FCNVME_MAX_LS_BUFFER_SIZE               2048
+
+#define FCNVME_GOOD_RSP_LEN                     12
+#define FCNVME_ASSOC_HOSTID_LEN                 16
+#define FCNVME_ASSOC_HOSTNQN_LEN                256
+#define FCNVME_ASSOC_SUBNQN_LEN                 256
+
+
+typedef uint64_t FCNVME_BE64;
+typedef uint32_t FCNVME_BE32;
+typedef uint16_t FCNVME_BE16;
+
+/*
+ * FC-NVME LS Commands
+ */
+enum {
+	FCNVME_LS_RSVD                = 0,
+	FCNVME_LS_RJT                 = 1,
+	FCNVME_LS_ACC                 = 2,
+	FCNVME_LS_CREATE_ASSOCIATION  = 3,
+	FCNVME_LS_CREATE_CONNECTION	  = 4,
+	FCNVME_LS_DISCONNECT          = 5,
+};
+
+/*
+ * FC-NVME Link Service Descriptors
+ */
+enum {
+	FCNVME_LSDESC_RSVD             = 0x0,
+	FCNVME_LSDESC_RQST             = 0x1,
+	FCNVME_LSDESC_RJT              = 0x2,
+	FCNVME_LSDESC_CREATE_ASSOC_CMD = 0x3,
+	FCNVME_LSDESC_CREATE_CONN_CMD  = 0x4,
+	FCNVME_LSDESC_DISCONN_CMD      = 0x5,
+	FCNVME_LSDESC_CONN_ID          = 0x6,
+	FCNVME_LSDESC_ASSOC_ID         = 0x7,
+};
+
+/*
+ * LS Reject reason_codes
+ */
+enum fcnvme_ls_rjt_reason {
+	FCNVME_RJT_RC_NONE         = 0,     /* no reason - not to be sent */
+	FCNVME_RJT_RC_INVAL        = 0x01,  /* invalid NVMe_LS command code */
+	FCNVME_RJT_RC_LOGIC        = 0x03,  /* logical error */
+	FCNVME_RJT_RC_UNAB         = 0x09,  /* unable to perform request */
+	FCNVME_RJT_RC_UNSUP        = 0x0b,  /* command not supported */
+	FCNVME_RJT_RC_INPROG       = 0x0e,  /* command already in progress */
+	FCNVME_RJT_RC_INV_ASSOC    = 0x40,  /* invalid Association ID */
+	FCNVME_RJT_RC_INV_CONN     = 0x41,  /* invalid Connection ID */
+	FCNVME_RJT_RC_INV_PARAM    = 0x42,  /* invalid parameters */
+	FCNVME_RJT_RC_INSUFF_RES   = 0x43,  /* insufficient resources */
+	FCNVME_RJT_RC_INV_HOST     = 0x44,  /* invalid or rejected host */
+	FCNVME_RJT_RC_VENDOR       = 0xff,  /* vendor specific error */
+};
+
+/*
+ * LS Reject reason_explanation codes
+ */
+enum fcnvme_ls_rjt_explan {
+	FCNVME_RJT_EXP_NONE	       = 0x00,  /* No additional explanation */
+	FCNVME_RJT_EXP_OXID_RXID   = 0x17,  /* invalid OX_ID-RX_ID combo */
+	FCNVME_RJT_EXP_UNAB_DATA   = 0x2a,  /* unable to supply data */
+	FCNVME_RJT_EXP_INV_LEN     = 0x2d,  /* invalid payload length */
+	FCNVME_RJT_EXP_INV_ESRP    = 0x40,  /* invalid ESRP ratio */
+	FCNVME_RJT_EXP_INV_CTL_ID  = 0x41,  /* invalid controller ID */
+	FCNVME_RJT_EXP_INV_Q_ID    = 0x42,  /* invalid queue ID */
+	FCNVME_RJT_EXP_SQ_SIZE     = 0x43,  /* invalid submission queue size */
+	FCNVME_RJT_EXP_INV_HOST_ID = 0x44,  /* invalid or rejected host ID */
+	FCNVME_RJT_EXP_INV_HOSTNQN = 0x45,  /* invalid or rejected host NQN */
+	FCNVME_RJT_EXP_INV_SUBNQN  = 0x46,  /* invalid or rejected subsys nqn */
+};
+
+/*
+ * NVMe over FC CMD IU
+ */
+struct spdk_nvmf_fc_cmnd_iu {
+	uint32_t scsi_id: 8,
+		 fc_id: 8,
+		 cmnd_iu_len: 16;
+	uint32_t rsvd0: 24,
+		 flags: 8;
+	uint64_t conn_id;
+	uint32_t cmnd_seq_num;
+	uint32_t data_len;
+	struct spdk_nvme_cmd cmd;
+	uint32_t rsvd1[2];
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_cmnd_iu) == 96, "size_mismatch");
+
+/*
+ * NVMe over Extended Response IU
+ */
+struct spdk_nvmf_fc_ersp_iu {
+	uint32_t status_code: 8,
+		 rsvd0: 8,
+		 ersp_len: 16;
+	uint32_t response_seq_no;
+	uint32_t transferred_data_len;
+	uint32_t rsvd1;
+	struct spdk_nvme_cpl rsp;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ersp_iu) == 32, "size_mismatch");
+
+/*
+ * Transfer ready IU
+ */
+struct spdk_nvmf_fc_xfer_rdy_iu {
+	uint32_t relative_offset;
+	uint32_t burst_len;
+	uint32_t rsvd;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_xfer_rdy_iu) == 12, "size_mismatch");
+
+/*
+ * FC NVME Frame Header
+ */
+struct spdk_nvmf_fc_frame_hdr {
+	FCNVME_BE32 r_ctl: 8,
+		    d_id: 24;
+	FCNVME_BE32 cs_ctl: 8,
+		    s_id: 24;
+	FCNVME_BE32 type: 8,
+		    f_ctl: 24;
+	FCNVME_BE32 seq_id: 8,
+		    df_ctl: 8,
+		    seq_cnt: 16;
+	FCNVME_BE32 ox_id: 16,
+		    rx_id: 16;
+	FCNVME_BE32 parameter;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_frame_hdr) == 24, "size_mismatch");
+
+/*
+ * Request payload word 0
+ */
+struct spdk_nvmf_fc_ls_rqst_w0 {
+	uint8_t	ls_cmd;			/* FCNVME_LS_xxx */
+	uint8_t zeros[3];
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_rqst_w0) == 4, "size_mismatch");
+
+/*
+ * LS request information descriptor
+ */
+struct spdk_nvmf_fc_lsdesc_rqst {
+	FCNVME_BE32 desc_tag;		/* FCNVME_LSDESC_xxx */
+	FCNVME_BE32 desc_len;
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 rsvd12;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_rqst) == 16, "size_mismatch");
+
+/*
+ * LS accept header
+ */
+struct spdk_nvmf_fc_ls_acc_hdr {
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 desc_list_len;
+	struct spdk_nvmf_fc_lsdesc_rqst rqst;
+	/* Followed by cmd-specific ACC descriptors, see next definitions */
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_acc_hdr) == 24, "size_mismatch");
+
+/*
+ * LS descriptor connection id
+ */
+struct spdk_nvmf_fc_lsdesc_conn_id {
+	FCNVME_BE32 desc_tag;
+	FCNVME_BE32 desc_len;
+	FCNVME_BE64 connection_id;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_conn_id) == 16, "size_mismatch");
+
+/*
+ * LS decriptor association id
+ */
+struct spdk_nvmf_fc_lsdesc_assoc_id {
+	FCNVME_BE32 desc_tag;
+	FCNVME_BE32 desc_len;
+	FCNVME_BE64 association_id;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_assoc_id) == 16, "size_mismatch");
+
+/*
+ * LS Create Association descriptor
+ */
+struct spdk_nvmf_fc_lsdesc_cr_assoc_cmd {
+	FCNVME_BE32  desc_tag;
+	FCNVME_BE32  desc_len;
+	FCNVME_BE16  ersp_ratio;
+	FCNVME_BE16  rsvd10;
+	FCNVME_BE32  rsvd12[9];
+	FCNVME_BE16  cntlid;
+	FCNVME_BE16  sqsize;
+	FCNVME_BE32  rsvd52;
+	uint8_t hostid[FCNVME_ASSOC_HOSTID_LEN];
+	uint8_t hostnqn[FCNVME_ASSOC_HOSTNQN_LEN];
+	uint8_t subnqn[FCNVME_ASSOC_SUBNQN_LEN];
+	uint8_t rsvd584[432];
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_cr_assoc_cmd) == 1016, "size_mismatch");
+
+/*
+ * LS Create Association reqeust payload
+ */
+struct spdk_nvmf_fc_ls_cr_assoc_rqst {
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 desc_list_len;
+	struct spdk_nvmf_fc_lsdesc_cr_assoc_cmd assoc_cmd;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_cr_assoc_rqst) == 1024, "size_mismatch");
+
+/*
+ * LS Create Association accept payload
+ */
+struct spdk_nvmf_fc_ls_cr_assoc_acc {
+	struct spdk_nvmf_fc_ls_acc_hdr hdr;
+	struct spdk_nvmf_fc_lsdesc_assoc_id assoc_id;
+	struct spdk_nvmf_fc_lsdesc_conn_id conn_id;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_cr_assoc_acc) == 56, "size_mismatch");
+
+/*
+ * LS Create IO Connection descriptor
+ */
+struct spdk_nvmf_fc_lsdesc_cr_conn_cmd {
+	FCNVME_BE32 desc_tag;
+	FCNVME_BE32 desc_len;
+	FCNVME_BE16 ersp_ratio;
+	FCNVME_BE16 rsvd10;
+	FCNVME_BE32 rsvd12[9];
+	FCNVME_BE16 qid;
+	FCNVME_BE16 sqsize;
+	FCNVME_BE32 rsvd52;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_cr_assoc_acc) == 56, "size_mismatch");
+
+/*
+ * LS Create IO Connection payload
+ */
+struct spdk_nvmf_fc_ls_cr_conn_rqst {
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 desc_list_len;
+	struct spdk_nvmf_fc_lsdesc_assoc_id assoc_id;
+	struct spdk_nvmf_fc_lsdesc_cr_conn_cmd connect_cmd;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_cr_conn_rqst) == 80, "size_mismatch");
+
+/*
+ * LS Create IO Connection accept payload
+ */
+struct spdk_nvmf_fc_ls_cr_conn_acc {
+	struct spdk_nvmf_fc_ls_acc_hdr hdr;
+	struct spdk_nvmf_fc_lsdesc_conn_id conn_id;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_cr_conn_acc) == 40, "size_mismatch");
+
+/*
+ * LS Disconnect descriptor
+ */
+struct spdk_nvmf_fc_lsdesc_disconn_cmd {
+	FCNVME_BE32 desc_tag;
+	FCNVME_BE32 desc_len;
+	FCNVME_BE32 rsvd8;
+	FCNVME_BE32 rsvd12;
+	FCNVME_BE32 rsvd16;
+	FCNVME_BE32 rsvd20;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_disconn_cmd) == 24, "size_mismatch");
+
+/*
+ * LS Disconnect payload
+ */
+struct spdk_nvmf_fc_ls_disconnect_rqst {
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 desc_list_len;
+	struct spdk_nvmf_fc_lsdesc_assoc_id assoc_id;
+	struct spdk_nvmf_fc_lsdesc_disconn_cmd disconn_cmd;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_disconnect_rqst) == 48, "size_mismatch");
+
+/*
+ * LS Disconnect accept payload
+ */
+struct spdk_nvmf_fc_ls_disconnect_acc {
+	struct spdk_nvmf_fc_ls_acc_hdr hdr;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_disconnect_acc) == 24, "size_mismatch");
+
+/*
+ * LS Reject descriptor
+ */
+struct spdk_nvmf_fc_lsdesc_rjt {
+	FCNVME_BE32 desc_tag;
+	FCNVME_BE32 desc_len;
+	uint8_t rsvd8;
+
+	uint8_t reason_code;
+	uint8_t reason_explanation;
+
+	uint8_t vendor;
+	FCNVME_BE32 rsvd12;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_lsdesc_rjt) == 16, "size_mismatch");
+
+/*
+ * LS Reject payload
+ */
+struct spdk_nvmf_fc_ls_rjt {
+	struct spdk_nvmf_fc_ls_rqst_w0 w0;
+	FCNVME_BE32 desc_list_len;
+	struct spdk_nvmf_fc_lsdesc_rqst rqst;
+	struct spdk_nvmf_fc_lsdesc_rjt rjt;
+};
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_ls_rjt) == 40, "size_mismatch");
+
+#endif
diff --git a/include/spdk/pci_ids.h b/include/spdk/pci_ids.h
index c79ef10ba..6b3e7b5f9 100644
--- a/include/spdk/pci_ids.h
+++ b/include/spdk/pci_ids.h
@@ -47,8 +47,10 @@ extern "C" {
 #define SPDK_PCI_ANY_ID			0xffff
 #define SPDK_PCI_VID_INTEL		0x8086
 #define SPDK_PCI_VID_MEMBLAZE		0x1c5f
+#define SPDK_PCI_VID_SAMSUNG		0x144d
 #define SPDK_PCI_VID_VIRTUALBOX		0x80ee
 #define SPDK_PCI_VID_VIRTIO		0x1af4
+#define SPDK_PCI_VID_CNEXLABS		0x1d1d
 
 /**
  * PCI class code for NVMe devices.
diff --git a/include/spdk/rpc.h b/include/spdk/rpc.h
index 4053f2acb..ab1fa61bd 100644
--- a/include/spdk/rpc.h
+++ b/include/spdk/rpc.h
@@ -75,15 +75,30 @@ typedef void (*spdk_rpc_method_handler)(struct spdk_jsonrpc_request *request,
  *
  * \param method Name for the registered method.
  * \param func Function registered for this method to handle the RPC request.
+ * \param state_mask State mask of the registered method. If the bit of the state of
+ * the RPC server is set in the state_mask, the method is allowed. Otherwise, it is rejected.
  */
-void spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func);
+void spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func,
+			      uint32_t state_mask);
 
-#define SPDK_RPC_REGISTER(method, func) \
+#define SPDK_RPC_STARTUP	0x1
+#define SPDK_RPC_RUNTIME	0x2
+
+#define SPDK_RPC_REGISTER(method, func, state_mask) \
 static void __attribute__((constructor)) rpc_register_##func(void) \
 { \
-	spdk_rpc_register_method(method, func); \
+	spdk_rpc_register_method(method, func, state_mask); \
 }
 
+/**
+ * Set the state mask of the RPC server. Any RPC method whose state mask is
+ * equal to the state of the RPC server is allowed.
+ *
+ * \param state_mask New state mask of the RPC server.
+ */
+void spdk_rpc_set_state(uint32_t state_mask);
+
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/scsi.h b/include/spdk/scsi.h
index ded624407..6ecea307e 100644
--- a/include/spdk/scsi.h
+++ b/include/spdk/scsi.h
@@ -41,6 +41,7 @@
 
 #include "spdk/stdinc.h"
 
+#include "spdk/bdev.h"
 #include "spdk/queue.h"
 
 #ifdef __cplusplus
@@ -140,48 +141,190 @@ struct spdk_scsi_task {
 	TAILQ_ENTRY(spdk_scsi_task) scsi_link;
 
 	uint32_t abort_id;
+	struct spdk_bdev_io_wait_entry bdev_io_wait;
 };
 
 struct spdk_scsi_port;
 struct spdk_scsi_dev;
 struct spdk_scsi_lun;
+struct spdk_scsi_desc;
 
+typedef void (*spdk_scsi_remove_cb_t)(struct spdk_scsi_lun *, void *);
+
+/**
+ * Initialize SCSI layer.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_scsi_init(void);
 
+/**
+ * Stop and clean the SCSI layer.
+ */
 void spdk_scsi_fini(void);
 
+/**
+ * Get the LUN id of the given logical unit.
+ *
+ * \param lun Logical unit.
+ *
+ * \return LUN id of the logical unit.
+ */
 int spdk_scsi_lun_get_id(const struct spdk_scsi_lun *lun);
+
+/**
+ * Get the name of the bdev associated with the given logical unit.
+ *
+ * \param lun Logical unit.
+ *
+ * \return the name of the bdev associated with the logical unit.
+ */
 const char *spdk_scsi_lun_get_bdev_name(const struct spdk_scsi_lun *lun);
+
+/**
+ * Get the SCSI device associated with the given logical unit.
+ *
+ * \param lun Logical unit.
+ *
+ * \return the SCSI device associated with the logical unit.
+ */
 const struct spdk_scsi_dev *spdk_scsi_lun_get_dev(const struct spdk_scsi_lun *lun);
 
+/**
+ * Check if the logical unit is hot removing.
+ *
+ * \param lun Logical unit
+ *
+ * \return true if removing, false otherwise.
+ */
+bool spdk_scsi_lun_is_removing(const struct spdk_scsi_lun *lun);
+
+/**
+ * Get the name of the given SCSI device.
+ *
+ * \param dev SCSI device.
+ *
+ * \return the name of the SCSI device on success, or NULL on failure.
+ */
 const char *spdk_scsi_dev_get_name(const struct spdk_scsi_dev *dev);
+
+/**
+ * Get the id of the given SCSI device.
+ *
+ * \param dev SCSI device.
+ *
+ * \return the id of the SCSI device.
+ */
 int spdk_scsi_dev_get_id(const struct spdk_scsi_dev *dev);
+
+/**
+ * Get the logical unit of the given SCSI device whose id is lun_id.
+ *
+ * \param dev SCSI device.
+ * \param lun_id Id of the logical unit.
+ *
+ * \return the logical unit on success, or NULL on failure.
+ */
 struct spdk_scsi_lun *spdk_scsi_dev_get_lun(struct spdk_scsi_dev *dev, int lun_id);
+
+/**
+ * Check whether the SCSI device has any pending task.
+ *
+ * \param dev SCSI device.
+ *
+ * \return true if the SCSI device has any pending task, or false otherwise.
+ */
 bool spdk_scsi_dev_has_pending_tasks(const struct spdk_scsi_dev *dev);
+
+/**
+ * Destruct the SCSI decice.
+ *
+ * \param dev SCSI device.
+ */
 void spdk_scsi_dev_destruct(struct spdk_scsi_dev *dev);
+
+/**
+ * Execute the SCSI management task.
+ *
+ * The task can be constructed by the function spdk_scsi_task_construct().
+ *
+ * \param dev SCSI device.
+ * \param task SCSI task to be executed.
+ * \param func Task management function to be executed.
+ */
 void spdk_scsi_dev_queue_mgmt_task(struct spdk_scsi_dev *dev, struct spdk_scsi_task *task,
 				   enum spdk_scsi_task_func func);
+/**
+ * Execute the SCSI task.
+ *
+ * The task can be constructed by the function spdk_scsi_task_construct().
+ *
+ * \param dev SCSI device.
+ * \param task Task to be executed.
+ */
 void spdk_scsi_dev_queue_task(struct spdk_scsi_dev *dev, struct spdk_scsi_task *task);
+
+/**
+ * Add a new port to the given SCSI device.
+ *
+ * \param dev SCSI device.
+ * \param id Port id.
+ * \param name Port name.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_scsi_dev_add_port(struct spdk_scsi_dev *dev, uint64_t id, const char *name);
+
+/**
+ * Delete a specified port of the given SCSI device.
+ *
+ * \param dev SCSI device.
+ * \param id Port id.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_scsi_dev_delete_port(struct spdk_scsi_dev *dev, uint64_t id);
+
+/**
+ * Get the port of the given SCSI device whose port ID is id.
+ *
+ * \param dev SCSI device.
+ * \param id Port id.
+ *
+ * \return the port of the SCSI device on success, or NULL on failure.
+ */
 struct spdk_scsi_port *spdk_scsi_dev_find_port_by_id(struct spdk_scsi_dev *dev, uint64_t id);
+
+/**
+ * Allocate I/O channels for all LUNs of the given SCSI device.
+ *
+ * \param dev SCSI device.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_scsi_dev_allocate_io_channels(struct spdk_scsi_dev *dev);
+
+/**
+ * Free I/O channels from all LUNs of the given SCSI device.
+ */
 void spdk_scsi_dev_free_io_channels(struct spdk_scsi_dev *dev);
 
 /**
- * \brief Constructs a SCSI device object using the given parameters.
+ * Construct a SCSI device object using the given parameters.
  *
  * \param name Name for the SCSI device.
  * \param bdev_name_list List of bdev names to attach to the LUNs for this SCSI
- *                       device.
- * \param lun_id_list List of LUN IDs for the LUN in this SCSI device.  Caller is
- *		      responsible for managing the memory containing this list.
- *		      lun_id_list[x] is the LUN ID for lun_list[x].
+ * device.
+ * \param lun_id_list List of LUN IDs for the LUN in this SCSI device. Caller is
+ * responsible for managing the memory containing this list. lun_id_list[x] is
+ * the LUN ID for lun_list[x].
  * \param num_luns Number of entries in lun_list and lun_id_list.
- * \param hotremove_cb Callback to lun hotremoval. Will be called
- *		       once hotremove is first triggered.
- * \param hotremove_ctx Additional argument to hotremove_cb
- * \return The constructed spdk_scsi_dev object.
+ * \param protocol_id SCSI SPC protocol identifier to report in INQUIRY data
+ * \param hotremove_cb Callback to lun hotremoval. Will be called once hotremove
+ * is first triggered.
+ * \param hotremove_ctx Additional argument to hotremove_cb.
+ *
+ * \return the constructed spdk_scsi_dev object.
  */
 struct spdk_scsi_dev *spdk_scsi_dev_construct(const char *name,
 		const char *bdev_name_list[],
@@ -191,53 +334,182 @@ struct spdk_scsi_dev *spdk_scsi_dev_construct(const char *name,
 		void (*hotremove_cb)(const struct spdk_scsi_lun *, void *),
 		void *hotremove_ctx);
 
+/**
+ * Delete a logical unit of the given SCSI device.
+ *
+ * \param dev SCSI device.
+ * \param lun Logical unit to delete.
+ */
 void spdk_scsi_dev_delete_lun(struct spdk_scsi_dev *dev, struct spdk_scsi_lun *lun);
+
+/**
+ * Add a new logical unit to the given SCSI device.
+ *
+ * \param dev SCSI device.
+ * \param bdev_name Name of the bdev attached to the logical unit.
+ * \param lun_id LUN id for the new logical unit.
+ * \param hotremove_cb Callback to lun hotremoval. Will be called once hotremove
+ * is first triggered.
+ * \param hotremove_ctx Additional argument to hotremove_cb.
+ */
 int spdk_scsi_dev_add_lun(struct spdk_scsi_dev *dev, const char *bdev_name, int lun_id,
 			  void (*hotremove_cb)(const struct spdk_scsi_lun *, void *),
 			  void *hotremove_ctx);
 
+/**
+ * Create a new SCSI port.
+ *
+ * \param id Port id.
+ * \param index Port index.
+ * \param name Port Name.
+ *
+ * \return a pointer to the created SCSI port on success, or NULL on failure.
+ */
 struct spdk_scsi_port *spdk_scsi_port_create(uint64_t id, uint16_t index, const char *name);
+
+/**
+ * Free the SCSI port.
+ *
+ * \param pport SCSI port to free.
+ */
 void spdk_scsi_port_free(struct spdk_scsi_port **pport);
-const char *spdk_scsi_port_get_name(const struct spdk_scsi_port *port);
 
+/**
+ * Get the name of the SCSI port.
+ *
+ * \param port SCSI port to query.
+ *
+ * \return the name of the SCSI port.
+ */
+const char *spdk_scsi_port_get_name(const struct spdk_scsi_port *port);
 
+/**
+ * Construct a new SCSI task.
+ *
+ * \param task SCSI task to consturct.
+ * \param cpl_fn Called when the task is completed.
+ * \param free_fn Called when the task is freed
+ */
 void spdk_scsi_task_construct(struct spdk_scsi_task *task,
 			      spdk_scsi_task_cpl cpl_fn,
 			      spdk_scsi_task_free free_fn);
+
+/**
+ * Put the SCSI task.
+ *
+ * \param task SCSI task to put.
+ */
 void spdk_scsi_task_put(struct spdk_scsi_task *task);
 
-void spdk_scsi_task_free_data(struct spdk_scsi_task *task);
 /**
  * Set internal buffer to given one. Caller is owner of that buffer.
  *
- * \param task Task struct
- * \param data Pointer to buffer
- * \param len Buffer length
+ * \param task SCSI task.
+ * \param data Pointer to buffer.
+ * \param len Buffer length.
  */
 void spdk_scsi_task_set_data(struct spdk_scsi_task *task, void *data, uint32_t len);
 
 /**
- * Allocate internal buffer of requested size. Caller is not owner of
- * returned buffer and must not free it. Caller is permitted to call
- * spdk_scsi_task_free_data() to free internal buffer if it is not required
- * anymore, but must assert that task is done and not used by library.
+ * Single buffer -> vector of buffers.
  *
- * Allocated buffer is stored in iov field of task object.
+ * \param task SCSI task.
+ * \param src A pointer to the data buffer read from.
+ * \param len Length of the data buffer read from.
  *
- * \param task Task struct
- * \param alloc_len Size of allocated buffer.
- * \return Pointer to buffer or NULL on error.
+ * \return the total length of the vector of buffers written into on success, or
+ * -1 on failure.
  */
-void *spdk_scsi_task_alloc_data(struct spdk_scsi_task *task, uint32_t alloc_len);
-
 int spdk_scsi_task_scatter_data(struct spdk_scsi_task *task, const void *src, size_t len);
+
+/**
+ * Vector of buffers -> single buffer.
+ *
+ * \param task SCSI task,
+ * \param len Length of the buffer allocated and written into.
+ *
+ * \return a pointer to the buffer allocated and written into.
+ */
 void *spdk_scsi_task_gather_data(struct spdk_scsi_task *task, int *len);
+
+/**
+ * Build sense data for the SCSI task.
+ *
+ * \param task SCSI task.
+ * \param sk Sense key.
+ * \param asc Additional sense code.
+ * \param ascq Additional sense code qualifier.
+ */
 void spdk_scsi_task_build_sense_data(struct spdk_scsi_task *task, int sk, int asc,
 				     int ascq);
+
+/**
+ * Set SCSI status code to the SCSI task. When the status code is CHECK CONDITION,
+ * sense data is build too.
+ *
+ * \param task SCSI task.
+ * \param sc Sense code
+ * \param sk Sense key.
+ * \param asc Additional sense code.
+ * \param ascq Additional sense code qualifier.
+ */
 void spdk_scsi_task_set_status(struct spdk_scsi_task *task, int sc, int sk, int asc,
 			       int ascq);
+
+/**
+ * Copy SCSI status.
+ *
+ * \param dst SCSI task whose status is written to.
+ * \param src SCSI task whose status is read from.
+ */
+void spdk_scsi_task_copy_status(struct spdk_scsi_task *dst, struct spdk_scsi_task *src);
+
+/**
+ * Process the SCSI task when no LUN is attached.
+ *
+ * \param task SCSI task.
+ */
 void spdk_scsi_task_process_null_lun(struct spdk_scsi_task *task);
 
+/**
+ * Open a logical unit for I/O operations.
+ *
+ * The registered callback function must get all tasks from the upper layer
+ *  (e.g. iSCSI) to the LUN done, free the IO channel of the LUN if allocated,
+ *  and then close the LUN.
+ *
+ * \param lun Logical unit to open.
+ * \param hotremove_cb Callback function for hot removal of the logical unit.
+ * \param hotremove_ctx Param for hot removal callback function.
+ * \param desc Output parameter for the descriptor when operation is successful.
+ * \return 0 if operation is successful, suitable errno value otherwise
+ */
+int spdk_scsi_lun_open(struct spdk_scsi_lun *lun, spdk_scsi_remove_cb_t hotremove_cb,
+		       void *hotremove_ctx, struct spdk_scsi_desc **desc);
+
+/**
+ * Close an opened logical unit.
+ *
+ * \param desc Descriptor of the logical unit.
+ */
+void spdk_scsi_lun_close(struct spdk_scsi_desc *desc);
+
+/**
+ * Allocate I/O channel for the LUN
+ *
+ * \param desc Descriptor of the logical unit.
+ *
+ * \return 0 on success, -1 on failure.
+ */
+int spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_desc *desc);
+
+/**
+ * Free I/O channel from the logical unit
+ *
+ * \param desc Descriptor of the logical unit.
+ */
+void spdk_scsi_lun_free_io_channel(struct spdk_scsi_desc *desc);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/spdk/sock.h b/include/spdk/sock.h
index b4a614c0a..6732372ee 100644
--- a/include/spdk/sock.h
+++ b/include/spdk/sock.h
@@ -47,29 +47,195 @@ extern "C" {
 struct spdk_sock;
 struct spdk_sock_group;
 
+/**
+ * Get client and server addresses of the given socket.
+ *
+ * \param sock Socket to get address.
+ * \param saddr A pointer to the buffer to hold the address of server.
+ * \param slen Length of the buffer 'saddr'.
+ * \param caddr A pointer to the buffer to hold the address of client.
+ * \param clen Length of the buffer 'caddr'.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_getaddr(struct spdk_sock *sock, char *saddr, int slen, char *caddr, int clen);
+
+/**
+ * Create a socket, connect the socket to the specified address and port (of the
+ * server), and then return the socket. This function is used by client.
+ *
+ * \param ip IP address of the server.
+ * \param port Port number of the server.
+ *
+ * \return a pointer to the connected socket on success, or NULL on failure.
+ */
 struct spdk_sock *spdk_sock_connect(const char *ip, int port);
+
+/**
+ * Create a socket, bind the socket to the specified address and port and listen
+ * on the socket, and then return the socket. This function is used by server.
+ *
+ * \param ip IP address to listen on.
+ * \param port Port number.
+ *
+ * \return a pointer to the listened socket on success, or NULL on failure.
+ */
 struct spdk_sock *spdk_sock_listen(const char *ip, int port);
+
+/**
+ * Accept a new connection from a client on the specified socket and return a
+ * socket structure which holds the connection.
+ *
+ * \param sock Listening socket.
+ *
+ * \return a pointer to the accepted socket on success, or NULL on failure.
+ */
 struct spdk_sock *spdk_sock_accept(struct spdk_sock *sock);
+
+/**
+ * Close a socket.
+ *
+ * \param sock Socket to close.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_close(struct spdk_sock **sock);
+
+/**
+ * Receive a message from the given socket.
+ *
+ * \param sock Socket to receive message.
+ * \param buf Pointer to a buffer to hold the data.
+ * \param len Length of the buffer.
+ *
+ * \return the length of the received message on success, -1 on failure.
+ */
 ssize_t spdk_sock_recv(struct spdk_sock *sock, void *buf, size_t len);
+
+/**
+ * Write message to the given socket from the I/O vector array.
+ *
+ * \param sock Socket to write to.
+ * \param iov I/O vector.
+ * \param iovcnt Number of I/O vectors in the array.
+ *
+ * \return the length of written message on success, -1 on failure.
+ */
 ssize_t spdk_sock_writev(struct spdk_sock *sock, struct iovec *iov, int iovcnt);
 
+/**
+ * Set the value used to specify the low water mark (in bytes) for this socket.
+ *
+ * \param sock Socket to set for.
+ * \param nbytes Value for recvlowat.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_set_recvlowat(struct spdk_sock *sock, int nbytes);
+
+/**
+ * Set receive buffer size for the given socket.
+ *
+ * \param sock Socket to set buffer size for.
+ * \param sz Buffer size in bytes.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_set_recvbuf(struct spdk_sock *sock, int sz);
+
+/**
+ * Set send buffer size for the given socket.
+ *
+ * \param sock Socket to set buffer size for.
+ * \param sz Buffer size in bytes.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_set_sendbuf(struct spdk_sock *sock, int sz);
 
+/**
+ * Check whether the address of socket is ipv6.
+ *
+ * \param sock Socket to check.
+ *
+ * \return true if the address of socket is ipv6, or false otherwise.
+ */
 bool spdk_sock_is_ipv6(struct spdk_sock *sock);
+
+/**
+ * Check whether the address of socket is ipv4.
+ *
+ * \param sock Socket to check.
+ *
+ * \return true if the address of socket is ipv4, or false otherwise.
+ */
 bool spdk_sock_is_ipv4(struct spdk_sock *sock);
 
+/**
+ * Callback function for spdk_sock_group_add_sock().
+ *
+ * \param arg Argument for the callback function.
+ * \param group Socket group.
+ * \param sock Socket.
+ */
 typedef void (*spdk_sock_cb)(void *arg, struct spdk_sock_group *group, struct spdk_sock *sock);
 
+/**
+ * Create a new socket group.
+ *
+ * \return a pointer to the created group on success, or NULL on failure.
+ */
 struct spdk_sock_group *spdk_sock_group_create(void);
+
+/**
+ * Add a socket to the group.
+ *
+ * \param group Socket group.
+ * \param sock Socket to add.
+ * \param cb_fn Called when the operation completes.
+ * \param cb_arg Argument passed to the callback function.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_group_add_sock(struct spdk_sock_group *group, struct spdk_sock *sock,
 			     spdk_sock_cb cb_fn, void *cb_arg);
+
+/**
+ * Remove a socket from the group.
+ *
+ * \param group Socket group.
+ * \param sock Socket to remove.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_group_remove_sock(struct spdk_sock_group *group, struct spdk_sock *sock);
+
+/**
+ * Poll incoming events for each registered socket.
+ *
+ * \param group Group to poll.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_group_poll(struct spdk_sock_group *group);
+
+/**
+ * Poll incoming events up to max_events for each registered socket.
+ *
+ * \param group Group to poll.
+ * \param max_events Number of maximum events to poll for each socket.
+ *
+ * \return the number of events on success, -1 on failure.
+ */
 int spdk_sock_group_poll_count(struct spdk_sock_group *group, int max_events);
+
+/**
+ * Close all registered sockets of the group and then remove the group.
+ *
+ * \param group Group to close.
+ *
+ * \return 0 on success, -1 on failure.
+ */
 int spdk_sock_group_close(struct spdk_sock_group **group);
 
 #ifdef __cplusplus
diff --git a/include/spdk/string.h b/include/spdk/string.h
index 3e6aecdb3..baec46c0c 100644
--- a/include/spdk/string.h
+++ b/include/spdk/string.h
@@ -47,18 +47,25 @@ extern "C" {
 /**
  * sprintf with automatic buffer allocation.
  *
- * The return value is the formatted string,
- * which should be passed to free() when no longer needed,
- * or NULL on failure.
+ * The return value is the formatted string, which should be passed to free()
+ * when no longer needed.
+ *
+ * \param format Format for the string to print.
+ *
+ * \return the formatted string on success, or NULL on failure.
  */
 char *spdk_sprintf_alloc(const char *format, ...) __attribute__((format(printf, 1, 2)));
 
 /**
  * vsprintf with automatic buffer allocation.
  *
- * The return value is the formatted string,
- * which should be passed to free() when no longer needed,
- * or NULL on failure.
+ * The return value is the formatted string, which should be passed to free()
+ * when no longer needed.
+ *
+ * \param format Format for the string to print.
+ * \param args A value that identifies a variable arguments list.
+ *
+ * \return the formatted string on success, or NULL on failure.
  */
 char *spdk_vsprintf_alloc(const char *format, va_list args);
 
@@ -66,19 +73,23 @@ char *spdk_vsprintf_alloc(const char *format, va_list args);
  * Convert string to lowercase in place.
  *
  * \param s String to convert to lowercase.
+ *
+ * \return the converted string.
  */
 char *spdk_strlwr(char *s);
 
 /**
  * Parse a delimited string with quote handling.
  *
- * \param stringp Pointer to starting location in string. *stringp will be updated to point to the
- * start of the next field, or NULL if the end of the string has been reached.
- * \param delim Null-terminated string containing the list of accepted delimiters.
+ * Note that the string will be modified in place to add the string terminator
+ * to each field.
  *
- * \return Pointer to beginning of the current field.
+ * \param stringp Pointer to starting location in string. *stringp will be updated
+ * to point to the start of the next field, or NULL if the end of the string has
+ * been reached.
+ * \param delim Null-terminated string containing the list of accepted delimiters.
  *
- * Note that the string will be modified in place to add the string terminator to each field.
+ * \return a pointer to beginning of the current field.
  */
 char *spdk_strsepq(char **stringp, const char *delim);
 
@@ -86,47 +97,52 @@ char *spdk_strsepq(char **stringp, const char *delim);
  * Trim whitespace from a string in place.
  *
  * \param s String to trim.
+ *
+ * \return the trimmed string.
  */
 char *spdk_str_trim(char *s);
 
 /**
  * Copy the string version of an error into the user supplied buffer
  *
- * \param errnum Error code
- * \param buf Pointer to a buffer in which to place the error message
- * \param buflen the size of the buffer in bytes
+ * \param errnum Error code.
+ * \param buf Pointer to a buffer in which to place the error message.
+ * \param buflen The size of the buffer in bytes.
  */
 void spdk_strerror_r(int errnum, char *buf, size_t buflen);
 
 /**
- * Return the string version of an error from a static, thread-local buffer.
- * This function is thread safe.
+ * Return the string version of an error from a static, thread-local buffer. This
+ * function is thread safe.
  *
- * \param errnum Error code
+ * \param errnum Error code.
  *
- * \return pointer to buffer upon success.
+ * \return a pointer to buffer upon success.
  */
 const char *spdk_strerror(int errnum);
 
 /**
  * Remove trailing newlines from the end of a string in place.
  *
- * Any sequence of trailing \r and \n characters is removed from the end of the string.
+ * Any sequence of trailing \\r and \\n characters is removed from the end of the
+ * string.
  *
  * \param s String to remove newline from.
- * \return Number of characters removed.
+ *
+ * \return the number of characters removed.
  */
 size_t spdk_str_chomp(char *s);
 
 /**
- * Copy a string into a fixed-size buffer, padding extra bytes with a specific character.
+ * Copy a string into a fixed-size buffer, padding extra bytes with a specific
+ * character.
+ *
+ * If src is longer than size, only size bytes will be copied.
  *
  * \param dst Pointer to destination fixed-size buffer to fill.
  * \param src Pointer to source null-terminated string to copy into dst.
  * \param size Number of bytes to fill in dst.
  * \param pad Character to pad extra space in dst beyond the size of src.
- *
- * If src is longer than size, only size bytes will be copied.
  */
 void spdk_strcpy_pad(void *dst, const char *src, size_t size, int pad);
 
@@ -137,37 +153,39 @@ void spdk_strcpy_pad(void *dst, const char *src, size_t size, int pad);
  * \param size Size of the full string pointed to by str, including padding.
  * \param pad Character that was used to pad str up to size.
  *
- * \return Length of the non-padded portion of str.
+ * \return the length of the non-padded portion of str.
  */
 size_t spdk_strlen_pad(const void *str, size_t size, int pad);
 
 /**
- * Parse an IP address into its hostname and port components.
- * This modifies the IP address in place.
+ * Parse an IP address into its hostname and port components. This modifies the
+ * IP address in place.
  *
- * \param ip A null terminated IP address, including port.
- *           Both IPv4 and IPv6 are supported.
- * \param host Will point to the start of the hostname within ip.
- *             The string will be null terminated.
- * \param port Will point to the start of the port within ip.
- *             The string will be null terminated.
+ * \param ip A null terminated IP address, including port. Both IPv4 and IPv6
+ * are supported.
+ * \param host Will point to the start of the hostname within ip. The string will
+ * be null terminated.
+ * \param port Will point to the start of the port within ip. The string will be
+ * null terminated.
  *
- * \return 0 if successful. -1 on error.
+ * \return 0 on success. -1 on failure.
  */
 int spdk_parse_ip_addr(char *ip, char **host, char **port);
 
 /**
  * Parse a string representing a number possibly followed by a binary prefix.
+ *
  * The string can contain a trailing "B" (KB,MB,GB) but it's not necessary.
  * "128K" = 128 * 1024; "2G" = 2 * 1024 * 1024; "2GB" = 2 * 1024 * 1024;
  * Additionally, lowercase "k", "m", "g" are parsed as well. They are processed
  * the same as their uppercase equivalents.
  *
- * \param cap_str null terminated string
- * \param cap pointer where the parsed capacity (in bytes) will be put
- * \param has_prefix pointer to a flag that will be set to describe whether given
- * string contains a binary prefix
- * \returned 0 on success, negative errno otherwise
+ * \param cap_str Null terminated string.
+ * \param cap Pointer where the parsed capacity (in bytes) will be put.
+ * \param has_prefix Pointer to a flag that will be set to describe whether given
+ * string contains a binary prefix.
+ *
+ * \return 0 on success, or negative errno on failure.
  */
 int spdk_parse_capacity(const char *cap_str, uint64_t *cap, bool *has_prefix);
 
@@ -176,7 +194,9 @@ int spdk_parse_capacity(const char *cap_str, uint64_t *cap, bool *has_prefix);
  *
  * \param data Buffer to check.
  * \param size Size of data in bytes.
- * \return true if data consists entirely of zeroes, or false if any byte in data is not zero.
+ *
+ * \return true if data consists entirely of zeroes, or false if any byte in data
+ * is not zero.
  */
 bool spdk_mem_all_zero(const void *data, size_t size);
 
diff --git a/include/spdk/thread.h b/include/spdk/thread.h
new file mode 100644
index 000000000..457df8bde
--- /dev/null
+++ b/include/spdk/thread.h
@@ -0,0 +1,415 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/** \file
+ * Thread
+ */
+
+#ifndef SPDK_THREAD_H_
+#define SPDK_THREAD_H_
+
+#include "spdk/stdinc.h"
+
+#include "spdk/queue.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+struct spdk_thread;
+struct spdk_io_channel_iter;
+struct spdk_poller;
+
+/**
+ * Callback function for a thread.
+ *
+ * \param ctx Context passed as arg to spdk_thread_pass_msg().
+ */
+typedef void (*spdk_thread_fn)(void *ctx);
+
+/**
+ * Function to be called to pass a message to a thread.
+ *
+ * \param fn Callback function for a thread.
+ * \param ctx Context passed to fn.
+ * \param thread_ctx Context for the thread.
+ */
+typedef void (*spdk_thread_pass_msg)(spdk_thread_fn fn, void *ctx,
+				     void *thread_ctx);
+
+/**
+ * Callback function for a poller.
+ *
+ * \param ctx Context passed as arg to spdk_poller_register().
+ * \return 0 to indicate that polling took place but no events were found;
+ * positive to indicate that polling took place and some events were processed;
+ * negative if the poller does not provide spin-wait information.
+ */
+typedef int (*spdk_poller_fn)(void *ctx);
+
+/**
+ * Function to be called to start a poller for the thread.
+ *
+ * \param thread_ctx Context for the thread.
+ * \param fn Callback function for a poller.
+ * \param arg Argument passed to callback.
+ * \param period Polling period in microseconds.
+ *
+ * \return a pointer to the poller on success, or NULL on failure.
+ */
+typedef struct spdk_poller *(*spdk_start_poller)(void *thread_ctx,
+		spdk_poller_fn fn,
+		void *arg,
+		uint64_t period_microseconds);
+
+/**
+ * Function to be called to stop a poller.
+ *
+ * \param poller Poller to stop.
+ * \param thread_ctx Context for the thread.
+ */
+typedef void (*spdk_stop_poller)(struct spdk_poller *poller, void *thread_ctx);
+
+/**
+ * I/O channel creation callback.
+ *
+ * \param io_device I/O device associated with this channel.
+ * \param ctx_buf Context for the I/O device.
+ */
+typedef int (*spdk_io_channel_create_cb)(void *io_device, void *ctx_buf);
+
+/**
+ * I/O channel destruction callback.
+ *
+ * \param io_device I/O device associated with this channel.
+ * \param ctx_buf Context for the I/O device.
+ */
+typedef void (*spdk_io_channel_destroy_cb)(void *io_device, void *ctx_buf);
+
+/**
+ * I/O device unregister callback.
+ *
+ * \param io_device Unregistered I/O device.
+ */
+typedef void (*spdk_io_device_unregister_cb)(void *io_device);
+
+/**
+ * Called on the appropriate thread for each channel associated with io_device.
+ *
+ * \param i I/O channel iterator.
+ */
+typedef void (*spdk_channel_msg)(struct spdk_io_channel_iter *i);
+
+/**
+ * spdk_for_each_channel() callback.
+ *
+ * \param i I/O channel iterator.
+ * \param status 0 if it completed successfully, or negative errno if it failed.
+ */
+typedef void (*spdk_channel_for_each_cpl)(struct spdk_io_channel_iter *i, int status);
+
+/**
+ * \brief Represents a per-thread channel for accessing an I/O device.
+ *
+ * An I/O device may be a physical entity (i.e. NVMe controller) or a software
+ *  entity (i.e. a blobstore).
+ *
+ * This structure is not part of the API - all accesses should be done through
+ *  spdk_io_channel function calls.
+ */
+struct spdk_io_channel {
+	struct spdk_thread		*thread;
+	struct io_device		*dev;
+	uint32_t			ref;
+	TAILQ_ENTRY(spdk_io_channel)	tailq;
+	spdk_io_channel_destroy_cb	destroy_cb;
+
+	/*
+	 * Modules will allocate extra memory off the end of this structure
+	 *  to store references to hardware-specific references (i.e. NVMe queue
+	 *  pairs, or references to child device spdk_io_channels (i.e.
+	 *  virtual bdevs).
+	 */
+};
+
+/**
+ * Initializes the calling thread for I/O channel allocation.
+ *
+ * \param msg_fn A function that may be called from any thread and is passed a function
+ * pointer (spdk_thread_fn) that must be called on the same thread that spdk_allocate_thread
+ * was called from.
+ * \param start_poller_fn Function to be called to start a poller for the thread.
+ * \param stop_poller_fn Function to be called to stop a poller for the thread.
+ * \param thread_ctx Context that will be passed to fn, start_poller_fn and spdk_stop_poller.
+ * \param name Human-readable name for the thread; can be retrieved with spdk_thread_get_name().
+ * The string is copied, so the pointed-to data only needs to be valid during the
+ * spdk_allocate_thread() call. May be NULL to specify no name.
+ *
+ * \return a pointer to the allocated thread on success or NULL on failure..
+ */
+struct spdk_thread *spdk_allocate_thread(spdk_thread_pass_msg msg_fn,
+		spdk_start_poller start_poller_fn,
+		spdk_stop_poller stop_poller_fn,
+		void *thread_ctx,
+		const char *name);
+
+/**
+ * Release any resources related to the calling thread for I/O channel allocation.
+ *
+ * All I/O channel references related to the calling thread must be released using
+ * spdk_put_io_channel() prior to calling this function.
+ */
+void spdk_free_thread(void);
+
+/**
+ * Get count of allocated threads.
+ */
+uint32_t spdk_thread_get_count(void);
+
+/**
+ * Get a handle to the current thread.
+ *
+ * This handle may be passed to other threads and used as the target of
+ * spdk_thread_send_msg().
+ *
+ * \sa spdk_io_channel_get_thread()
+ *
+ * \return a pointer to the current thread on success or NULL on failure.
+ */
+struct spdk_thread *spdk_get_thread(void);
+
+/**
+ * Get a thread's name.
+ *
+ * \param thread Thread to query.
+ *
+ * \return the name of the thread.
+ */
+const char *spdk_thread_get_name(const struct spdk_thread *thread);
+
+/**
+ * Send a message to the given thread.
+ *
+ * The message may be sent asynchronously - i.e. spdk_thread_send_msg may return
+ * prior to `fn` being called.
+ *
+ * \param thread The target thread.
+ * \param fn This function will be called on the given thread.
+ * \param ctx This context will be passed to fn when called.
+ */
+void spdk_thread_send_msg(const struct spdk_thread *thread, spdk_thread_fn fn, void *ctx);
+
+/**
+ * Send a message to each thread, serially.
+ *
+ * The message is sent asynchronously - i.e. spdk_for_each_thread will return
+ * prior to `fn` being called on each thread.
+ *
+ * \param fn This is the function that will be called on each thread.
+ * \param ctx This context will be passed to fn when called.
+ * \param cpl This will be called on the originating thread after `fn` has been
+ * called on each thread.
+ */
+void spdk_for_each_thread(spdk_thread_fn fn, void *ctx, spdk_thread_fn cpl);
+
+/**
+ * Register a poller on the current thread.
+ *
+ * The poller can be unregistered by calling spdk_poller_unregister().
+ *
+ * \param fn This function will be called every `period_microseconds`.
+ * \param arg Argument passed to fn.
+ * \param period_microseconds How often to call `fn`. If 0, call `fn` as often
+ *  as possible.
+ *
+ * \return a pointer to the poller registered on the current thread on success
+ * or NULL on failure.
+ */
+struct spdk_poller *spdk_poller_register(spdk_poller_fn fn,
+		void *arg,
+		uint64_t period_microseconds);
+
+/**
+ * Unregister a poller on the current thread.
+ *
+ * \param ppoller The poller to unregister.
+ */
+void spdk_poller_unregister(struct spdk_poller **ppoller);
+
+/**
+ * Register the opaque io_device context as an I/O device.
+ *
+ * After an I/O device is registered, it can return I/O channels using the
+ * spdk_get_io_channel() function.
+ *
+ * \param io_device The pointer to io_device context.
+ * \param create_cb Callback function invoked to allocate any resources required
+ * for a new I/O channel.
+ * \param destroy_cb Callback function invoked to release the resources for an
+ * I/O channel.
+ * \param ctx_size The size of the context buffer allocated to store references
+ * to allocated I/O channel resources.
+ */
+void spdk_io_device_register(void *io_device, spdk_io_channel_create_cb create_cb,
+			     spdk_io_channel_destroy_cb destroy_cb, uint32_t ctx_size);
+
+/**
+ * Unregister the opaque io_device context as an I/O device.
+ *
+ * The actual unregistration might be deferred until all active I/O channels are
+ * destroyed.
+ *
+ * \param io_device The pointer to io_device context.
+ * \param unregister_cb An optional callback function invoked to release any
+ * references to this I/O device.
+ */
+void spdk_io_device_unregister(void *io_device, spdk_io_device_unregister_cb unregister_cb);
+
+/**
+ * Get an I/O channel for the specified io_device to be used by the calling thread.
+ *
+ * The io_device context pointer specified must have previously been registered
+ * using spdk_io_device_register(). If an existing I/O channel does not exist
+ * yet for the given io_device on the calling thread, it will allocate an I/O
+ * channel and invoke the create_cb function pointer specified in spdk_io_device_register().
+ * If an I/O channel already exists for the given io_device on the calling thread,
+ * its reference is returned rather than creating a new I/O channel.
+ *
+ * \param io_device The pointer to io_device context.
+ *
+ * \return a pointer to the I/O channel for this device on success or NULL on failure.
+ */
+struct spdk_io_channel *spdk_get_io_channel(void *io_device);
+
+/**
+ * Release a reference to an I/O channel. This happens asynchronously.
+ *
+ * Actual release will happen on the same thread that called spdk_get_io_channel()
+ * for the specified I/O channel. If this releases the last reference to the
+ * I/O channel, The destroy_cb function specified in spdk_io_device_register()
+ * will be invoked to release any associated resources.
+ *
+ * \param ch I/O channel to release a reference.
+ */
+void spdk_put_io_channel(struct spdk_io_channel *ch);
+
+/**
+ * Get the context buffer associated with an I/O channel.
+ *
+ * \param ch I/O channel.
+ *
+ * \return a pointer to the context buffer.
+ */
+static inline void *
+spdk_io_channel_get_ctx(struct spdk_io_channel *ch)
+{
+	return (uint8_t *)ch + sizeof(*ch);
+}
+
+/**
+ * Get I/O channel from the context buffer. This is the inverse of
+ * spdk_io_channel_get_ctx().
+ *
+ * \param ctx The pointer to the context buffer.
+ *
+ * \return a pointer to the I/O channel associated with the context buffer.
+ */
+struct spdk_io_channel *spdk_io_channel_from_ctx(void *ctx);
+
+/**
+ * Get the thread associated with an I/O channel.
+ *
+ * \param ch I/O channel.
+ *
+ * \return a pointer to the thread associated with the I/O channel
+ */
+struct spdk_thread *spdk_io_channel_get_thread(struct spdk_io_channel *ch);
+
+/**
+ * Call 'fn' on each channel associated with io_device.
+ *
+ * This happens asynchronously, so fn may be called after spdk_for_each_channel
+ * returns. 'fn' will be called for each channel serially, such that two calls
+ * to 'fn' will not overlap in time. After 'fn' has been called, call
+ * spdk_for_each_channel_continue() to continue iterating.
+ *
+ * \param io_device 'fn' will be called on each channel associated with this io_device.
+ * \param fn Called on the appropriate thread for each channel associated with io_device.
+ * \param ctx Context buffer registered to spdk_io_channel_iter that can be obatined
+ * form the function spdk_io_channel_iter_get_ctx().
+ * \param cpl Called on the thread that spdk_for_each_channel was initially called
+ * from when 'fn' has been called on each channel.
+ */
+void spdk_for_each_channel(void *io_device, spdk_channel_msg fn, void *ctx,
+			   spdk_channel_for_each_cpl cpl);
+
+/**
+ * Get io_device from the I/O channel iterator.
+ *
+ * \param i I/O channel iterator.
+ *
+ * \return a pointer to the io_device.
+ */
+void *spdk_io_channel_iter_get_io_device(struct spdk_io_channel_iter *i);
+
+/**
+ * Get I/O channel from the I/O channel iterator.
+ *
+ * \param i I/O channel iterator.
+ *
+ * \return a pointer to the I/O channel.
+ */
+struct spdk_io_channel *spdk_io_channel_iter_get_channel(struct spdk_io_channel_iter *i);
+
+/**
+ * Get context buffer from the I/O channel iterator.
+ *
+ * \param i I/O channel iterator.
+ *
+ * \return a pointer to the context buffer.
+ */
+void *spdk_io_channel_iter_get_ctx(struct spdk_io_channel_iter *i);
+
+/**
+ * Helper function to iterate all channels for spdk_for_each_channel().
+ *
+ * \param i I/O channel iterator.
+ * \param status Status for the I/O channel iterator.
+ */
+void spdk_for_each_channel_continue(struct spdk_io_channel_iter *i, int status);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* SPDK_THREAD_H_ */
diff --git a/include/spdk/trace.h b/include/spdk/trace.h
index d0f6cb8b7..b897383eb 100644
--- a/include/spdk/trace.h
+++ b/include/spdk/trace.h
@@ -234,7 +234,7 @@ void spdk_trace_register_object(uint8_t type, char id_prefix);
  * \param new_object New object for the tpoint.
  * \param arg1_is_ptr This argument indicates whether argument1 is a pointer.
  * \param arg1_is_alias This argument indicates whether argument1 is an alias.
- * \param agr1_name Name of argument.
+ * \param arg1_name Name of argument.
  */
 void spdk_trace_register_description(const char *name, const char *short_name,
 				     uint16_t tpoint_id, uint8_t owner_type,
diff --git a/include/spdk/uuid.h b/include/spdk/uuid.h
index 774773d2a..61a58744c 100644
--- a/include/spdk/uuid.h
+++ b/include/spdk/uuid.h
@@ -58,7 +58,7 @@ SPDK_STATIC_ASSERT(sizeof(struct spdk_uuid) == 16, "Incorrect size");
 /**
  * Convert UUID in textual format into a spdk_uuid.
  *
- * \param uuid[output] User-provided UUID buffer.
+ * \param[out] uuid User-provided UUID buffer.
  * \param uuid_str UUID in textual format in C string.
  *
  * \return 0 on success, or negative errno on failure.
@@ -89,7 +89,7 @@ int spdk_uuid_compare(const struct spdk_uuid *u1, const struct spdk_uuid *u2);
 /**
  * Generate a new UUID.
  *
- * \param uuid[out] User-provided UUID buffer to fill.
+ * \param[out] uuid User-provided UUID buffer to fill.
  */
 void spdk_uuid_generate(struct spdk_uuid *uuid);
 
diff --git a/include/spdk/version.h b/include/spdk/version.h
index 6b061337c..c04385d7f 100644
--- a/include/spdk/version.h
+++ b/include/spdk/version.h
@@ -46,7 +46,7 @@
 /**
  * Minor version number (month of original release).
  */
-#define SPDK_VERSION_MINOR	4
+#define SPDK_VERSION_MINOR	7
 
 /**
  * Patch level.
@@ -59,7 +59,7 @@
 /**
  * Version string suffix.
  */
-#define SPDK_VERSION_SUFFIX	""
+#define SPDK_VERSION_SUFFIX	"-pre"
 
 /**
  * Single numeric value representing a version number for compile-time comparisons.
diff --git a/include/spdk/vhost.h b/include/spdk/vhost.h
index 7af284d84..1b0e80793 100644
--- a/include/spdk/vhost.h
+++ b/include/spdk/vhost.h
@@ -134,7 +134,7 @@ const char *spdk_vhost_dev_get_name(struct spdk_vhost_dev *vdev);
  * Get cpuset of the vhost device.  The cpuset is constant throughout the lifetime
  * of a vdev. It is a subset of SPDK app cpuset vhost was started with.
  *
- * \param dev vhost device.
+ * \param vdev vhost device.
  *
  * \return cpuset of the vdev.
  */
@@ -162,6 +162,18 @@ const struct spdk_cpuset *spdk_vhost_dev_get_cpumask(struct spdk_vhost_dev *vdev
 int spdk_vhost_set_coalescing(struct spdk_vhost_dev *vdev, uint32_t delay_base_us,
 			      uint32_t iops_threshold);
 
+/**
+ * Get coalescing parameters.
+ *
+ * \see spdk_vhost_set_coalescing
+ *
+ * \param vdev vhost device.
+ * \param delay_base_us Optional pointer to store base delay time.
+ * \param iops_threshold Optional pointer to store IOPS threshold.
+ */
+void spdk_vhost_get_coalescing(struct spdk_vhost_dev *vdev, uint32_t *delay_base_us,
+			       uint32_t *iops_threshold);
+
 /**
  * Construct an empty vhost SCSI device.  This will create a
  * Unix domain socket together with a vhost-user slave server waiting
@@ -176,7 +188,7 @@ int spdk_vhost_set_coalescing(struct spdk_vhost_dev *vdev, uint32_t delay_base_u
  *
  * \param name name of the vhost device. The name will also be used
  * for socket name, which is exactly \c socket_base_dir/name
- * \param mask string containing cpumask in hex. The leading *0x*
+ * \param cpumask string containing cpumask in hex. The leading *0x*
  * is allowed but not required. The mask itself can be constructed as:
  * ((1 << cpu0) | (1 << cpu1) | ... | (1 << cpuN)).
  *
@@ -190,9 +202,9 @@ int spdk_vhost_scsi_dev_construct(const char *name, const char *cpumask);
  * LUN0 associated with given SPDK bdev. Currently only one LUN per
  * device is supported.
  *
- * If vhost SCSI device has an active socket connection, it is
- * required that it has negotiated \c VIRTIO_SCSI_F_HOTPLUG feature
- * flag. Otherwise an -ENOTSUP error code is returned.
+ * If the vhost SCSI device has an active connection and has negotiated
+ * \c VIRTIO_SCSI_F_HOTPLUG feature,  the new SCSI target should be
+ * automatically detected by the other side.
  *
  * \param vdev vhost SCSI device.
  * \param scsi_tgt_num slot to attach to.
@@ -256,7 +268,7 @@ int spdk_vhost_scsi_dev_remove_tgt(struct spdk_vhost_dev *vdev, unsigned scsi_tg
  *
  * \param name name of the vhost blk device. The name will also be
  * used for socket name, which is exactly \c socket_base_dir/name
- * \param mask string containing cpumask in hex. The leading *0x*
+ * \param cpumask string containing cpumask in hex. The leading *0x*
  * is allowed but not required. The mask itself can be constructed as:
  * ((1 << cpu0) | (1 << cpu1) | ... | (1 << cpuN)).
  * \param dev_name bdev name to associate with this vhost device
@@ -281,7 +293,7 @@ int spdk_vhost_dev_remove(struct spdk_vhost_dev *vdev);
  * Get underlying SPDK bdev from vhost blk device. The bdev might be NULL, as it
  * could have been hotremoved.
  *
- * \param ctrl vhost blk device.
+ * \param ctrlr vhost blk device.
  *
  * \return SPDK bdev associated with given vdev.
  */
diff --git a/include/spdk_internal/lvolstore.h b/include/spdk_internal/lvolstore.h
index 89557a681..cbe1d05c2 100644
--- a/include/spdk_internal/lvolstore.h
+++ b/include/spdk_internal/lvolstore.h
@@ -37,7 +37,7 @@
 #include "spdk/blob.h"
 #include "spdk/lvol.h"
 #include "spdk/uuid.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 /* Default size of blobstore cluster */
 #define SPDK_LVS_OPTS_CLUSTER_SZ (4 * 1024 * 1024)
@@ -54,6 +54,7 @@ struct spdk_lvol_req {
 	void                    *cb_arg;
 	struct spdk_lvol	*lvol;
 	size_t			sz;
+	struct spdk_io_channel	*channel;
 	char			name[SPDK_LVOL_NAME_MAX];
 };
 
diff --git a/include/spdk_internal/virtio.h b/include/spdk_internal/virtio.h
index c6d15d82d..777440292 100644
--- a/include/spdk_internal/virtio.h
+++ b/include/spdk_internal/virtio.h
@@ -44,10 +44,14 @@
 #include "spdk/likely.h"
 #include "spdk/queue.h"
 #include "spdk/json.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/pci_ids.h"
 #include "spdk/env.h"
 
+#ifndef VHOST_USER_F_PROTOCOL_FEATURES
+#define VHOST_USER_F_PROTOCOL_FEATURES	30
+#endif
+
 /**
  * The maximum virtqueue size is 2^15. Use that value as the end of
  * descriptor chain terminator since it will never be a valid index
@@ -94,10 +98,10 @@ struct virtio_dev {
 };
 
 struct virtio_dev_ops {
-	void (*read_dev_cfg)(struct virtio_dev *hw, size_t offset,
-			     void *dst, int len);
-	void (*write_dev_cfg)(struct virtio_dev *hw, size_t offset,
-			      const void *src, int len);
+	int (*read_dev_cfg)(struct virtio_dev *hw, size_t offset,
+			    void *dst, int len);
+	int (*write_dev_cfg)(struct virtio_dev *hw, size_t offset,
+			     const void *src, int len);
 	uint8_t (*get_status)(struct virtio_dev *hw);
 	void (*set_status)(struct virtio_dev *hw, uint8_t status);
 
@@ -169,6 +173,7 @@ struct virtqueue {
 
 	uint16_t req_start;
 	uint16_t req_end;
+	uint16_t reqs_finished;
 
 	struct vq_desc_extra vq_descx[0];
 };
@@ -193,16 +198,18 @@ typedef int (*virtio_pci_create_cb)(struct virtio_pci_ctx *pci_ctx, void *ctx);
 uint16_t virtio_recv_pkts(struct virtqueue *vq, void **io, uint32_t *len, uint16_t io_cnt);
 
 /**
- * Start a new request on the current vring head position. The request will
- * be bound to given opaque cookie object. All previous requests will be
- * still kept in a ring until they are flushed or the request is aborted.
- * If a previous request is empty (no descriptors have been added) this call
- * will overwrite it. The device owning given virtqueue must be started.
+ * Start a new request on the current vring head position and associate it
+ * with an opaque cookie object. The previous request in given vq will be
+ * made visible to the device in hopes it can be processed early, but there's
+ * no guarantee it will be until the device is notified with \c
+ * virtqueue_req_flush. This behavior is simply an optimization and virtqueues
+ * must always be flushed. Empty requests (with no descriptors added) will be
+ * ignored. The device owning given virtqueue must be started.
  *
  * \param vq virtio queue
- * \param cookie opaque object to bind with this request. Once the request
+ * \param cookie opaque object to associate with this request. Once the request
  * is sent, processed and a response is received, the same object will be
- * returned to the user calling the virtio poll API.
+ * returned to the user after calling the virtio poll API.
  * \param iovcnt number of required iovectors for the request. This can be
  * higher than than the actual number of iovectors to be added.
  * \return 0 on success or negative errno otherwise. If the `iovcnt` is
@@ -212,9 +219,8 @@ uint16_t virtio_recv_pkts(struct virtqueue *vq, void **io, uint32_t *len, uint16
 int virtqueue_req_start(struct virtqueue *vq, void *cookie, int iovcnt);
 
 /**
- * Flush a virtqueue. This will make the host device see and process all
- * previously queued requests. An interrupt might be automatically sent if
- * the host device expects it. The device owning given virtqueue must be started.
+ * Flush a virtqueue. This will notify the device if it's required.
+ * The device owning given virtqueue must be started.
  *
  * \param vq virtio queue
  */
@@ -386,8 +392,9 @@ void virtio_dev_set_status(struct virtio_dev *vdev, uint8_t flag);
  * \param offset offset in bytes
  * \param src pointer to data to copy from
  * \param len length of data to copy in bytes
+ * \return 0 on success, negative errno otherwise
  */
-void virtio_dev_write_dev_config(struct virtio_dev *vdev, size_t offset, const void *src, int len);
+int virtio_dev_write_dev_config(struct virtio_dev *vdev, size_t offset, const void *src, int len);
 
 /**
  * Read raw data from the device config at given offset.  This call does not
@@ -397,8 +404,9 @@ void virtio_dev_write_dev_config(struct virtio_dev *vdev, size_t offset, const v
  * \param offset offset in bytes
  * \param dst pointer to buffer to copy data into
  * \param len length of data to copy in bytes
+ * \return 0 on success, negative errno otherwise
  */
-void virtio_dev_read_dev_config(struct virtio_dev *vdev, size_t offset, void *dst, int len);
+int virtio_dev_read_dev_config(struct virtio_dev *vdev, size_t offset, void *dst, int len);
 
 /**
  * Get backend-specific ops for given device.
diff --git a/intel-ipsec-mb b/intel-ipsec-mb
new file mode 160000
index 000000000..60a1f479c
--- /dev/null
+++ b/intel-ipsec-mb
@@ -0,0 +1 @@
+Subproject commit 60a1f479c20d5374b7efe333e3c1b6c908d66d7d
diff --git a/lib/Makefile b/lib/Makefile
index 789c924ec..8de59e3af 100644
--- a/lib/Makefile
+++ b/lib/Makefile
@@ -34,8 +34,8 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y += bdev blob blobfs conf copy cunit event json jsonrpc \
-          log lvol env_dpdk net rpc trace util nvme nvmf scsi ioat \
+DIRS-y += bdev blob blobfs conf copy event json jsonrpc \
+          log lvol net rpc sock thread trace util nvme nvmf scsi ioat \
 	  ut_mock iscsi
 ifeq ($(OS),Linux)
 DIRS-y += nbd
@@ -43,6 +43,12 @@ DIRS-$(CONFIG_VHOST) += vhost
 DIRS-$(CONFIG_VIRTIO) += virtio
 endif
 
+# If CONFIG_ENV is pointing at a directory in lib, build it.
+# Out-of-tree env implementations must be built separately by the user.
+ENV_NAME := $(notdir $(CONFIG_ENV))
+ifeq ($(abspath $(CONFIG_ENV)),$(SPDK_ROOT_DIR)/lib/$(ENV_NAME))
+DIRS-y += $(ENV_NAME)
+endif
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/lib/bdev/Makefile b/lib/bdev/Makefile
index e5291212d..d29f9a56f 100644
--- a/lib/bdev/Makefile
+++ b/lib/bdev/Makefile
@@ -52,5 +52,6 @@ DIRS-$(CONFIG_PMDK) += pmem
 endif
 
 DIRS-$(CONFIG_RBD) += rbd
+DIRS-$(CONFIG_RAID) += raid
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/bdev/aio/bdev_aio.c b/lib/bdev/aio/bdev_aio.c
index be10d3f11..c664e018b 100644
--- a/lib/bdev/aio/bdev_aio.c
+++ b/lib/bdev/aio/bdev_aio.c
@@ -39,7 +39,7 @@
 #include "spdk/conf.h"
 #include "spdk/env.h"
 #include "spdk/fd.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/json.h"
 #include "spdk/util.h"
 #include "spdk/string.h"
@@ -65,7 +65,6 @@ static struct spdk_bdev_module aio_if = {
 	.module_fini	= NULL,
 	.config_text	= bdev_aio_get_spdk_running_config,
 	.get_ctx_size	= bdev_aio_get_ctx_size,
-	.examine	= NULL,
 };
 
 SPDK_BDEV_MODULE_REGISTER(&aio_if)
@@ -174,8 +173,7 @@ bdev_aio_writev(struct file_disk *fdisk, struct spdk_io_channel *ch,
 }
 
 static void
-bdev_aio_flush(struct file_disk *fdisk, struct bdev_aio_task *aio_task,
-	       uint64_t offset, uint64_t nbytes)
+bdev_aio_flush(struct file_disk *fdisk, struct bdev_aio_task *aio_task)
 {
 	int rc = fsync(fdisk->fd);
 
@@ -329,9 +327,7 @@ static int _bdev_aio_submit_request(struct spdk_io_channel *ch, struct spdk_bdev
 		return 0;
 	case SPDK_BDEV_IO_TYPE_FLUSH:
 		bdev_aio_flush((struct file_disk *)bdev_io->bdev->ctxt,
-			       (struct bdev_aio_task *)bdev_io->driver_ctx,
-			       bdev_io->u.bdev.offset_blocks * bdev_io->bdev->blocklen,
-			       bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen);
+			       (struct bdev_aio_task *)bdev_io->driver_ctx);
 		return 0;
 
 	case SPDK_BDEV_IO_TYPE_RESET:
@@ -550,6 +546,17 @@ error_return:
 	return NULL;
 }
 
+void
+delete_aio_disk(struct spdk_bdev *bdev, spdk_delete_aio_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &aio_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 static int
 bdev_aio_initialize(void)
 {
diff --git a/lib/bdev/aio/bdev_aio.h b/lib/bdev/aio/bdev_aio.h
index 77c483f31..e8c1fc6dc 100644
--- a/lib/bdev/aio/bdev_aio.h
+++ b/lib/bdev/aio/bdev_aio.h
@@ -41,7 +41,7 @@
 #include "spdk/queue.h"
 #include "spdk/bdev.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 struct bdev_aio_task {
 	struct iocb			iocb;
@@ -65,6 +65,10 @@ struct file_disk {
 	bool			block_size_override;
 };
 
+typedef void (*spdk_delete_aio_complete)(void *cb_arg, int bdeverrno);
+
 struct spdk_bdev *create_aio_disk(const char *name, const char *filename, uint32_t block_size);
 
+void delete_aio_disk(struct spdk_bdev *bdev, spdk_delete_aio_complete cb_fn, void *cb_arg);
+
 #endif // SPDK_BDEV_AIO_H
diff --git a/lib/bdev/aio/bdev_aio_rpc.c b/lib/bdev/aio/bdev_aio_rpc.c
index a4409013a..10dd237a7 100644
--- a/lib/bdev/aio/bdev_aio_rpc.c
+++ b/lib/bdev/aio/bdev_aio_rpc.c
@@ -34,7 +34,7 @@
 #include "bdev_aio.h"
 #include "spdk/rpc.h"
 #include "spdk/util.h"
-
+#include "spdk/string.h"
 #include "spdk_internal/log.h"
 
 struct rpc_construct_aio {
@@ -87,9 +87,7 @@ spdk_rpc_construct_aio_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -97,4 +95,66 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_construct_aio(&req);
 }
-SPDK_RPC_REGISTER("construct_aio_bdev", spdk_rpc_construct_aio_bdev)
+SPDK_RPC_REGISTER("construct_aio_bdev", spdk_rpc_construct_aio_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_aio {
+	char *name;
+};
+
+static void
+free_rpc_delete_aio(struct rpc_delete_aio *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_aio_decoders[] = {
+	{"name", offsetof(struct rpc_delete_aio, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_aio_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_aio_bdev(struct spdk_jsonrpc_request *request,
+			 const struct spdk_json_val *params)
+{
+	struct rpc_delete_aio req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_aio_decoders,
+				    SPDK_COUNTOF(rpc_delete_aio_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	delete_aio_disk(bdev, _spdk_rpc_delete_aio_bdev_cb, request);
+
+	free_rpc_delete_aio(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_aio(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_aio_bdev", spdk_rpc_delete_aio_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/bdev.c b/lib/bdev/bdev.c
index 93b222ffc..44a25d515 100644
--- a/lib/bdev/bdev.c
+++ b/lib/bdev/bdev.c
@@ -39,14 +39,14 @@
 
 #include "spdk/env.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/likely.h"
 #include "spdk/queue.h"
 #include "spdk/nvme_spec.h"
 #include "spdk/scsi_spec.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 #include "spdk/string.h"
 
@@ -65,7 +65,17 @@ int __itt_init_ittlib(const char *, __itt_group_id);
 #define SPDK_BDEV_QOS_TIMESLICE_IN_USEC		1000
 #define SPDK_BDEV_SEC_TO_USEC			1000000ULL
 #define SPDK_BDEV_QOS_MIN_IO_PER_TIMESLICE	1
+#define SPDK_BDEV_QOS_MIN_BYTE_PER_TIMESLICE	512
 #define SPDK_BDEV_QOS_MIN_IOS_PER_SEC		10000
+#define SPDK_BDEV_QOS_MIN_BW_IN_MB_PER_SEC	10
+
+enum spdk_bdev_qos_type {
+	SPDK_BDEV_QOS_RW_IOPS_RATE_LIMIT = 0,
+	SPDK_BDEV_QOS_RW_BYTEPS_RATE_LIMIT,
+	SPDK_BDEV_QOS_NUM_TYPES /* Keep last */
+};
+
+static const char *qos_type_str[SPDK_BDEV_QOS_NUM_TYPES] = {"Limit_IOPS", "Limit_BWPS"};
 
 struct spdk_bdev_mgr {
 	struct spdk_mempool *bdev_io_pool;
@@ -94,6 +104,11 @@ static struct spdk_bdev_mgr g_bdev_mgr = {
 	.module_init_complete = false,
 };
 
+static struct spdk_bdev_opts	g_bdev_opts = {
+	.bdev_io_pool_size = SPDK_BDEV_IO_POOL_SIZE,
+	.bdev_io_cache_size = SPDK_BDEV_IO_CACHE_SIZE,
+};
+
 static spdk_bdev_init_cb	g_init_cb_fn = NULL;
 static void			*g_init_cb_arg = NULL;
 
@@ -101,6 +116,40 @@ static spdk_bdev_fini_cb	g_fini_cb_fn = NULL;
 static void			*g_fini_cb_arg = NULL;
 static struct spdk_thread	*g_fini_thread = NULL;
 
+struct spdk_bdev_qos {
+	/** Rate limit, in I/O per second */
+	uint64_t iops_rate_limit;
+
+	/** Rate limit, in byte per second */
+	uint64_t byte_rate_limit;
+
+	/** The channel that all I/O are funneled through */
+	struct spdk_bdev_channel *ch;
+
+	/** The thread on which the poller is running. */
+	struct spdk_thread *thread;
+
+	/** Queue of I/O waiting to be issued. */
+	bdev_io_tailq_t queued;
+
+	/** Maximum allowed IOs to be issued in one timeslice (e.g., 1ms) and
+	 *  only valid for the master channel which manages the outstanding IOs. */
+	uint64_t max_ios_per_timeslice;
+
+	/** Maximum allowed bytes to be issued in one timeslice (e.g., 1ms) and
+	 *  only valid for the master channel which manages the outstanding IOs. */
+	uint64_t max_byte_per_timeslice;
+
+	/** Submitted IO in one timeslice (e.g., 1ms) */
+	uint64_t io_submitted_this_timeslice;
+
+	/** Submitted byte in one timeslice (e.g., 1ms) */
+	uint64_t byte_submitted_this_timeslice;
+
+	/** Polller that processes queued I/O commands each time slice. */
+	struct spdk_poller *poller;
+};
+
 struct spdk_bdev_mgmt_channel {
 	bdev_io_stailq_t need_buf_small;
 	bdev_io_stailq_t need_buf_large;
@@ -114,15 +163,18 @@ struct spdk_bdev_mgmt_channel {
 	 */
 	bdev_io_stailq_t per_thread_cache;
 	uint32_t	per_thread_cache_count;
+	uint32_t	bdev_io_cache_size;
+
+	TAILQ_HEAD(, spdk_bdev_shared_resource)	shared_resources;
+	TAILQ_HEAD(, spdk_bdev_io_wait_entry)	io_wait_queue;
 };
 
 /*
- * Per-module (or per-io_device) channel. Multiple bdevs built on the same io_device
+ * Per-module (or per-io_device) data. Multiple bdevs built on the same io_device
  * will queue here their IO that awaits retry. It makes it posible to retry sending
  * IO to one bdev after IO from other bdev completes.
  */
-struct spdk_bdev_module_channel {
-
+struct spdk_bdev_shared_resource {
 	/* The bdev management channel */
 	struct spdk_bdev_mgmt_channel *mgmt_ch;
 
@@ -143,7 +195,13 @@ struct spdk_bdev_module_channel {
 	 */
 	uint64_t		nomem_threshold;
 
-	TAILQ_ENTRY(spdk_bdev_module_channel) link;
+	/* I/O channel allocated by a bdev module */
+	struct spdk_io_channel	*shared_ch;
+
+	/* Refcount of bdev channels using this resource */
+	uint32_t		ref;
+
+	TAILQ_ENTRY(spdk_bdev_shared_resource) link;
 };
 
 #define BDEV_CH_RESET_IN_PROGRESS	(1 << 0)
@@ -155,8 +213,8 @@ struct spdk_bdev_channel {
 	/* The channel for the underlying device */
 	struct spdk_io_channel	*channel;
 
-	/* Channel for the bdev module */
-	struct spdk_bdev_module_channel	*module_ch;
+	/* Per io_device per thread data */
+	struct spdk_bdev_shared_resource *shared_resource;
 
 	struct spdk_bdev_io_stat stat;
 
@@ -174,6 +232,7 @@ struct spdk_bdev_channel {
 	uint64_t		start_tsc;
 	uint64_t		interval_tsc;
 	__itt_string_handle	*handle;
+	struct spdk_bdev_io_stat prev_stat;
 #endif
 
 };
@@ -182,15 +241,51 @@ struct spdk_bdev_desc {
 	struct spdk_bdev		*bdev;
 	spdk_bdev_remove_cb_t		remove_cb;
 	void				*remove_ctx;
+	bool				remove_scheduled;
 	bool				write;
 	TAILQ_ENTRY(spdk_bdev_desc)	link;
 };
 
+struct spdk_bdev_iostat_ctx {
+	struct spdk_bdev_io_stat *stat;
+	spdk_bdev_get_device_stat_cb cb;
+	void *cb_arg;
+};
+
 #define __bdev_to_io_dev(bdev)		(((char *)bdev) + 1)
 #define __bdev_from_io_dev(io_dev)	((struct spdk_bdev *)(((char *)io_dev) - 1))
 
 static void spdk_bdev_write_zeroes_split(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg);
 
+void
+spdk_bdev_get_opts(struct spdk_bdev_opts *opts)
+{
+	*opts = g_bdev_opts;
+}
+
+int
+spdk_bdev_set_opts(struct spdk_bdev_opts *opts)
+{
+	uint32_t min_pool_size;
+
+	/*
+	 * Add 1 to the thread count to account for the extra mgmt_ch that gets created during subsystem
+	 *  initialization.  A second mgmt_ch will be created on the same thread when the application starts
+	 *  but before the deferred put_io_channel event is executed for the first mgmt_ch.
+	 */
+	min_pool_size = opts->bdev_io_cache_size * (spdk_thread_get_count() + 1);
+	if (opts->bdev_io_pool_size < min_pool_size) {
+		SPDK_ERRLOG("bdev_io_pool_size %" PRIu32 " is not compatible with bdev_io_cache_size %" PRIu32
+			    " and %" PRIu32 " threads\n", opts->bdev_io_pool_size, opts->bdev_io_cache_size,
+			    spdk_thread_get_count());
+		SPDK_ERRLOG("bdev_io_pool_size must be at least %" PRIu32 "\n", min_pool_size);
+		return -1;
+	}
+
+	g_bdev_opts = *opts;
+	return 0;
+}
+
 struct spdk_bdev *
 spdk_bdev_first(void)
 {
@@ -209,7 +304,7 @@ spdk_bdev_next(struct spdk_bdev *prev)
 {
 	struct spdk_bdev *bdev;
 
-	bdev = TAILQ_NEXT(prev, link);
+	bdev = TAILQ_NEXT(prev, internal.link);
 	if (bdev) {
 		SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Continuing bdev iteration at %s\n", bdev->name);
 	}
@@ -221,10 +316,10 @@ static struct spdk_bdev *
 _bdev_next_leaf(struct spdk_bdev *bdev)
 {
 	while (bdev != NULL) {
-		if (bdev->claim_module == NULL) {
+		if (bdev->internal.claim_module == NULL) {
 			return bdev;
 		} else {
-			bdev = TAILQ_NEXT(bdev, link);
+			bdev = TAILQ_NEXT(bdev, internal.link);
 		}
 	}
 
@@ -250,7 +345,7 @@ spdk_bdev_next_leaf(struct spdk_bdev *prev)
 {
 	struct spdk_bdev *bdev;
 
-	bdev = _bdev_next_leaf(TAILQ_NEXT(prev, link));
+	bdev = _bdev_next_leaf(TAILQ_NEXT(prev, internal.link));
 
 	if (bdev) {
 		SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Continuing bdev iteration at %s\n", bdev->name);
@@ -282,17 +377,33 @@ spdk_bdev_get_by_name(const char *bdev_name)
 	return NULL;
 }
 
-static void
-spdk_bdev_io_set_buf(struct spdk_bdev_io *bdev_io, void *buf)
+size_t
+spdk_bdev_io_set_buf(struct spdk_bdev_io *bdev_io, void *buf, size_t len)
 {
-	assert(bdev_io->get_buf_cb != NULL);
-	assert(buf != NULL);
-	assert(bdev_io->u.bdev.iovs != NULL);
+	struct iovec **iovs;
+	int *iovcnt;
+	void *aligned_buf;
+
+	iovs = &bdev_io->u.bdev.iovs;
+	iovcnt = &bdev_io->u.bdev.iovcnt;
 
-	bdev_io->buf = buf;
-	bdev_io->u.bdev.iovs[0].iov_base = (void *)((unsigned long)((char *)buf + 512) & ~511UL);
-	bdev_io->u.bdev.iovs[0].iov_len = bdev_io->buf_len;
-	bdev_io->get_buf_cb(bdev_io->ch->channel, bdev_io);
+	if (*iovs == NULL || *iovcnt == 0) {
+		*iovs = &bdev_io->iov;
+		*iovcnt = 1;
+	}
+
+	if (buf != NULL) {
+		aligned_buf = (void *)(((uintptr_t)buf + 511) & ~511UL);
+		len = len - ((uintptr_t)aligned_buf - (uintptr_t)buf);
+	} else {
+		aligned_buf = NULL;
+		assert(len == 0);
+	}
+
+	(*iovs)[0].iov_base = aligned_buf;
+	(*iovs)[0].iov_len = len;
+
+	return len;
 }
 
 static void
@@ -303,26 +414,37 @@ spdk_bdev_io_put_buf(struct spdk_bdev_io *bdev_io)
 	void *buf;
 	bdev_io_stailq_t *stailq;
 	struct spdk_bdev_mgmt_channel *ch;
+	size_t len;
 
 	assert(bdev_io->u.bdev.iovcnt == 1);
 
-	buf = bdev_io->buf;
-	ch = bdev_io->ch->module_ch->mgmt_ch;
+	buf = bdev_io->internal.buf;
+	ch = bdev_io->internal.ch->shared_resource->mgmt_ch;
 
-	if (bdev_io->buf_len <= SPDK_BDEV_SMALL_BUF_MAX_SIZE) {
+	if (bdev_io->internal.buf_len <= SPDK_BDEV_SMALL_BUF_MAX_SIZE) {
 		pool = g_bdev_mgr.buf_small_pool;
 		stailq = &ch->need_buf_small;
+		len = SPDK_BDEV_SMALL_BUF_MAX_SIZE + 512;
 	} else {
 		pool = g_bdev_mgr.buf_large_pool;
 		stailq = &ch->need_buf_large;
+		len = SPDK_BDEV_LARGE_BUF_MAX_SIZE + 512;
 	}
 
 	if (STAILQ_EMPTY(stailq)) {
 		spdk_mempool_put(pool, buf);
 	} else {
 		tmp = STAILQ_FIRST(stailq);
-		STAILQ_REMOVE_HEAD(stailq, buf_link);
-		spdk_bdev_io_set_buf(tmp, buf);
+		STAILQ_REMOVE_HEAD(stailq, internal.buf_link);
+		len = spdk_bdev_io_set_buf(tmp, buf, len);
+		if (len < tmp->internal.buf_len) {
+			SPDK_ERRLOG("Unable to use buffer due to alignment\n");
+			spdk_mempool_put(pool, buf);
+			spdk_bdev_io_set_buf(tmp, NULL, 0);
+			return;
+		}
+		tmp->internal.buf = buf;
+		tmp->internal.get_buf_cb(tmp->internal.ch->channel, tmp);
 	}
 }
 
@@ -333,35 +455,50 @@ spdk_bdev_io_get_buf(struct spdk_bdev_io *bdev_io, spdk_bdev_io_get_buf_cb cb, u
 	bdev_io_stailq_t *stailq;
 	void *buf = NULL;
 	struct spdk_bdev_mgmt_channel *mgmt_ch;
+	size_t buf_len;
 
 	assert(cb != NULL);
 	assert(bdev_io->u.bdev.iovs != NULL);
 
 	if (spdk_unlikely(bdev_io->u.bdev.iovs[0].iov_base != NULL)) {
 		/* Buffer already present */
-		cb(bdev_io->ch->channel, bdev_io);
+		cb(bdev_io->internal.ch->channel, bdev_io);
 		return;
 	}
 
 	assert(len <= SPDK_BDEV_LARGE_BUF_MAX_SIZE);
-	mgmt_ch = bdev_io->ch->module_ch->mgmt_ch;
+	mgmt_ch = bdev_io->internal.ch->shared_resource->mgmt_ch;
 
-	bdev_io->buf_len = len;
-	bdev_io->get_buf_cb = cb;
+	bdev_io->internal.buf_len = len;
+	bdev_io->internal.get_buf_cb = cb;
 	if (len <= SPDK_BDEV_SMALL_BUF_MAX_SIZE) {
 		pool = g_bdev_mgr.buf_small_pool;
 		stailq = &mgmt_ch->need_buf_small;
+		buf_len = SPDK_BDEV_SMALL_BUF_MAX_SIZE + 512;
 	} else {
 		pool = g_bdev_mgr.buf_large_pool;
 		stailq = &mgmt_ch->need_buf_large;
+		buf_len = SPDK_BDEV_LARGE_BUF_MAX_SIZE + 512;
 	}
 
 	buf = spdk_mempool_get(pool);
 
 	if (!buf) {
-		STAILQ_INSERT_TAIL(stailq, bdev_io, buf_link);
+		STAILQ_INSERT_TAIL(stailq, bdev_io, internal.buf_link);
 	} else {
-		spdk_bdev_io_set_buf(bdev_io, buf);
+		size_t aligned_len;
+
+		aligned_len = spdk_bdev_io_set_buf(bdev_io, buf, buf_len);
+		if (aligned_len < len) {
+			SPDK_ERRLOG("Unable to use buffer after alignment calculations.\n");
+			spdk_mempool_put(pool, buf);
+			spdk_bdev_io_set_buf(bdev_io, NULL, 0);
+			STAILQ_INSERT_TAIL(stailq, bdev_io, internal.buf_link);
+			return;
+		}
+
+		bdev_io->internal.buf = buf;
+		bdev_io->internal.get_buf_cb(bdev_io->internal.ch->channel, bdev_io);
 	}
 }
 
@@ -371,7 +508,7 @@ spdk_bdev_module_get_max_ctx_size(void)
 	struct spdk_bdev_module *bdev_module;
 	int max_bdev_module_size = 0;
 
-	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, tailq) {
+	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, internal.tailq) {
 		if (bdev_module->get_ctx_size && bdev_module->get_ctx_size() > max_bdev_module_size) {
 			max_bdev_module_size = bdev_module->get_ctx_size();
 		}
@@ -385,7 +522,7 @@ spdk_bdev_config_text(FILE *fp)
 {
 	struct spdk_bdev_module *bdev_module;
 
-	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, tailq) {
+	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, internal.tailq) {
 		if (bdev_module->config_text) {
 			bdev_module->config_text(fp);
 		}
@@ -402,13 +539,22 @@ spdk_bdev_subsystem_config_json(struct spdk_json_write_ctx *w)
 
 	spdk_json_write_array_begin(w);
 
-	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, tailq) {
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_string(w, "method", "set_bdev_options");
+	spdk_json_write_name(w, "params");
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_uint32(w, "bdev_io_pool_size", g_bdev_opts.bdev_io_pool_size);
+	spdk_json_write_named_uint32(w, "bdev_io_cache_size", g_bdev_opts.bdev_io_cache_size);
+	spdk_json_write_object_end(w);
+	spdk_json_write_object_end(w);
+
+	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, internal.tailq) {
 		if (bdev_module->config_json) {
 			bdev_module->config_json(w);
 		}
 	}
 
-	TAILQ_FOREACH(bdev, &g_bdev_mgr.bdevs, link) {
+	TAILQ_FOREACH(bdev, &g_bdev_mgr.bdevs, internal.link) {
 		spdk_bdev_config_json(bdev, w);
 	}
 
@@ -419,12 +565,26 @@ static int
 spdk_bdev_mgmt_channel_create(void *io_device, void *ctx_buf)
 {
 	struct spdk_bdev_mgmt_channel *ch = ctx_buf;
+	struct spdk_bdev_io *bdev_io;
+	uint32_t i;
 
 	STAILQ_INIT(&ch->need_buf_small);
 	STAILQ_INIT(&ch->need_buf_large);
 
 	STAILQ_INIT(&ch->per_thread_cache);
+	ch->bdev_io_cache_size = g_bdev_opts.bdev_io_cache_size;
+
+	/* Pre-populate bdev_io cache to ensure this thread cannot be starved. */
 	ch->per_thread_cache_count = 0;
+	for (i = 0; i < ch->bdev_io_cache_size; i++) {
+		bdev_io = spdk_mempool_get(g_bdev_mgr.bdev_io_pool);
+		assert(bdev_io != NULL);
+		ch->per_thread_cache_count++;
+		STAILQ_INSERT_TAIL(&ch->per_thread_cache, bdev_io, internal.buf_link);
+	}
+
+	TAILQ_INIT(&ch->shared_resources);
+	TAILQ_INIT(&ch->io_wait_queue);
 
 	return 0;
 }
@@ -436,12 +596,16 @@ spdk_bdev_mgmt_channel_destroy(void *io_device, void *ctx_buf)
 	struct spdk_bdev_io *bdev_io;
 
 	if (!STAILQ_EMPTY(&ch->need_buf_small) || !STAILQ_EMPTY(&ch->need_buf_large)) {
-		SPDK_ERRLOG("Pending I/O list wasn't empty on channel free\n");
+		SPDK_ERRLOG("Pending I/O list wasn't empty on mgmt channel free\n");
+	}
+
+	if (!TAILQ_EMPTY(&ch->shared_resources)) {
+		SPDK_ERRLOG("Module channel list wasn't empty on mgmt channel free\n");
 	}
 
 	while (!STAILQ_EMPTY(&ch->per_thread_cache)) {
 		bdev_io = STAILQ_FIRST(&ch->per_thread_cache);
-		STAILQ_REMOVE_HEAD(&ch->per_thread_cache, buf_link);
+		STAILQ_REMOVE_HEAD(&ch->per_thread_cache, internal.buf_link);
 		ch->per_thread_cache_count--;
 		spdk_mempool_put(g_bdev_mgr.bdev_io_pool, (void *)bdev_io);
 	}
@@ -464,9 +628,11 @@ spdk_bdev_init_complete(int rc)
 	 * For modules that need to know when subsystem init is complete,
 	 * inform them now.
 	 */
-	TAILQ_FOREACH(m, &g_bdev_mgr.bdev_modules, tailq) {
-		if (m->init_complete) {
-			m->init_complete();
+	if (rc == 0) {
+		TAILQ_FOREACH(m, &g_bdev_mgr.bdev_modules, internal.tailq) {
+			if (m->init_complete) {
+				m->init_complete();
+			}
 		}
 	}
 
@@ -492,8 +658,8 @@ spdk_bdev_module_action_complete(void)
 	 * exist, return immediately since we cannot finish bdev subsystem
 	 * initialization until all are completed.
 	 */
-	TAILQ_FOREACH(m, &g_bdev_mgr.bdev_modules, tailq) {
-		if (m->action_in_progress > 0) {
+	TAILQ_FOREACH(m, &g_bdev_mgr.bdev_modules, internal.tailq) {
+		if (m->internal.action_in_progress > 0) {
 			return;
 		}
 	}
@@ -509,8 +675,8 @@ spdk_bdev_module_action_complete(void)
 static void
 spdk_bdev_module_action_done(struct spdk_bdev_module *module)
 {
-	assert(module->action_in_progress > 0);
-	module->action_in_progress--;
+	assert(module->internal.action_in_progress > 0);
+	module->internal.action_in_progress--;
 	spdk_bdev_module_action_complete();
 }
 
@@ -526,48 +692,13 @@ spdk_bdev_module_examine_done(struct spdk_bdev_module *module)
 	spdk_bdev_module_action_done(module);
 }
 
-static int
-spdk_bdev_module_channel_create(void *io_device, void *ctx_buf)
-{
-	struct spdk_bdev_module_channel *ch = ctx_buf;
-	struct spdk_io_channel *mgmt_ch;
-
-	ch->io_outstanding = 0;
-	TAILQ_INIT(&ch->nomem_io);
-	ch->nomem_threshold = 0;
-
-	mgmt_ch = spdk_get_io_channel(&g_bdev_mgr);
-	if (!mgmt_ch) {
-		return -1;
-	}
-
-	ch->mgmt_ch = spdk_io_channel_get_ctx(mgmt_ch);
-
-	return 0;
-}
-
-static void
-spdk_bdev_module_channel_destroy(void *io_device, void *ctx_buf)
-{
-	struct spdk_bdev_module_channel *ch = ctx_buf;
-
-	assert(ch->io_outstanding == 0);
-	assert(TAILQ_EMPTY(&ch->nomem_io));
-
-	spdk_put_io_channel(spdk_io_channel_from_ctx(ch->mgmt_ch));
-}
-
 static int
 spdk_bdev_modules_init(void)
 {
 	struct spdk_bdev_module *module;
 	int rc = 0;
 
-	TAILQ_FOREACH(module, &g_bdev_mgr.bdev_modules, tailq) {
-		spdk_io_device_register(module,
-					spdk_bdev_module_channel_create,
-					spdk_bdev_module_channel_destroy,
-					sizeof(struct spdk_bdev_module_channel));
+	TAILQ_FOREACH(module, &g_bdev_mgr.bdev_modules, internal.tailq) {
 		rc = module->module_init();
 		if (rc != 0) {
 			break;
@@ -577,22 +708,55 @@ spdk_bdev_modules_init(void)
 	g_bdev_mgr.module_init_complete = true;
 	return rc;
 }
+
+static void
+spdk_bdev_init_failed(void *cb_arg)
+{
+	spdk_bdev_init_complete(-1);
+	return;
+}
+
 void
 spdk_bdev_initialize(spdk_bdev_init_cb cb_fn, void *cb_arg)
 {
+	struct spdk_conf_section *sp;
+	struct spdk_bdev_opts bdev_opts;
+	int32_t bdev_io_pool_size, bdev_io_cache_size;
 	int cache_size;
 	int rc = 0;
 	char mempool_name[32];
 
 	assert(cb_fn != NULL);
 
+	sp = spdk_conf_find_section(NULL, "Bdev");
+	if (sp != NULL) {
+		spdk_bdev_get_opts(&bdev_opts);
+
+		bdev_io_pool_size = spdk_conf_section_get_intval(sp, "BdevIoPoolSize");
+		if (bdev_io_pool_size >= 0) {
+			bdev_opts.bdev_io_pool_size = bdev_io_pool_size;
+		}
+
+		bdev_io_cache_size = spdk_conf_section_get_intval(sp, "BdevIoCacheSize");
+		if (bdev_io_cache_size >= 0) {
+			bdev_opts.bdev_io_cache_size = bdev_io_cache_size;
+		}
+
+		if (spdk_bdev_set_opts(&bdev_opts)) {
+			spdk_bdev_init_complete(-1);
+			return;
+		}
+
+		assert(memcmp(&bdev_opts, &g_bdev_opts, sizeof(bdev_opts)) == 0);
+	}
+
 	g_init_cb_fn = cb_fn;
 	g_init_cb_arg = cb_arg;
 
 	snprintf(mempool_name, sizeof(mempool_name), "bdev_io_%d", getpid());
 
 	g_bdev_mgr.bdev_io_pool = spdk_mempool_create(mempool_name,
-				  SPDK_BDEV_IO_POOL_SIZE,
+				  g_bdev_opts.bdev_io_pool_size,
 				  sizeof(struct spdk_bdev_io) +
 				  spdk_bdev_module_get_max_ctx_size(),
 				  0,
@@ -606,10 +770,10 @@ spdk_bdev_initialize(spdk_bdev_init_cb cb_fn, void *cb_arg)
 
 	/**
 	 * Ensure no more than half of the total buffers end up local caches, by
-	 *   using spdk_env_get_core_count() to determine how many local caches we need
+	 *   using spdk_thread_get_count() to determine how many local caches we need
 	 *   to account for.
 	 */
-	cache_size = BUF_SMALL_POOL_SIZE / (2 * spdk_env_get_core_count());
+	cache_size = BUF_SMALL_POOL_SIZE / (2 * spdk_thread_get_count());
 	snprintf(mempool_name, sizeof(mempool_name), "buf_small_pool_%d", getpid());
 
 	g_bdev_mgr.buf_small_pool = spdk_mempool_create(mempool_name,
@@ -623,7 +787,7 @@ spdk_bdev_initialize(spdk_bdev_init_cb cb_fn, void *cb_arg)
 		return;
 	}
 
-	cache_size = BUF_LARGE_POOL_SIZE / (2 * spdk_env_get_core_count());
+	cache_size = BUF_LARGE_POOL_SIZE / (2 * spdk_thread_get_count());
 	snprintf(mempool_name, sizeof(mempool_name), "buf_large_pool_%d", getpid());
 
 	g_bdev_mgr.buf_large_pool = spdk_mempool_create(mempool_name,
@@ -656,7 +820,7 @@ spdk_bdev_initialize(spdk_bdev_init_cb cb_fn, void *cb_arg)
 	rc = spdk_bdev_modules_init();
 	if (rc != 0) {
 		SPDK_ERRLOG("bdev modules init failed\n");
-		spdk_bdev_init_complete(-1);
+		spdk_bdev_finish(spdk_bdev_init_failed, NULL);
 		return;
 	}
 
@@ -668,10 +832,10 @@ spdk_bdev_mgr_unregister_cb(void *io_device)
 {
 	spdk_bdev_fini_cb cb_fn = g_fini_cb_fn;
 
-	if (spdk_mempool_count(g_bdev_mgr.bdev_io_pool) != SPDK_BDEV_IO_POOL_SIZE) {
+	if (spdk_mempool_count(g_bdev_mgr.bdev_io_pool) != g_bdev_opts.bdev_io_pool_size) {
 		SPDK_ERRLOG("bdev IO pool count is %zu but should be %u\n",
 			    spdk_mempool_count(g_bdev_mgr.bdev_io_pool),
-			    SPDK_BDEV_IO_POOL_SIZE);
+			    g_bdev_opts.bdev_io_pool_size);
 	}
 
 	if (spdk_mempool_count(g_bdev_mgr.buf_small_pool) != BUF_SMALL_POOL_SIZE) {
@@ -709,35 +873,36 @@ spdk_bdev_module_finish_iter(void *arg)
 	if (!g_resume_bdev_module) {
 		bdev_module = TAILQ_FIRST(&g_bdev_mgr.bdev_modules);
 	} else {
-		bdev_module = TAILQ_NEXT(g_resume_bdev_module, tailq);
+		bdev_module = TAILQ_NEXT(g_resume_bdev_module, internal.tailq);
 	}
 
-	if (bdev_module) {
-		/* Save our place so we can resume later. We must
-		 * save the variable here, before calling module_fini()
-		 * below, because in some cases the module may immediately
-		 * call spdk_bdev_module_finish_done() and re-enter
-		 * this function to continue iterating. */
-		g_resume_bdev_module = bdev_module;
+	while (bdev_module) {
+		if (bdev_module->async_fini) {
+			/* Save our place so we can resume later. We must
+			 * save the variable here, before calling module_fini()
+			 * below, because in some cases the module may immediately
+			 * call spdk_bdev_module_finish_done() and re-enter
+			 * this function to continue iterating. */
+			g_resume_bdev_module = bdev_module;
+		}
 
 		if (bdev_module->module_fini) {
 			bdev_module->module_fini();
 		}
 
-		if (!bdev_module->async_fini) {
-			spdk_bdev_module_finish_done();
+		if (bdev_module->async_fini) {
+			return;
 		}
 
-		return;
+		bdev_module = TAILQ_NEXT(bdev_module, internal.tailq);
 	}
 
 	g_resume_bdev_module = NULL;
-
 	spdk_io_device_unregister(&g_bdev_mgr, spdk_bdev_mgr_unregister_cb);
 }
 
-static void
-spdk_bdev_module_unregister_cb(void *io_device)
+void
+spdk_bdev_module_finish_done(void)
 {
 	if (spdk_get_thread() != g_fini_thread) {
 		spdk_thread_send_msg(g_fini_thread, spdk_bdev_module_finish_iter, NULL);
@@ -746,12 +911,6 @@ spdk_bdev_module_unregister_cb(void *io_device)
 	}
 }
 
-void
-spdk_bdev_module_finish_done(void)
-{
-	spdk_io_device_unregister(g_resume_bdev_module, spdk_bdev_module_unregister_cb);
-}
-
 static void
 _spdk_bdev_finish_unregister_bdevs_iter(void *cb_arg, int bdeverrno)
 {
@@ -766,7 +925,7 @@ _spdk_bdev_finish_unregister_bdevs_iter(void *cb_arg, int bdeverrno)
 		 *  bdev; try to continue by manually removing this bdev from the list and continue
 		 *  with the next bdev in the list.
 		 */
-		TAILQ_REMOVE(&g_bdev_mgr.bdevs, bdev, link);
+		TAILQ_REMOVE(&g_bdev_mgr.bdevs, bdev, internal.link);
 	}
 
 	if (TAILQ_EMPTY(&g_bdev_mgr.bdevs)) {
@@ -811,60 +970,101 @@ spdk_bdev_finish(spdk_bdev_fini_cb cb_fn, void *cb_arg)
 static struct spdk_bdev_io *
 spdk_bdev_get_io(struct spdk_bdev_channel *channel)
 {
-	struct spdk_bdev_mgmt_channel *ch = channel->module_ch->mgmt_ch;
+	struct spdk_bdev_mgmt_channel *ch = channel->shared_resource->mgmt_ch;
 	struct spdk_bdev_io *bdev_io;
 
 	if (ch->per_thread_cache_count > 0) {
 		bdev_io = STAILQ_FIRST(&ch->per_thread_cache);
-		STAILQ_REMOVE_HEAD(&ch->per_thread_cache, buf_link);
+		STAILQ_REMOVE_HEAD(&ch->per_thread_cache, internal.buf_link);
 		ch->per_thread_cache_count--;
+	} else if (spdk_unlikely(!TAILQ_EMPTY(&ch->io_wait_queue))) {
+		/*
+		 * Don't try to look for bdev_ios in the global pool if there are
+		 * waiters on bdev_ios - we don't want this caller to jump the line.
+		 */
+		bdev_io = NULL;
 	} else {
 		bdev_io = spdk_mempool_get(g_bdev_mgr.bdev_io_pool);
-		if (!bdev_io) {
-			SPDK_ERRLOG("Unable to get spdk_bdev_io\n");
-			return NULL;
-		}
 	}
 
 	return bdev_io;
 }
 
-static void
-spdk_bdev_put_io(struct spdk_bdev_io *bdev_io)
+void
+spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
 {
-	struct spdk_bdev_mgmt_channel *ch = bdev_io->ch->module_ch->mgmt_ch;
+	struct spdk_bdev_mgmt_channel *ch = bdev_io->internal.ch->shared_resource->mgmt_ch;
 
-	if (bdev_io->buf != NULL) {
+	assert(bdev_io != NULL);
+	assert(bdev_io->internal.status != SPDK_BDEV_IO_STATUS_PENDING);
+
+	if (bdev_io->internal.buf != NULL) {
 		spdk_bdev_io_put_buf(bdev_io);
 	}
 
-	if (ch->per_thread_cache_count < SPDK_BDEV_IO_CACHE_SIZE) {
+	if (ch->per_thread_cache_count < ch->bdev_io_cache_size) {
 		ch->per_thread_cache_count++;
-		STAILQ_INSERT_TAIL(&ch->per_thread_cache, bdev_io, buf_link);
+		STAILQ_INSERT_TAIL(&ch->per_thread_cache, bdev_io, internal.buf_link);
+		while (ch->per_thread_cache_count > 0 && !TAILQ_EMPTY(&ch->io_wait_queue)) {
+			struct spdk_bdev_io_wait_entry *entry;
+
+			entry = TAILQ_FIRST(&ch->io_wait_queue);
+			TAILQ_REMOVE(&ch->io_wait_queue, entry, link);
+			entry->cb_fn(entry->cb_arg);
+		}
 	} else {
+		/* We should never have a full cache with entries on the io wait queue. */
+		assert(TAILQ_EMPTY(&ch->io_wait_queue));
 		spdk_mempool_put(g_bdev_mgr.bdev_io_pool, (void *)bdev_io);
 	}
 }
 
+static uint64_t
+_spdk_bdev_get_io_size_in_byte(struct spdk_bdev_io *bdev_io)
+{
+	struct spdk_bdev	*bdev = bdev_io->bdev;
+
+	switch (bdev_io->type) {
+	case SPDK_BDEV_IO_TYPE_NVME_ADMIN:
+	case SPDK_BDEV_IO_TYPE_NVME_IO:
+	case SPDK_BDEV_IO_TYPE_NVME_IO_MD:
+		return bdev_io->u.nvme_passthru.nbytes;
+	case SPDK_BDEV_IO_TYPE_READ:
+	case SPDK_BDEV_IO_TYPE_WRITE:
+	case SPDK_BDEV_IO_TYPE_UNMAP:
+	case SPDK_BDEV_IO_TYPE_WRITE_ZEROES:
+		return bdev_io->u.bdev.num_blocks * bdev->blocklen;
+	default:
+		return 0;
+	}
+}
+
 static void
 _spdk_bdev_qos_io_submit(struct spdk_bdev_channel *ch)
 {
 	struct spdk_bdev_io		*bdev_io = NULL;
 	struct spdk_bdev		*bdev = ch->bdev;
-	struct spdk_bdev_qos		*qos = &bdev->qos;
-	struct spdk_bdev_module_channel *module_ch = ch->module_ch;
+	struct spdk_bdev_qos		*qos = bdev->internal.qos;
+	struct spdk_bdev_shared_resource *shared_resource = ch->shared_resource;
 
 	while (!TAILQ_EMPTY(&qos->queued)) {
-		if (qos->io_submitted_this_timeslice < qos->max_ios_per_timeslice) {
-			bdev_io = TAILQ_FIRST(&qos->queued);
-			TAILQ_REMOVE(&qos->queued, bdev_io, link);
-			qos->io_submitted_this_timeslice++;
-			ch->io_outstanding++;
-			module_ch->io_outstanding++;
-			bdev->fn_table->submit_request(ch->channel, bdev_io);
-		} else {
+		if (qos->max_ios_per_timeslice > 0 &&
+		    qos->io_submitted_this_timeslice >= qos->max_ios_per_timeslice) {
+			break;
+		}
+
+		if (qos->max_byte_per_timeslice > 0 &&
+		    qos->byte_submitted_this_timeslice >= qos->max_byte_per_timeslice) {
 			break;
 		}
+
+		bdev_io = TAILQ_FIRST(&qos->queued);
+		TAILQ_REMOVE(&qos->queued, bdev_io, internal.link);
+		qos->io_submitted_this_timeslice++;
+		qos->byte_submitted_this_timeslice += _spdk_bdev_get_io_size_in_byte(bdev_io);
+		ch->io_outstanding++;
+		shared_resource->io_outstanding++;
+		bdev->fn_table->submit_request(ch->channel, bdev_io);
 	}
 }
 
@@ -873,47 +1073,53 @@ _spdk_bdev_io_submit(void *ctx)
 {
 	struct spdk_bdev_io *bdev_io = ctx;
 	struct spdk_bdev *bdev = bdev_io->bdev;
-	struct spdk_bdev_channel *bdev_ch = bdev_io->ch;
+	struct spdk_bdev_channel *bdev_ch = bdev_io->internal.ch;
 	struct spdk_io_channel *ch = bdev_ch->channel;
-	struct spdk_bdev_module_channel	*module_ch = bdev_ch->module_ch;
+	struct spdk_bdev_shared_resource *shared_resource = bdev_ch->shared_resource;
 
-	bdev_io->submit_tsc = spdk_get_ticks();
+	bdev_io->internal.submit_tsc = spdk_get_ticks();
 	bdev_ch->io_outstanding++;
-	module_ch->io_outstanding++;
-	bdev_io->in_submit_request = true;
+	shared_resource->io_outstanding++;
+	bdev_io->internal.in_submit_request = true;
 	if (spdk_likely(bdev_ch->flags == 0)) {
-		if (spdk_likely(TAILQ_EMPTY(&module_ch->nomem_io))) {
+		if (spdk_likely(TAILQ_EMPTY(&shared_resource->nomem_io))) {
 			bdev->fn_table->submit_request(ch, bdev_io);
 		} else {
 			bdev_ch->io_outstanding--;
-			module_ch->io_outstanding--;
-			TAILQ_INSERT_TAIL(&module_ch->nomem_io, bdev_io, link);
+			shared_resource->io_outstanding--;
+			TAILQ_INSERT_TAIL(&shared_resource->nomem_io, bdev_io, internal.link);
 		}
 	} else if (bdev_ch->flags & BDEV_CH_RESET_IN_PROGRESS) {
 		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
 	} else if (bdev_ch->flags & BDEV_CH_QOS_ENABLED) {
 		bdev_ch->io_outstanding--;
-		module_ch->io_outstanding--;
-		TAILQ_INSERT_TAIL(&bdev->qos.queued, bdev_io, link);
+		shared_resource->io_outstanding--;
+		TAILQ_INSERT_TAIL(&bdev->internal.qos->queued, bdev_io, internal.link);
 		_spdk_bdev_qos_io_submit(bdev_ch);
 	} else {
 		SPDK_ERRLOG("unknown bdev_ch flag %x found\n", bdev_ch->flags);
 		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
 	}
-	bdev_io->in_submit_request = false;
+	bdev_io->internal.in_submit_request = false;
 }
 
 static void
 spdk_bdev_io_submit(struct spdk_bdev_io *bdev_io)
 {
 	struct spdk_bdev *bdev = bdev_io->bdev;
+	struct spdk_thread *thread = spdk_io_channel_get_thread(bdev_io->internal.ch->channel);
 
-	assert(bdev_io->status == SPDK_BDEV_IO_STATUS_PENDING);
+	assert(thread != NULL);
+	assert(bdev_io->internal.status == SPDK_BDEV_IO_STATUS_PENDING);
 
-	if (bdev_io->ch->flags & BDEV_CH_QOS_ENABLED) {
-		bdev_io->io_submit_ch = bdev_io->ch;
-		bdev_io->ch = bdev->qos.ch;
-		spdk_thread_send_msg(bdev->qos.thread, _spdk_bdev_io_submit, bdev_io);
+	if (bdev_io->internal.ch->flags & BDEV_CH_QOS_ENABLED) {
+		if ((thread == bdev->internal.qos->thread) || !bdev->internal.qos->thread) {
+			_spdk_bdev_io_submit(bdev_io);
+		} else {
+			bdev_io->internal.io_submit_ch = bdev_io->internal.ch;
+			bdev_io->internal.ch = bdev->internal.qos->ch;
+			spdk_thread_send_msg(bdev->internal.qos->thread, _spdk_bdev_io_submit, bdev_io);
+		}
 	} else {
 		_spdk_bdev_io_submit(bdev_io);
 	}
@@ -923,14 +1129,14 @@ static void
 spdk_bdev_io_submit_reset(struct spdk_bdev_io *bdev_io)
 {
 	struct spdk_bdev *bdev = bdev_io->bdev;
-	struct spdk_bdev_channel *bdev_ch = bdev_io->ch;
+	struct spdk_bdev_channel *bdev_ch = bdev_io->internal.ch;
 	struct spdk_io_channel *ch = bdev_ch->channel;
 
-	assert(bdev_io->status == SPDK_BDEV_IO_STATUS_PENDING);
+	assert(bdev_io->internal.status == SPDK_BDEV_IO_STATUS_PENDING);
 
-	bdev_io->in_submit_request = true;
+	bdev_io->internal.in_submit_request = true;
 	bdev->fn_table->submit_request(ch, bdev_io);
-	bdev_io->in_submit_request = false;
+	bdev_io->internal.in_submit_request = false;
 }
 
 static void
@@ -939,18 +1145,39 @@ spdk_bdev_io_init(struct spdk_bdev_io *bdev_io,
 		  spdk_bdev_io_completion_cb cb)
 {
 	bdev_io->bdev = bdev;
-	bdev_io->caller_ctx = cb_arg;
-	bdev_io->cb = cb;
-	bdev_io->status = SPDK_BDEV_IO_STATUS_PENDING;
-	bdev_io->in_submit_request = false;
-	bdev_io->buf = NULL;
-	bdev_io->io_submit_ch = NULL;
+	bdev_io->internal.caller_ctx = cb_arg;
+	bdev_io->internal.cb = cb;
+	bdev_io->internal.status = SPDK_BDEV_IO_STATUS_PENDING;
+	bdev_io->internal.in_submit_request = false;
+	bdev_io->internal.buf = NULL;
+	bdev_io->internal.io_submit_ch = NULL;
+}
+
+static bool
+_spdk_bdev_io_type_supported(struct spdk_bdev *bdev, enum spdk_bdev_io_type io_type)
+{
+	return bdev->fn_table->io_type_supported(bdev->ctxt, io_type);
 }
 
 bool
 spdk_bdev_io_type_supported(struct spdk_bdev *bdev, enum spdk_bdev_io_type io_type)
 {
-	return bdev->fn_table->io_type_supported(bdev->ctxt, io_type);
+	bool supported;
+
+	supported = _spdk_bdev_io_type_supported(bdev, io_type);
+
+	if (!supported) {
+		switch (io_type) {
+		case SPDK_BDEV_IO_TYPE_WRITE_ZEROES:
+			/* The bdev layer will emulate write zeroes as long as write is supported. */
+			supported = _spdk_bdev_io_type_supported(bdev, SPDK_BDEV_IO_TYPE_WRITE);
+			break;
+		default:
+			break;
+		}
+	}
+
+	return supported;
 }
 
 int
@@ -979,53 +1206,50 @@ spdk_bdev_config_json(struct spdk_bdev *bdev, struct spdk_json_write_ctx *w)
 }
 
 static void
-spdk_bdev_qos_update_max_ios_per_timeslice(struct spdk_bdev_qos *qos)
+spdk_bdev_qos_update_max_quota_per_timeslice(struct spdk_bdev_qos *qos)
 {
-	uint64_t max_ios_per_timeslice = 0;
+	uint64_t max_ios_per_timeslice = 0, max_byte_per_timeslice = 0;
+
+	if (qos->iops_rate_limit > 0) {
+		max_ios_per_timeslice = qos->iops_rate_limit * SPDK_BDEV_QOS_TIMESLICE_IN_USEC /
+					SPDK_BDEV_SEC_TO_USEC;
+		qos->max_ios_per_timeslice = spdk_max(max_ios_per_timeslice,
+						      SPDK_BDEV_QOS_MIN_IO_PER_TIMESLICE);
+	}
 
-	max_ios_per_timeslice = qos->rate_limit * SPDK_BDEV_QOS_TIMESLICE_IN_USEC /
-				SPDK_BDEV_SEC_TO_USEC;
-	qos->max_ios_per_timeslice = spdk_max(max_ios_per_timeslice,
-					      SPDK_BDEV_QOS_MIN_IO_PER_TIMESLICE);
+	if (qos->byte_rate_limit > 0) {
+		max_byte_per_timeslice = qos->byte_rate_limit * SPDK_BDEV_QOS_TIMESLICE_IN_USEC /
+					 SPDK_BDEV_SEC_TO_USEC;
+		qos->max_byte_per_timeslice = spdk_max(max_byte_per_timeslice,
+						       SPDK_BDEV_QOS_MIN_BYTE_PER_TIMESLICE);
+	}
 }
 
 static int
 spdk_bdev_channel_poll_qos(void *arg)
 {
-	struct spdk_bdev_channel	*ch = arg;
+	struct spdk_bdev_qos *qos = arg;
 
 	/* Reset for next round of rate limiting */
-	ch->bdev->qos.io_submitted_this_timeslice = 0;
-
-	_spdk_bdev_qos_io_submit(ch);
-
-	return -1;
-}
-
-static int
-_spdk_bdev_channel_create(struct spdk_bdev_channel *ch, void *io_device)
-{
-	struct spdk_bdev		*bdev = __bdev_from_io_dev(io_device);
+	qos->io_submitted_this_timeslice = 0;
 
-	ch->bdev = bdev;
-	ch->channel = bdev->fn_table->get_io_channel(bdev->ctxt);
-	if (!ch->channel) {
-		return -1;
+	/* More bytes sent in the last timeslice, allow less in this timeslice */
+	if (qos->byte_submitted_this_timeslice > qos->max_byte_per_timeslice) {
+		qos->byte_submitted_this_timeslice -= qos->max_byte_per_timeslice;
+	} else {
+		qos->byte_submitted_this_timeslice = 0;
 	}
 
-	ch->module_ch = spdk_io_channel_get_ctx(spdk_get_io_channel(bdev->module));
-
-	memset(&ch->stat, 0, sizeof(ch->stat));
-	ch->io_outstanding = 0;
-	TAILQ_INIT(&ch->queued_resets);
-	ch->flags = 0;
+	_spdk_bdev_qos_io_submit(qos->ch);
 
-	return 0;
+	return -1;
 }
 
 static void
 _spdk_bdev_channel_destroy_resource(struct spdk_bdev_channel *ch)
 {
+	struct spdk_bdev_shared_resource *shared_resource;
+
 	if (!ch) {
 		return;
 	}
@@ -1034,64 +1258,56 @@ _spdk_bdev_channel_destroy_resource(struct spdk_bdev_channel *ch)
 		spdk_put_io_channel(ch->channel);
 	}
 
-	if (ch->module_ch) {
-		spdk_put_io_channel(spdk_io_channel_from_ctx(ch->module_ch));
+	assert(ch->io_outstanding == 0);
+
+	shared_resource = ch->shared_resource;
+	if (shared_resource) {
+		assert(ch->io_outstanding == 0);
+		assert(shared_resource->ref > 0);
+		shared_resource->ref--;
+		if (shared_resource->ref == 0) {
+			assert(shared_resource->io_outstanding == 0);
+			TAILQ_REMOVE(&shared_resource->mgmt_ch->shared_resources, shared_resource, link);
+			spdk_put_io_channel(spdk_io_channel_from_ctx(shared_resource->mgmt_ch));
+			free(shared_resource);
+		}
 	}
 }
 
-/* Caller must hold bdev->mutex. */
-static int
-spdk_bdev_qos_channel_create(struct spdk_bdev *bdev)
+/* Caller must hold bdev->internal.mutex. */
+static void
+_spdk_bdev_enable_qos(struct spdk_bdev *bdev, struct spdk_bdev_channel *ch)
 {
-	assert(bdev->qos.ch == NULL);
-	assert(bdev->qos.thread == NULL);
-
-	bdev->qos.ch = calloc(1, sizeof(struct spdk_bdev_channel));
-	if (!bdev->qos.ch) {
-		return -1;
-	}
+	struct spdk_bdev_qos *qos = bdev->internal.qos;
 
-	bdev->qos.thread = spdk_get_thread();
-	if (!bdev->qos.thread) {
-		free(bdev->qos.ch);
-		bdev->qos.ch = NULL;
-		return -1;
-	}
+	/* Rate limiting on this bdev enabled */
+	if (qos) {
+		if (qos->ch == NULL) {
+			struct spdk_io_channel *io_ch;
 
-	if (_spdk_bdev_channel_create(bdev->qos.ch, __bdev_to_io_dev(bdev)) != 0) {
-		free(bdev->qos.ch);
-		bdev->qos.ch = NULL;
-		bdev->qos.thread = NULL;
-		return -1;
-	}
+			SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Selecting channel %p as QoS channel for bdev %s on thread %p\n", ch,
+				      bdev->name, spdk_get_thread());
 
-	TAILQ_INIT(&bdev->qos.queued);
+			/* No qos channel has been selected, so set one up */
 
-	bdev->qos.ch->flags |= BDEV_CH_QOS_ENABLED;
-	spdk_bdev_qos_update_max_ios_per_timeslice(&bdev->qos);
+			/* Take another reference to ch */
+			io_ch = spdk_get_io_channel(__bdev_to_io_dev(bdev));
+			qos->ch = ch;
 
-	bdev->qos.poller = spdk_poller_register(spdk_bdev_channel_poll_qos,
-						bdev->qos.ch,
-						SPDK_BDEV_QOS_TIMESLICE_IN_USEC);
+			qos->thread = spdk_io_channel_get_thread(io_ch);
 
-	return 0;
-}
+			TAILQ_INIT(&qos->queued);
+			spdk_bdev_qos_update_max_quota_per_timeslice(qos);
+			qos->io_submitted_this_timeslice = 0;
+			qos->byte_submitted_this_timeslice = 0;
 
-/* Caller must hold bdev->mutex */
-static int
-_spdk_bdev_enable_qos(struct spdk_bdev *bdev, struct spdk_bdev_channel *ch)
-{
-	/* Rate limiting on this bdev enabled */
-	if (bdev->qos.enabled) {
-		if (bdev->qos.ch == NULL) {
-			if (spdk_bdev_qos_channel_create(bdev) != 0) {
-				return -1;
-			}
+			qos->poller = spdk_poller_register(spdk_bdev_channel_poll_qos,
+							   qos,
+							   SPDK_BDEV_QOS_TIMESLICE_IN_USEC);
 		}
+
 		ch->flags |= BDEV_CH_QOS_ENABLED;
 	}
-
-	return 0;
 }
 
 static int
@@ -1099,12 +1315,53 @@ spdk_bdev_channel_create(void *io_device, void *ctx_buf)
 {
 	struct spdk_bdev		*bdev = __bdev_from_io_dev(io_device);
 	struct spdk_bdev_channel	*ch = ctx_buf;
+	struct spdk_io_channel		*mgmt_io_ch;
+	struct spdk_bdev_mgmt_channel	*mgmt_ch;
+	struct spdk_bdev_shared_resource *shared_resource;
+
+	ch->bdev = bdev;
+	ch->channel = bdev->fn_table->get_io_channel(bdev->ctxt);
+	if (!ch->channel) {
+		return -1;
+	}
 
-	if (_spdk_bdev_channel_create(ch, io_device) != 0) {
-		_spdk_bdev_channel_destroy_resource(ch);
+	mgmt_io_ch = spdk_get_io_channel(&g_bdev_mgr);
+	if (!mgmt_io_ch) {
 		return -1;
 	}
 
+	mgmt_ch = spdk_io_channel_get_ctx(mgmt_io_ch);
+	TAILQ_FOREACH(shared_resource, &mgmt_ch->shared_resources, link) {
+		if (shared_resource->shared_ch == ch->channel) {
+			spdk_put_io_channel(mgmt_io_ch);
+			shared_resource->ref++;
+			break;
+		}
+	}
+
+	if (shared_resource == NULL) {
+		shared_resource = calloc(1, sizeof(*shared_resource));
+		if (shared_resource == NULL) {
+			spdk_put_io_channel(mgmt_io_ch);
+			return -1;
+		}
+
+		shared_resource->mgmt_ch = mgmt_ch;
+		shared_resource->io_outstanding = 0;
+		TAILQ_INIT(&shared_resource->nomem_io);
+		shared_resource->nomem_threshold = 0;
+		shared_resource->shared_ch = ch->channel;
+		shared_resource->ref = 1;
+		TAILQ_INSERT_TAIL(&mgmt_ch->shared_resources, shared_resource, link);
+	}
+
+	memset(&ch->stat, 0, sizeof(ch->stat));
+	ch->stat.ticks_rate = spdk_get_ticks_hz();
+	ch->io_outstanding = 0;
+	TAILQ_INIT(&ch->queued_resets);
+	ch->flags = 0;
+	ch->shared_resource = shared_resource;
+
 #ifdef SPDK_CONFIG_VTUNE
 	{
 		char *name;
@@ -1118,27 +1375,20 @@ spdk_bdev_channel_create(void *io_device, void *ctx_buf)
 		free(name);
 		ch->start_tsc = spdk_get_ticks();
 		ch->interval_tsc = spdk_get_ticks_hz() / 100;
+		memset(&ch->prev_stat, 0, sizeof(ch->prev_stat));
 	}
 #endif
 
-	pthread_mutex_lock(&bdev->mutex);
-
-	if (_spdk_bdev_enable_qos(bdev, ch)) {
-		_spdk_bdev_channel_destroy_resource(ch);
-		pthread_mutex_unlock(&bdev->mutex);
-		return -1;
-	}
-
-	bdev->channel_count++;
-
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	_spdk_bdev_enable_qos(bdev, ch);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	return 0;
 }
 
 /*
  * Abort I/O that are waiting on a data buffer.  These types of I/O are
- *  linked using the spdk_bdev_io buf_link TAILQ_ENTRY.
+ *  linked using the spdk_bdev_io internal.buf_link TAILQ_ENTRY.
  */
 static void
 _spdk_bdev_abort_buf_io(bdev_io_stailq_t *queue, struct spdk_bdev_channel *ch)
@@ -1150,11 +1400,11 @@ _spdk_bdev_abort_buf_io(bdev_io_stailq_t *queue, struct spdk_bdev_channel *ch)
 
 	while (!STAILQ_EMPTY(queue)) {
 		bdev_io = STAILQ_FIRST(queue);
-		STAILQ_REMOVE_HEAD(queue, buf_link);
-		if (bdev_io->ch == ch) {
+		STAILQ_REMOVE_HEAD(queue, internal.buf_link);
+		if (bdev_io->internal.ch == ch) {
 			spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
 		} else {
-			STAILQ_INSERT_TAIL(&tmp, bdev_io, buf_link);
+			STAILQ_INSERT_TAIL(&tmp, bdev_io, internal.buf_link);
 		}
 	}
 
@@ -1170,9 +1420,9 @@ _spdk_bdev_abort_queued_io(bdev_io_tailq_t *queue, struct spdk_bdev_channel *ch)
 {
 	struct spdk_bdev_io *bdev_io, *tmp;
 
-	TAILQ_FOREACH_SAFE(bdev_io, queue, link, tmp) {
-		if (bdev_io->ch == ch) {
-			TAILQ_REMOVE(queue, bdev_io, link);
+	TAILQ_FOREACH_SAFE(bdev_io, queue, internal.link, tmp) {
+		if (bdev_io->internal.ch == ch) {
+			TAILQ_REMOVE(queue, bdev_io, internal.link);
 			/*
 			 * spdk_bdev_io_complete() assumes that the completed I/O had
 			 *  been submitted to the bdev module.  Since in this case it
@@ -1181,7 +1431,7 @@ _spdk_bdev_abort_queued_io(bdev_io_tailq_t *queue, struct spdk_bdev_channel *ch)
 			 */
 			if (bdev_io->type != SPDK_BDEV_IO_TYPE_RESET) {
 				ch->io_outstanding++;
-				ch->module_ch->io_outstanding++;
+				ch->shared_resource->io_outstanding++;
 			}
 			spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
 		}
@@ -1189,77 +1439,88 @@ _spdk_bdev_abort_queued_io(bdev_io_tailq_t *queue, struct spdk_bdev_channel *ch)
 }
 
 static void
-_spdk_bdev_channel_destroy(struct spdk_bdev_channel *ch)
+spdk_bdev_qos_channel_destroy(void *cb_arg)
 {
-	struct spdk_bdev_mgmt_channel	*mgmt_ch;
-	struct spdk_bdev_module_channel	*module_ch = ch->module_ch;
+	struct spdk_bdev_qos *qos = cb_arg;
 
-	mgmt_ch = module_ch->mgmt_ch;
+	spdk_put_io_channel(spdk_io_channel_from_ctx(qos->ch));
+	spdk_poller_unregister(&qos->poller);
 
-	_spdk_bdev_abort_queued_io(&ch->queued_resets, ch);
-	_spdk_bdev_abort_queued_io(&module_ch->nomem_io, ch);
-	_spdk_bdev_abort_buf_io(&mgmt_ch->need_buf_small, ch);
-	_spdk_bdev_abort_buf_io(&mgmt_ch->need_buf_large, ch);
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Free QoS %p.\n", qos);
 
-	_spdk_bdev_channel_destroy_resource(ch);
+	free(qos);
 }
 
-struct qos_channel_destroy_ctx {
-	struct spdk_bdev_channel *qos_channel;
-	struct spdk_poller *poller;
-};
-
-static void
-spdk_bdev_qos_channel_destroy(void *cb_arg)
+static int
+spdk_bdev_qos_destroy(struct spdk_bdev *bdev)
 {
-	struct qos_channel_destroy_ctx *ctx = cb_arg;
+	/*
+	 * Cleanly shutting down the QoS poller is tricky, because
+	 * during the asynchronous operation the user could open
+	 * a new descriptor and create a new channel, spawning
+	 * a new QoS poller.
+	 *
+	 * The strategy is to create a new QoS structure here and swap it
+	 * in. The shutdown path then continues to refer to the old one
+	 * until it completes and then releases it.
+	 */
+	struct spdk_bdev_qos *new_qos, *old_qos;
 
-	_spdk_bdev_channel_destroy(ctx->qos_channel);
+	old_qos = bdev->internal.qos;
 
-	spdk_poller_unregister(&ctx->poller);
+	new_qos = calloc(1, sizeof(*new_qos));
+	if (!new_qos) {
+		SPDK_ERRLOG("Unable to allocate memory to shut down QoS.\n");
+		return -ENOMEM;
+	}
 
-	free(ctx->qos_channel);
-	free(ctx);
+	/* Copy the old QoS data into the newly allocated structure */
+	memcpy(new_qos, old_qos, sizeof(*new_qos));
+
+	/* Zero out the key parts of the QoS structure */
+	new_qos->ch = NULL;
+	new_qos->thread = NULL;
+	new_qos->max_ios_per_timeslice = 0;
+	new_qos->max_byte_per_timeslice = 0;
+	new_qos->io_submitted_this_timeslice = 0;
+	new_qos->byte_submitted_this_timeslice = 0;
+	new_qos->poller = NULL;
+	TAILQ_INIT(&new_qos->queued);
+
+	bdev->internal.qos = new_qos;
+
+	if (old_qos->thread == NULL) {
+		free(old_qos);
+	} else {
+		spdk_thread_send_msg(old_qos->thread, spdk_bdev_qos_channel_destroy,
+				     old_qos);
+	}
+
+	/* It is safe to continue with destroying the bdev even though the QoS channel hasn't
+	 * been destroyed yet. The destruction path will end up waiting for the final
+	 * channel to be put before it releases resources. */
+
+	return 0;
 }
 
 static void
 spdk_bdev_channel_destroy(void *io_device, void *ctx_buf)
 {
 	struct spdk_bdev_channel	*ch = ctx_buf;
-	struct spdk_bdev		*bdev = ch->bdev;
-
-	_spdk_bdev_channel_destroy(ch);
-
-	pthread_mutex_lock(&bdev->mutex);
-	bdev->channel_count--;
-	if (bdev->channel_count == 0 && bdev->qos.enabled && bdev->qos.ch != NULL) {
-		struct qos_channel_destroy_ctx *ctx;
-
-		/* All I/O channels for this bdev have been destroyed - destroy the QoS channel. */
+	struct spdk_bdev_mgmt_channel	*mgmt_ch;
+	struct spdk_bdev_shared_resource *shared_resource = ch->shared_resource;
 
-		ctx = calloc(1, sizeof(*ctx));
-		if (!ctx) {
-			/* We can't stop the old QoS thread. Just leave it where it is. */
-			pthread_mutex_unlock(&bdev->mutex);
-			return;
-		}
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Destroying channel %p for bdev %s on thread %p\n", ch, ch->bdev->name,
+		      spdk_get_thread());
 
-		ctx->qos_channel = bdev->qos.ch;
-		ctx->poller = bdev->qos.poller;
+	mgmt_ch = shared_resource->mgmt_ch;
 
-		spdk_thread_send_msg(bdev->qos.thread, spdk_bdev_qos_channel_destroy,
-				     ctx);
+	_spdk_bdev_abort_queued_io(&ch->queued_resets, ch);
+	_spdk_bdev_abort_queued_io(&shared_resource->nomem_io, ch);
+	_spdk_bdev_abort_buf_io(&mgmt_ch->need_buf_small, ch);
+	_spdk_bdev_abort_buf_io(&mgmt_ch->need_buf_large, ch);
 
-		/*
-		 * Set qos_channel to NULL within the critical section so that
-		 * if another channel is created, it will see qos_channel == NULL and
-		 * re-create the QoS channel even if the asynchronous qos_channel_destroy
-		 * isn't finished yet.
-		 */
-		bdev->qos.ch = NULL;
-		bdev->qos.thread = NULL;
-	}
-	pthread_mutex_unlock(&bdev->mutex);
+	_spdk_bdev_channel_destroy_resource(ch);
 }
 
 int
@@ -1351,9 +1612,17 @@ spdk_bdev_get_num_blocks(const struct spdk_bdev *bdev)
 }
 
 uint64_t
-spdk_bdev_get_qos_ios_per_sec(const struct spdk_bdev *bdev)
+spdk_bdev_get_qos_ios_per_sec(struct spdk_bdev *bdev)
 {
-	return bdev->qos.rate_limit;
+	uint64_t iops_rate_limit = 0;
+
+	pthread_mutex_lock(&bdev->internal.mutex);
+	if (bdev->internal.qos) {
+		iops_rate_limit = bdev->internal.qos->iops_rate_limit;
+	}
+	pthread_mutex_unlock(&bdev->internal.mutex);
+
+	return iops_rate_limit;
 }
 
 size_t
@@ -1385,15 +1654,72 @@ spdk_bdev_get_uuid(const struct spdk_bdev *bdev)
 	return &bdev->uuid;
 }
 
+uint64_t
+spdk_bdev_get_qd(const struct spdk_bdev *bdev)
+{
+	return bdev->internal.measured_queue_depth;
+}
+
+uint64_t
+spdk_bdev_get_qd_sampling_period(const struct spdk_bdev *bdev)
+{
+	return bdev->internal.period;
+}
+
+static void
+_calculate_measured_qd_cpl(struct spdk_io_channel_iter *i, int status)
+{
+	struct spdk_bdev *bdev = spdk_io_channel_iter_get_ctx(i);
+
+	bdev->internal.measured_queue_depth = bdev->internal.temporary_queue_depth;
+}
+
+static void
+_calculate_measured_qd(struct spdk_io_channel_iter *i)
+{
+	struct spdk_bdev *bdev = spdk_io_channel_iter_get_ctx(i);
+	struct spdk_io_channel *io_ch = spdk_io_channel_iter_get_channel(i);
+	struct spdk_bdev_channel *ch = spdk_io_channel_get_ctx(io_ch);
+
+	bdev->internal.temporary_queue_depth += ch->io_outstanding;
+	spdk_for_each_channel_continue(i, 0);
+}
+
+static int
+spdk_bdev_calculate_measured_queue_depth(void *ctx)
+{
+	struct spdk_bdev *bdev = ctx;
+	bdev->internal.temporary_queue_depth = 0;
+	spdk_for_each_channel(__bdev_to_io_dev(bdev), _calculate_measured_qd, bdev,
+			      _calculate_measured_qd_cpl);
+	return 0;
+}
+
+void
+spdk_bdev_set_qd_sampling_period(struct spdk_bdev *bdev, uint64_t period)
+{
+	bdev->internal.period = period;
+
+	if (bdev->internal.qd_poller != NULL) {
+		spdk_poller_unregister(&bdev->internal.qd_poller);
+		bdev->internal.measured_queue_depth = UINT64_MAX;
+	}
+
+	if (period != 0) {
+		bdev->internal.qd_poller = spdk_poller_register(spdk_bdev_calculate_measured_queue_depth, bdev,
+					   period);
+	}
+}
+
 int
 spdk_bdev_notify_blockcnt_change(struct spdk_bdev *bdev, uint64_t size)
 {
 	int ret;
 
-	pthread_mutex_lock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
 
 	/* bdev has open descriptors */
-	if (!TAILQ_EMPTY(&bdev->open_descs) &&
+	if (!TAILQ_EMPTY(&bdev->internal.open_descs) &&
 	    bdev->blockcnt > size) {
 		ret = -EBUSY;
 	} else {
@@ -1401,7 +1727,7 @@ spdk_bdev_notify_blockcnt_change(struct spdk_bdev *bdev, uint64_t size)
 		ret = 0;
 	}
 
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	return ret;
 }
@@ -1469,15 +1795,14 @@ spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("spdk_bdev_io memory allocation failed duing read\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_READ;
-	bdev_io->u.bdev.iov.iov_base = buf;
-	bdev_io->u.bdev.iov.iov_len = num_blocks * bdev->blocklen;
-	bdev_io->u.bdev.iovs = &bdev_io->u.bdev.iov;
+	bdev_io->u.bdev.iovs = &bdev_io->iov;
+	bdev_io->u.bdev.iovs[0].iov_base = buf;
+	bdev_io->u.bdev.iovs[0].iov_len = num_blocks * bdev->blocklen;
 	bdev_io->u.bdev.iovcnt = 1;
 	bdev_io->u.bdev.num_blocks = num_blocks;
 	bdev_io->u.bdev.offset_blocks = offset_blocks;
@@ -1517,11 +1842,10 @@ int spdk_bdev_readv_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("spdk_bdev_io memory allocation failed duing read\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_READ;
 	bdev_io->u.bdev.iovs = iov;
 	bdev_io->u.bdev.iovcnt = iovcnt;
@@ -1566,15 +1890,14 @@ spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing write\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_WRITE;
-	bdev_io->u.bdev.iov.iov_base = buf;
-	bdev_io->u.bdev.iov.iov_len = num_blocks * bdev->blocklen;
-	bdev_io->u.bdev.iovs = &bdev_io->u.bdev.iov;
+	bdev_io->u.bdev.iovs = &bdev_io->iov;
+	bdev_io->u.bdev.iovs[0].iov_base = buf;
+	bdev_io->u.bdev.iovs[0].iov_len = num_blocks * bdev->blocklen;
 	bdev_io->u.bdev.iovcnt = 1;
 	bdev_io->u.bdev.num_blocks = num_blocks;
 	bdev_io->u.bdev.offset_blocks = offset_blocks;
@@ -1619,11 +1942,10 @@ spdk_bdev_writev_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing writev\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_WRITE;
 	bdev_io->u.bdev.iovs = iov;
 	bdev_io->u.bdev.iovcnt = iovcnt;
@@ -1660,9 +1982,8 @@ spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channe
 	uint64_t len;
 	bool split_request = false;
 
-	if (num_blocks > UINT64_MAX / spdk_bdev_get_block_size(bdev)) {
-		SPDK_ERRLOG("length argument out of range in write_zeroes\n");
-		return -ERANGE;
+	if (!desc->write) {
+		return -EBADF;
 	}
 
 	if (!spdk_bdev_io_valid_blocks(bdev, offset_blocks, num_blocks)) {
@@ -1672,20 +1993,19 @@ spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channe
 	bdev_io = spdk_bdev_get_io(channel);
 
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing write_zeroes\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->u.bdev.offset_blocks = offset_blocks;
 
-	if (spdk_bdev_io_type_supported(bdev, SPDK_BDEV_IO_TYPE_WRITE_ZEROES)) {
+	if (_spdk_bdev_io_type_supported(bdev, SPDK_BDEV_IO_TYPE_WRITE_ZEROES)) {
 		bdev_io->type = SPDK_BDEV_IO_TYPE_WRITE_ZEROES;
 		bdev_io->u.bdev.num_blocks = num_blocks;
 		bdev_io->u.bdev.iovs = NULL;
 		bdev_io->u.bdev.iovcnt = 0;
 
-	} else {
+	} else if (_spdk_bdev_io_type_supported(bdev, SPDK_BDEV_IO_TYPE_WRITE)) {
 		assert(spdk_bdev_get_block_size(bdev) <= ZERO_BUFFER_SIZE);
 
 		len = spdk_bdev_get_block_size(bdev) * num_blocks;
@@ -1696,13 +2016,16 @@ spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channe
 		}
 
 		bdev_io->type = SPDK_BDEV_IO_TYPE_WRITE;
-		bdev_io->u.bdev.iov.iov_base = g_bdev_mgr.zero_buffer;
-		bdev_io->u.bdev.iov.iov_len = len;
-		bdev_io->u.bdev.iovs = &bdev_io->u.bdev.iov;
+		bdev_io->u.bdev.iovs = &bdev_io->iov;
+		bdev_io->u.bdev.iovs[0].iov_base = g_bdev_mgr.zero_buffer;
+		bdev_io->u.bdev.iovs[0].iov_len = len;
 		bdev_io->u.bdev.iovcnt = 1;
 		bdev_io->u.bdev.num_blocks = len / spdk_bdev_get_block_size(bdev);
 		bdev_io->u.bdev.split_remaining_num_blocks = num_blocks - bdev_io->u.bdev.num_blocks;
 		bdev_io->u.bdev.split_current_offset_blocks = offset_blocks + bdev_io->u.bdev.num_blocks;
+	} else {
+		spdk_bdev_free_io(bdev_io);
+		return -ENOTSUP;
 	}
 
 	if (split_request) {
@@ -1753,16 +2076,17 @@ spdk_bdev_unmap_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing unmap\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_UNMAP;
-	bdev_io->u.bdev.iov.iov_base = NULL;
-	bdev_io->u.bdev.iov.iov_len = 0;
-	bdev_io->u.bdev.iovs = &bdev_io->u.bdev.iov;
+
+	bdev_io->u.bdev.iovs = &bdev_io->iov;
+	bdev_io->u.bdev.iovs[0].iov_base = NULL;
+	bdev_io->u.bdev.iovs[0].iov_len = 0;
 	bdev_io->u.bdev.iovcnt = 1;
+
 	bdev_io->u.bdev.offset_blocks = offset_blocks;
 	bdev_io->u.bdev.num_blocks = num_blocks;
 	spdk_bdev_io_init(bdev_io, bdev, cb_arg, cb);
@@ -1804,11 +2128,10 @@ spdk_bdev_flush_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing flush\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_FLUSH;
 	bdev_io->u.bdev.iovs = NULL;
 	bdev_io->u.bdev.iovcnt = 0;
@@ -1827,7 +2150,7 @@ _spdk_bdev_reset_dev(struct spdk_io_channel_iter *i, int status)
 	struct spdk_bdev_io *bdev_io;
 
 	bdev_io = TAILQ_FIRST(&ch->queued_resets);
-	TAILQ_REMOVE(&ch->queued_resets, bdev_io, link);
+	TAILQ_REMOVE(&ch->queued_resets, bdev_io, internal.link);
 	spdk_bdev_io_submit_reset(bdev_io);
 }
 
@@ -1837,43 +2160,38 @@ _spdk_bdev_reset_freeze_channel(struct spdk_io_channel_iter *i)
 	struct spdk_io_channel		*ch;
 	struct spdk_bdev_channel	*channel;
 	struct spdk_bdev_mgmt_channel	*mgmt_channel;
-	struct spdk_bdev_module_channel	*module_ch;
+	struct spdk_bdev_shared_resource *shared_resource;
+	bdev_io_tailq_t			tmp_queued;
+
+	TAILQ_INIT(&tmp_queued);
 
 	ch = spdk_io_channel_iter_get_channel(i);
 	channel = spdk_io_channel_get_ctx(ch);
-	module_ch = channel->module_ch;
-	mgmt_channel = module_ch->mgmt_ch;
+	shared_resource = channel->shared_resource;
+	mgmt_channel = shared_resource->mgmt_ch;
 
 	channel->flags |= BDEV_CH_RESET_IN_PROGRESS;
 
-	_spdk_bdev_abort_queued_io(&module_ch->nomem_io, channel);
+	if ((channel->flags & BDEV_CH_QOS_ENABLED) != 0) {
+		/* The QoS object is always valid and readable while
+		 * the channel flag is set, so the lock here should not
+		 * be necessary. We're not in the fast path though, so
+		 * just take it anyway. */
+		pthread_mutex_lock(&channel->bdev->internal.mutex);
+		if (channel->bdev->internal.qos->ch == channel) {
+			TAILQ_SWAP(&channel->bdev->internal.qos->queued, &tmp_queued, spdk_bdev_io, internal.link);
+		}
+		pthread_mutex_unlock(&channel->bdev->internal.mutex);
+	}
+
+	_spdk_bdev_abort_queued_io(&shared_resource->nomem_io, channel);
 	_spdk_bdev_abort_buf_io(&mgmt_channel->need_buf_small, channel);
 	_spdk_bdev_abort_buf_io(&mgmt_channel->need_buf_large, channel);
+	_spdk_bdev_abort_queued_io(&tmp_queued, channel);
 
 	spdk_for_each_channel_continue(i, 0);
 }
 
-static void
-_spdk_bdev_reset_freeze_qos_channel(void *ctx)
-{
-	struct spdk_bdev		*bdev = ctx;
-	struct spdk_bdev_mgmt_channel	*mgmt_channel = NULL;
-	struct spdk_bdev_channel	*qos_channel = bdev->qos.ch;
-	struct spdk_bdev_module_channel	*module_ch = NULL;
-
-	if (qos_channel) {
-		module_ch = qos_channel->module_ch;
-		mgmt_channel = module_ch->mgmt_ch;
-
-		qos_channel->flags |= BDEV_CH_RESET_IN_PROGRESS;
-
-		_spdk_bdev_abort_queued_io(&module_ch->nomem_io, qos_channel);
-		_spdk_bdev_abort_queued_io(&bdev->qos.queued, qos_channel);
-		_spdk_bdev_abort_buf_io(&mgmt_channel->need_buf_small, qos_channel);
-		_spdk_bdev_abort_buf_io(&mgmt_channel->need_buf_large, qos_channel);
-	}
-}
-
 static void
 _spdk_bdev_start_reset(void *ctx)
 {
@@ -1890,9 +2208,9 @@ _spdk_bdev_channel_start_reset(struct spdk_bdev_channel *ch)
 
 	assert(!TAILQ_EMPTY(&ch->queued_resets));
 
-	pthread_mutex_lock(&bdev->mutex);
-	if (bdev->reset_in_progress == NULL) {
-		bdev->reset_in_progress = TAILQ_FIRST(&ch->queued_resets);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	if (bdev->internal.reset_in_progress == NULL) {
+		bdev->internal.reset_in_progress = TAILQ_FIRST(&ch->queued_resets);
 		/*
 		 * Take a channel reference for the target bdev for the life of this
 		 *  reset.  This guards against the channel getting destroyed while
@@ -1900,10 +2218,10 @@ _spdk_bdev_channel_start_reset(struct spdk_bdev_channel *ch)
 		 *  progress.  We will release the reference when this reset is
 		 *  completed.
 		 */
-		bdev->reset_in_progress->u.reset.ch_ref = spdk_get_io_channel(__bdev_to_io_dev(bdev));
+		bdev->internal.reset_in_progress->u.reset.ch_ref = spdk_get_io_channel(__bdev_to_io_dev(bdev));
 		_spdk_bdev_start_reset(ch);
 	}
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 }
 
 int
@@ -1916,27 +2234,20 @@ spdk_bdev_reset(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed duing reset\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_RESET;
 	bdev_io->u.reset.ch_ref = NULL;
 	spdk_bdev_io_init(bdev_io, bdev, cb_arg, cb);
 
-	pthread_mutex_lock(&bdev->mutex);
-	TAILQ_INSERT_TAIL(&channel->queued_resets, bdev_io, link);
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	TAILQ_INSERT_TAIL(&channel->queued_resets, bdev_io, internal.link);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	_spdk_bdev_channel_start_reset(channel);
 
-	/* Explicitly handle the QoS bdev channel as no IO channel associated */
-	if (bdev->qos.enabled && bdev->qos.thread) {
-		spdk_thread_send_msg(bdev->qos.thread,
-				     _spdk_bdev_reset_freeze_qos_channel, bdev);
-	}
-
 	return 0;
 }
 
@@ -1944,17 +2255,62 @@ void
 spdk_bdev_get_io_stat(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
 		      struct spdk_bdev_io_stat *stat)
 {
-#ifdef SPDK_CONFIG_VTUNE
-	SPDK_ERRLOG("Calling spdk_bdev_get_io_stat is not allowed when VTune integration is enabled.\n");
-	memset(stat, 0, sizeof(*stat));
-	return;
-#endif
-
 	struct spdk_bdev_channel *channel = spdk_io_channel_get_ctx(ch);
 
-	channel->stat.ticks_rate = spdk_get_ticks_hz();
 	*stat = channel->stat;
-	memset(&channel->stat, 0, sizeof(channel->stat));
+}
+
+static void
+_spdk_bdev_get_device_stat_done(struct spdk_io_channel_iter *i, int status)
+{
+	void *io_device = spdk_io_channel_iter_get_io_device(i);
+	struct spdk_bdev_iostat_ctx *bdev_iostat_ctx = spdk_io_channel_iter_get_ctx(i);
+
+	bdev_iostat_ctx->cb(__bdev_from_io_dev(io_device), bdev_iostat_ctx->stat,
+			    bdev_iostat_ctx->cb_arg, 0);
+	free(bdev_iostat_ctx);
+}
+
+static void
+_spdk_bdev_get_each_channel_stat(struct spdk_io_channel_iter *i)
+{
+	struct spdk_bdev_iostat_ctx *bdev_iostat_ctx = spdk_io_channel_iter_get_ctx(i);
+	struct spdk_io_channel *ch = spdk_io_channel_iter_get_channel(i);
+	struct spdk_bdev_channel *channel = spdk_io_channel_get_ctx(ch);
+
+	bdev_iostat_ctx->stat->bytes_read += channel->stat.bytes_read;
+	bdev_iostat_ctx->stat->num_read_ops += channel->stat.num_read_ops;
+	bdev_iostat_ctx->stat->bytes_written += channel->stat.bytes_written;
+	bdev_iostat_ctx->stat->num_write_ops += channel->stat.num_write_ops;
+
+	spdk_for_each_channel_continue(i, 0);
+}
+
+void
+spdk_bdev_get_device_stat(struct spdk_bdev *bdev, struct spdk_bdev_io_stat *stat,
+			  spdk_bdev_get_device_stat_cb cb, void *cb_arg)
+{
+	struct spdk_bdev_iostat_ctx *bdev_iostat_ctx;
+
+	assert(bdev != NULL);
+	assert(stat != NULL);
+	assert(cb != NULL);
+
+	bdev_iostat_ctx = calloc(1, sizeof(struct spdk_bdev_iostat_ctx));
+	if (bdev_iostat_ctx == NULL) {
+		SPDK_ERRLOG("Unable to allocate memory for spdk_bdev_iostat_ctx\n");
+		cb(bdev, stat, cb_arg, -ENOMEM);
+		return;
+	}
+
+	bdev_iostat_ctx->stat = stat;
+	bdev_iostat_ctx->cb = cb;
+	bdev_iostat_ctx->cb_arg = cb_arg;
+
+	spdk_for_each_channel(__bdev_to_io_dev(bdev),
+			      _spdk_bdev_get_each_channel_stat,
+			      bdev_iostat_ctx,
+			      _spdk_bdev_get_device_stat_done);
 }
 
 int
@@ -1972,11 +2328,10 @@ spdk_bdev_nvme_admin_passthru(struct spdk_bdev_desc *desc, struct spdk_io_channe
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed during nvme_admin_passthru\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_NVME_ADMIN;
 	bdev_io->u.nvme_passthru.cmd = *cmd;
 	bdev_io->u.nvme_passthru.buf = buf;
@@ -2010,11 +2365,10 @@ spdk_bdev_nvme_io_passthru(struct spdk_bdev_desc *desc, struct spdk_io_channel *
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed during nvme_admin_passthru\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_NVME_IO;
 	bdev_io->u.nvme_passthru.cmd = *cmd;
 	bdev_io->u.nvme_passthru.buf = buf;
@@ -2048,11 +2402,10 @@ spdk_bdev_nvme_io_passthru_md(struct spdk_bdev_desc *desc, struct spdk_io_channe
 
 	bdev_io = spdk_bdev_get_io(channel);
 	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io memory allocation failed during nvme_admin_passthru\n");
 		return -ENOMEM;
 	}
 
-	bdev_io->ch = channel;
+	bdev_io->internal.ch = channel;
 	bdev_io->type = SPDK_BDEV_IO_TYPE_NVME_IO_MD;
 	bdev_io->u.nvme_passthru.cmd = *cmd;
 	bdev_io->u.nvme_passthru.buf = buf;
@@ -2067,21 +2420,23 @@ spdk_bdev_nvme_io_passthru_md(struct spdk_bdev_desc *desc, struct spdk_io_channe
 }
 
 int
-spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
+spdk_bdev_queue_io_wait(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
+			struct spdk_bdev_io_wait_entry *entry)
 {
-	if (!bdev_io) {
-		SPDK_ERRLOG("bdev_io is NULL\n");
-		return -1;
-	}
+	struct spdk_bdev_channel *channel = spdk_io_channel_get_ctx(ch);
+	struct spdk_bdev_mgmt_channel *mgmt_ch = channel->shared_resource->mgmt_ch;
 
-	if (bdev_io->status == SPDK_BDEV_IO_STATUS_PENDING) {
-		SPDK_ERRLOG("bdev_io is in pending state\n");
-		assert(false);
-		return -1;
+	if (bdev != entry->bdev) {
+		SPDK_ERRLOG("bdevs do not match\n");
+		return -EINVAL;
 	}
 
-	spdk_bdev_put_io(bdev_io);
+	if (mgmt_ch->per_thread_cache_count > 0) {
+		SPDK_ERRLOG("Cannot queue io_wait if spdk_bdev_io available in per-thread cache\n");
+		return -EINVAL;
+	}
 
+	TAILQ_INSERT_TAIL(&mgmt_ch->io_wait_queue, entry, link);
 	return 0;
 }
 
@@ -2089,10 +2444,10 @@ static void
 _spdk_bdev_ch_retry_io(struct spdk_bdev_channel *bdev_ch)
 {
 	struct spdk_bdev *bdev = bdev_ch->bdev;
-	struct spdk_bdev_module_channel	*module_ch = bdev_ch->module_ch;
+	struct spdk_bdev_shared_resource *shared_resource = bdev_ch->shared_resource;
 	struct spdk_bdev_io *bdev_io;
 
-	if (module_ch->io_outstanding > module_ch->nomem_threshold) {
+	if (shared_resource->io_outstanding > shared_resource->nomem_threshold) {
 		/*
 		 * Allow some more I/O to complete before retrying the nomem_io queue.
 		 *  Some drivers (such as nvme) cannot immediately take a new I/O in
@@ -2104,14 +2459,14 @@ _spdk_bdev_ch_retry_io(struct spdk_bdev_channel *bdev_ch)
 		return;
 	}
 
-	while (!TAILQ_EMPTY(&module_ch->nomem_io)) {
-		bdev_io = TAILQ_FIRST(&module_ch->nomem_io);
-		TAILQ_REMOVE(&module_ch->nomem_io, bdev_io, link);
-		bdev_io->ch->io_outstanding++;
-		module_ch->io_outstanding++;
-		bdev_io->status = SPDK_BDEV_IO_STATUS_PENDING;
-		bdev->fn_table->submit_request(bdev_io->ch->channel, bdev_io);
-		if (bdev_io->status == SPDK_BDEV_IO_STATUS_NOMEM) {
+	while (!TAILQ_EMPTY(&shared_resource->nomem_io)) {
+		bdev_io = TAILQ_FIRST(&shared_resource->nomem_io);
+		TAILQ_REMOVE(&shared_resource->nomem_io, bdev_io, internal.link);
+		bdev_io->internal.ch->io_outstanding++;
+		shared_resource->io_outstanding++;
+		bdev_io->internal.status = SPDK_BDEV_IO_STATUS_PENDING;
+		bdev->fn_table->submit_request(bdev_io->internal.ch->channel, bdev_io);
+		if (bdev_io->internal.status == SPDK_BDEV_IO_STATUS_NOMEM) {
 			break;
 		}
 	}
@@ -2122,36 +2477,36 @@ _spdk_bdev_io_complete(void *ctx)
 {
 	struct spdk_bdev_io *bdev_io = ctx;
 
-	if (spdk_unlikely(bdev_io->in_submit_request || bdev_io->io_submit_ch)) {
+	if (spdk_unlikely(bdev_io->internal.in_submit_request || bdev_io->internal.io_submit_ch)) {
 		/*
 		 * Send the completion to the thread that originally submitted the I/O,
 		 * which may not be the current thread in the case of QoS.
 		 */
-		if (bdev_io->io_submit_ch) {
-			bdev_io->ch = bdev_io->io_submit_ch;
-			bdev_io->io_submit_ch = NULL;
+		if (bdev_io->internal.io_submit_ch) {
+			bdev_io->internal.ch = bdev_io->internal.io_submit_ch;
+			bdev_io->internal.io_submit_ch = NULL;
 		}
 
 		/*
 		 * Defer completion to avoid potential infinite recursion if the
 		 * user's completion callback issues a new I/O.
 		 */
-		spdk_thread_send_msg(spdk_io_channel_get_thread(bdev_io->ch->channel),
+		spdk_thread_send_msg(spdk_io_channel_get_thread(bdev_io->internal.ch->channel),
 				     _spdk_bdev_io_complete, bdev_io);
 		return;
 	}
 
-	if (bdev_io->status == SPDK_BDEV_IO_STATUS_SUCCESS) {
+	if (bdev_io->internal.status == SPDK_BDEV_IO_STATUS_SUCCESS) {
 		switch (bdev_io->type) {
 		case SPDK_BDEV_IO_TYPE_READ:
-			bdev_io->ch->stat.bytes_read += bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen;
-			bdev_io->ch->stat.num_read_ops++;
-			bdev_io->ch->stat.read_latency_ticks += (spdk_get_ticks() - bdev_io->submit_tsc);
+			bdev_io->internal.ch->stat.bytes_read += bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen;
+			bdev_io->internal.ch->stat.num_read_ops++;
+			bdev_io->internal.ch->stat.read_latency_ticks += (spdk_get_ticks() - bdev_io->internal.submit_tsc);
 			break;
 		case SPDK_BDEV_IO_TYPE_WRITE:
-			bdev_io->ch->stat.bytes_written += bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen;
-			bdev_io->ch->stat.num_write_ops++;
-			bdev_io->ch->stat.write_latency_ticks += (spdk_get_ticks() - bdev_io->submit_tsc);
+			bdev_io->internal.ch->stat.bytes_written += bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen;
+			bdev_io->internal.ch->stat.num_write_ops++;
+			bdev_io->internal.ch->stat.write_latency_ticks += (spdk_get_ticks() - bdev_io->internal.submit_tsc);
 			break;
 		default:
 			break;
@@ -2160,40 +2515,29 @@ _spdk_bdev_io_complete(void *ctx)
 
 #ifdef SPDK_CONFIG_VTUNE
 	uint64_t now_tsc = spdk_get_ticks();
-	if (now_tsc > (bdev_io->ch->start_tsc + bdev_io->ch->interval_tsc)) {
+	if (now_tsc > (bdev_io->internal.ch->start_tsc + bdev_io->internal.ch->interval_tsc)) {
 		uint64_t data[5];
 
-		data[0] = bdev_io->ch->stat.num_read_ops;
-		data[1] = bdev_io->ch->stat.bytes_read;
-		data[2] = bdev_io->ch->stat.num_write_ops;
-		data[3] = bdev_io->ch->stat.bytes_written;
+		data[0] = bdev_io->internal.ch->stat.num_read_ops - bdev_io->internal.ch->prev_stat.num_read_ops;
+		data[1] = bdev_io->internal.ch->stat.bytes_read - bdev_io->internal.ch->prev_stat.bytes_read;
+		data[2] = bdev_io->internal.ch->stat.num_write_ops - bdev_io->internal.ch->prev_stat.num_write_ops;
+		data[3] = bdev_io->internal.ch->stat.bytes_written - bdev_io->internal.ch->prev_stat.bytes_written;
 		data[4] = bdev_io->bdev->fn_table->get_spin_time ?
-			  bdev_io->bdev->fn_table->get_spin_time(bdev_io->ch->channel) : 0;
+			  bdev_io->bdev->fn_table->get_spin_time(bdev_io->internal.ch->channel) : 0;
 
-		__itt_metadata_add(g_bdev_mgr.domain, __itt_null, bdev_io->ch->handle,
+		__itt_metadata_add(g_bdev_mgr.domain, __itt_null, bdev_io->internal.ch->handle,
 				   __itt_metadata_u64, 5, data);
 
-		memset(&bdev_io->ch->stat, 0, sizeof(bdev_io->ch->stat));
-		bdev_io->ch->start_tsc = now_tsc;
+		bdev_io->internal.ch->prev_stat = bdev_io->internal.ch->stat;
+		bdev_io->internal.ch->start_tsc = now_tsc;
 	}
 #endif
 
-	assert(bdev_io->cb != NULL);
-	assert(spdk_get_thread() == spdk_io_channel_get_thread(bdev_io->ch->channel));
-
-	bdev_io->cb(bdev_io, bdev_io->status == SPDK_BDEV_IO_STATUS_SUCCESS,
-		    bdev_io->caller_ctx);
-}
-
-static void
-_spdk_bdev_unfreeze_qos_channel(void *ctx)
-{
-	struct spdk_bdev	*bdev = ctx;
+	assert(bdev_io->internal.cb != NULL);
+	assert(spdk_get_thread() == spdk_io_channel_get_thread(bdev_io->internal.ch->channel));
 
-	if (bdev->qos.ch) {
-		bdev->qos.ch->flags &= ~BDEV_CH_RESET_IN_PROGRESS;
-		assert(TAILQ_EMPTY(&bdev->qos.ch->queued_resets));
-	}
+	bdev_io->internal.cb(bdev_io, bdev_io->internal.status == SPDK_BDEV_IO_STATUS_SUCCESS,
+			     bdev_io->internal.caller_ctx);
 }
 
 static void
@@ -2227,10 +2571,10 @@ void
 spdk_bdev_io_complete(struct spdk_bdev_io *bdev_io, enum spdk_bdev_io_status status)
 {
 	struct spdk_bdev *bdev = bdev_io->bdev;
-	struct spdk_bdev_channel *bdev_ch = bdev_io->ch;
-	struct spdk_bdev_module_channel	*module_ch = bdev_ch->module_ch;
+	struct spdk_bdev_channel *bdev_ch = bdev_io->internal.ch;
+	struct spdk_bdev_shared_resource *shared_resource = bdev_ch->shared_resource;
 
-	bdev_io->status = status;
+	bdev_io->internal.status = status;
 
 	if (spdk_unlikely(bdev_io->type == SPDK_BDEV_IO_TYPE_RESET)) {
 		bool unlock_channels = false;
@@ -2238,44 +2582,38 @@ spdk_bdev_io_complete(struct spdk_bdev_io *bdev_io, enum spdk_bdev_io_status sta
 		if (status == SPDK_BDEV_IO_STATUS_NOMEM) {
 			SPDK_ERRLOG("NOMEM returned for reset\n");
 		}
-		pthread_mutex_lock(&bdev->mutex);
-		if (bdev_io == bdev->reset_in_progress) {
-			bdev->reset_in_progress = NULL;
+		pthread_mutex_lock(&bdev->internal.mutex);
+		if (bdev_io == bdev->internal.reset_in_progress) {
+			bdev->internal.reset_in_progress = NULL;
 			unlock_channels = true;
 		}
-		pthread_mutex_unlock(&bdev->mutex);
+		pthread_mutex_unlock(&bdev->internal.mutex);
 
 		if (unlock_channels) {
-			/* Explicitly handle the QoS bdev channel as no IO channel associated */
-			if (bdev->qos.enabled && bdev->qos.thread) {
-				spdk_thread_send_msg(bdev->qos.thread,
-						     _spdk_bdev_unfreeze_qos_channel, bdev);
-			}
-
 			spdk_for_each_channel(__bdev_to_io_dev(bdev), _spdk_bdev_unfreeze_channel,
 					      bdev_io, _spdk_bdev_reset_complete);
 			return;
 		}
 	} else {
 		assert(bdev_ch->io_outstanding > 0);
-		assert(module_ch->io_outstanding > 0);
+		assert(shared_resource->io_outstanding > 0);
 		bdev_ch->io_outstanding--;
-		module_ch->io_outstanding--;
+		shared_resource->io_outstanding--;
 
 		if (spdk_unlikely(status == SPDK_BDEV_IO_STATUS_NOMEM)) {
-			TAILQ_INSERT_HEAD(&module_ch->nomem_io, bdev_io, link);
+			TAILQ_INSERT_HEAD(&shared_resource->nomem_io, bdev_io, internal.link);
 			/*
 			 * Wait for some of the outstanding I/O to complete before we
 			 *  retry any of the nomem_io.  Normally we will wait for
 			 *  NOMEM_THRESHOLD_COUNT I/O to complete but for low queue
 			 *  depth channels we will instead wait for half to complete.
 			 */
-			module_ch->nomem_threshold = spdk_max((int64_t)module_ch->io_outstanding / 2,
-							      (int64_t)module_ch->io_outstanding - NOMEM_THRESHOLD_COUNT);
+			shared_resource->nomem_threshold = spdk_max((int64_t)shared_resource->io_outstanding / 2,
+							   (int64_t)shared_resource->io_outstanding - NOMEM_THRESHOLD_COUNT);
 			return;
 		}
 
-		if (spdk_unlikely(!TAILQ_EMPTY(&module_ch->nomem_io))) {
+		if (spdk_unlikely(!TAILQ_EMPTY(&shared_resource->nomem_io))) {
 			_spdk_bdev_ch_retry_io(bdev_ch);
 		}
 	}
@@ -2288,16 +2626,16 @@ spdk_bdev_io_complete_scsi_status(struct spdk_bdev_io *bdev_io, enum spdk_scsi_s
 				  enum spdk_scsi_sense sk, uint8_t asc, uint8_t ascq)
 {
 	if (sc == SPDK_SCSI_STATUS_GOOD) {
-		bdev_io->status = SPDK_BDEV_IO_STATUS_SUCCESS;
+		bdev_io->internal.status = SPDK_BDEV_IO_STATUS_SUCCESS;
 	} else {
-		bdev_io->status = SPDK_BDEV_IO_STATUS_SCSI_ERROR;
-		bdev_io->error.scsi.sc = sc;
-		bdev_io->error.scsi.sk = sk;
-		bdev_io->error.scsi.asc = asc;
-		bdev_io->error.scsi.ascq = ascq;
+		bdev_io->internal.status = SPDK_BDEV_IO_STATUS_SCSI_ERROR;
+		bdev_io->internal.error.scsi.sc = sc;
+		bdev_io->internal.error.scsi.sk = sk;
+		bdev_io->internal.error.scsi.asc = asc;
+		bdev_io->internal.error.scsi.ascq = ascq;
 	}
 
-	spdk_bdev_io_complete(bdev_io, bdev_io->status);
+	spdk_bdev_io_complete(bdev_io, bdev_io->internal.status);
 }
 
 void
@@ -2309,7 +2647,7 @@ spdk_bdev_io_get_scsi_status(const struct spdk_bdev_io *bdev_io,
 	assert(asc != NULL);
 	assert(ascq != NULL);
 
-	switch (bdev_io->status) {
+	switch (bdev_io->internal.status) {
 	case SPDK_BDEV_IO_STATUS_SUCCESS:
 		*sc = SPDK_SCSI_STATUS_GOOD;
 		*sk = SPDK_SCSI_SENSE_NO_SENSE;
@@ -2320,10 +2658,10 @@ spdk_bdev_io_get_scsi_status(const struct spdk_bdev_io *bdev_io,
 		spdk_scsi_nvme_translate(bdev_io, sc, sk, asc, ascq);
 		break;
 	case SPDK_BDEV_IO_STATUS_SCSI_ERROR:
-		*sc = bdev_io->error.scsi.sc;
-		*sk = bdev_io->error.scsi.sk;
-		*asc = bdev_io->error.scsi.asc;
-		*ascq = bdev_io->error.scsi.ascq;
+		*sc = bdev_io->internal.error.scsi.sc;
+		*sk = bdev_io->internal.error.scsi.sk;
+		*asc = bdev_io->internal.error.scsi.asc;
+		*ascq = bdev_io->internal.error.scsi.ascq;
 		break;
 	default:
 		*sc = SPDK_SCSI_STATUS_CHECK_CONDITION;
@@ -2338,14 +2676,14 @@ void
 spdk_bdev_io_complete_nvme_status(struct spdk_bdev_io *bdev_io, int sct, int sc)
 {
 	if (sct == SPDK_NVME_SCT_GENERIC && sc == SPDK_NVME_SC_SUCCESS) {
-		bdev_io->status = SPDK_BDEV_IO_STATUS_SUCCESS;
+		bdev_io->internal.status = SPDK_BDEV_IO_STATUS_SUCCESS;
 	} else {
-		bdev_io->error.nvme.sct = sct;
-		bdev_io->error.nvme.sc = sc;
-		bdev_io->status = SPDK_BDEV_IO_STATUS_NVME_ERROR;
+		bdev_io->internal.error.nvme.sct = sct;
+		bdev_io->internal.error.nvme.sc = sc;
+		bdev_io->internal.status = SPDK_BDEV_IO_STATUS_NVME_ERROR;
 	}
 
-	spdk_bdev_io_complete(bdev_io, bdev_io->status);
+	spdk_bdev_io_complete(bdev_io, bdev_io->internal.status);
 }
 
 void
@@ -2354,10 +2692,10 @@ spdk_bdev_io_get_nvme_status(const struct spdk_bdev_io *bdev_io, int *sct, int *
 	assert(sct != NULL);
 	assert(sc != NULL);
 
-	if (bdev_io->status == SPDK_BDEV_IO_STATUS_NVME_ERROR) {
-		*sct = bdev_io->error.nvme.sct;
-		*sc = bdev_io->error.nvme.sc;
-	} else if (bdev_io->status == SPDK_BDEV_IO_STATUS_SUCCESS) {
+	if (bdev_io->internal.status == SPDK_BDEV_IO_STATUS_NVME_ERROR) {
+		*sct = bdev_io->internal.error.nvme.sct;
+		*sc = bdev_io->internal.error.nvme.sc;
+	} else if (bdev_io->internal.status == SPDK_BDEV_IO_STATUS_SUCCESS) {
 		*sct = SPDK_NVME_SCT_GENERIC;
 		*sc = SPDK_NVME_SC_SUCCESS;
 	} else {
@@ -2369,7 +2707,57 @@ spdk_bdev_io_get_nvme_status(const struct spdk_bdev_io *bdev_io, int *sct, int *
 struct spdk_thread *
 spdk_bdev_io_get_thread(struct spdk_bdev_io *bdev_io)
 {
-	return spdk_io_channel_get_thread(bdev_io->ch->channel);
+	return spdk_io_channel_get_thread(bdev_io->internal.ch->channel);
+}
+
+static void
+_spdk_bdev_qos_config_type(struct spdk_bdev *bdev, uint64_t qos_set,
+			   enum spdk_bdev_qos_type qos_type)
+{
+	uint64_t	min_qos_set = 0;
+
+	switch (qos_type) {
+	case SPDK_BDEV_QOS_RW_IOPS_RATE_LIMIT:
+		min_qos_set = SPDK_BDEV_QOS_MIN_IOS_PER_SEC;
+		break;
+	case SPDK_BDEV_QOS_RW_BYTEPS_RATE_LIMIT:
+		min_qos_set = SPDK_BDEV_QOS_MIN_BW_IN_MB_PER_SEC;
+		break;
+	default:
+		SPDK_ERRLOG("Unsupported QoS type.\n");
+		return;
+	}
+
+	if (qos_set % min_qos_set) {
+		SPDK_ERRLOG("Assigned QoS %" PRIu64 " on bdev %s is not multiple of %lu\n",
+			    qos_set, bdev->name, min_qos_set);
+		SPDK_ERRLOG("Failed to enable QoS on this bdev %s\n", bdev->name);
+		return;
+	}
+
+	if (!bdev->internal.qos) {
+		bdev->internal.qos = calloc(1, sizeof(*bdev->internal.qos));
+		if (!bdev->internal.qos) {
+			SPDK_ERRLOG("Unable to allocate memory for QoS tracking\n");
+			return;
+		}
+	}
+
+	switch (qos_type) {
+	case SPDK_BDEV_QOS_RW_IOPS_RATE_LIMIT:
+		bdev->internal.qos->iops_rate_limit = qos_set;
+		break;
+	case SPDK_BDEV_QOS_RW_BYTEPS_RATE_LIMIT:
+		bdev->internal.qos->byte_rate_limit = qos_set * 1024 * 1024;
+		break;
+	default:
+		break;
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Bdev:%s QoS type:%d set:%lu\n",
+		      bdev->name, qos_type, qos_set);
+
+	return;
 }
 
 static void
@@ -2377,46 +2765,40 @@ _spdk_bdev_qos_config(struct spdk_bdev *bdev)
 {
 	struct spdk_conf_section	*sp = NULL;
 	const char			*val = NULL;
-	uint64_t			ios_per_sec = 0;
-	int				i = 0;
+	uint64_t			qos_set = 0;
+	int				i = 0, j = 0;
 
 	sp = spdk_conf_find_section(NULL, "QoS");
 	if (!sp) {
 		return;
 	}
 
-	while (true) {
-		val = spdk_conf_section_get_nmval(sp, "Limit_IOPS", i, 0);
-		if (!val) {
-			break;
-		}
-
-		if (strcmp(bdev->name, val) != 0) {
-			i++;
-			continue;
-		}
+	while (j < SPDK_BDEV_QOS_NUM_TYPES) {
+		i = 0;
+		while (true) {
+			val = spdk_conf_section_get_nmval(sp, qos_type_str[j], i, 0);
+			if (!val) {
+				break;
+			}
 
-		val = spdk_conf_section_get_nmval(sp, "Limit_IOPS", i, 1);
-		if (!val) {
-			return;
-		}
+			if (strcmp(bdev->name, val) != 0) {
+				i++;
+				continue;
+			}
 
-		ios_per_sec = strtoull(val, NULL, 10);
-		if (ios_per_sec > 0) {
-			if (ios_per_sec % SPDK_BDEV_QOS_MIN_IOS_PER_SEC) {
-				SPDK_ERRLOG("Assigned IOPS %" PRIu64 " on bdev %s is not multiple of %u\n",
-					    ios_per_sec, bdev->name, SPDK_BDEV_QOS_MIN_IOS_PER_SEC);
-				SPDK_ERRLOG("Failed to enable QoS on this bdev %s\n", bdev->name);
-			} else {
-				bdev->qos.enabled = true;
-				bdev->qos.rate_limit = ios_per_sec;
-				SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Bdev:%s QoS:%lu\n",
-					      bdev->name, bdev->qos.rate_limit);
+			val = spdk_conf_section_get_nmval(sp, qos_type_str[j], i, 1);
+			if (val) {
+				qos_set = strtoull(val, NULL, 10);
+				_spdk_bdev_qos_config_type(bdev, qos_set, j);
 			}
+
+			break;
 		}
 
-		return;
+		j++;
 	}
+
+	return;
 }
 
 static int
@@ -2434,13 +2816,14 @@ spdk_bdev_init(struct spdk_bdev *bdev)
 		return -EEXIST;
 	}
 
-	bdev->status = SPDK_BDEV_STATUS_READY;
+	bdev->internal.status = SPDK_BDEV_STATUS_READY;
+	bdev->internal.measured_queue_depth = UINT64_MAX;
 
-	TAILQ_INIT(&bdev->open_descs);
+	TAILQ_INIT(&bdev->internal.open_descs);
 
 	TAILQ_INIT(&bdev->aliases);
 
-	bdev->reset_in_progress = NULL;
+	bdev->internal.reset_in_progress = NULL;
 
 	_spdk_bdev_qos_config(bdev);
 
@@ -2448,7 +2831,7 @@ spdk_bdev_init(struct spdk_bdev *bdev)
 				spdk_bdev_channel_create, spdk_bdev_channel_destroy,
 				sizeof(struct spdk_bdev_channel));
 
-	pthread_mutex_init(&bdev->mutex, NULL);
+	pthread_mutex_init(&bdev->internal.mutex, NULL);
 	return 0;
 }
 
@@ -2461,8 +2844,8 @@ spdk_bdev_destroy_cb(void *io_device)
 	void			*cb_arg;
 
 	bdev = __bdev_from_io_dev(io_device);
-	cb_fn = bdev->unregister_cb;
-	cb_arg = bdev->unregister_ctx;
+	cb_fn = bdev->internal.unregister_cb;
+	cb_arg = bdev->internal.unregister_ctx;
 
 	rc = bdev->fn_table->destruct(bdev->ctxt);
 	if (rc < 0) {
@@ -2477,7 +2860,9 @@ spdk_bdev_destroy_cb(void *io_device)
 static void
 spdk_bdev_fini(struct spdk_bdev *bdev)
 {
-	pthread_mutex_destroy(&bdev->mutex);
+	pthread_mutex_destroy(&bdev->internal.mutex);
+
+	free(bdev->internal.qos);
 
 	spdk_io_device_unregister(__bdev_to_io_dev(bdev), spdk_bdev_destroy_cb);
 }
@@ -2486,14 +2871,32 @@ static void
 spdk_bdev_start(struct spdk_bdev *bdev)
 {
 	struct spdk_bdev_module *module;
+	uint32_t action;
 
 	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Inserting bdev %s into list\n", bdev->name);
-	TAILQ_INSERT_TAIL(&g_bdev_mgr.bdevs, bdev, link);
+	TAILQ_INSERT_TAIL(&g_bdev_mgr.bdevs, bdev, internal.link);
+
+	/* Examine configuration before initializing I/O */
+	TAILQ_FOREACH(module, &g_bdev_mgr.bdev_modules, internal.tailq) {
+		if (module->examine_config) {
+			action = module->internal.action_in_progress;
+			module->internal.action_in_progress++;
+			module->examine_config(bdev);
+			if (action != module->internal.action_in_progress) {
+				SPDK_ERRLOG("examine_config for module %s did not call spdk_bdev_module_examine_done()\n",
+					    module->name);
+			}
+		}
+	}
 
-	TAILQ_FOREACH(module, &g_bdev_mgr.bdev_modules, tailq) {
-		if (module->examine) {
-			module->action_in_progress++;
-			module->examine(bdev);
+	if (bdev->internal.claim_module) {
+		return;
+	}
+
+	TAILQ_FOREACH(module, &g_bdev_mgr.bdev_modules, internal.tailq) {
+		if (module->examine_disk) {
+			module->internal.action_in_progress++;
+			module->examine_disk(bdev);
 		}
 	}
 }
@@ -2519,9 +2922,9 @@ spdk_vbdev_remove_base_bdevs(struct spdk_bdev *vbdev)
 	bool found;
 
 	/* Iterate over base bdevs to remove vbdev from them. */
-	for (i = 0; i < vbdev->base_bdevs_cnt; i++) {
+	for (i = 0; i < vbdev->internal.base_bdevs_cnt; i++) {
 		found = false;
-		base = vbdev->base_bdevs[i];
+		base = vbdev->internal.base_bdevs[i];
 
 		for (j = 0; j < base->vbdevs_cnt; j++) {
 			if (base->vbdevs[j] != vbdev) {
@@ -2552,9 +2955,9 @@ spdk_vbdev_remove_base_bdevs(struct spdk_bdev *vbdev)
 		}
 	}
 
-	free(vbdev->base_bdevs);
-	vbdev->base_bdevs = NULL;
-	vbdev->base_bdevs_cnt = 0;
+	free(vbdev->internal.base_bdevs);
+	vbdev->internal.base_bdevs = NULL;
+	vbdev->internal.base_bdevs_cnt = 0;
 }
 
 static int
@@ -2565,23 +2968,23 @@ spdk_vbdev_set_base_bdevs(struct spdk_bdev *vbdev, struct spdk_bdev **base_bdevs
 	size_t i;
 
 	/* Adding base bdevs isn't supported (yet?). */
-	assert(vbdev->base_bdevs_cnt == 0);
+	assert(vbdev->internal.base_bdevs_cnt == 0);
 
-	vbdev->base_bdevs = malloc(cnt * sizeof(vbdev->base_bdevs[0]));
-	if (!vbdev->base_bdevs) {
+	vbdev->internal.base_bdevs = malloc(cnt * sizeof(vbdev->internal.base_bdevs[0]));
+	if (!vbdev->internal.base_bdevs) {
 		SPDK_ERRLOG("%s - realloc() failed\n", vbdev->name);
 		return -ENOMEM;
 	}
 
-	memcpy(vbdev->base_bdevs, base_bdevs, cnt * sizeof(vbdev->base_bdevs[0]));
-	vbdev->base_bdevs_cnt = cnt;
+	memcpy(vbdev->internal.base_bdevs, base_bdevs, cnt * sizeof(vbdev->internal.base_bdevs[0]));
+	vbdev->internal.base_bdevs_cnt = cnt;
 
 	/* Iterate over base bdevs to add this vbdev to them. */
 	for (i = 0; i < cnt; i++) {
-		base = vbdev->base_bdevs[i];
+		base = vbdev->internal.base_bdevs[i];
 
 		assert(base != NULL);
-		assert(base->claim_module != NULL);
+		assert(base->internal.claim_module != NULL);
 
 		vbdevs = realloc(base->vbdevs, (base->vbdevs_cnt + 1) * sizeof(vbdevs[0]));
 		if (!vbdevs) {
@@ -2627,8 +3030,8 @@ spdk_vbdev_register(struct spdk_bdev *vbdev, struct spdk_bdev **base_bdevs, int
 void
 spdk_bdev_destruct_done(struct spdk_bdev *bdev, int bdeverrno)
 {
-	if (bdev->unregister_cb != NULL) {
-		bdev->unregister_cb(bdev->unregister_ctx, bdeverrno);
+	if (bdev->internal.unregister_cb != NULL) {
+		bdev->internal.unregister_cb(bdev->internal.unregister_ctx, bdeverrno);
 	}
 }
 
@@ -2652,19 +3055,21 @@ spdk_bdev_unregister(struct spdk_bdev *bdev, spdk_bdev_unregister_cb cb_fn, void
 	thread = spdk_get_thread();
 	if (!thread) {
 		/* The user called this from a non-SPDK thread. */
-		cb_fn(cb_arg, -ENOTSUP);
+		if (cb_fn != NULL) {
+			cb_fn(cb_arg, -ENOTSUP);
+		}
 		return;
 	}
 
-	pthread_mutex_lock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
 
 	spdk_vbdev_remove_base_bdevs(bdev);
 
-	bdev->status = SPDK_BDEV_STATUS_REMOVING;
-	bdev->unregister_cb = cb_fn;
-	bdev->unregister_ctx = cb_arg;
+	bdev->internal.status = SPDK_BDEV_STATUS_REMOVING;
+	bdev->internal.unregister_cb = cb_fn;
+	bdev->internal.unregister_ctx = cb_arg;
 
-	TAILQ_FOREACH_SAFE(desc, &bdev->open_descs, link, tmp) {
+	TAILQ_FOREACH_SAFE(desc, &bdev->internal.open_descs, link, tmp) {
 		if (desc->remove_cb) {
 			do_destruct = false;
 			/*
@@ -2673,17 +3078,21 @@ spdk_bdev_unregister(struct spdk_bdev *bdev, spdk_bdev_unregister_cb cb_fn, void
 			 *  we don't recursively unregister this bdev again if the remove_cb
 			 *  immediately closes its descriptor.
 			 */
-			spdk_thread_send_msg(thread, _remove_notify, desc);
+			if (!desc->remove_scheduled) {
+				/* Avoid scheduling removal of the same descriptor multiple times. */
+				desc->remove_scheduled = true;
+				spdk_thread_send_msg(thread, _remove_notify, desc);
+			}
 		}
 	}
 
 	if (!do_destruct) {
-		pthread_mutex_unlock(&bdev->mutex);
+		pthread_mutex_unlock(&bdev->internal.mutex);
 		return;
 	}
 
-	TAILQ_REMOVE(&g_bdev_mgr.bdevs, bdev, link);
-	pthread_mutex_unlock(&bdev->mutex);
+	TAILQ_REMOVE(&g_bdev_mgr.bdevs, bdev, internal.link);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	spdk_bdev_fini(bdev);
 }
@@ -2700,16 +3109,19 @@ spdk_bdev_open(struct spdk_bdev *bdev, bool write, spdk_bdev_remove_cb_t remove_
 		return -ENOMEM;
 	}
 
-	pthread_mutex_lock(&bdev->mutex);
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Opening descriptor %p for bdev %s on thread %p\n", desc, bdev->name,
+		      spdk_get_thread());
 
-	if (write && bdev->claim_module) {
-		SPDK_INFOLOG(SPDK_LOG_BDEV, "Could not open %s - already claimed\n", bdev->name);
+	pthread_mutex_lock(&bdev->internal.mutex);
+
+	if (write && bdev->internal.claim_module) {
+		SPDK_ERRLOG("Could not open %s - already claimed\n", bdev->name);
 		free(desc);
-		pthread_mutex_unlock(&bdev->mutex);
+		pthread_mutex_unlock(&bdev->internal.mutex);
 		return -EPERM;
 	}
 
-	TAILQ_INSERT_TAIL(&bdev->open_descs, desc, link);
+	TAILQ_INSERT_TAIL(&bdev->internal.open_descs, desc, link);
 
 	desc->bdev = bdev;
 	desc->remove_cb = remove_cb;
@@ -2717,7 +3129,7 @@ spdk_bdev_open(struct spdk_bdev *bdev, bool write, spdk_bdev_remove_cb_t remove_
 	desc->write = write;
 	*_desc = desc;
 
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	return 0;
 }
@@ -2728,18 +3140,36 @@ spdk_bdev_close(struct spdk_bdev_desc *desc)
 	struct spdk_bdev *bdev = desc->bdev;
 	bool do_unregister = false;
 
-	pthread_mutex_lock(&bdev->mutex);
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Closing descriptor %p for bdev %s on thread %p\n", desc, bdev->name,
+		      spdk_get_thread());
+
+	pthread_mutex_lock(&bdev->internal.mutex);
 
-	TAILQ_REMOVE(&bdev->open_descs, desc, link);
+	TAILQ_REMOVE(&bdev->internal.open_descs, desc, link);
 	free(desc);
 
-	if (bdev->status == SPDK_BDEV_STATUS_REMOVING && TAILQ_EMPTY(&bdev->open_descs)) {
+	/* If no more descriptors, kill QoS channel */
+	if (bdev->internal.qos && TAILQ_EMPTY(&bdev->internal.open_descs)) {
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV, "Closed last descriptor for bdev %s on thread %p. Stopping QoS.\n",
+			      bdev->name, spdk_get_thread());
+
+		if (spdk_bdev_qos_destroy(bdev)) {
+			/* There isn't anything we can do to recover here. Just let the
+			 * old QoS poller keep running. The QoS handling won't change
+			 * cores when the user allocates a new channel, but it won't break. */
+			SPDK_ERRLOG("Unable to shut down QoS poller. It will continue running on the current thread.\n");
+		}
+	}
+
+	spdk_bdev_set_qd_sampling_period(bdev, 0);
+
+	if (bdev->internal.status == SPDK_BDEV_STATUS_REMOVING && TAILQ_EMPTY(&bdev->internal.open_descs)) {
 		do_unregister = true;
 	}
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	if (do_unregister == true) {
-		spdk_bdev_unregister(bdev, bdev->unregister_cb, bdev->unregister_ctx);
+		spdk_bdev_unregister(bdev, bdev->internal.unregister_cb, bdev->internal.unregister_ctx);
 	}
 }
 
@@ -2747,9 +3177,9 @@ int
 spdk_bdev_module_claim_bdev(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
 			    struct spdk_bdev_module *module)
 {
-	if (bdev->claim_module != NULL) {
+	if (bdev->internal.claim_module != NULL) {
 		SPDK_ERRLOG("bdev %s already claimed by module %s\n", bdev->name,
-			    bdev->claim_module->name);
+			    bdev->internal.claim_module->name);
 		return -EPERM;
 	}
 
@@ -2757,15 +3187,15 @@ spdk_bdev_module_claim_bdev(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
 		desc->write = true;
 	}
 
-	bdev->claim_module = module;
+	bdev->internal.claim_module = module;
 	return 0;
 }
 
 void
 spdk_bdev_module_release_bdev(struct spdk_bdev *bdev)
 {
-	assert(bdev->claim_module != NULL);
-	bdev->claim_module = NULL;
+	assert(bdev->internal.claim_module != NULL);
+	bdev->internal.claim_module = NULL;
 }
 
 struct spdk_bdev *
@@ -2812,12 +3242,12 @@ spdk_bdev_module_list_add(struct spdk_bdev_module *bdev_module)
 {
 
 	if (spdk_bdev_module_list_find(bdev_module->name)) {
-		fprintf(stderr, "ERROR: module '%s' already registered.\n", bdev_module->name);
+		SPDK_ERRLOG("ERROR: module '%s' already registered.\n", bdev_module->name);
 		assert(false);
 	}
 
 	if (bdev_module->async_init) {
-		bdev_module->action_in_progress = 1;
+		bdev_module->internal.action_in_progress = 1;
 	}
 
 	/*
@@ -2825,10 +3255,10 @@ spdk_bdev_module_list_add(struct spdk_bdev_module *bdev_module)
 	 *  ready to handle examine callbacks from later modules that will
 	 *  register physical bdevs.
 	 */
-	if (bdev_module->examine != NULL) {
-		TAILQ_INSERT_HEAD(&g_bdev_mgr.bdev_modules, bdev_module, tailq);
+	if (bdev_module->examine_config != NULL || bdev_module->examine_disk != NULL) {
+		TAILQ_INSERT_HEAD(&g_bdev_mgr.bdev_modules, bdev_module, internal.tailq);
 	} else {
-		TAILQ_INSERT_TAIL(&g_bdev_mgr.bdev_modules, bdev_module, tailq);
+		TAILQ_INSERT_TAIL(&g_bdev_mgr.bdev_modules, bdev_module, internal.tailq);
 	}
 }
 
@@ -2837,7 +3267,7 @@ spdk_bdev_module_list_find(const char *name)
 {
 	struct spdk_bdev_module *bdev_module;
 
-	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, tailq) {
+	TAILQ_FOREACH(bdev_module, &g_bdev_mgr.bdev_modules, internal.tailq) {
 		if (strcmp(name, bdev_module->name) == 0) {
 			break;
 		}
@@ -2852,7 +3282,7 @@ spdk_bdev_write_zeroes_split(struct spdk_bdev_io *bdev_io, bool success, void *c
 	uint64_t len;
 
 	if (!success) {
-		bdev_io->cb = bdev_io->u.bdev.stored_user_cb;
+		bdev_io->internal.cb = bdev_io->u.bdev.stored_user_cb;
 		_spdk_bdev_io_complete(bdev_io);
 		return;
 	}
@@ -2862,7 +3292,7 @@ spdk_bdev_write_zeroes_split(struct spdk_bdev_io *bdev_io, bool success, void *c
 		       ZERO_BUFFER_SIZE);
 
 	bdev_io->u.bdev.offset_blocks = bdev_io->u.bdev.split_current_offset_blocks;
-	bdev_io->u.bdev.iov.iov_len = len;
+	bdev_io->u.bdev.iovs[0].iov_len = len;
 	bdev_io->u.bdev.num_blocks = len / spdk_bdev_get_block_size(bdev_io->bdev);
 	bdev_io->u.bdev.split_remaining_num_blocks -= bdev_io->u.bdev.num_blocks;
 	bdev_io->u.bdev.split_current_offset_blocks += bdev_io->u.bdev.num_blocks;
@@ -2885,9 +3315,9 @@ struct set_qos_limit_ctx {
 static void
 _spdk_bdev_set_qos_limit_done(struct set_qos_limit_ctx *ctx, int status)
 {
-	pthread_mutex_lock(&ctx->bdev->mutex);
-	ctx->bdev->qos.mod_in_progress = false;
-	pthread_mutex_unlock(&ctx->bdev->mutex);
+	pthread_mutex_lock(&ctx->bdev->internal.mutex);
+	ctx->bdev->internal.qos_mod_in_progress = false;
+	pthread_mutex_unlock(&ctx->bdev->internal.mutex);
 
 	ctx->cb_fn(ctx->cb_arg, status);
 	free(ctx);
@@ -2898,21 +3328,36 @@ _spdk_bdev_disable_qos_done(void *cb_arg)
 {
 	struct set_qos_limit_ctx *ctx = cb_arg;
 	struct spdk_bdev *bdev = ctx->bdev;
+	struct spdk_bdev_io *bdev_io;
 	struct spdk_bdev_qos *qos;
 
-	pthread_mutex_lock(&bdev->mutex);
-	qos = &bdev->qos;
+	pthread_mutex_lock(&bdev->internal.mutex);
+	qos = bdev->internal.qos;
+	bdev->internal.qos = NULL;
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
-	qos->enabled = false;
-	_spdk_bdev_abort_queued_io(&qos->queued, qos->ch);
-	_spdk_bdev_channel_destroy(qos->ch);
-	free(qos->ch);
-	qos->ch = NULL;
-	qos->thread = NULL;
-	qos->max_ios_per_timeslice = 0;
-	qos->io_submitted_this_timeslice = 0;
+	while (!TAILQ_EMPTY(&qos->queued)) {
+		/* Send queued I/O back to their original thread for resubmission. */
+		bdev_io = TAILQ_FIRST(&qos->queued);
+		TAILQ_REMOVE(&qos->queued, bdev_io, internal.link);
+
+		if (bdev_io->internal.io_submit_ch) {
+			/*
+			 * Channel was changed when sending it to the QoS thread - change it back
+			 *  before sending it back to the original thread.
+			 */
+			bdev_io->internal.ch = bdev_io->internal.io_submit_ch;
+			bdev_io->internal.io_submit_ch = NULL;
+		}
+
+		spdk_thread_send_msg(spdk_io_channel_get_thread(bdev_io->internal.ch->channel),
+				     _spdk_bdev_io_submit, bdev_io);
+	}
+
+	spdk_put_io_channel(spdk_io_channel_from_ctx(qos->ch));
 	spdk_poller_unregister(&qos->poller);
-	pthread_mutex_unlock(&bdev->mutex);
+
+	free(qos);
 
 	_spdk_bdev_set_qos_limit_done(ctx, 0);
 }
@@ -2925,13 +3370,11 @@ _spdk_bdev_disable_qos_msg_done(struct spdk_io_channel_iter *i, int status)
 	struct set_qos_limit_ctx *ctx = spdk_io_channel_iter_get_ctx(i);
 	struct spdk_thread *thread;
 
-	pthread_mutex_lock(&bdev->mutex);
-	thread = bdev->qos.thread;
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	thread = bdev->internal.qos->thread;
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
-	if (thread) {
-		spdk_thread_send_msg(thread, _spdk_bdev_disable_qos_done, ctx);
-	}
+	spdk_thread_send_msg(thread, _spdk_bdev_disable_qos_done, ctx);
 }
 
 static void
@@ -2951,9 +3394,9 @@ _spdk_bdev_update_qos_limit_iops_msg(void *cb_arg)
 	struct set_qos_limit_ctx *ctx = cb_arg;
 	struct spdk_bdev *bdev = ctx->bdev;
 
-	pthread_mutex_lock(&bdev->mutex);
-	spdk_bdev_qos_update_max_ios_per_timeslice(&bdev->qos);
-	pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	spdk_bdev_qos_update_max_quota_per_timeslice(bdev->internal.qos);
+	pthread_mutex_unlock(&bdev->internal.mutex);
 
 	_spdk_bdev_set_qos_limit_done(ctx, 0);
 }
@@ -2965,13 +3408,11 @@ _spdk_bdev_enable_qos_msg(struct spdk_io_channel_iter *i)
 	struct spdk_bdev *bdev = __bdev_from_io_dev(io_device);
 	struct spdk_io_channel *ch = spdk_io_channel_iter_get_channel(i);
 	struct spdk_bdev_channel *bdev_ch = spdk_io_channel_get_ctx(ch);
-	int rc;
 
-	pthread_mutex_lock(&bdev->mutex);
-	rc = _spdk_bdev_enable_qos(bdev, bdev_ch);
-	pthread_mutex_unlock(&bdev->mutex);
-
-	spdk_for_each_channel_continue(i, rc);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	_spdk_bdev_enable_qos(bdev, bdev_ch);
+	pthread_mutex_unlock(&bdev->internal.mutex);
+	spdk_for_each_channel_continue(i, 0);
 }
 
 static void
@@ -2987,7 +3428,6 @@ spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
 			     void (*cb_fn)(void *cb_arg, int status), void *cb_arg)
 {
 	struct set_qos_limit_ctx *ctx;
-	struct spdk_thread *thread;
 
 	if (ios_per_sec > 0 && ios_per_sec % SPDK_BDEV_QOS_MIN_IOS_PER_SEC) {
 		SPDK_ERRLOG("Requested ios_per_sec limit %" PRIu64 " is not a multiple of %u\n",
@@ -3006,44 +3446,50 @@ spdk_bdev_set_qos_limit_iops(struct spdk_bdev *bdev, uint64_t ios_per_sec,
 	ctx->cb_arg = cb_arg;
 	ctx->bdev = bdev;
 
-	pthread_mutex_lock(&bdev->mutex);
-	if (bdev->qos.mod_in_progress) {
-		pthread_mutex_unlock(&bdev->mutex);
+	pthread_mutex_lock(&bdev->internal.mutex);
+	if (bdev->internal.qos_mod_in_progress) {
+		pthread_mutex_unlock(&bdev->internal.mutex);
 		free(ctx);
 		cb_fn(cb_arg, -EAGAIN);
 		return;
 	}
-	thread = bdev->qos.thread;
-	/* QoS not enabled on this bdev */
-	if (!thread && ios_per_sec == 0) {
-		pthread_mutex_unlock(&bdev->mutex);
-		SPDK_ERRLOG("Requested ios_per_sec limit %" PRIu64 " is not a multiple of %u\n",
-			    ios_per_sec, SPDK_BDEV_QOS_MIN_IOS_PER_SEC);
-		free(ctx);
-		cb_fn(cb_arg, -EINVAL);
-		return;
-	}
-	bdev->qos.enabled = true;
-	bdev->qos.mod_in_progress = true;
-	bdev->qos.rate_limit = ios_per_sec;
-	pthread_mutex_unlock(&bdev->mutex);
+	bdev->internal.qos_mod_in_progress = true;
+
+	if (ios_per_sec > 0) {
+		if (bdev->internal.qos == NULL) {
+			/* Enabling */
+			bdev->internal.qos = calloc(1, sizeof(*bdev->internal.qos));
+			if (!bdev->internal.qos) {
+				pthread_mutex_unlock(&bdev->internal.mutex);
+				SPDK_ERRLOG("Unable to allocate memory for QoS tracking\n");
+				free(ctx);
+				cb_fn(cb_arg, -ENOMEM);
+				return;
+			}
 
-	if (thread) {
-		if (ios_per_sec == 0) {
+			bdev->internal.qos->iops_rate_limit = ios_per_sec;
+			spdk_for_each_channel(__bdev_to_io_dev(bdev),
+					      _spdk_bdev_enable_qos_msg, ctx,
+					      _spdk_bdev_enable_qos_done);
+		} else {
+			/* Updating */
+			bdev->internal.qos->iops_rate_limit = ios_per_sec;
+			spdk_thread_send_msg(bdev->internal.qos->thread, _spdk_bdev_update_qos_limit_iops_msg, ctx);
+		}
+	} else {
+		if (bdev->internal.qos != NULL) {
 			/* Disabling */
 			spdk_for_each_channel(__bdev_to_io_dev(bdev),
 					      _spdk_bdev_disable_qos_msg, ctx,
 					      _spdk_bdev_disable_qos_msg_done);
 		} else {
-			/* Updating */
-			spdk_thread_send_msg(thread, _spdk_bdev_update_qos_limit_iops_msg, ctx);
+			pthread_mutex_unlock(&bdev->internal.mutex);
+			_spdk_bdev_set_qos_limit_done(ctx, 0);
+			return;
 		}
-	} else {
-		/* Enabling */
-		spdk_for_each_channel(__bdev_to_io_dev(bdev),
-				      _spdk_bdev_enable_qos_msg, ctx,
-				      _spdk_bdev_enable_qos_done);
 	}
+
+	pthread_mutex_unlock(&bdev->internal.mutex);
 }
 
 SPDK_LOG_REGISTER_COMPONENT("bdev", SPDK_LOG_BDEV)
diff --git a/lib/bdev/error/vbdev_error.c b/lib/bdev/error/vbdev_error.c
index 2226785ec..95cd85e43 100644
--- a/lib/bdev/error/vbdev_error.c
+++ b/lib/bdev/error/vbdev_error.c
@@ -43,7 +43,7 @@
 #include "spdk/nvme_spec.h"
 #include "spdk/string.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 #include "vbdev_error.h"
@@ -89,19 +89,13 @@ static struct spdk_bdev_module error_if = {
 	.name = "error",
 	.module_init = vbdev_error_init,
 	.module_fini = vbdev_error_fini,
-	.examine = vbdev_error_examine,
+	.examine_config = vbdev_error_examine,
 	.config_json = vbdev_error_config_json,
 
 };
 
 SPDK_BDEV_MODULE_REGISTER(&error_if)
 
-static void
-spdk_error_free_base(struct spdk_bdev_part_base *base)
-{
-	free(base);
-}
-
 int
 spdk_vbdev_inject_error(char *name, uint32_t io_type, uint32_t error_type, uint32_t error_num)
 {
@@ -119,7 +113,7 @@ spdk_vbdev_inject_error(char *name, uint32_t io_type, uint32_t error_type, uint3
 	}
 
 	TAILQ_FOREACH(part, &g_error_disks, tailq) {
-		if (bdev == &part->bdev) {
+		if (bdev == spdk_bdev_part_get_bdev(part)) {
 			error_disk = (struct error_disk *)part;
 			break;
 		}
@@ -212,7 +206,7 @@ static int
 vbdev_error_destruct(void *ctx)
 {
 	struct error_disk *error_disk = ctx;
-	struct spdk_bdev *base_bdev = error_disk->part.base->bdev;
+	struct spdk_bdev *base_bdev = spdk_bdev_part_get_base_bdev(&error_disk->part);
 	int rc;
 
 	rc = vbdev_error_config_remove(base_bdev->name);
@@ -227,12 +221,13 @@ static int
 vbdev_error_dump_info_json(void *ctx, struct spdk_json_write_ctx *w)
 {
 	struct error_disk *error_disk = ctx;
+	struct spdk_bdev *base_bdev = spdk_bdev_part_get_base_bdev(&error_disk->part);
 
 	spdk_json_write_name(w, "error_disk");
 	spdk_json_write_object_begin(w);
 
 	spdk_json_write_name(w, "base_bdev");
-	spdk_json_write_string(w, error_disk->part.base->bdev->name);
+	spdk_json_write_string(w, base_bdev->name);
 
 	spdk_json_write_object_end(w);
 
@@ -267,33 +262,27 @@ _spdk_vbdev_error_create(struct spdk_bdev *base_bdev)
 	char *name;
 	int rc;
 
-	base = calloc(1, sizeof(*base));
+	base = spdk_bdev_part_base_construct(base_bdev,
+					     spdk_vbdev_error_base_bdev_hotremove_cb,
+					     &error_if, &vbdev_error_fn_table, &g_error_disks,
+					     NULL, NULL, sizeof(struct error_channel),
+					     NULL, NULL);
 	if (!base) {
-		SPDK_ERRLOG("Memory allocation failure\n");
-		return -1;
-	}
-
-	rc = spdk_bdev_part_base_construct(base, base_bdev,
-					   spdk_vbdev_error_base_bdev_hotremove_cb,
-					   &error_if, &vbdev_error_fn_table,
-					   &g_error_disks, spdk_error_free_base,
-					   sizeof(struct error_channel), NULL, NULL);
-	if (rc) {
 		SPDK_ERRLOG("could not construct part base for bdev %s\n", spdk_bdev_get_name(base_bdev));
-		return rc;
+		return -ENOMEM;
 	}
 
 	disk = calloc(1, sizeof(*disk));
 	if (!disk) {
 		SPDK_ERRLOG("Memory allocation failure\n");
-		spdk_error_free_base(base);
+		spdk_bdev_part_base_free(base);
 		return -ENOMEM;
 	}
 
 	name = spdk_sprintf_alloc("EE_%s", spdk_bdev_get_name(base_bdev));
 	if (!name) {
 		SPDK_ERRLOG("name allocation failure\n");
-		spdk_error_free_base(base);
+		spdk_bdev_part_base_free(base);
 		free(disk);
 		return -ENOMEM;
 	}
@@ -303,7 +292,7 @@ _spdk_vbdev_error_create(struct spdk_bdev *base_bdev)
 	if (rc) {
 		SPDK_ERRLOG("could not construct part for bdev %s\n", spdk_bdev_get_name(base_bdev));
 		/* spdk_bdev_part_construct will free name on failure */
-		spdk_error_free_base(base);
+		spdk_bdev_part_base_free(base);
 		free(disk);
 		return rc;
 	}
@@ -341,6 +330,17 @@ spdk_vbdev_error_create(const char *base_bdev_name)
 	return rc;
 }
 
+void
+spdk_vbdev_error_delete(struct spdk_bdev *vbdev, spdk_delete_error_complete cb_fn, void *cb_arg)
+{
+	if (!vbdev || vbdev->module != &error_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(vbdev, cb_fn, cb_arg);
+}
+
 static void
 vbdev_error_clear_config(void)
 {
diff --git a/lib/bdev/error/vbdev_error.h b/lib/bdev/error/vbdev_error.h
index afa1cd7b1..4ff1ac199 100644
--- a/lib/bdev/error/vbdev_error.h
+++ b/lib/bdev/error/vbdev_error.h
@@ -42,6 +42,8 @@ enum vbdev_error_type {
 	VBDEV_IO_PENDING,
 };
 
+typedef void (*spdk_delete_error_complete)(void *cb_arg, int bdeverrno);
+
 /**
  * Create a vbdev on the base bdev to inject error into it.
  *
@@ -50,6 +52,16 @@ enum vbdev_error_type {
  */
 int spdk_vbdev_error_create(const char *base_bdev_name);
 
+/**
+ * Delete vbdev used to inject errors.
+ *
+ * \param bdev Pointer to error vbdev.
+ * \param cb_fn Function to call after deletion.
+ * \param cb_arg Arguments to pass to cb_fn.
+ */
+void spdk_vbdev_error_delete(struct spdk_bdev *vbdev, spdk_delete_error_complete cb_fn,
+			     void *cb_arg);
+
 /**
  * Inject error to the base bdev. Users can specify which IO type error is injected,
  * what type of error is injected, and how many errors are injected.
diff --git a/lib/bdev/error/vbdev_error_rpc.c b/lib/bdev/error/vbdev_error_rpc.c
index 1e7530dcb..8d95fd093 100644
--- a/lib/bdev/error/vbdev_error_rpc.c
+++ b/lib/bdev/error/vbdev_error_rpc.c
@@ -35,7 +35,7 @@
 #include "spdk/string.h"
 #include "spdk/rpc.h"
 #include "spdk/util.h"
-
+#include "spdk/string.h"
 #include "spdk_internal/log.h"
 #include "vbdev_error.h"
 
@@ -122,7 +122,69 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_construct_error_bdev(&req);
 }
-SPDK_RPC_REGISTER("construct_error_bdev", spdk_rpc_construct_error_bdev)
+SPDK_RPC_REGISTER("construct_error_bdev", spdk_rpc_construct_error_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_error {
+	char *name;
+};
+
+static void
+free_rpc_delete_error(struct rpc_delete_error *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_error_decoders[] = {
+	{"name", offsetof(struct rpc_delete_error, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_error_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_error_bdev(struct spdk_jsonrpc_request *request,
+			   const struct spdk_json_val *params)
+{
+	struct rpc_delete_error req = {NULL};
+	struct spdk_bdev *vbdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_error_decoders,
+				    SPDK_COUNTOF(rpc_delete_error_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	vbdev = spdk_bdev_get_by_name(req.name);
+	if (vbdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	spdk_vbdev_error_delete(vbdev, _spdk_rpc_delete_error_bdev_cb, request);
+
+	free_rpc_delete_error(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_error(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_error_bdev", spdk_rpc_delete_error_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_error_information {
 	char *name;
@@ -193,4 +255,4 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_error_information(&req);
 }
-SPDK_RPC_REGISTER("bdev_inject_error", spdk_rpc_bdev_inject_error)
+SPDK_RPC_REGISTER("bdev_inject_error", spdk_rpc_bdev_inject_error, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/gpt/vbdev_gpt.c b/lib/bdev/gpt/vbdev_gpt.c
index 47895d73f..3d2c203d1 100644
--- a/lib/bdev/gpt/vbdev_gpt.c
+++ b/lib/bdev/gpt/vbdev_gpt.c
@@ -41,12 +41,12 @@
 #include "spdk/conf.h"
 #include "spdk/endian.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/rpc.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 static int vbdev_gpt_init(void);
@@ -55,15 +55,15 @@ static void vbdev_gpt_examine(struct spdk_bdev *bdev);
 static struct spdk_bdev_module gpt_if = {
 	.name = "gpt",
 	.module_init = vbdev_gpt_init,
-	.examine = vbdev_gpt_examine,
+	.examine_disk = vbdev_gpt_examine,
 
 };
 SPDK_BDEV_MODULE_REGISTER(&gpt_if)
 
 /* Base block device gpt context */
 struct gpt_base {
-	struct spdk_bdev_part_base	part_base;
 	struct spdk_gpt			gpt;
+	struct spdk_bdev_part_base	*part_base;
 
 	/* This channel is only used for reading the partition table. */
 	struct spdk_io_channel		*ch;
@@ -84,9 +84,9 @@ static SPDK_BDEV_PART_TAILQ g_gpt_disks = TAILQ_HEAD_INITIALIZER(g_gpt_disks);
 static bool g_gpt_disabled;
 
 static void
-spdk_gpt_base_free(struct spdk_bdev_part_base *base)
+spdk_gpt_base_free(void *ctx)
 {
-	struct gpt_base *gpt_base = SPDK_CONTAINEROF(base, struct gpt_base, part_base);
+	struct gpt_base *gpt_base = ctx;
 
 	spdk_dma_free(gpt_base->gpt.buf);
 	free(gpt_base);
@@ -113,7 +113,6 @@ spdk_gpt_base_bdev_init(struct spdk_bdev *bdev)
 {
 	struct gpt_base *gpt_base;
 	struct spdk_gpt *gpt;
-	int rc;
 
 	gpt_base = calloc(1, sizeof(*gpt_base));
 	if (!gpt_base) {
@@ -121,12 +120,13 @@ spdk_gpt_base_bdev_init(struct spdk_bdev *bdev)
 		return NULL;
 	}
 
-	rc = spdk_bdev_part_base_construct(&gpt_base->part_base, bdev,
-					   spdk_gpt_base_bdev_hotremove_cb,
-					   &gpt_if, &vbdev_gpt_fn_table,
-					   &g_gpt_disks, spdk_gpt_base_free,
-					   sizeof(struct gpt_channel), NULL, NULL);
-	if (rc) {
+	gpt_base->part_base = spdk_bdev_part_base_construct(bdev,
+			      spdk_gpt_base_bdev_hotremove_cb,
+			      &gpt_if, &vbdev_gpt_fn_table,
+			      &g_gpt_disks, spdk_gpt_base_free, gpt_base,
+			      sizeof(struct gpt_channel), NULL, NULL);
+	if (!gpt_base->part_base) {
+		free(gpt_base);
 		SPDK_ERRLOG("cannot construct gpt_base");
 		return NULL;
 	}
@@ -136,7 +136,7 @@ spdk_gpt_base_bdev_init(struct spdk_bdev *bdev)
 	gpt->buf = spdk_dma_zmalloc(gpt->buf_size, spdk_bdev_get_buf_align(bdev), NULL);
 	if (!gpt->buf) {
 		SPDK_ERRLOG("Cannot alloc buf\n");
-		spdk_bdev_part_base_free(&gpt_base->part_base);
+		spdk_bdev_part_base_free(gpt_base->part_base);
 		return NULL;
 	}
 
@@ -192,19 +192,22 @@ write_string_utf16le(struct spdk_json_write_ctx *w, const uint16_t *str, size_t
 static int
 vbdev_gpt_dump_info_json(void *ctx, struct spdk_json_write_ctx *w)
 {
-	struct gpt_disk *gpt_disk = ctx;
-	struct gpt_base *gpt_base = (struct gpt_base *)gpt_disk->part.base;
+	struct gpt_disk *gpt_disk = SPDK_CONTAINEROF(ctx, struct gpt_disk, part);
+	struct spdk_bdev_part_base *base_bdev = spdk_bdev_part_get_base(&gpt_disk->part);
+	struct gpt_base *gpt_base = spdk_bdev_part_base_get_ctx(base_bdev);
+	struct spdk_bdev *part_base_bdev = spdk_bdev_part_base_get_bdev(base_bdev);
 	struct spdk_gpt *gpt = &gpt_base->gpt;
 	struct spdk_gpt_partition_entry *gpt_entry = &gpt->partitions[gpt_disk->partition_index];
+	uint64_t offset_blocks = spdk_bdev_part_get_offset_blocks(&gpt_disk->part);
 
 	spdk_json_write_name(w, "gpt");
 	spdk_json_write_object_begin(w);
 
 	spdk_json_write_name(w, "base_bdev");
-	spdk_json_write_string(w, spdk_bdev_get_name(gpt_disk->part.base->bdev));
+	spdk_json_write_string(w, spdk_bdev_get_name(part_base_bdev));
 
 	spdk_json_write_name(w, "offset_blocks");
-	spdk_json_write_uint64(w, gpt_disk->part.offset_blocks);
+	spdk_json_write_uint64(w, offset_blocks);
 
 	spdk_json_write_name(w, "partition_type_guid");
 	write_guid(w, &gpt_entry->part_type_guid);
@@ -225,6 +228,7 @@ vbdev_gpt_create_bdevs(struct gpt_base *gpt_base)
 {
 	uint32_t num_partition_entries;
 	uint64_t i, head_lba_start, head_lba_end;
+	uint32_t num_partitions;
 	struct spdk_gpt_partition_entry *p;
 	struct gpt_disk *d;
 	struct spdk_gpt *gpt;
@@ -236,6 +240,7 @@ vbdev_gpt_create_bdevs(struct gpt_base *gpt_base)
 	num_partition_entries = from_le32(&gpt->header->num_partition_entries);
 	head_lba_start = from_le64(&gpt->header->first_usable_lba);
 	head_lba_end = from_le64(&gpt->header->last_usable_lba);
+	num_partitions = 0;
 
 	for (i = 0; i < num_partition_entries; i++) {
 		p = &gpt->partitions[i];
@@ -258,7 +263,7 @@ vbdev_gpt_create_bdevs(struct gpt_base *gpt_base)
 		}
 
 		/* index start at 1 instead of 0 to match the existing style */
-		base_bdev = gpt_base->part_base.bdev;
+		base_bdev = spdk_bdev_part_base_get_bdev(gpt_base->part_base);
 		name = spdk_sprintf_alloc("%sp%" PRIu64, spdk_bdev_get_name(base_bdev), i + 1);
 		if (!name) {
 			SPDK_ERRLOG("name allocation failure\n");
@@ -266,7 +271,7 @@ vbdev_gpt_create_bdevs(struct gpt_base *gpt_base)
 			return -1;
 		}
 
-		rc = spdk_bdev_part_construct(&d->part, &gpt_base->part_base, name,
+		rc = spdk_bdev_part_construct(&d->part, gpt_base->part_base, name,
 					      lba_start, lba_end - lba_start, "GPT Disk");
 		if (rc) {
 			SPDK_ERRLOG("could not construct bdev part\n");
@@ -274,19 +279,19 @@ vbdev_gpt_create_bdevs(struct gpt_base *gpt_base)
 			free(d);
 			return -1;
 		}
-
+		num_partitions++;
 		d->partition_index = i;
 	}
 
-	return 0;
+	return num_partitions;
 }
 
 static void
 spdk_gpt_bdev_complete(struct spdk_bdev_io *bdev_io, bool status, void *arg)
 {
 	struct gpt_base *gpt_base = (struct gpt_base *)arg;
-	struct spdk_bdev *bdev = gpt_base->part_base.bdev;
-	int rc;
+	struct spdk_bdev *bdev = spdk_bdev_part_base_get_bdev(gpt_base->part_base);
+	int rc, num_partitions = 0;
 
 	spdk_bdev_free_io(bdev_io);
 	spdk_put_io_channel(gpt_base->ch);
@@ -304,8 +309,8 @@ spdk_gpt_bdev_complete(struct spdk_bdev_io *bdev_io, bool status, void *arg)
 		goto end;
 	}
 
-	rc = vbdev_gpt_create_bdevs(gpt_base);
-	if (rc < 0) {
+	num_partitions = vbdev_gpt_create_bdevs(gpt_base);
+	if (num_partitions < 0) {
 		SPDK_DEBUGLOG(SPDK_LOG_VBDEV_GPT, "Failed to split dev=%s by gpt table\n",
 			      spdk_bdev_get_name(bdev));
 	}
@@ -317,9 +322,13 @@ end:
 	 */
 	spdk_bdev_module_examine_done(&gpt_if);
 
-	if (gpt_base->part_base.ref == 0) {
+	/*
+	 * vbdev_gpt_create_bdevs returns the number of bdevs created upon success.
+	 * We can branch on this value.
+	 */
+	if (num_partitions <= 0) {
 		/* If no gpt_disk instances were created, free the base context */
-		spdk_bdev_part_base_free(&gpt_base->part_base);
+		spdk_bdev_part_base_free(gpt_base->part_base);
 	}
 }
 
@@ -327,6 +336,7 @@ static int
 vbdev_gpt_read_gpt(struct spdk_bdev *bdev)
 {
 	struct gpt_base *gpt_base;
+	struct spdk_bdev_desc *part_base_desc;
 	int rc;
 
 	gpt_base = spdk_gpt_base_bdev_init(bdev);
@@ -335,18 +345,19 @@ vbdev_gpt_read_gpt(struct spdk_bdev *bdev)
 		return -1;
 	}
 
-	gpt_base->ch = spdk_bdev_get_io_channel(gpt_base->part_base.desc);
+	part_base_desc = spdk_bdev_part_base_get_desc(gpt_base->part_base);
+	gpt_base->ch = spdk_bdev_get_io_channel(part_base_desc);
 	if (gpt_base->ch == NULL) {
 		SPDK_ERRLOG("Failed to get an io_channel.\n");
-		spdk_bdev_part_base_free(&gpt_base->part_base);
+		spdk_bdev_part_base_free(gpt_base->part_base);
 		return -1;
 	}
 
-	rc = spdk_bdev_read(gpt_base->part_base.desc, gpt_base->ch, gpt_base->gpt.buf, 0,
+	rc = spdk_bdev_read(part_base_desc, gpt_base->ch, gpt_base->gpt.buf, 0,
 			    gpt_base->gpt.buf_size, spdk_gpt_bdev_complete, gpt_base);
 	if (rc < 0) {
 		spdk_put_io_channel(gpt_base->ch);
-		spdk_bdev_part_base_free(&gpt_base->part_base);
+		spdk_bdev_part_base_free(gpt_base->part_base);
 		SPDK_ERRLOG("Failed to send bdev_io command\n");
 		return -1;
 	}
diff --git a/lib/bdev/iscsi/Makefile b/lib/bdev/iscsi/Makefile
index dfaff337a..4a38886d5 100644
--- a/lib/bdev/iscsi/Makefile
+++ b/lib/bdev/iscsi/Makefile
@@ -40,7 +40,7 @@ CFLAGS += -I$(SPDK_ROOT_DIR)/lib/bdev/
 # this warning so just make sure the warning isn't treated as
 # an error.
 CFLAGS += -Wno-error
-C_SRCS = bdev_iscsi.c
+C_SRCS = bdev_iscsi.c bdev_iscsi_rpc.c
 LIBNAME = bdev_iscsi
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/bdev/iscsi/bdev_iscsi.c b/lib/bdev/iscsi/bdev_iscsi.c
index 835733f78..288aea875 100644
--- a/lib/bdev/iscsi/bdev_iscsi.c
+++ b/lib/bdev/iscsi/bdev_iscsi.c
@@ -37,20 +37,26 @@
 #include "spdk/conf.h"
 #include "spdk/env.h"
 #include "spdk/fd.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/json.h"
 #include "spdk/util.h"
 #include "spdk/rpc.h"
 #include "spdk/string.h"
+#include "spdk/iscsi_spec.h"
 
 #include "spdk_internal/log.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 #include "iscsi/iscsi.h"
 #include "iscsi/scsi-lowlevel.h"
 
+#include "bdev_iscsi.h"
+
 struct bdev_iscsi_lun;
 
+#define BDEV_ISCSI_CONNECTION_POLL_US 500 /* 0.5 ms */
+#define BDEV_ISCSI_NO_MASTER_CH_POLL_US 10000 /* 10ms */
+
 #define DEFAULT_INITIATOR_NAME "iqn.2016-06.io.spdk:init"
 
 static int bdev_iscsi_initialize(void);
@@ -58,7 +64,7 @@ static TAILQ_HEAD(, bdev_iscsi_lun) g_iscsi_lun_head = TAILQ_HEAD_INITIALIZER(g_
 static TAILQ_HEAD(, bdev_iscsi_conn_req) g_iscsi_conn_req = TAILQ_HEAD_INITIALIZER(
 			g_iscsi_conn_req);
 static struct spdk_poller *g_conn_poller = NULL;
-static bool g_module_is_initialized;
+static bool g_finish_in_process = false;
 
 struct bdev_iscsi_io {
 	struct spdk_thread *submit_td;
@@ -73,11 +79,13 @@ struct bdev_iscsi_lun {
 	struct spdk_bdev		bdev;
 	struct iscsi_context		*context;
 	char				*initiator_iqn;
-	struct iscsi_url		*url;
+	char				*url;
 	pthread_mutex_t			mutex;
 	uint32_t			ch_count;
 	struct bdev_iscsi_io_channel	*master_ch;
 	struct spdk_thread		*master_td;
+	struct spdk_poller		*no_master_ch_poller;
+	struct spdk_thread		*no_master_ch_poller_td;
 	TAILQ_ENTRY(bdev_iscsi_lun)	link;
 };
 
@@ -87,9 +95,12 @@ struct bdev_iscsi_io_channel {
 };
 
 struct bdev_iscsi_conn_req {
-	struct iscsi_url			*url;
+	char					*url;
 	char					*bdev_name;
+	char					*initiator_iqn;
 	struct iscsi_context			*context;
+	spdk_bdev_iscsi_create_cb		create_cb;
+	spdk_bdev_iscsi_create_cb		create_cb_arg;
 	TAILQ_ENTRY(bdev_iscsi_conn_req)	link;
 };
 
@@ -99,20 +110,15 @@ bdev_iscsi_get_ctx_size(void)
 	return sizeof(struct bdev_iscsi_io);
 }
 
-static void
-bdev_iscsi_remove_conn_req(struct bdev_iscsi_conn_req *req)
-{
-	TAILQ_REMOVE(&g_iscsi_conn_req, req, link);
-	free(req);
-}
-
 static void
 bdev_iscsi_finish_done(void)
 {
-	struct bdev_iscsi_conn_req *req, *tmp;
+	struct bdev_iscsi_conn_req *req;
 
-	TAILQ_FOREACH_SAFE(req, &g_iscsi_conn_req, link, tmp) {
-		bdev_iscsi_remove_conn_req(req);
+	while (!TAILQ_EMPTY(&g_iscsi_conn_req)) {
+		req = TAILQ_FIRST(&g_iscsi_conn_req);
+		TAILQ_REMOVE(&g_iscsi_conn_req, req, link);
+		free(req);
 	}
 
 	if (g_conn_poller) {
@@ -125,6 +131,8 @@ static void iscsi_free_lun(struct bdev_iscsi_lun *lun)
 {
 	assert(lun != NULL);
 	free(lun->bdev.name);
+	free(lun->url);
+	free(lun->initiator_iqn);
 	free(lun);
 }
 
@@ -133,9 +141,8 @@ bdev_iscsi_lun_cleanup(struct bdev_iscsi_lun *lun)
 {
 	TAILQ_REMOVE(&g_iscsi_lun_head, lun, link);
 	iscsi_destroy_context(lun->context);
-	iscsi_destroy_url(lun->url);
 	iscsi_free_lun(lun);
-	if (TAILQ_EMPTY(&g_iscsi_lun_head)) {
+	if (TAILQ_EMPTY(&g_iscsi_lun_head) && g_finish_in_process) {
 		bdev_iscsi_finish_done();
 		spdk_bdev_module_finish_done();
 	}
@@ -159,6 +166,12 @@ bdev_iscsi_finish(void)
 {
 	struct bdev_iscsi_lun *lun, *tmp;
 
+	/*
+	 * Set this flag so that bdev_iscsi_lun_cleanup knows it needs to mark
+	 *  the module finish as done when the TAILQ is not empty.
+	 */
+	g_finish_in_process = true;
+
 	if (TAILQ_EMPTY(&g_iscsi_lun_head)) {
 		bdev_iscsi_finish_done();
 		spdk_bdev_module_finish_done();
@@ -207,14 +220,15 @@ bdev_iscsi_io_complete(struct bdev_iscsi_io *iscsi_io, enum spdk_bdev_io_status
 	}
 }
 
+/* Common call back function for read/write/flush command */
 static void
-bdev_iscsi_rw_cb(struct iscsi_context *context, int status, void *_task, void *_iscsi_io)
+bdev_iscsi_command_cb(struct iscsi_context *context, int status, void *_task, void *_iscsi_io)
 {
 	struct scsi_task *task = _task;
 	struct bdev_iscsi_io *iscsi_io = _iscsi_io;
 
 	iscsi_io->scsi_status = task->status;
-	iscsi_io->sk = task->sense.key;
+	iscsi_io->sk = (uint8_t)task->sense.key;
 	iscsi_io->asc = (task->sense.ascq >> 8) & 0xFF;
 	iscsi_io->ascq = task->sense.ascq & 0xFF;
 
@@ -232,7 +246,7 @@ bdev_iscsi_readv(struct bdev_iscsi_lun *lun, struct bdev_iscsi_io *iscsi_io,
 		      iovcnt, nbytes, lba);
 
 	task = iscsi_read16_task(lun->context, 0, lba, nbytes, lun->bdev.blocklen, 0, 0, 0, 0, 0,
-				 bdev_iscsi_rw_cb, iscsi_io);
+				 bdev_iscsi_command_cb, iscsi_io);
 	if (task == NULL) {
 		SPDK_ERRLOG("failed to get read16_task\n");
 		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
@@ -259,7 +273,7 @@ bdev_iscsi_writev(struct bdev_iscsi_lun *lun, struct bdev_iscsi_io *iscsi_io,
 		      iovcnt, nbytes, lba);
 
 	task = iscsi_write16_task(lun->context, 0, lba, NULL, nbytes, lun->bdev.blocklen, 0, 0, 0, 0, 0,
-				  bdev_iscsi_rw_cb, iscsi_io);
+				  bdev_iscsi_command_cb, iscsi_io);
 	if (task == NULL) {
 		SPDK_ERRLOG("failed to get write16_task\n");
 		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
@@ -276,21 +290,102 @@ bdev_iscsi_writev(struct bdev_iscsi_lun *lun, struct bdev_iscsi_io *iscsi_io,
 #endif
 }
 
+static void
+bdev_iscsi_destruct_cb(void *ctx)
+{
+	struct bdev_iscsi_lun *lun = ctx;
+
+	spdk_poller_unregister(&lun->no_master_ch_poller);
+	spdk_bdev_destruct_done(&lun->bdev, 0);
+	bdev_iscsi_lun_cleanup(lun);
+}
+
 static int
 bdev_iscsi_destruct(void *ctx)
 {
 	struct bdev_iscsi_lun *lun = ctx;
-	int rc = 0;
 
-	TAILQ_REMOVE(&g_iscsi_lun_head, lun, link);
-	return rc;
+	assert(lun->no_master_ch_poller_td);
+	spdk_thread_send_msg(lun->no_master_ch_poller_td, bdev_iscsi_destruct_cb, lun);
+	return 1;
+}
+
+static void
+bdev_iscsi_flush(struct bdev_iscsi_lun *lun, struct bdev_iscsi_io *iscsi_io, uint32_t num_blocks,
+		 int immed, uint64_t lba)
+{
+	struct scsi_task *task;
+
+	task = iscsi_synchronizecache16_task(lun->context, 0, lba,
+					     num_blocks, 0, immed, bdev_iscsi_command_cb, iscsi_io);
+	if (task == NULL) {
+		SPDK_ERRLOG("failed to get sync16_task\n");
+		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
+		return;
+	}
+}
+
+static void
+bdev_iscsi_unmap(struct bdev_iscsi_lun *lun, struct bdev_iscsi_io *iscsi_io,
+		 uint64_t lba, uint64_t num_blocks)
+{
+	struct scsi_task *task;
+	struct unmap_list list[1];
+
+	list[0].lba = lba;
+	list[0].num = num_blocks;
+	task = iscsi_unmap_task(lun->context, 0, 0, 0, list, 1,
+				bdev_iscsi_command_cb, iscsi_io);
+	if (task == NULL) {
+		SPDK_ERRLOG("failed to get unmap_task\n");
+		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
+		return;
+	}
+}
+
+static void
+bdev_iscsi_reset_cb(struct iscsi_context *context __attribute__((unused)), int status,
+		    void *command_data, void *private_data)
+{
+	uint32_t tmf_response;
+	struct bdev_iscsi_io *iscsi_io = private_data;
+
+	tmf_response = *(uint32_t *)command_data;
+	if (tmf_response == ISCSI_TASK_FUNC_RESP_COMPLETE) {
+		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_SUCCESS);
+	} else {
+		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
+	}
+}
+
+static void
+_bdev_iscsi_reset(void *_bdev_io)
+{
+	int rc;
+	struct spdk_bdev_io *bdev_io = _bdev_io;
+	struct bdev_iscsi_lun *lun = (struct bdev_iscsi_lun *)bdev_io->bdev->ctxt;
+	struct bdev_iscsi_io *iscsi_io = (struct bdev_iscsi_io *)bdev_io->driver_ctx;
+	struct iscsi_context *context = lun->context;
+
+	rc = iscsi_task_mgmt_lun_reset_async(context, 0,
+					     bdev_iscsi_reset_cb, iscsi_io);
+	if (rc != 0) {
+		SPDK_ERRLOG("failed to do iscsi reset\n");
+		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
+		return;
+	}
+}
+
+static void
+bdev_iscsi_reset(struct spdk_bdev_io *bdev_io)
+{
+	struct bdev_iscsi_lun *lun = (struct bdev_iscsi_lun *)bdev_io->bdev->ctxt;
+	spdk_thread_send_msg(lun->master_td, _bdev_iscsi_reset, bdev_io);
 }
 
 static int
-bdev_iscsi_poll(void *arg)
+bdev_iscsi_poll_lun(struct bdev_iscsi_lun *lun)
 {
-	struct bdev_iscsi_io_channel *ch = arg;
-	struct bdev_iscsi_lun *lun = ch->lun;
 	struct pollfd pfd = {};
 
 	pfd.fd = iscsi_get_fd(lun->context);
@@ -307,7 +402,34 @@ bdev_iscsi_poll(void *arg)
 		}
 	}
 
-	return 0;
+	return -1;
+}
+
+static int
+bdev_iscsi_no_master_ch_poll(void *arg)
+{
+	struct bdev_iscsi_lun *lun = arg;
+	int rc = 0;
+
+	if (pthread_mutex_trylock(&lun->mutex)) {
+		/* Don't care about the error code here. */
+		return -1;
+	}
+
+	if (lun->ch_count == 0) {
+		rc = bdev_iscsi_poll_lun(arg);
+	}
+
+	pthread_mutex_unlock(&lun->mutex);
+	return rc;
+}
+
+static int
+bdev_iscsi_poll(void *arg)
+{
+	struct bdev_iscsi_io_channel *ch = arg;
+
+	return bdev_iscsi_poll_lun(ch->lun);
 }
 
 static void bdev_iscsi_get_buf_cb(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io)
@@ -339,6 +461,20 @@ static void _bdev_iscsi_submit_request(void *_bdev_io)
 				  bdev_io->u.bdev.num_blocks * bdev_io->bdev->blocklen,
 				  bdev_io->u.bdev.offset_blocks);
 		break;
+	case SPDK_BDEV_IO_TYPE_FLUSH:
+		bdev_iscsi_flush(lun, iscsi_io,
+				 bdev_io->u.bdev.num_blocks,
+				 ISCSI_IMMEDIATE_DATA_NO,
+				 bdev_io->u.bdev.offset_blocks);
+		break;
+	case SPDK_BDEV_IO_TYPE_RESET:
+		bdev_iscsi_reset(bdev_io);
+		break;
+	case SPDK_BDEV_IO_TYPE_UNMAP:
+		bdev_iscsi_unmap(lun, iscsi_io,
+				 bdev_io->u.bdev.offset_blocks,
+				 bdev_io->u.bdev.num_blocks);
+		break;
 	default:
 		bdev_iscsi_io_complete(iscsi_io, SPDK_BDEV_IO_STATUS_FAILED);
 		break;
@@ -366,6 +502,9 @@ bdev_iscsi_io_type_supported(void *ctx, enum spdk_bdev_io_type io_type)
 	switch (io_type) {
 	case SPDK_BDEV_IO_TYPE_READ:
 	case SPDK_BDEV_IO_TYPE_WRITE:
+	case SPDK_BDEV_IO_TYPE_FLUSH:
+	case SPDK_BDEV_IO_TYPE_UNMAP:
+	case SPDK_BDEV_IO_TYPE_RESET:
 		return true;
 
 	default:
@@ -405,6 +544,8 @@ bdev_iscsi_destroy_cb(void *io_device, void *ctx_buf)
 	if (lun->ch_count == 0) {
 		assert(lun->master_ch != NULL);
 		assert(lun->master_td != NULL);
+		assert(lun->master_td == spdk_get_thread());
+
 		lun->master_ch = NULL;
 		lun->master_td = NULL;
 		spdk_poller_unregister(&io_channel->poller);
@@ -429,24 +570,54 @@ bdev_iscsi_dump_info_json(void *ctx, struct spdk_json_write_ctx *w)
 	spdk_json_write_object_begin(w);
 	spdk_json_write_name(w, "initiator_name");
 	spdk_json_write_string(w, lun->initiator_iqn);
-	spdk_json_write_name(w, "target");
-	spdk_json_write_string(w, lun->url->target);
+	spdk_json_write_name(w, "url");
+	spdk_json_write_string(w, lun->url);
 	spdk_json_write_object_end(w);
 
 	return 0;
 }
 
+static void
+bdev_iscsi_write_config_json(struct spdk_bdev *bdev, struct spdk_json_write_ctx *w)
+{
+	struct bdev_iscsi_lun *lun = bdev->ctxt;
+
+	pthread_mutex_lock(&lun->mutex);
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "method", "construct_iscsi_bdev");
+
+	spdk_json_write_named_object_begin(w, "params");
+	spdk_json_write_named_string(w, "name", bdev->name);
+	spdk_json_write_named_string(w, "initiator_iqn", lun->initiator_iqn);
+	spdk_json_write_named_string(w, "url", lun->url);
+	spdk_json_write_object_end(w);
+
+	spdk_json_write_object_end(w);
+	pthread_mutex_unlock(&lun->mutex);
+}
+
 static const struct spdk_bdev_fn_table iscsi_fn_table = {
 	.destruct		= bdev_iscsi_destruct,
 	.submit_request		= bdev_iscsi_submit_request,
 	.io_type_supported	= bdev_iscsi_io_type_supported,
 	.get_io_channel		= bdev_iscsi_get_io_channel,
 	.dump_info_json		= bdev_iscsi_dump_info_json,
+	.write_config_json	= bdev_iscsi_write_config_json,
 };
 
-static struct spdk_bdev *
-create_iscsi_lun(struct iscsi_context *context, struct iscsi_url *url,
-		 const char *name, uint64_t num_blocks, uint32_t block_size)
+static void
+complete_conn_req(struct bdev_iscsi_conn_req *req, struct spdk_bdev *bdev,
+		  int status)
+{
+	TAILQ_REMOVE(&g_iscsi_conn_req, req, link);
+	req->create_cb(req->create_cb_arg, bdev, status);
+	free(req);
+}
+
+static int
+create_iscsi_lun(struct iscsi_context *context, char *url, char *initiator_iqn, char *name,
+		 uint64_t num_blocks, uint32_t block_size, struct spdk_bdev **bdev)
 {
 	struct bdev_iscsi_lun *lun;
 	int rc;
@@ -454,18 +625,16 @@ create_iscsi_lun(struct iscsi_context *context, struct iscsi_url *url,
 	lun = calloc(sizeof(*lun), 1);
 	if (!lun) {
 		SPDK_ERRLOG("Unable to allocate enough memory for iscsi backend\n");
-		return NULL;
+		return -ENOMEM;
 	}
 
 	lun->context = context;
 	lun->url = url;
+	lun->initiator_iqn = initiator_iqn;
 
 	pthread_mutex_init(&lun->mutex, NULL);
 
-	lun->bdev.name = strdup(name);
-	if (!lun->bdev.name) {
-		goto error_return;
-	}
+	lun->bdev.name = name;
 	lun->bdev.product_name = "iSCSI LUN";
 	lun->bdev.module = &g_iscsi_bdev_module;
 	lun->bdev.blocklen = block_size;
@@ -482,45 +651,17 @@ create_iscsi_lun(struct iscsi_context *context, struct iscsi_url *url,
 		goto error_return;
 	}
 
+	lun->no_master_ch_poller_td = spdk_get_thread();
+	lun->no_master_ch_poller = spdk_poller_register(bdev_iscsi_no_master_ch_poll, lun,
+				   BDEV_ISCSI_NO_MASTER_CH_POLL_US);
+
 	TAILQ_INSERT_TAIL(&g_iscsi_lun_head, lun, link);
-	return &lun->bdev;
+	*bdev = &lun->bdev;
+	return 0;
 
 error_return:
 	iscsi_free_lun(lun);
-	return NULL;
-}
-
-static struct bdev_iscsi_conn_req *
-bdev_iscsi_allocate_conn_req(struct iscsi_context *context, char *bdev_name, struct iscsi_url *url)
-{
-	struct bdev_iscsi_conn_req *req;
-
-	req = calloc(1, sizeof(struct bdev_iscsi_conn_req));
-	if (!req) {
-		SPDK_ERRLOG("Cannot allocate pointer of struct bdev_iscsi_conn_req\n");
-		return NULL;
-	}
-
-	req->bdev_name = bdev_name;
-	req->url = url;
-	req->context = context;
-
-	return req;
-}
-
-static void
-_bdev_iscsi_set_module_init(void)
-{
-	spdk_bdev_module_init_done(&g_iscsi_bdev_module);
-	g_module_is_initialized = true;
-}
-
-static void
-bdev_iscsi_set_module_init(void)
-{
-	if (!g_module_is_initialized && TAILQ_EMPTY(&g_iscsi_conn_req)) {
-		_bdev_iscsi_set_module_init();
-	}
+	return rc;
 }
 
 static void
@@ -529,24 +670,29 @@ iscsi_readcapacity16_cb(struct iscsi_context *iscsi, int status,
 {
 	struct bdev_iscsi_conn_req *req = private_data;
 	struct scsi_readcapacity16 *readcap16;
-	struct spdk_bdev *bdev;
+	struct spdk_bdev *bdev = NULL;
 	struct scsi_task *task = command_data;
 
 	if (status != SPDK_SCSI_STATUS_GOOD) {
+		SPDK_ERRLOG("iSCSI error: %s\n", iscsi_get_error(iscsi));
 		goto ret;
 	}
 
 	readcap16 = scsi_datain_unmarshall(task);
-	bdev = create_iscsi_lun(req->context, req->url, req->bdev_name,
-				readcap16->returned_lba + 1, readcap16->block_length);
-	if (!bdev) {
-		SPDK_ERRLOG("Unable to create iscsi bdev\n");
+	if (!readcap16) {
+		status = -ENOMEM;
+		goto ret;
+	}
+
+	status = create_iscsi_lun(req->context, req->url, req->initiator_iqn, req->bdev_name,
+				  readcap16->returned_lba + 1, readcap16->block_length, &bdev);
+	if (status) {
+		SPDK_ERRLOG("Unable to create iscsi bdev: %s (%d)\n", spdk_strerror(-status), status);
 	}
 
 ret:
 	scsi_free_scsi_task(task);
-	bdev_iscsi_remove_conn_req(req);
-	bdev_iscsi_set_module_init();
+	complete_conn_req(req, bdev, status);
 }
 
 static void
@@ -564,9 +710,10 @@ iscsi_connect_cb(struct iscsi_context *iscsi, int status,
 	if (task) {
 		return;
 	}
+
 ret:
-	bdev_iscsi_remove_conn_req(req);
-	bdev_iscsi_set_module_init();
+	SPDK_ERRLOG("iSCSI error: %s\n", iscsi_get_error(req->context));
+	complete_conn_req(req, NULL, status);
 }
 
 static int
@@ -574,10 +721,12 @@ iscsi_bdev_conn_poll(void *arg)
 {
 	struct bdev_iscsi_conn_req *req, *tmp;
 	struct pollfd pfd;
+	struct iscsi_context *context;
 
 	TAILQ_FOREACH_SAFE(req, &g_iscsi_conn_req, link, tmp) {
-		pfd.fd = iscsi_get_fd(req->context);
-		pfd.events = iscsi_which_events(req->context);
+		context = req->context;
+		pfd.fd = iscsi_get_fd(context);
+		pfd.events = iscsi_which_events(context);
 		pfd.revents = 0;
 		if (poll(&pfd, 1, 0) < 0) {
 			SPDK_ERRLOG("poll failed\n");
@@ -585,28 +734,122 @@ iscsi_bdev_conn_poll(void *arg)
 		}
 
 		if (pfd.revents != 0) {
-			if (iscsi_service(req->context, pfd.revents) < 0) {
-				SPDK_ERRLOG("iscsi_service failed: %s\n", iscsi_get_error(req->context));
+			if (iscsi_service(context, pfd.revents) < 0) {
+				SPDK_ERRLOG("iscsi_service failed: %s\n", iscsi_get_error(context));
 			}
 		}
 	}
 
+	return -1;
+}
+
+int
+create_iscsi_disk(const char *bdev_name, const char *url, const char *initiator_iqn,
+		  spdk_bdev_iscsi_create_cb cb_fn, void *cb_arg)
+{
+	struct bdev_iscsi_conn_req *req;
+	struct iscsi_url *iscsi_url = NULL;
+	int rc;
+
+	if (!bdev_name || !url || !initiator_iqn || strlen(initiator_iqn) == 0 || !cb_fn) {
+		return -EINVAL;
+	}
+
+	req = calloc(1, sizeof(struct bdev_iscsi_conn_req));
+	if (!req) {
+		SPDK_ERRLOG("Cannot allocate pointer of struct bdev_iscsi_conn_req\n");
+		return -ENOMEM;
+	}
+
+	req->bdev_name = strdup(bdev_name);
+	req->url = strdup(url);
+	req->initiator_iqn = strdup(initiator_iqn);
+	req->context = iscsi_create_context(initiator_iqn);
+	if (!req->bdev_name || !req->url || !req->initiator_iqn || !req->context) {
+		SPDK_ERRLOG("Out of memory\n");
+		rc = -ENOMEM;
+		goto err;
+	}
+
+	req->create_cb = cb_fn;
+	req->create_cb_arg = cb_arg;
+
+	iscsi_url = iscsi_parse_full_url(req->context, url);
+	if (iscsi_url == NULL) {
+		SPDK_ERRLOG("could not parse URL: %s\n", iscsi_get_error(req->context));
+		rc = -EINVAL;
+		goto err;
+	}
+
+	rc = iscsi_set_session_type(req->context, ISCSI_SESSION_NORMAL);
+	rc = rc ? rc : iscsi_set_header_digest(req->context, ISCSI_HEADER_DIGEST_NONE);
+	rc = rc ? rc : iscsi_set_targetname(req->context, iscsi_url->target);
+	rc = rc ? rc : iscsi_full_connect_async(req->context, iscsi_url->portal, iscsi_url->lun,
+						iscsi_connect_cb, req);
+	if (rc == 0 && iscsi_url->user[0] != '\0') {
+		rc = iscsi_set_initiator_username_pwd(req->context, iscsi_url->user, iscsi_url->passwd);
+	}
+
+	if (rc < 0) {
+		SPDK_ERRLOG("Failed to connect provided URL=%s: %s\n", url, iscsi_get_error(req->context));
+		goto err;
+	}
+
+	iscsi_destroy_url(iscsi_url);
+	TAILQ_INSERT_TAIL(&g_iscsi_conn_req, req, link);
+	if (!g_conn_poller) {
+		g_conn_poller = spdk_poller_register(iscsi_bdev_conn_poll, NULL, BDEV_ISCSI_CONNECTION_POLL_US);
+	}
+
 	return 0;
+
+err:
+	/* iscsi_destroy_url() is not NULL-proof */
+	if (iscsi_url) {
+		iscsi_destroy_url(iscsi_url);
+	}
+
+	if (req->context) {
+		iscsi_destroy_context(req->context);
+	}
+
+	free(req->initiator_iqn);
+	free(req->bdev_name);
+	free(req->url);
+	free(req);
+	return rc;
+}
+
+void
+delete_iscsi_disk(struct spdk_bdev *bdev, spdk_delete_iscsi_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &g_iscsi_bdev_module) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
+static void
+bdev_iscsi_initialize_cb(void *cb_arg, struct spdk_bdev *bdev, int status)
+{
+	if (TAILQ_EMPTY(&g_iscsi_conn_req)) {
+		spdk_bdev_module_init_done(&g_iscsi_bdev_module);
+	}
 }
 
 static int
 bdev_iscsi_initialize(void)
 {
 	struct spdk_conf_section *sp;
-	struct iscsi_context *context;
-	struct iscsi_url *url;
-	char *val, *bdev_name, *initiator_iqn;
-	struct bdev_iscsi_conn_req *req;
+
+	const char *url, *bdev_name, *initiator_iqn;
 	int i, rc;
 
 	sp = spdk_conf_find_section(NULL, "iSCSI_Initiator");
 	if (sp == NULL) {
-		_bdev_iscsi_set_module_init();
+		spdk_bdev_module_init_done(&g_iscsi_bdev_module);
 		return 0;
 	}
 
@@ -615,54 +858,26 @@ bdev_iscsi_initialize(void)
 		initiator_iqn = DEFAULT_INITIATOR_NAME;
 	}
 
-	i = 0;
-	while (true) {
-		val = spdk_conf_section_get_nmval(sp, "URL", i, 0);
-		if (val == NULL) {
-			break;
-		}
-
+	rc = 0;
+	for (i = 0; (url = spdk_conf_section_get_nmval(sp, "URL", i, 0)) != NULL; i++) {
 		bdev_name = spdk_conf_section_get_nmval(sp, "URL", i, 1);
 		if (bdev_name == NULL) {
-			SPDK_ERRLOG("no bdev name specified for URL %s\n", val);
+			SPDK_ERRLOG("no bdev name specified for URL %s\n", url);
+			rc = -EINVAL;
 			break;
 		}
 
-		context = iscsi_create_context(initiator_iqn);
-		if (context == NULL) {
-			SPDK_ERRLOG("could not create iscsi context\n");
+		rc = create_iscsi_disk(bdev_name, url, initiator_iqn, bdev_iscsi_initialize_cb, NULL);
+		if (rc) {
 			break;
 		}
-
-		url = iscsi_parse_full_url(context, val);
-		if (url == NULL) {
-			SPDK_ERRLOG("could not parse URL\n");
-			break;
-		}
-
-		req = bdev_iscsi_allocate_conn_req(context, bdev_name, url);
-		if (!req) {
-			_bdev_iscsi_set_module_init();
-			return -1;
-		}
-
-		iscsi_set_session_type(context, ISCSI_SESSION_NORMAL);
-		iscsi_set_header_digest(context, ISCSI_HEADER_DIGEST_NONE);
-		rc = iscsi_full_connect_async(context, url->portal, url->lun, iscsi_connect_cb, req);
-		if (rc < 0) {
-			free(req);
-			SPDK_ERRLOG("Failed to connect provided URL=%s, will ignore it\n", val);
-			continue;
-		}
-
-		TAILQ_INSERT_TAIL(&g_iscsi_conn_req, req, link);
-		i++;
 	}
 
-	if (!TAILQ_EMPTY(&g_iscsi_conn_req)) {
-		g_conn_poller = spdk_poller_register(iscsi_bdev_conn_poll, NULL, 0);
+	if (i == 0) {
+		spdk_bdev_module_init_done(&g_iscsi_bdev_module);
 	}
-	return 0;
+
+	return rc;
 }
 
 SPDK_LOG_REGISTER_COMPONENT("iscsi_init", SPDK_LOG_ISCSI_INIT)
diff --git a/lib/bdev/iscsi/bdev_iscsi.h b/lib/bdev/iscsi/bdev_iscsi.h
new file mode 100644
index 000000000..b1d22fa82
--- /dev/null
+++ b/lib/bdev/iscsi/bdev_iscsi.h
@@ -0,0 +1,75 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef SPDK_BDEV_ISCSI_H
+#define SPDK_BDEV_ISCSI_H
+
+#include "spdk/bdev.h"
+
+typedef void (*spdk_delete_iscsi_complete)(void *cb_arg, int bdeverrno);
+
+/**
+ * SPDK bdev iSCSI callback type.
+ *
+ * \param cb_arg Completion callback custom arguments
+ * \param bdev created bdev
+ * \param status operation status. Zero on success.
+ */
+typedef void (*spdk_bdev_iscsi_create_cb)(void *cb_arg, struct spdk_bdev *bdev, int status);
+
+/**
+ * Create new iSCSI bdev.
+ *
+ * \warning iSCSI URL allow providing login and password. Be careful because
+ * they will show up in configuration dump.
+ *
+ * \param name name for new bdev.
+ * \param initiator_iqn connection iqn name we identify to target as
+ * \param url iSCSI URL string.
+ * \param cb_fn Completion callback
+ * \param cb_arg Completion callback custom arguments
+ * \return 0 on success or negative error code. If success bdev with provided name was created.
+ */
+int create_iscsi_disk(const char *bdev_name, const char *initiator_iqn, const char *url,
+		      spdk_bdev_iscsi_create_cb cb_fn, void *cb_arg);
+
+/**
+ * Delete iSCSI bdev.
+ *
+ * \param bdev Pointer to iSCSI bdev.
+ * \param cb_fn Completion callback
+ * \param cb_arg Completion callback custom arguments
+ */
+void delete_iscsi_disk(struct spdk_bdev *bdev, spdk_delete_iscsi_complete cb_fn, void *cb_arg);
+
+#endif // SPDK_BDEV_ISCSI_H
diff --git a/lib/bdev/iscsi/bdev_iscsi_rpc.c b/lib/bdev/iscsi/bdev_iscsi_rpc.c
new file mode 100644
index 000000000..3682b6129
--- /dev/null
+++ b/lib/bdev/iscsi/bdev_iscsi_rpc.c
@@ -0,0 +1,173 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "bdev_iscsi.h"
+#include "spdk/rpc.h"
+#include "spdk/util.h"
+#include "spdk/string.h"
+
+#include "spdk_internal/log.h"
+
+struct rpc_construct_iscsi_bdev {
+	char *name;
+	char *initiator_iqn;
+	char *url;
+};
+
+static const struct spdk_json_object_decoder rpc_construct_iscsi_bdev_decoders[] = {
+	{"name", offsetof(struct rpc_construct_iscsi_bdev, name), spdk_json_decode_string},
+	{"initiator_iqn", offsetof(struct rpc_construct_iscsi_bdev, initiator_iqn), spdk_json_decode_string},
+	{"url", offsetof(struct rpc_construct_iscsi_bdev, url), spdk_json_decode_string},
+};
+
+static void
+free_rpc_construct_iscsi_bdev(struct rpc_construct_iscsi_bdev *req)
+{
+	free(req->name);
+	free(req->initiator_iqn);
+	free(req->url);
+}
+
+static void
+construct_iscsi_bdev_cb(void *cb_arg, struct spdk_bdev *bdev, int status)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	if (status > 0) {
+		spdk_jsonrpc_send_error_response_fmt(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						     "iSCSI error (%d).", status);
+	} else if (status < 0) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						 spdk_strerror(-status));
+	} else {
+		w = spdk_jsonrpc_begin_result(request);
+		if (w == NULL) {
+			return;
+		}
+
+		spdk_json_write_string(w, spdk_bdev_get_name(bdev));
+		spdk_jsonrpc_end_result(request, w);
+	}
+}
+
+static void
+spdk_rpc_construct_iscsi_bdev(struct spdk_jsonrpc_request *request,
+			      const struct spdk_json_val *params)
+{
+	struct rpc_construct_iscsi_bdev req = {};
+	int rc = 0;
+
+	if (spdk_json_decode_object(params, rpc_construct_iscsi_bdev_decoders,
+				    SPDK_COUNTOF(rpc_construct_iscsi_bdev_decoders),
+				    &req)) {
+		SPDK_ERRLOG("spdk_json_decode_object failed\n");
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	rc = create_iscsi_disk(req.name, req.url, req.initiator_iqn, construct_iscsi_bdev_cb, request);
+	if (rc) {
+		goto invalid;
+	}
+
+	free_rpc_construct_iscsi_bdev(&req);
+	return;
+
+invalid:
+	free_rpc_construct_iscsi_bdev(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("construct_iscsi_bdev", spdk_rpc_construct_iscsi_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_iscsi {
+	char *name;
+};
+
+static void
+free_rpc_delete_iscsi(struct rpc_delete_iscsi *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_iscsi_decoders[] = {
+	{"name", offsetof(struct rpc_delete_iscsi, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_iscsi_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_iscsi_bdev(struct spdk_jsonrpc_request *request,
+			   const struct spdk_json_val *params)
+{
+	struct rpc_delete_iscsi req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_iscsi_decoders,
+				    SPDK_COUNTOF(rpc_delete_iscsi_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	delete_iscsi_disk(bdev, _spdk_rpc_delete_iscsi_bdev_cb, request);
+
+	free_rpc_delete_iscsi(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_iscsi(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_iscsi_bdev", spdk_rpc_delete_iscsi_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/lvol/vbdev_lvol.c b/lib/bdev/lvol/vbdev_lvol.c
index 790f10425..cfe319417 100644
--- a/lib/bdev/lvol/vbdev_lvol.c
+++ b/lib/bdev/lvol/vbdev_lvol.c
@@ -33,7 +33,7 @@
 
 #include "spdk/blob_bdev.h"
 #include "spdk/rpc.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 #include "spdk/string.h"
 #include "spdk/uuid.h"
@@ -50,7 +50,7 @@ static void vbdev_lvs_examine(struct spdk_bdev *bdev);
 static struct spdk_bdev_module g_lvol_if = {
 	.name = "lvol",
 	.module_init = vbdev_lvs_init,
-	.examine = vbdev_lvs_examine,
+	.examine_disk = vbdev_lvs_examine,
 	.get_ctx_size = vbdev_lvs_get_ctx_size,
 
 };
@@ -899,6 +899,7 @@ _create_lvol_disk(struct spdk_lvol *lvol)
 	assert((total_size % bdev->blocklen) == 0);
 	bdev->blockcnt = total_size / bdev->blocklen;
 	bdev->uuid = lvol->uuid;
+	bdev->need_aligned_buffer = lvs_bdev->bdev->need_aligned_buffer;
 
 	bdev->ctxt = lvol;
 	bdev->fn_table = &vbdev_lvol_fn_table;
diff --git a/lib/bdev/lvol/vbdev_lvol.h b/lib/bdev/lvol/vbdev_lvol.h
index 89eaf1bda..93991d085 100644
--- a/lib/bdev/lvol/vbdev_lvol.h
+++ b/lib/bdev/lvol/vbdev_lvol.h
@@ -35,7 +35,7 @@
 #define SPDK_VBDEV_LVOL_H
 
 #include "spdk/lvol.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 #include "spdk_internal/lvolstore.h"
 
diff --git a/lib/bdev/lvol/vbdev_lvol_rpc.c b/lib/bdev/lvol/vbdev_lvol_rpc.c
index c892ec280..fe8c76b9e 100644
--- a/lib/bdev/lvol/vbdev_lvol_rpc.c
+++ b/lib/bdev/lvol/vbdev_lvol_rpc.c
@@ -107,9 +107,7 @@ _spdk_rpc_lvol_store_construct_cb(void *cb_arg, struct spdk_lvol_store *lvol_sto
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, lvol_store_uuid);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -166,7 +164,7 @@ invalid:
 					 spdk_strerror(-rc));
 	free_rpc_construct_lvol_store(&req);
 }
-SPDK_RPC_REGISTER("construct_lvol_store", spdk_rpc_construct_lvol_store)
+SPDK_RPC_REGISTER("construct_lvol_store", spdk_rpc_construct_lvol_store, SPDK_RPC_RUNTIME)
 
 struct rpc_rename_lvol_store {
 	char *old_name;
@@ -242,7 +240,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
 	free_rpc_rename_lvol_store(&req);
 }
-SPDK_RPC_REGISTER("rename_lvol_store", spdk_rpc_rename_lvol_store)
+SPDK_RPC_REGISTER("rename_lvol_store", spdk_rpc_rename_lvol_store, SPDK_RPC_RUNTIME)
 
 struct rpc_destroy_lvol_store {
 	char *uuid;
@@ -317,7 +315,7 @@ invalid:
 					 spdk_strerror(-rc));
 	free_rpc_destroy_lvol_store(&req);
 }
-SPDK_RPC_REGISTER("destroy_lvol_store", spdk_rpc_destroy_lvol_store)
+SPDK_RPC_REGISTER("destroy_lvol_store", spdk_rpc_destroy_lvol_store, SPDK_RPC_RUNTIME)
 
 struct rpc_construct_lvol_bdev {
 	char *uuid;
@@ -358,9 +356,7 @@ _spdk_rpc_construct_lvol_bdev_cb(void *cb_arg, struct spdk_lvol *lvol, int lvole
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, lvol->bdev->name);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -413,7 +409,7 @@ invalid:
 	free_rpc_construct_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("construct_lvol_bdev", spdk_rpc_construct_lvol_bdev)
+SPDK_RPC_REGISTER("construct_lvol_bdev", spdk_rpc_construct_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_snapshot_lvol_bdev {
 	char *lvol_name;
@@ -447,9 +443,7 @@ _spdk_rpc_snapshot_lvol_bdev_cb(void *cb_arg, struct spdk_lvol *lvol, int lvoler
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, lvol->bdev->name);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -501,7 +495,7 @@ invalid:
 	free_rpc_snapshot_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("snapshot_lvol_bdev", spdk_rpc_snapshot_lvol_bdev)
+SPDK_RPC_REGISTER("snapshot_lvol_bdev", spdk_rpc_snapshot_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_clone_lvol_bdev {
 	char *snapshot_name;
@@ -535,9 +529,7 @@ _spdk_rpc_clone_lvol_bdev_cb(void *cb_arg, struct spdk_lvol *lvol, int lvolerrno
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, lvol->bdev->name);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -589,7 +581,7 @@ invalid:
 	free_rpc_clone_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("clone_lvol_bdev", spdk_rpc_clone_lvol_bdev)
+SPDK_RPC_REGISTER("clone_lvol_bdev", spdk_rpc_clone_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_rename_lvol_bdev {
 	char *old_name;
@@ -675,7 +667,135 @@ invalid:
 	free_rpc_rename_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("rename_lvol_bdev", spdk_rpc_rename_lvol_bdev)
+SPDK_RPC_REGISTER("rename_lvol_bdev", spdk_rpc_rename_lvol_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_inflate_lvol_bdev {
+	char *name;
+};
+
+static void
+free_rpc_inflate_lvol_bdev(struct rpc_inflate_lvol_bdev *req)
+{
+	free(req->name);
+}
+
+static const struct spdk_json_object_decoder rpc_inflate_lvol_bdev_decoders[] = {
+	{"name", offsetof(struct rpc_inflate_lvol_bdev, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_inflate_lvol_bdev_cb(void *cb_arg, int lvolerrno)
+{
+	struct spdk_json_write_ctx *w;
+	struct spdk_jsonrpc_request *request = cb_arg;
+
+	if (lvolerrno != 0) {
+		goto invalid;
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+	return;
+
+invalid:
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+					 spdk_strerror(-lvolerrno));
+}
+
+static void
+spdk_rpc_inflate_lvol_bdev(struct spdk_jsonrpc_request *request,
+			   const struct spdk_json_val *params)
+{
+	struct rpc_inflate_lvol_bdev req = {};
+	struct spdk_bdev *bdev;
+	struct spdk_lvol *lvol;
+	int rc = 0;
+
+	SPDK_INFOLOG(SPDK_LOG_LVOL_RPC, "Inflating lvol\n");
+
+	if (spdk_json_decode_object(params, rpc_inflate_lvol_bdev_decoders,
+				    SPDK_COUNTOF(rpc_inflate_lvol_bdev_decoders),
+				    &req)) {
+		SPDK_INFOLOG(SPDK_LOG_LVOL_RPC, "spdk_json_decode_object failed\n");
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	lvol = vbdev_lvol_get_from_bdev(bdev);
+	if (lvol == NULL) {
+		SPDK_ERRLOG("lvol does not exist\n");
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	spdk_lvol_inflate(lvol, _spdk_rpc_inflate_lvol_bdev_cb, request);
+
+	free_rpc_inflate_lvol_bdev(&req);
+	return;
+
+invalid:
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+	free_rpc_inflate_lvol_bdev(&req);
+}
+
+SPDK_RPC_REGISTER("inflate_lvol_bdev", spdk_rpc_inflate_lvol_bdev, SPDK_RPC_RUNTIME)
+
+static void
+spdk_rpc_decouple_parent_lvol_bdev(struct spdk_jsonrpc_request *request,
+				   const struct spdk_json_val *params)
+{
+	struct rpc_inflate_lvol_bdev req = {};
+	struct spdk_bdev *bdev;
+	struct spdk_lvol *lvol;
+	int rc = 0;
+
+	SPDK_INFOLOG(SPDK_LOG_LVOL_RPC, "Decoupling parent of lvol\n");
+
+	if (spdk_json_decode_object(params, rpc_inflate_lvol_bdev_decoders,
+				    SPDK_COUNTOF(rpc_inflate_lvol_bdev_decoders),
+				    &req)) {
+		SPDK_INFOLOG(SPDK_LOG_LVOL_RPC, "spdk_json_decode_object failed\n");
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	lvol = vbdev_lvol_get_from_bdev(bdev);
+	if (lvol == NULL) {
+		SPDK_ERRLOG("lvol does not exist\n");
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	spdk_lvol_decouple_parent(lvol, _spdk_rpc_inflate_lvol_bdev_cb, request);
+
+	free_rpc_inflate_lvol_bdev(&req);
+	return;
+
+invalid:
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+	free_rpc_inflate_lvol_bdev(&req);
+}
+
+SPDK_RPC_REGISTER("decouple_parent_lvol_bdev", spdk_rpc_decouple_parent_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_resize_lvol_bdev {
 	char *name;
@@ -766,7 +886,7 @@ invalid:
 	free_rpc_resize_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("resize_lvol_bdev", spdk_rpc_resize_lvol_bdev)
+SPDK_RPC_REGISTER("resize_lvol_bdev", spdk_rpc_resize_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_destroy_lvol_bdev {
 	char *name;
@@ -847,7 +967,7 @@ invalid:
 	free_rpc_destroy_lvol_bdev(&req);
 }
 
-SPDK_RPC_REGISTER("destroy_lvol_bdev", spdk_rpc_destroy_lvol_bdev)
+SPDK_RPC_REGISTER("destroy_lvol_bdev", spdk_rpc_destroy_lvol_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_get_lvol_stores {
 	char *uuid;
@@ -965,4 +1085,4 @@ invalid:
 	free_rpc_get_lvol_stores(&req);
 }
 
-SPDK_RPC_REGISTER("get_lvol_stores", spdk_rpc_get_lvol_stores)
+SPDK_RPC_REGISTER("get_lvol_stores", spdk_rpc_get_lvol_stores, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/malloc/bdev_malloc.c b/lib/bdev/malloc/bdev_malloc.c
index 699eb7e00..d7a84a0c9 100644
--- a/lib/bdev/malloc/bdev_malloc.c
+++ b/lib/bdev/malloc/bdev_malloc.c
@@ -41,11 +41,11 @@
 #include "spdk/env.h"
 #include "spdk/copy_engine.h"
 #include "spdk/json.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/queue.h"
 #include "spdk/string.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 struct malloc_disk {
@@ -448,6 +448,17 @@ struct spdk_bdev *create_malloc_disk(const char *name, const struct spdk_uuid *u
 	return &mdisk->disk;
 }
 
+void
+delete_malloc_disk(struct spdk_bdev *bdev, spdk_delete_malloc_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &malloc_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 static int bdev_malloc_initialize(void)
 {
 	struct spdk_conf_section *sp = spdk_conf_find_section(NULL, "Malloc");
diff --git a/lib/bdev/malloc/bdev_malloc.h b/lib/bdev/malloc/bdev_malloc.h
index 494594739..8ebdba780 100644
--- a/lib/bdev/malloc/bdev_malloc.h
+++ b/lib/bdev/malloc/bdev_malloc.h
@@ -38,7 +38,11 @@
 
 #include "spdk/bdev.h"
 
+typedef void (*spdk_delete_malloc_complete)(void *cb_arg, int bdeverrno);
+
 struct spdk_bdev *create_malloc_disk(const char *name, const struct spdk_uuid *uuid,
 				     uint64_t num_blocks, uint32_t block_size);
 
+void delete_malloc_disk(struct spdk_bdev *bdev, spdk_delete_malloc_complete cb_fn, void *cb_arg);
+
 #endif /* SPDK_BDEV_MALLOC_H */
diff --git a/lib/bdev/malloc/bdev_malloc_rpc.c b/lib/bdev/malloc/bdev_malloc_rpc.c
index c76a2e10a..4066cf2fb 100644
--- a/lib/bdev/malloc/bdev_malloc_rpc.c
+++ b/lib/bdev/malloc/bdev_malloc_rpc.c
@@ -35,7 +35,7 @@
 #include "spdk/rpc.h"
 #include "spdk/util.h"
 #include "spdk/uuid.h"
-
+#include "spdk/string.h"
 #include "spdk_internal/log.h"
 
 struct rpc_construct_malloc {
@@ -95,9 +95,7 @@ spdk_rpc_construct_malloc_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -105,4 +103,68 @@ invalid:
 	free_rpc_construct_malloc(&req);
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 }
-SPDK_RPC_REGISTER("construct_malloc_bdev", spdk_rpc_construct_malloc_bdev)
+SPDK_RPC_REGISTER("construct_malloc_bdev", spdk_rpc_construct_malloc_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_malloc {
+	char *name;
+};
+
+static void
+free_rpc_delete_malloc(struct rpc_delete_malloc *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_malloc_decoders[] = {
+	{"name", offsetof(struct rpc_delete_malloc, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_malloc_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_malloc_bdev(struct spdk_jsonrpc_request *request,
+			    const struct spdk_json_val *params)
+{
+	struct rpc_delete_malloc req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_malloc_decoders,
+				    SPDK_COUNTOF(rpc_delete_malloc_decoders),
+				    &req)) {
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_MALLOC, "spdk_json_decode_object failed\n");
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		SPDK_INFOLOG(SPDK_LOG_BDEV_MALLOC, "bdev '%s' does not exist\n", req.name);
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	delete_malloc_disk(bdev, _spdk_rpc_delete_malloc_bdev_cb, request);
+
+	free_rpc_delete_malloc(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_malloc(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_malloc_bdev", spdk_rpc_delete_malloc_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/null/bdev_null.c b/lib/bdev/null/bdev_null.c
index 5df16367d..f6cf49284 100644
--- a/lib/bdev/null/bdev_null.c
+++ b/lib/bdev/null/bdev_null.c
@@ -36,10 +36,10 @@
 #include "spdk/bdev.h"
 #include "spdk/conf.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/json.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 #include "bdev_null.h"
@@ -214,6 +214,17 @@ create_null_bdev(const char *name, const struct spdk_uuid *uuid,
 	return &bdev->bdev;
 }
 
+void
+delete_null_bdev(struct spdk_bdev *bdev, spdk_delete_null_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &null_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 static int
 null_io_poll(void *arg)
 {
diff --git a/lib/bdev/null/bdev_null.h b/lib/bdev/null/bdev_null.h
index 45065df02..fa0123e32 100644
--- a/lib/bdev/null/bdev_null.h
+++ b/lib/bdev/null/bdev_null.h
@@ -36,10 +36,22 @@
 
 #include "spdk/stdinc.h"
 
+typedef void (*spdk_delete_null_complete)(void *cb_arg, int bdeverrno);
+
 struct spdk_bdev;
 struct spdk_uuid;
 
 struct spdk_bdev *create_null_bdev(const char *name, const struct spdk_uuid *uuid,
 				   uint64_t num_blocks, uint32_t block_size);
 
+/**
+ * Delete null bdev.
+ *
+ * \param bdev Pointer to null bdev.
+ * \param cb_fn Function to call after deletion.
+ * \param cb_arg Argument to pass to cb_fn.
+ */
+void delete_null_bdev(struct spdk_bdev *bdev, spdk_delete_null_complete cb_fn,
+		      void *cb_arg);
+
 #endif /* SPDK_BDEV_NULL_H */
diff --git a/lib/bdev/null/bdev_null_rpc.c b/lib/bdev/null/bdev_null_rpc.c
index f8d0ea1b9..9410b7ad1 100644
--- a/lib/bdev/null/bdev_null_rpc.c
+++ b/lib/bdev/null/bdev_null_rpc.c
@@ -33,8 +33,8 @@
 
 #include "spdk/rpc.h"
 #include "spdk/util.h"
-
-#include "spdk_internal/bdev.h"
+#include "spdk/string.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 #include "bdev_null.h"
@@ -95,9 +95,7 @@ spdk_rpc_construct_null_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, bdev->name);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	free_rpc_construct_null(&req);
 	return;
@@ -106,4 +104,66 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_construct_null(&req);
 }
-SPDK_RPC_REGISTER("construct_null_bdev", spdk_rpc_construct_null_bdev)
+SPDK_RPC_REGISTER("construct_null_bdev", spdk_rpc_construct_null_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_null {
+	char *name;
+};
+
+static void
+free_rpc_delete_null(struct rpc_delete_null *req)
+{
+	free(req->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_null_decoders[] = {
+	{"name", offsetof(struct rpc_delete_null, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_null_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_null_bdev(struct spdk_jsonrpc_request *request,
+			  const struct spdk_json_val *params)
+{
+	struct rpc_delete_null req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_null_decoders,
+				    SPDK_COUNTOF(rpc_delete_null_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	delete_null_bdev(bdev, _spdk_rpc_delete_null_bdev_cb, request);
+
+	free_rpc_delete_null(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_null(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_null_bdev", spdk_rpc_delete_null_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/nvme/bdev_nvme.c b/lib/bdev/nvme/bdev_nvme.c
index 799541636..ebf82504f 100644
--- a/lib/bdev/nvme/bdev_nvme.c
+++ b/lib/bdev/nvme/bdev_nvme.c
@@ -41,42 +41,17 @@
 #include "spdk/bdev.h"
 #include "spdk/json.h"
 #include "spdk/nvme.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/string.h"
 #include "spdk/likely.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 static void bdev_nvme_get_spdk_running_config(FILE *fp);
 static int bdev_nvme_config_json(struct spdk_json_write_ctx *w);
 
-struct nvme_ctrlr {
-	/**
-	 * points to pinned, physically contiguous memory region;
-	 * contains 4KB IDENTIFY structure for controller which is
-	 *  target for CONTROLLER IDENTIFY command during initialization
-	 */
-	struct spdk_nvme_ctrlr		*ctrlr;
-	struct spdk_nvme_transport_id	trid;
-	char				*name;
-	int				ref;
-
-	struct spdk_poller		*adminq_timer_poller;
-
-	/** linked list pointer for device list */
-	TAILQ_ENTRY(nvme_ctrlr)	tailq;
-};
-
-struct nvme_bdev {
-	struct spdk_bdev	disk;
-	struct nvme_ctrlr	*nvme_ctrlr;
-	struct spdk_nvme_ns	*ns;
-
-	TAILQ_ENTRY(nvme_bdev)	link;
-};
-
 struct nvme_io_channel {
 	struct spdk_nvme_qpair	*qpair;
 	struct spdk_poller	*poller;
@@ -116,6 +91,7 @@ struct nvme_probe_ctx {
 	size_t count;
 	struct spdk_nvme_transport_id trids[NVME_MAX_CONTROLLERS];
 	const char *names[NVME_MAX_CONTROLLERS];
+	const char *hostnqn;
 };
 
 enum timeout_action {
@@ -126,15 +102,15 @@ enum timeout_action {
 
 static int g_hot_insert_nvme_controller_index = 0;
 static enum timeout_action g_action_on_timeout = TIMEOUT_ACTION_NONE;
-static int g_timeout = 0;
+static uint64_t g_timeout_us = 0;
 static int g_nvme_adminq_poll_timeout_us = 0;
 static bool g_nvme_hotplug_enabled = false;
 static int g_nvme_hotplug_poll_timeout_us = 0;
 static struct spdk_poller *g_hotplug_poller;
+static char *g_nvme_hostnqn = NULL;
 static pthread_mutex_t g_bdev_nvme_mutex = PTHREAD_MUTEX_INITIALIZER;
 
 static TAILQ_HEAD(, nvme_ctrlr)	g_nvme_ctrlrs = TAILQ_HEAD_INITIALIZER(g_nvme_ctrlrs);
-static TAILQ_HEAD(, nvme_bdev) g_nvme_bdevs = TAILQ_HEAD_INITIALIZER(g_nvme_bdevs);
 
 static int nvme_ctrlr_create_bdevs(struct nvme_ctrlr *nvme_ctrlr);
 static int bdev_nvme_library_init(void);
@@ -152,6 +128,7 @@ static int bdev_nvme_io_passthru(struct nvme_bdev *nbdev, struct spdk_io_channel
 static int bdev_nvme_io_passthru_md(struct nvme_bdev *nbdev, struct spdk_io_channel *ch,
 				    struct nvme_bdev_io *bio,
 				    struct spdk_nvme_cmd *cmd, void *buf, size_t nbytes, void *md_buf, size_t md_len);
+static int nvme_ctrlr_create_bdev(struct nvme_ctrlr *nvme_ctrlr, uint32_t nsid);
 
 static int
 bdev_nvme_get_ctx_size(void)
@@ -252,16 +229,16 @@ bdev_nvme_destruct(void *ctx)
 	struct nvme_ctrlr *nvme_ctrlr = nvme_disk->nvme_ctrlr;
 
 	pthread_mutex_lock(&g_bdev_nvme_mutex);
-	TAILQ_REMOVE(&g_nvme_bdevs, nvme_disk, link);
 	nvme_ctrlr->ref--;
 	free(nvme_disk->disk.name);
-	free(nvme_disk);
+	memset(nvme_disk, 0, sizeof(*nvme_disk));
 	if (nvme_ctrlr->ref == 0) {
 		TAILQ_REMOVE(&g_nvme_ctrlrs, nvme_ctrlr, tailq);
 		pthread_mutex_unlock(&g_bdev_nvme_mutex);
 		spdk_io_device_unregister(nvme_ctrlr->ctrlr, bdev_nvme_unregister_cb);
 		spdk_poller_unregister(&nvme_ctrlr->adminq_timer_poller);
 		free(nvme_ctrlr->name);
+		free(nvme_ctrlr->bdevs);
 		free(nvme_ctrlr);
 		return 0;
 	}
@@ -711,6 +688,66 @@ static const struct spdk_bdev_fn_table nvmelib_fn_table = {
 	.get_spin_time		= bdev_nvme_get_spin_time,
 };
 
+static int
+nvme_ctrlr_create_bdev(struct nvme_ctrlr *nvme_ctrlr, uint32_t nsid)
+{
+	struct spdk_nvme_ctrlr	*ctrlr = nvme_ctrlr->ctrlr;
+	struct nvme_bdev	*bdev;
+	struct spdk_nvme_ns	*ns;
+	const struct spdk_uuid	*uuid;
+	const struct spdk_nvme_ctrlr_data *cdata;
+	int			rc;
+
+	cdata = spdk_nvme_ctrlr_get_data(ctrlr);
+
+	ns = spdk_nvme_ctrlr_get_ns(ctrlr, nsid);
+	if (!ns) {
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Invalid NS %d\n", nsid);
+		return -EINVAL;
+	}
+
+	bdev = &nvme_ctrlr->bdevs[nsid - 1];
+	bdev->id = nsid;
+
+	bdev->nvme_ctrlr = nvme_ctrlr;
+	bdev->ns = ns;
+	nvme_ctrlr->ref++;
+
+	bdev->disk.name = spdk_sprintf_alloc("%sn%d", nvme_ctrlr->name, spdk_nvme_ns_get_id(ns));
+	if (!bdev->disk.name) {
+		return -ENOMEM;
+	}
+	bdev->disk.product_name = "NVMe disk";
+
+	bdev->disk.write_cache = 0;
+	if (cdata->vwc.present) {
+		/* Enable if the Volatile Write Cache exists */
+		bdev->disk.write_cache = 1;
+	}
+	bdev->disk.blocklen = spdk_nvme_ns_get_sector_size(ns);
+	bdev->disk.blockcnt = spdk_nvme_ns_get_num_sectors(ns);
+	bdev->disk.optimal_io_boundary = spdk_nvme_ns_get_optimal_io_boundary(ns);
+
+	uuid = spdk_nvme_ns_get_uuid(ns);
+	if (uuid != NULL) {
+		bdev->disk.uuid = *uuid;
+	}
+
+	bdev->disk.ctxt = bdev;
+	bdev->disk.fn_table = &nvmelib_fn_table;
+	bdev->disk.module = &nvme_if;
+	rc = spdk_bdev_register(&bdev->disk);
+	if (rc) {
+		free(bdev->disk.name);
+		memset(bdev, 0, sizeof(*bdev));
+		return rc;
+	}
+	bdev->active = true;
+
+	return 0;
+}
+
+
 static bool
 hotplug_probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 		 struct spdk_nvme_ctrlr_opts *opts)
@@ -738,6 +775,7 @@ static bool
 probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	 struct spdk_nvme_ctrlr_opts *opts)
 {
+	struct nvme_probe_ctx *ctx = cb_ctx;
 
 	SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Probing device %s\n", trid->traddr);
 
@@ -749,7 +787,6 @@ probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 
 	if (trid->trtype == SPDK_NVME_TRANSPORT_PCIE) {
 		bool claim_device = false;
-		struct nvme_probe_ctx *ctx = cb_ctx;
 		size_t i;
 
 		for (i = 0; i < ctx->count; i++) {
@@ -765,6 +802,10 @@ probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 		}
 	}
 
+	if (ctx->hostnqn) {
+		snprintf(opts->hostnqn, sizeof(opts->hostnqn), "%s", ctx->hostnqn);
+	}
+
 	return true;
 }
 
@@ -816,52 +857,87 @@ timeout_cb(void *cb_arg, struct spdk_nvme_ctrlr *ctrlr,
 }
 
 static void
-attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
-	  struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_ctrlr_opts *opts)
+nvme_ctrlr_deactivate_bdev(struct nvme_bdev *bdev)
 {
-	struct nvme_ctrlr *nvme_ctrlr;
-	struct nvme_probe_ctx *ctx = cb_ctx;
-	char *name = NULL;
-	size_t i;
+	spdk_bdev_unregister(&bdev->disk, NULL, NULL);
+	bdev->active = false;
+}
 
-	if (ctx) {
-		for (i = 0; i < ctx->count; i++) {
-			if (spdk_nvme_transport_id_compare(trid, &ctx->trids[i]) == 0) {
-				name = strdup(ctx->names[i]);
-				break;
-			}
+static void
+nvme_ctrlr_update_ns_bdevs(struct nvme_ctrlr *nvme_ctrlr)
+{
+	struct spdk_nvme_ctrlr	*ctrlr = nvme_ctrlr->ctrlr;
+	uint32_t		i;
+	struct nvme_bdev	*bdev;
+
+	for (i = 0; i < nvme_ctrlr->num_ns; i++) {
+		uint32_t	nsid = i + 1;
+
+		bdev = &nvme_ctrlr->bdevs[i];
+		if (!bdev->active && spdk_nvme_ctrlr_is_active_ns(ctrlr, nsid)) {
+			SPDK_NOTICELOG("NSID %u to be added\n", nsid);
+			nvme_ctrlr_create_bdev(nvme_ctrlr, nsid);
+		}
+
+		if (bdev->active && !spdk_nvme_ctrlr_is_active_ns(ctrlr, nsid)) {
+			SPDK_NOTICELOG("NSID %u Bdev %s is removed\n", nsid, bdev->disk.name);
+			nvme_ctrlr_deactivate_bdev(bdev);
 		}
-	} else {
-		name = spdk_sprintf_alloc("HotInNvme%d", g_hot_insert_nvme_controller_index++);
 	}
-	if (!name) {
-		SPDK_ERRLOG("Failed to assign name to NVMe device\n");
+
+}
+
+static void
+aer_cb(void *arg, const struct spdk_nvme_cpl *cpl)
+{
+	struct nvme_ctrlr *nvme_ctrlr		= arg;
+	union spdk_nvme_async_event_completion	event;
+
+	if (spdk_nvme_cpl_is_error(cpl)) {
+		SPDK_WARNLOG("AER request execute failed");
 		return;
 	}
 
-	SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Attached to %s (%s)\n", trid->traddr, name);
+	event.raw = cpl->cdw0;
+	if ((event.bits.async_event_type == SPDK_NVME_ASYNC_EVENT_TYPE_NOTICE) &&
+	    (event.bits.async_event_info == SPDK_NVME_ASYNC_EVENT_NS_ATTR_CHANGED)) {
+		nvme_ctrlr_update_ns_bdevs(nvme_ctrlr);
+	}
+}
+
+static int
+create_ctrlr(struct spdk_nvme_ctrlr *ctrlr,
+	     const char *name,
+	     const struct spdk_nvme_transport_id *trid)
+{
+	struct nvme_ctrlr *nvme_ctrlr;
 
 	nvme_ctrlr = calloc(1, sizeof(*nvme_ctrlr));
 	if (nvme_ctrlr == NULL) {
 		SPDK_ERRLOG("Failed to allocate device struct\n");
-		free((void *)name);
-		return;
+		return -ENOMEM;
+	}
+	nvme_ctrlr->num_ns = spdk_nvme_ctrlr_get_num_ns(ctrlr);
+	nvme_ctrlr->bdevs = calloc(nvme_ctrlr->num_ns, sizeof(struct nvme_bdev));
+	if (!nvme_ctrlr->bdevs) {
+		SPDK_ERRLOG("Failed to allocate block devices struct\n");
+		free(nvme_ctrlr);
+		return -ENOMEM;
 	}
 
 	nvme_ctrlr->adminq_timer_poller = NULL;
 	nvme_ctrlr->ctrlr = ctrlr;
 	nvme_ctrlr->ref = 0;
 	nvme_ctrlr->trid = *trid;
-	nvme_ctrlr->name = name;
+	nvme_ctrlr->name = strdup(name);
 
 	spdk_io_device_register(ctrlr, bdev_nvme_create_cb, bdev_nvme_destroy_cb,
 				sizeof(struct nvme_io_channel));
 
 	if (nvme_ctrlr_create_bdevs(nvme_ctrlr) != 0) {
 		spdk_io_device_unregister(ctrlr, NULL);
-		free(nvme_ctrlr->name);
 		free(nvme_ctrlr);
-		return;
+		return -1;
 	}
 
 	nvme_ctrlr->adminq_timer_poller = spdk_poller_register(bdev_nvme_poll_adminq, ctrlr,
@@ -870,22 +946,66 @@ attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	TAILQ_INSERT_TAIL(&g_nvme_ctrlrs, nvme_ctrlr, tailq);
 
 	if (g_action_on_timeout != TIMEOUT_ACTION_NONE) {
-		spdk_nvme_ctrlr_register_timeout_callback(ctrlr, g_timeout,
+		spdk_nvme_ctrlr_register_timeout_callback(ctrlr, g_timeout_us,
 				timeout_cb, NULL);
 	}
+
+	spdk_nvme_ctrlr_register_aer_callback(ctrlr, aer_cb, nvme_ctrlr);
+
+	return 0;
+}
+
+static void
+attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
+	  struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_ctrlr_opts *opts)
+{
+	struct nvme_probe_ctx *ctx = cb_ctx;
+	char *name = NULL;
+	size_t i;
+
+	if (ctx) {
+		for (i = 0; i < ctx->count; i++) {
+			if (spdk_nvme_transport_id_compare(trid, &ctx->trids[i]) == 0) {
+				name = strdup(ctx->names[i]);
+				break;
+			}
+		}
+	} else {
+		name = spdk_sprintf_alloc("HotInNvme%d", g_hot_insert_nvme_controller_index++);
+	}
+	if (!name) {
+		SPDK_ERRLOG("Failed to assign name to NVMe device\n");
+		return;
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Attached to %s (%s)\n", trid->traddr, name);
+
+	create_ctrlr(ctrlr, name, trid);
+
+	free(name);
 }
 
 static void
 remove_cb(void *cb_ctx, struct spdk_nvme_ctrlr *ctrlr)
 {
-	struct nvme_bdev *nvme_bdev, *btmp;
+	uint32_t i;
+	struct nvme_ctrlr *nvme_ctrlr;
+	struct nvme_bdev *nvme_bdev;
 
 	pthread_mutex_lock(&g_bdev_nvme_mutex);
-	TAILQ_FOREACH_SAFE(nvme_bdev, &g_nvme_bdevs, link, btmp) {
-		if (nvme_bdev->nvme_ctrlr->ctrlr == ctrlr) {
+	TAILQ_FOREACH(nvme_ctrlr, &g_nvme_ctrlrs, tailq) {
+		if (nvme_ctrlr->ctrlr == ctrlr) {
 			pthread_mutex_unlock(&g_bdev_nvme_mutex);
-			spdk_bdev_unregister(&nvme_bdev->disk, NULL, NULL);
-			pthread_mutex_lock(&g_bdev_nvme_mutex);
+			for (i = 0; i < nvme_ctrlr->num_ns; i++) {
+				uint32_t	nsid = i + 1;
+
+				nvme_bdev = &nvme_ctrlr->bdevs[nsid - 1];
+				assert(nvme_bdev->id == nsid);
+				if (nvme_bdev->active) {
+					spdk_bdev_unregister(&nvme_bdev->disk, NULL, NULL);
+				}
+			}
+			return;
 		}
 	}
 	pthread_mutex_unlock(&g_bdev_nvme_mutex);
@@ -904,11 +1024,13 @@ bdev_nvme_hotplug(void *arg)
 int
 spdk_bdev_nvme_create(struct spdk_nvme_transport_id *trid,
 		      const char *base_name,
-		      const char **names, size_t *count)
+		      const char **names, size_t *count,
+		      const char *hostnqn)
 {
 	struct nvme_probe_ctx	*probe_ctx;
 	struct nvme_ctrlr	*nvme_ctrlr;
 	struct nvme_bdev	*nvme_bdev;
+	uint32_t		i, nsid;
 	size_t			j;
 
 	if (nvme_ctrlr_get(trid) != NULL) {
@@ -925,6 +1047,7 @@ spdk_bdev_nvme_create(struct spdk_nvme_transport_id *trid,
 	probe_ctx->count = 1;
 	probe_ctx->trids[0] = *trid;
 	probe_ctx->names[0] = base_name;
+	probe_ctx->hostnqn = hostnqn;
 	if (spdk_nvme_probe(trid, probe_ctx, probe_cb, attach_cb, NULL)) {
 		SPDK_ERRLOG("Failed to probe for new devices\n");
 		free(probe_ctx);
@@ -943,18 +1066,24 @@ spdk_bdev_nvme_create(struct spdk_nvme_transport_id *trid,
 	 * There can be more than one bdev per NVMe controller since one bdev is created per namespace.
 	 */
 	j = 0;
-	TAILQ_FOREACH(nvme_bdev, &g_nvme_bdevs, link) {
-		if (nvme_bdev->nvme_ctrlr == nvme_ctrlr) {
-			if (j < *count) {
-				names[j] = nvme_bdev->disk.name;
-				j++;
-			} else {
-				SPDK_ERRLOG("Unable to return all names of created bdevs\n");
-				free(probe_ctx);
-				return -1;
-			}
+	for (i = 0; i < nvme_ctrlr->num_ns; i++) {
+		nsid = i + 1;
+		nvme_bdev = &nvme_ctrlr->bdevs[nsid - 1];
+		if (!nvme_bdev->active) {
+			continue;
+		}
+		assert(nvme_bdev->id == nsid);
+		if (j < *count) {
+			names[j] = nvme_bdev->disk.name;
+			j++;
+		} else {
+			SPDK_ERRLOG("Maximum number of namespaces supported per NVMe controller is %zu. Unable to return all names of created bdevs\n",
+				    *count);
+			free(probe_ctx);
+			return -1;
 		}
 	}
+
 	*count = j;
 
 	free(probe_ctx);
@@ -970,6 +1099,7 @@ bdev_nvme_library_init(void)
 	size_t i;
 	struct nvme_probe_ctx *probe_ctx = NULL;
 	int retry_count;
+	int timeout;
 	uint32_t local_nvme_num = 0;
 
 	sp = spdk_conf_find_section(NULL, "Nvme");
@@ -995,17 +1125,29 @@ bdev_nvme_library_init(void)
 
 	spdk_nvme_retry_count = retry_count;
 
-	if ((g_timeout = spdk_conf_section_get_intval(sp, "Timeout")) < 0) {
+	val = spdk_conf_section_get_val(sp, "TimeoutUsec");
+	if (val != NULL) {
+		g_timeout_us = strtoll(val, NULL, 10);
+	} else {
 		/* Check old name for backward compatibility */
-		if ((g_timeout = spdk_conf_section_get_intval(sp, "NvmeTimeoutValue")) < 0) {
-			g_timeout = 0;
+		timeout = spdk_conf_section_get_intval(sp, "Timeout");
+		if (timeout < 0) {
+			timeout = spdk_conf_section_get_intval(sp, "NvmeTimeoutValue");
+			if (timeout < 0) {
+				g_timeout_us = 0;
+			} else {
+				g_timeout_us = timeout * 1000000ULL;
+				SPDK_WARNLOG("NvmeTimeoutValue (in seconds) was renamed to TimeoutUsec (in microseconds)\n");
+				SPDK_WARNLOG("Please update your configuration file\n");
+			}
 		} else {
-			SPDK_WARNLOG("NvmeTimeoutValue was renamed to Timeout\n");
+			g_timeout_us = timeout * 1000000ULL;
+			SPDK_WARNLOG("Timeout (in seconds) was renamed to TimeoutUsec (in microseconds)\n");
 			SPDK_WARNLOG("Please update your configuration file\n");
 		}
 	}
 
-	if (g_timeout > 0) {
+	if (g_timeout_us > 0) {
 		val = spdk_conf_section_get_val(sp, "ActionOnTimeout");
 		if (val != NULL) {
 			if (!strcasecmp(val, "Reset")) {
@@ -1041,6 +1183,11 @@ bdev_nvme_library_init(void)
 		g_nvme_hotplug_poll_timeout_us = 100000;
 	}
 
+	g_nvme_hostnqn = spdk_conf_section_get_val(sp, "HostNQN");
+	if (g_nvme_hostnqn) {
+		probe_ctx->hostnqn = g_nvme_hostnqn;
+	}
+
 	for (i = 0; i < NVME_MAX_CONTROLLERS; i++) {
 		val = spdk_conf_section_get_nmval(sp, "TransportID", i, 0);
 		if (val == NULL) {
@@ -1065,16 +1212,40 @@ bdev_nvme_library_init(void)
 		probe_ctx->count++;
 
 		if (probe_ctx->trids[i].trtype != SPDK_NVME_TRANSPORT_PCIE) {
+			struct spdk_nvme_ctrlr *ctrlr;
+			struct spdk_nvme_ctrlr_opts opts;
+
+			if (nvme_ctrlr_get(&probe_ctx->trids[i])) {
+				SPDK_ERRLOG("A controller with the provided trid (traddr: %s) already exists.\n",
+					    probe_ctx->trids[i].traddr);
+				rc = -1;
+				goto end;
+			}
+
 			if (probe_ctx->trids[i].subnqn[0] == '\0') {
 				SPDK_ERRLOG("Need to provide subsystem nqn\n");
 				rc = -1;
 				goto end;
 			}
 
-			if (spdk_nvme_probe(&probe_ctx->trids[i], probe_ctx, probe_cb, attach_cb, NULL)) {
+			spdk_nvme_ctrlr_get_default_ctrlr_opts(&opts, sizeof(opts));
+
+			if (probe_ctx->hostnqn != NULL) {
+				snprintf(opts.hostnqn, sizeof(opts.hostnqn), "%s", probe_ctx->hostnqn);
+			}
+
+			ctrlr = spdk_nvme_connect(&probe_ctx->trids[i], &opts, sizeof(opts));
+			if (ctrlr == NULL) {
+				SPDK_ERRLOG("Unable to connect to provided trid (traddr: %s)\n",
+					    probe_ctx->trids[i].traddr);
 				rc = -1;
 				goto end;
 			}
+
+			rc = create_ctrlr(ctrlr, probe_ctx->names[i], &probe_ctx->trids[i]);
+			if (!rc) {
+				goto end;
+			}
 		} else {
 			local_nvme_num++;
 		}
@@ -1086,6 +1257,17 @@ bdev_nvme_library_init(void)
 			rc = -1;
 			goto end;
 		}
+
+		for (i = 0; i < probe_ctx->count; i++) {
+			if (probe_ctx->trids[i].trtype != SPDK_NVME_TRANSPORT_PCIE) {
+				continue;
+			}
+
+			if (!nvme_ctrlr_get(&probe_ctx->trids[i])) {
+				SPDK_ERRLOG("NVMe SSD \"%s\" could not be found.\n", probe_ctx->trids[i].traddr);
+				SPDK_ERRLOG("Check PCIe BDF and that it is attached to UIO/VFIO driver.\n");
+			}
+		}
 	}
 
 	if (g_nvme_hotplug_enabled) {
@@ -1109,73 +1291,16 @@ bdev_nvme_library_fini(void)
 static int
 nvme_ctrlr_create_bdevs(struct nvme_ctrlr *nvme_ctrlr)
 {
-	struct nvme_bdev	*bdev;
-	struct spdk_nvme_ctrlr	*ctrlr = nvme_ctrlr->ctrlr;
-	struct spdk_nvme_ns	*ns;
-	const struct spdk_nvme_ctrlr_data *cdata;
-	const struct spdk_uuid	*uuid;
 	int			rc;
 	int			bdev_created = 0;
 	uint32_t		nsid;
 
-	cdata = spdk_nvme_ctrlr_get_data(ctrlr);
-
-	for (nsid = spdk_nvme_ctrlr_get_first_active_ns(ctrlr);
-	     nsid != 0; nsid = spdk_nvme_ctrlr_get_next_active_ns(ctrlr, nsid)) {
-		ns = spdk_nvme_ctrlr_get_ns(ctrlr, nsid);
-		if (!ns) {
-			SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Skipping invalid NS %d\n", nsid);
-			continue;
+	for (nsid = spdk_nvme_ctrlr_get_first_active_ns(nvme_ctrlr->ctrlr);
+	     nsid != 0; nsid = spdk_nvme_ctrlr_get_next_active_ns(nvme_ctrlr->ctrlr, nsid)) {
+		rc = nvme_ctrlr_create_bdev(nvme_ctrlr, nsid);
+		if (rc == 0) {
+			bdev_created++;
 		}
-
-		if (!spdk_nvme_ns_is_active(ns)) {
-			SPDK_DEBUGLOG(SPDK_LOG_BDEV_NVME, "Skipping inactive NS %d\n", nsid);
-			continue;
-		}
-
-		bdev = calloc(1, sizeof(*bdev));
-		if (!bdev) {
-			break;
-		}
-
-		bdev->nvme_ctrlr = nvme_ctrlr;
-		bdev->ns = ns;
-		nvme_ctrlr->ref++;
-
-		bdev->disk.name = spdk_sprintf_alloc("%sn%d", nvme_ctrlr->name, spdk_nvme_ns_get_id(ns));
-		if (!bdev->disk.name) {
-			free(bdev);
-			break;
-		}
-		bdev->disk.product_name = "NVMe disk";
-
-		bdev->disk.write_cache = 0;
-		if (cdata->vwc.present) {
-			/* Enable if the Volatile Write Cache exists */
-			bdev->disk.write_cache = 1;
-		}
-		bdev->disk.blocklen = spdk_nvme_ns_get_sector_size(ns);
-		bdev->disk.blockcnt = spdk_nvme_ns_get_num_sectors(ns);
-		bdev->disk.optimal_io_boundary = spdk_nvme_ns_get_optimal_io_boundary(ns);
-
-		uuid = spdk_nvme_ns_get_uuid(ns);
-		if (uuid != NULL) {
-			bdev->disk.uuid = *uuid;
-		}
-
-		bdev->disk.ctxt = bdev;
-		bdev->disk.fn_table = &nvmelib_fn_table;
-		bdev->disk.module = &nvme_if;
-		rc = spdk_bdev_register(&bdev->disk);
-		if (rc) {
-			free(bdev->disk.name);
-			free(bdev);
-			break;
-		}
-
-		TAILQ_INSERT_TAIL(&g_nvme_bdevs, bdev, link);
-
-		bdev_created++;
 	}
 
 	return (bdev_created > 0) ? 0 : -1;
@@ -1337,8 +1462,10 @@ bdev_nvme_admin_passthru(struct nvme_bdev *nbdev, struct spdk_io_channel *ch,
 			 struct nvme_bdev_io *bio,
 			 struct spdk_nvme_cmd *cmd, void *buf, size_t nbytes)
 {
-	if (nbytes > UINT32_MAX) {
-		SPDK_ERRLOG("nbytes is greater than UINT32_MAX.\n");
+	uint32_t max_xfer_size = spdk_nvme_ctrlr_get_max_xfer_size(nbdev->nvme_ctrlr->ctrlr);
+
+	if (nbytes > max_xfer_size) {
+		SPDK_ERRLOG("nbytes is greater than MDTS %" PRIu32 ".\n", max_xfer_size);
 		return -EINVAL;
 	}
 
@@ -1354,9 +1481,10 @@ bdev_nvme_io_passthru(struct nvme_bdev *nbdev, struct spdk_io_channel *ch,
 		      struct spdk_nvme_cmd *cmd, void *buf, size_t nbytes)
 {
 	struct nvme_io_channel *nvme_ch = spdk_io_channel_get_ctx(ch);
+	uint32_t max_xfer_size = spdk_nvme_ctrlr_get_max_xfer_size(nbdev->nvme_ctrlr->ctrlr);
 
-	if (nbytes > UINT32_MAX) {
-		SPDK_ERRLOG("nbytes is greater than UINT32_MAX.\n");
+	if (nbytes > max_xfer_size) {
+		SPDK_ERRLOG("nbytes is greater than MDTS %" PRIu32 ".\n", max_xfer_size);
 		return -EINVAL;
 	}
 
@@ -1377,9 +1505,10 @@ bdev_nvme_io_passthru_md(struct nvme_bdev *nbdev, struct spdk_io_channel *ch,
 {
 	struct nvme_io_channel *nvme_ch = spdk_io_channel_get_ctx(ch);
 	size_t nr_sectors = nbytes / spdk_nvme_ns_get_sector_size(nbdev->ns);
+	uint32_t max_xfer_size = spdk_nvme_ctrlr_get_max_xfer_size(nbdev->nvme_ctrlr->ctrlr);
 
-	if (nbytes > UINT32_MAX) {
-		SPDK_ERRLOG("nbytes is greater than UINT32_MAX.\n");
+	if (nbytes > max_xfer_size) {
+		SPDK_ERRLOG("nbytes is greater than MDTS %" PRIu32 ".\n", max_xfer_size);
 		return -EINVAL;
 	}
 
@@ -1450,8 +1579,8 @@ bdev_nvme_get_spdk_running_config(FILE *fp)
 		"# this key to get the default behavior.\n");
 	fprintf(fp, "RetryCount %d\n", spdk_nvme_retry_count);
 	fprintf(fp, "\n"
-		"# Timeout for each command, in seconds. If 0, don't track timeouts.\n");
-	fprintf(fp, "Timeout %d\n", g_timeout);
+		"# Timeout for each command, in microseconds. If 0, don't track timeouts.\n");
+	fprintf(fp, "Timeout %"PRIu64"\n", g_timeout_us);
 
 	fprintf(fp, "\n"
 		"# Action to take on command time out. Only valid when Timeout is greater\n"
@@ -1483,6 +1612,9 @@ bdev_nvme_get_spdk_running_config(FILE *fp)
 		"# Set how often the hotplug is processed for insert and remove events."
 		"# Units in microseconds.\n");
 	fprintf(fp, "HotplugPollRate %d\n", g_nvme_hotplug_poll_timeout_us);
+	if (g_nvme_hostnqn) {
+		fprintf(fp, "HostNQN %s\n",  g_nvme_hostnqn);
+	}
 
 	fprintf(fp, "\n");
 }
diff --git a/lib/bdev/nvme/bdev_nvme.h b/lib/bdev/nvme/bdev_nvme.h
index edf77bacc..3660fafba 100644
--- a/lib/bdev/nvme/bdev_nvme.h
+++ b/lib/bdev/nvme/bdev_nvme.h
@@ -36,15 +36,44 @@
 
 #include "spdk/stdinc.h"
 
+#include "spdk/queue.h"
 #include "spdk/nvme.h"
+#include "spdk/bdev_module.h"
 
 #define NVME_MAX_CONTROLLERS 1024
 
-struct spdk_bdev;
+struct nvme_ctrlr {
+	/**
+	 * points to pinned, physically contiguous memory region;
+	 * contains 4KB IDENTIFY structure for controller which is
+	 *  target for CONTROLLER IDENTIFY command during initialization
+	 */
+	struct spdk_nvme_ctrlr		*ctrlr;
+	struct spdk_nvme_transport_id	trid;
+	char				*name;
+	int				ref;
+	uint32_t			num_ns;
+	/** Array of bdevs indexed by nsid - 1 */
+	struct nvme_bdev		*bdevs;
+
+	struct spdk_poller		*adminq_timer_poller;
+
+	/** linked list pointer for device list */
+	TAILQ_ENTRY(nvme_ctrlr)	tailq;
+};
+
+struct nvme_bdev {
+	struct spdk_bdev	disk;
+	struct nvme_ctrlr	*nvme_ctrlr;
+	uint32_t		id;
+	bool			active;
+	struct spdk_nvme_ns	*ns;
+};
 
 int spdk_bdev_nvme_create(struct spdk_nvme_transport_id *trid,
 			  const char *base_name,
-			  const char **names, size_t *count);
+			  const char **names, size_t *count,
+			  const char *hostnqn);
 struct spdk_nvme_ctrlr *spdk_bdev_nvme_get_ctrlr(struct spdk_bdev *bdev);
 
 #endif // SPDK_BDEV_NVME_H
diff --git a/lib/bdev/nvme/bdev_nvme_rpc.c b/lib/bdev/nvme/bdev_nvme_rpc.c
index 069cd7d8d..1ff41d075 100644
--- a/lib/bdev/nvme/bdev_nvme_rpc.c
+++ b/lib/bdev/nvme/bdev_nvme_rpc.c
@@ -40,7 +40,7 @@
 #include "spdk/util.h"
 
 #include "spdk_internal/log.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 struct open_descriptors {
 	void *desc;
@@ -56,6 +56,7 @@ struct rpc_construct_nvme {
 	char *traddr;
 	char *trsvcid;
 	char *subnqn;
+	char *hostnqn;
 };
 
 static void
@@ -67,6 +68,7 @@ free_rpc_construct_nvme(struct rpc_construct_nvme *req)
 	free(req->traddr);
 	free(req->trsvcid);
 	free(req->subnqn);
+	free(req->hostnqn);
 }
 
 static const struct spdk_json_object_decoder rpc_construct_nvme_decoders[] = {
@@ -77,9 +79,10 @@ static const struct spdk_json_object_decoder rpc_construct_nvme_decoders[] = {
 	{"adrfam", offsetof(struct rpc_construct_nvme, adrfam), spdk_json_decode_string, true},
 	{"trsvcid", offsetof(struct rpc_construct_nvme, trsvcid), spdk_json_decode_string, true},
 	{"subnqn", offsetof(struct rpc_construct_nvme, subnqn), spdk_json_decode_string, true},
+	{"hostnqn", offsetof(struct rpc_construct_nvme, hostnqn), spdk_json_decode_string, true}
 };
 
-#define NVME_MAX_BDEVS_PER_RPC 32
+#define NVME_MAX_BDEVS_PER_RPC 128
 
 static void
 spdk_rpc_construct_nvme_bdev(struct spdk_jsonrpc_request *request,
@@ -130,7 +133,7 @@ spdk_rpc_construct_nvme_bdev(struct spdk_jsonrpc_request *request,
 	}
 
 	count = NVME_MAX_BDEVS_PER_RPC;
-	if (spdk_bdev_nvme_create(&trid, req.name, names, &count)) {
+	if (spdk_bdev_nvme_create(&trid, req.name, names, &count, req.hostnqn)) {
 		goto invalid;
 	}
 
@@ -155,7 +158,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_construct_nvme(&req);
 }
-SPDK_RPC_REGISTER("construct_nvme_bdev", spdk_rpc_construct_nvme_bdev)
+SPDK_RPC_REGISTER("construct_nvme_bdev", spdk_rpc_construct_nvme_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_apply_firmware {
 	char *filename;
@@ -490,4 +493,4 @@ spdk_rpc_apply_nvme_firmware(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("apply_nvme_firmware", spdk_rpc_apply_nvme_firmware)
+SPDK_RPC_REGISTER("apply_nvme_firmware", spdk_rpc_apply_nvme_firmware, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/part.c b/lib/bdev/part.c
index e1c54266b..cd47faa37 100644
--- a/lib/bdev/part.c
+++ b/lib/bdev/part.c
@@ -38,7 +38,46 @@
 #include "spdk/bdev.h"
 #include "spdk/log.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
+
+struct spdk_bdev_part_base {
+	struct spdk_bdev		*bdev;
+	struct spdk_bdev_desc		*desc;
+	uint32_t			ref;
+	uint32_t			channel_size;
+	spdk_bdev_part_base_free_fn	base_free_fn;
+	void				*ctx;
+	bool				claimed;
+	struct spdk_bdev_module		*module;
+	struct spdk_bdev_fn_table	*fn_table;
+	struct bdev_part_tailq		*tailq;
+	spdk_io_channel_create_cb	ch_create_cb;
+	spdk_io_channel_destroy_cb	ch_destroy_cb;
+};
+
+struct spdk_bdev *
+spdk_bdev_part_base_get_bdev(struct spdk_bdev_part_base *part_base)
+{
+	return part_base->bdev;
+}
+
+struct spdk_bdev_desc *
+spdk_bdev_part_base_get_desc(struct spdk_bdev_part_base *part_base)
+{
+	return part_base->desc;
+}
+
+struct bdev_part_tailq *
+spdk_bdev_part_base_get_tailq(struct spdk_bdev_part_base *part_base)
+{
+	return part_base->tailq;
+}
+
+void *
+spdk_bdev_part_base_get_ctx(struct spdk_bdev_part_base *part_base)
+{
+	return part_base->ctx;
+}
 
 void
 spdk_bdev_part_base_free(struct spdk_bdev_part_base *base)
@@ -47,7 +86,12 @@ spdk_bdev_part_base_free(struct spdk_bdev_part_base *base)
 		spdk_bdev_close(base->desc);
 		base->desc = NULL;
 	}
-	base->base_free_fn(base);
+
+	if (base->base_free_fn != NULL) {
+		base->base_free_fn(base->ctx);
+	}
+
+	free(base);
 }
 
 static void
@@ -57,9 +101,9 @@ spdk_bdev_part_free_cb(void *io_device)
 	struct spdk_bdev_part_base *base;
 
 	assert(part);
-	assert(part->base);
+	assert(part->internal.base);
 
-	base = part->base;
+	base = part->internal.base;
 
 	TAILQ_REMOVE(base->tailq, part, tailq);
 
@@ -68,8 +112,8 @@ spdk_bdev_part_free_cb(void *io_device)
 		spdk_bdev_part_base_free(base);
 	}
 
-	spdk_bdev_destruct_done(&part->bdev, 0);
-	free(part->bdev.name);
+	spdk_bdev_destruct_done(&part->internal.bdev, 0);
+	free(part->internal.bdev.name);
 	free(part);
 }
 
@@ -89,8 +133,8 @@ spdk_bdev_part_base_hotremove(struct spdk_bdev *base_bdev, struct bdev_part_tail
 	struct spdk_bdev_part *part, *tmp;
 
 	TAILQ_FOREACH_SAFE(part, tailq, tailq, tmp) {
-		if (part->base->bdev == base_bdev) {
-			spdk_bdev_unregister(&part->bdev, NULL, NULL);
+		if (part->internal.base->bdev == base_bdev) {
+			spdk_bdev_unregister(&part->internal.bdev, NULL, NULL);
 		}
 	}
 }
@@ -100,7 +144,7 @@ spdk_bdev_part_io_type_supported(void *_part, enum spdk_bdev_io_type io_type)
 {
 	struct spdk_bdev_part *part = _part;
 
-	return part->base->bdev->fn_table->io_type_supported(part->base->bdev, io_type);
+	return part->internal.base->bdev->fn_table->io_type_supported(part->internal.base->bdev, io_type);
 }
 
 static struct spdk_io_channel *
@@ -111,6 +155,30 @@ spdk_bdev_part_get_io_channel(void *_part)
 	return spdk_get_io_channel(part);
 }
 
+struct spdk_bdev *
+spdk_bdev_part_get_bdev(struct spdk_bdev_part *part)
+{
+	return &part->internal.bdev;
+}
+
+struct spdk_bdev_part_base *
+spdk_bdev_part_get_base(struct spdk_bdev_part *part)
+{
+	return part->internal.base;
+}
+
+struct spdk_bdev *
+spdk_bdev_part_get_base_bdev(struct spdk_bdev_part *part)
+{
+	return part->internal.base->bdev;
+}
+
+uint64_t
+spdk_bdev_part_get_offset_blocks(struct spdk_bdev_part *part)
+{
+	return part->internal.offset_blocks;
+}
+
 static void
 spdk_bdev_part_complete_io(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
 {
@@ -126,38 +194,38 @@ spdk_bdev_part_submit_request(struct spdk_bdev_part_channel *ch, struct spdk_bde
 {
 	struct spdk_bdev_part *part = ch->part;
 	struct spdk_io_channel *base_ch = ch->base_ch;
-	struct spdk_bdev_desc *base_desc = part->base->desc;
+	struct spdk_bdev_desc *base_desc = part->internal.base->desc;
 	uint64_t offset;
 	int rc = 0;
 
 	/* Modify the I/O to adjust for the offset within the base bdev. */
 	switch (bdev_io->type) {
 	case SPDK_BDEV_IO_TYPE_READ:
-		offset = bdev_io->u.bdev.offset_blocks + part->offset_blocks;
+		offset = bdev_io->u.bdev.offset_blocks + part->internal.offset_blocks;
 		rc = spdk_bdev_readv_blocks(base_desc, base_ch, bdev_io->u.bdev.iovs,
 					    bdev_io->u.bdev.iovcnt, offset,
 					    bdev_io->u.bdev.num_blocks, spdk_bdev_part_complete_io,
 					    bdev_io);
 		break;
 	case SPDK_BDEV_IO_TYPE_WRITE:
-		offset = bdev_io->u.bdev.offset_blocks + part->offset_blocks;
+		offset = bdev_io->u.bdev.offset_blocks + part->internal.offset_blocks;
 		rc = spdk_bdev_writev_blocks(base_desc, base_ch, bdev_io->u.bdev.iovs,
 					     bdev_io->u.bdev.iovcnt, offset,
 					     bdev_io->u.bdev.num_blocks, spdk_bdev_part_complete_io,
 					     bdev_io);
 		break;
 	case SPDK_BDEV_IO_TYPE_WRITE_ZEROES:
-		offset = bdev_io->u.bdev.offset_blocks + part->offset_blocks;
+		offset = bdev_io->u.bdev.offset_blocks + part->internal.offset_blocks;
 		rc = spdk_bdev_write_zeroes_blocks(base_desc, base_ch, offset, bdev_io->u.bdev.num_blocks,
 						   spdk_bdev_part_complete_io, bdev_io);
 		break;
 	case SPDK_BDEV_IO_TYPE_UNMAP:
-		offset = bdev_io->u.bdev.offset_blocks + part->offset_blocks;
+		offset = bdev_io->u.bdev.offset_blocks + part->internal.offset_blocks;
 		rc = spdk_bdev_unmap_blocks(base_desc, base_ch, offset, bdev_io->u.bdev.num_blocks,
 					    spdk_bdev_part_complete_io, bdev_io);
 		break;
 	case SPDK_BDEV_IO_TYPE_FLUSH:
-		offset = bdev_io->u.bdev.offset_blocks + part->offset_blocks;
+		offset = bdev_io->u.bdev.offset_blocks + part->internal.offset_blocks;
 		rc = spdk_bdev_flush_blocks(base_desc, base_ch, offset, bdev_io->u.bdev.num_blocks,
 					    spdk_bdev_part_complete_io, bdev_io);
 		break;
@@ -182,13 +250,13 @@ spdk_bdev_part_channel_create_cb(void *io_device, void *ctx_buf)
 	struct spdk_bdev_part_channel *ch = ctx_buf;
 
 	ch->part = part;
-	ch->base_ch = spdk_bdev_get_io_channel(part->base->desc);
+	ch->base_ch = spdk_bdev_get_io_channel(part->internal.base->desc);
 	if (ch->base_ch == NULL) {
 		return -1;
 	}
 
-	if (part->base->ch_create_cb) {
-		return part->base->ch_create_cb(io_device, ctx_buf);
+	if (part->internal.base->ch_create_cb) {
+		return part->internal.base->ch_create_cb(io_device, ctx_buf);
 	} else {
 		return 0;
 	}
@@ -200,22 +268,28 @@ spdk_bdev_part_channel_destroy_cb(void *io_device, void *ctx_buf)
 	struct spdk_bdev_part *part = (struct spdk_bdev_part *)io_device;
 	struct spdk_bdev_part_channel *ch = ctx_buf;
 
-	if (part->base->ch_destroy_cb) {
-		part->base->ch_destroy_cb(io_device, ctx_buf);
+	if (part->internal.base->ch_destroy_cb) {
+		part->internal.base->ch_destroy_cb(io_device, ctx_buf);
 	}
 	spdk_put_io_channel(ch->base_ch);
 }
 
-int
-spdk_bdev_part_base_construct(struct spdk_bdev_part_base *base, struct spdk_bdev *bdev,
+struct spdk_bdev_part_base *
+	spdk_bdev_part_base_construct(struct spdk_bdev *bdev,
 			      spdk_bdev_remove_cb_t remove_cb, struct spdk_bdev_module *module,
 			      struct spdk_bdev_fn_table *fn_table, struct bdev_part_tailq *tailq,
-			      spdk_bdev_part_base_free_fn free_fn,
+			      spdk_bdev_part_base_free_fn free_fn, void *ctx,
 			      uint32_t channel_size, spdk_io_channel_create_cb ch_create_cb,
 			      spdk_io_channel_destroy_cb ch_destroy_cb)
 {
 	int rc;
+	struct spdk_bdev_part_base *base;
 
+	base = calloc(1, sizeof(*base));
+	if (!base) {
+		SPDK_ERRLOG("Memory allocation failure\n");
+		return NULL;
+	}
 	fn_table->get_io_channel = spdk_bdev_part_get_io_channel;
 	fn_table->io_type_supported = spdk_bdev_part_io_type_supported;
 
@@ -225,20 +299,21 @@ spdk_bdev_part_base_construct(struct spdk_bdev_part_base *base, struct spdk_bdev
 	base->module = module;
 	base->fn_table = fn_table;
 	base->tailq = tailq;
+	base->base_free_fn = free_fn;
+	base->ctx = ctx;
 	base->claimed = false;
 	base->channel_size = channel_size;
 	base->ch_create_cb = ch_create_cb;
 	base->ch_destroy_cb = ch_destroy_cb;
-	base->base_free_fn = free_fn;
 
 	rc = spdk_bdev_open(bdev, false, remove_cb, bdev, &base->desc);
 	if (rc) {
 		spdk_bdev_part_base_free(base);
 		SPDK_ERRLOG("could not open bdev %s\n", spdk_bdev_get_name(bdev));
-		return -1;
+		return NULL;
 	}
 
-	return 0;
+	return base;
 }
 
 int
@@ -246,20 +321,20 @@ spdk_bdev_part_construct(struct spdk_bdev_part *part, struct spdk_bdev_part_base
 			 char *name, uint64_t offset_blocks, uint64_t num_blocks,
 			 char *product_name)
 {
-	part->bdev.name = name;
-	part->bdev.blocklen = base->bdev->blocklen;
-	part->bdev.blockcnt = num_blocks;
-	part->offset_blocks = offset_blocks;
-
-	part->bdev.write_cache = base->bdev->write_cache;
-	part->bdev.need_aligned_buffer = base->bdev->need_aligned_buffer;
-	part->bdev.product_name = product_name;
-	part->bdev.ctxt = part;
-	part->bdev.module = base->module;
-	part->bdev.fn_table = base->fn_table;
+	part->internal.bdev.name = name;
+	part->internal.bdev.blocklen = base->bdev->blocklen;
+	part->internal.bdev.blockcnt = num_blocks;
+	part->internal.offset_blocks = offset_blocks;
+
+	part->internal.bdev.write_cache = base->bdev->write_cache;
+	part->internal.bdev.need_aligned_buffer = base->bdev->need_aligned_buffer;
+	part->internal.bdev.product_name = product_name;
+	part->internal.bdev.ctxt = part;
+	part->internal.bdev.module = base->module;
+	part->internal.bdev.fn_table = base->fn_table;
 
 	__sync_fetch_and_add(&base->ref, 1);
-	part->base = base;
+	part->internal.base = base;
 
 	if (!base->claimed) {
 		int rc;
@@ -267,7 +342,7 @@ spdk_bdev_part_construct(struct spdk_bdev_part *part, struct spdk_bdev_part_base
 		rc = spdk_bdev_module_claim_bdev(base->bdev, base->desc, base->module);
 		if (rc) {
 			SPDK_ERRLOG("could not claim bdev %s\n", spdk_bdev_get_name(base->bdev));
-			free(part->bdev.name);
+			free(part->internal.bdev.name);
 			return -1;
 		}
 		base->claimed = true;
@@ -276,7 +351,7 @@ spdk_bdev_part_construct(struct spdk_bdev_part *part, struct spdk_bdev_part_base
 	spdk_io_device_register(part, spdk_bdev_part_channel_create_cb,
 				spdk_bdev_part_channel_destroy_cb,
 				base->channel_size);
-	spdk_vbdev_register(&part->bdev, &base->bdev, 1);
+	spdk_vbdev_register(&part->internal.bdev, &base->bdev, 1);
 	TAILQ_INSERT_TAIL(base->tailq, part, tailq);
 
 	return 0;
diff --git a/lib/bdev/passthru/vbdev_passthru.c b/lib/bdev/passthru/vbdev_passthru.c
old mode 100755
new mode 100644
index 1c524776a..daea2955d
--- a/lib/bdev/passthru/vbdev_passthru.c
+++ b/lib/bdev/passthru/vbdev_passthru.c
@@ -44,10 +44,10 @@
 #include "spdk/conf.h"
 #include "spdk/endian.h"
 #include "spdk/string.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 
@@ -62,7 +62,7 @@ static struct spdk_bdev_module passthru_if = {
 	.module_init = vbdev_passthru_init,
 	.config_text = vbdev_passthru_get_spdk_running_config,
 	.get_ctx_size = vbdev_passthru_get_ctx_size,
-	.examine = vbdev_passthru_examine,
+	.examine_config = vbdev_passthru_examine,
 	.module_fini = vbdev_passthru_finish
 };
 
@@ -410,8 +410,7 @@ vbdev_passthru_get_spdk_running_config(FILE *fp)
 
 	fprintf(fp, "\n[Passthru]\n");
 	TAILQ_FOREACH(names, &g_bdev_names, link) {
-		fprintf(fp, "  PT %s %s ", names->bdev_name, names->vbdev_name);
-		fprintf(fp, "\n");
+		fprintf(fp, "  PT %s %s\n", names->bdev_name, names->vbdev_name);
 	}
 	fprintf(fp, "\n");
 }
@@ -446,7 +445,7 @@ static const struct spdk_bdev_fn_table vbdev_passthru_fn_table = {
 
 /* Called when the underlying base bdev goes away. */
 static void
-vbdev_passthru_examine_hotremove_cb(void *ctx)
+vbdev_passthru_base_bdev_hotremove_cb(void *ctx)
 {
 	struct vbdev_passthru *pt_node, *tmp;
 	struct spdk_bdev *bdev_find = ctx;
@@ -512,7 +511,7 @@ vbdev_passthru_register(struct spdk_bdev *bdev)
 					sizeof(struct pt_io_channel));
 		SPDK_NOTICELOG("io_device created at: 0x%p\n", pt_node);
 
-		rc = spdk_bdev_open(bdev, true, vbdev_passthru_examine_hotremove_cb,
+		rc = spdk_bdev_open(bdev, true, vbdev_passthru_base_bdev_hotremove_cb,
 				    bdev, &pt_node->base_desc);
 		if (rc) {
 			SPDK_ERRLOG("could not open bdev %s\n", spdk_bdev_get_name(bdev));
@@ -570,6 +569,17 @@ create_passthru_disk(const char *bdev_name, const char *vbdev_name)
 	return 0;
 }
 
+void
+delete_passthru_disk(struct spdk_bdev *bdev, spdk_delete_passthru_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &passthru_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 /* Because we specified this function in our pt bdev function table when we
  * registered our pt bdev, we'll get this call anytime a new bdev shows up.
  * Here we need to decide if we care about it and if so what to do. We
diff --git a/lib/bdev/passthru/vbdev_passthru.h b/lib/bdev/passthru/vbdev_passthru.h
index ab45f00d2..5705c4ed3 100644
--- a/lib/bdev/passthru/vbdev_passthru.h
+++ b/lib/bdev/passthru/vbdev_passthru.h
@@ -38,6 +38,25 @@
 
 #include "spdk/bdev.h"
 
+typedef void (*spdk_delete_passthru_complete)(void *cb_arg, int bdeverrno);
+
+/**
+ * Create new pass through bdev.
+ *
+ * \param bdev_name Bdev on which pass through vbdev will be created.
+ * \param vbdev_name Vbdev name.
+ * \return 0 on success, other on failure.
+ */
 int create_passthru_disk(const char *bdev_name, const char *vbdev_name);
 
+/**
+ * Delete passthru bdev.
+ *
+ * \param bdev Pointer to pass through bdev.
+ * \param cb_fn Function to call after deletion.
+ * \param cb_arg Argument to pass to cb_fn.
+ */
+void delete_passthru_disk(struct spdk_bdev *bdev, spdk_delete_passthru_complete cb_fn,
+			  void *cb_arg);
+
 #endif /* SPDK_VBDEV_PASSTHRU_H */
diff --git a/lib/bdev/passthru/vbdev_passthru_rpc.c b/lib/bdev/passthru/vbdev_passthru_rpc.c
index 44e3ba37c..9f0f95218 100644
--- a/lib/bdev/passthru/vbdev_passthru_rpc.c
+++ b/lib/bdev/passthru/vbdev_passthru_rpc.c
@@ -34,7 +34,7 @@
 #include "vbdev_passthru.h"
 #include "spdk/rpc.h"
 #include "spdk/util.h"
-
+#include "spdk/string.h"
 #include "spdk_internal/log.h"
 
 /* Structure to hold the parameters for this RPC method. */
@@ -86,9 +86,7 @@ spdk_rpc_construct_passthru_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, req.passthru_bdev_name);
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	free_rpc_construct_passthru(&req);
 	return;
@@ -97,4 +95,66 @@ invalid:
 	free_rpc_construct_passthru(&req);
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 }
-SPDK_RPC_REGISTER("construct_passthru_bdev", spdk_rpc_construct_passthru_bdev)
+SPDK_RPC_REGISTER("construct_passthru_bdev", spdk_rpc_construct_passthru_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_passthru {
+	char *name;
+};
+
+static void
+free_rpc_delete_passthru(struct rpc_delete_passthru *req)
+{
+	free(req->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_passthru_decoders[] = {
+	{"name", offsetof(struct rpc_delete_passthru, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_passthru_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_passthru_bdev(struct spdk_jsonrpc_request *request,
+			      const struct spdk_json_val *params)
+{
+	struct rpc_delete_passthru req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_passthru_decoders,
+				    SPDK_COUNTOF(rpc_delete_passthru_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	delete_passthru_disk(bdev, _spdk_rpc_delete_passthru_bdev_cb, request);
+
+	free_rpc_delete_passthru(&req);
+
+	return;
+
+invalid:
+	free_rpc_delete_passthru(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_passthru_bdev", spdk_rpc_delete_passthru_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/pmem/bdev_pmem.c b/lib/bdev/pmem/bdev_pmem.c
index 54b283a6d..2b6b4e5cd 100644
--- a/lib/bdev/pmem/bdev_pmem.c
+++ b/lib/bdev/pmem/bdev_pmem.c
@@ -36,7 +36,7 @@
 #include "spdk/likely.h"
 #include "spdk/util.h"
 #include "spdk/rpc.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 #include "bdev_pmem.h"
@@ -385,6 +385,17 @@ spdk_create_pmem_disk(const char *pmem_file, const char *name, struct spdk_bdev
 	return 0;
 }
 
+void
+spdk_delete_pmem_disk(struct spdk_bdev *bdev, spdk_delete_pmem_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &pmem_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 static void
 bdev_pmem_read_conf(void)
 {
diff --git a/lib/bdev/pmem/bdev_pmem.h b/lib/bdev/pmem/bdev_pmem.h
index 9011dacaf..abdfd5aa3 100644
--- a/lib/bdev/pmem/bdev_pmem.h
+++ b/lib/bdev/pmem/bdev_pmem.h
@@ -36,6 +36,29 @@
 
 #include "spdk/bdev.h"
 
+typedef void (*spdk_delete_pmem_complete)(void *cb_arg, int bdeverrno);
+
+/**
+ * Create new pmem bdev.
+ *
+ * \param pmem_file Pointer to pmem pool file.
+ * \param name Bdev name.
+ * \param bdev output parameter for bdev when operation is successful.
+ * \return 0 on success.
+ *         -EIO if pool check failed
+ *         -EINVAL if input paramteres check failed
+ *         -ENOMEM if buffer cannot be allocated
+ */
 int spdk_create_pmem_disk(const char *pmem_file, const char *name, struct spdk_bdev **bdev);
 
+/**
+ * Delete pmem bdev.
+ *
+ * \param bdev Pointer to pmem bdev.
+ * \param cb_fn Function to call after deletion.
+ * \param cb_arg Argument to pass to cb_fn.
+ */
+void spdk_delete_pmem_disk(struct spdk_bdev *bdev, spdk_delete_pmem_complete cb_fn,
+			   void *cb_arg);
+
 #endif /* SPDK_BDEV_PMEM_H */
diff --git a/lib/bdev/pmem/bdev_pmem_rpc.c b/lib/bdev/pmem/bdev_pmem_rpc.c
index 8616ca9eb..3156cffbe 100644
--- a/lib/bdev/pmem/bdev_pmem_rpc.c
+++ b/lib/bdev/pmem/bdev_pmem_rpc.c
@@ -86,9 +86,7 @@ spdk_rpc_construct_pmem_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 
 	free_rpc_construct_pmem_bdev(&req);
@@ -99,7 +97,67 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(rc));
 	free_rpc_construct_pmem_bdev(&req);
 }
-SPDK_RPC_REGISTER("construct_pmem_bdev", spdk_rpc_construct_pmem_bdev)
+SPDK_RPC_REGISTER("construct_pmem_bdev", spdk_rpc_construct_pmem_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_pmem {
+	char *name;
+};
+
+static void
+free_rpc_delete_pmem(struct rpc_delete_pmem *req)
+{
+	free(req->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_pmem_decoders[] = {
+	{"name", offsetof(struct rpc_delete_pmem, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_pmem_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_pmem_bdev(struct spdk_jsonrpc_request *request,
+			  const struct spdk_json_val *params)
+{
+	struct rpc_delete_pmem req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_pmem_decoders,
+				    SPDK_COUNTOF(rpc_delete_pmem_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	spdk_delete_pmem_disk(bdev, _spdk_rpc_delete_pmem_bdev_cb, request);
+	free_rpc_delete_pmem(&req);
+	return;
+
+invalid:
+	free_rpc_delete_pmem(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_pmem_bdev", spdk_rpc_delete_pmem_bdev, SPDK_RPC_RUNTIME)
 
 struct rpc_create_pmem_pool {
 	char *pmem_file;
@@ -167,7 +225,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_create_pmem_pool(&req);
 }
-SPDK_RPC_REGISTER("create_pmem_pool", spdk_rpc_create_pmem_pool)
+SPDK_RPC_REGISTER("create_pmem_pool", spdk_rpc_create_pmem_pool, SPDK_RPC_RUNTIME)
 
 struct rpc_pmem_pool_info {
 	char *pmem_file;
@@ -237,7 +295,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_pmem_pool_info(&req);
 }
-SPDK_RPC_REGISTER("pmem_pool_info", spdk_rpc_pmem_pool_info)
+SPDK_RPC_REGISTER("pmem_pool_info", spdk_rpc_pmem_pool_info, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_pmem_pool {
 	char *pmem_file;
@@ -289,4 +347,4 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_delete_pmem_pool(&req);
 }
-SPDK_RPC_REGISTER("delete_pmem_pool", spdk_rpc_delete_pmem_pool)
+SPDK_RPC_REGISTER("delete_pmem_pool", spdk_rpc_delete_pmem_pool, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/raid/Makefile b/lib/bdev/raid/Makefile
new file mode 100644
index 000000000..8332399df
--- /dev/null
+++ b/lib/bdev/raid/Makefile
@@ -0,0 +1,41 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+
+CFLAGS += -I$(SPDK_ROOT_DIR)/lib/bdev/
+C_SRCS = bdev_raid.c bdev_raid_rpc.c
+LIBNAME = vbdev_raid
+
+include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/bdev/raid/bdev_raid.c b/lib/bdev/raid/bdev_raid.c
new file mode 100644
index 000000000..aeb762af9
--- /dev/null
+++ b/lib/bdev/raid/bdev_raid.c
@@ -0,0 +1,1321 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "bdev_raid.h"
+#include "spdk/env.h"
+#include "spdk/io_channel.h"
+#include "spdk/conf.h"
+#include "spdk_internal/log.h"
+#include "spdk/string.h"
+#include "spdk/util.h"
+#include "spdk/json.h"
+#include "spdk/string.h"
+
+/* raid bdev config as read from config file */
+struct raid_config          g_spdk_raid_config;
+
+/*
+ * List of raid bdev in configured list, these raid bdevs are registered with
+ * bdev layer
+ */
+struct spdk_raid_configured_tailq       g_spdk_raid_bdev_configured_list;
+
+/* List of raid bdev in configuring list */
+struct spdk_raid_configuring_tailq      g_spdk_raid_bdev_configuring_list;
+
+/* List of all raid bdevs */
+struct spdk_raid_all_tailq              g_spdk_raid_bdev_list;
+
+/* List of all raid bdevs that are offline */
+struct spdk_raid_offline_tailq          g_spdk_raid_bdev_offline_list;
+
+/* Function declarations */
+static void   raid_bdev_examine(struct spdk_bdev *bdev);
+static int    raid_bdev_init(void);
+static void   raid_bdev_waitq_io_process(void *ctx);
+
+
+/*
+ * brief:
+ * raid_bdev_create_cb function is a cb function for raid bdev which creates the
+ * hierarchy from raid bdev to base bdev io channels. It will be called per core
+ * params:
+ * io_device - pointer to raid bdev io device represented by raid_bdev
+ * ctx_buf - pointer to context buffer for raid bdev io channel
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_create_cb(void *io_device, void *ctx_buf)
+{
+	struct raid_bdev            *raid_bdev = io_device;
+	struct raid_bdev_io_channel *ch = ctx_buf;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_create_cb, %p\n", ch);
+
+	assert(raid_bdev != NULL);
+	assert(raid_bdev->state == RAID_BDEV_STATE_ONLINE);
+
+	/*
+	 * Store raid_bdev_ctxt in each channel which is used to get the read only
+	 * raid bdev specific information during io split logic like base bdev
+	 * descriptors, strip size etc
+	 */
+	ch->raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+
+	ch->base_bdevs_io_channel = calloc(ch->raid_bdev_ctxt->raid_bdev.num_base_bdevs,
+					   sizeof(struct spdk_io_channel *));
+	if (!ch->base_bdevs_io_channel) {
+		SPDK_ERRLOG("Unable to allocate base bdevs io channel\n");
+		return -1;
+	}
+	for (uint32_t iter = 0; iter < ch->raid_bdev_ctxt->raid_bdev.num_base_bdevs; iter++) {
+		/*
+		 * Get the spdk_io_channel for all the base bdevs. This is used during
+		 * split logic to send the respective child bdev ios to respective base
+		 * bdev io channel.
+		 */
+		ch->base_bdevs_io_channel[iter] = spdk_bdev_get_io_channel(
+				raid_bdev->base_bdev_info[iter].base_bdev_desc);
+		if (!ch->base_bdevs_io_channel[iter]) {
+			for (uint32_t iter1 = 0; iter1 < iter ; iter1++) {
+				spdk_put_io_channel(ch->base_bdevs_io_channel[iter1]);
+			}
+			free(ch->base_bdevs_io_channel);
+			SPDK_ERRLOG("Unable to create io channel for base bdev\n");
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_destroy_cb function is a cb function for raid bdev which deletes the
+ * hierarchy from raid bdev to base bdev io channels. It will be called per core
+ * params:
+ * io_device - pointer to raid bdev io device represented by raid_bdev
+ * ctx_buf - pointer to context buffer for raid bdev io channel
+ * returns:
+ * none
+ */
+static void
+raid_bdev_destroy_cb(void *io_device, void *ctx_buf)
+{
+	struct raid_bdev_io_channel *ch = ctx_buf;
+	struct raid_bdev            *raid_bdev = io_device;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_destroy_cb\n");
+
+	assert(raid_bdev != NULL);
+	assert(ch != NULL);
+	assert(ch->base_bdevs_io_channel);
+	for (uint32_t iter = 0; iter < raid_bdev->num_base_bdevs; iter++) {
+		/* Free base bdev channels */
+		assert(ch->base_bdevs_io_channel[iter] != NULL);
+		spdk_put_io_channel(ch->base_bdevs_io_channel[iter]);
+		ch->base_bdevs_io_channel[iter] = NULL;
+	}
+	ch->raid_bdev_ctxt = NULL;
+	free(ch->base_bdevs_io_channel);
+	ch->base_bdevs_io_channel = NULL;
+}
+
+/*
+ * brief:
+ * raid_bdev_cleanup is used to cleanup and free raid_bdev related data
+ * structures.
+ * params:
+ * raid_bdev_ctxt - pointer to raid_bdev_ctxt
+ * returns:
+ * none
+ */
+static void
+raid_bdev_cleanup(struct raid_bdev_ctxt *raid_bdev_ctxt)
+{
+	struct raid_bdev *raid_bdev = &raid_bdev_ctxt->raid_bdev;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_cleanup, %p name %s, state %u, raid_bdev_config %p\n",
+		      raid_bdev_ctxt,
+		      raid_bdev_ctxt->bdev.name, raid_bdev->state, raid_bdev->raid_bdev_config);
+	if (raid_bdev->state == RAID_BDEV_STATE_CONFIGURING) {
+		TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+	} else if (raid_bdev->state == RAID_BDEV_STATE_OFFLINE) {
+		TAILQ_REMOVE(&g_spdk_raid_bdev_offline_list, raid_bdev, link_specific_list);
+	} else {
+		assert(0);
+	}
+	TAILQ_REMOVE(&g_spdk_raid_bdev_list, raid_bdev, link_global_list);
+	assert(raid_bdev_ctxt->bdev.name);
+	free(raid_bdev_ctxt->bdev.name);
+	raid_bdev_ctxt->bdev.name = NULL;
+	assert(raid_bdev->base_bdev_info);
+	free(raid_bdev->base_bdev_info);
+	raid_bdev->base_bdev_info = NULL;
+	if (raid_bdev->raid_bdev_config) {
+		raid_bdev->raid_bdev_config->raid_bdev_ctxt = NULL;
+	}
+	free(raid_bdev_ctxt);
+}
+
+/*
+ * brief:
+ * raid_bdev_destruct is the destruct function table pointer for raid bdev
+ * params:
+ * ctxt - pointer to raid_bdev_ctxt
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_destruct(void *ctxt)
+{
+	struct raid_bdev_ctxt *raid_bdev_ctxt = ctxt;
+	struct raid_bdev      *raid_bdev = &raid_bdev_ctxt->raid_bdev;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_destruct\n");
+
+	raid_bdev->destruct_called = true;
+	for (uint16_t iter = 0; iter < raid_bdev->num_base_bdevs; iter++) {
+		/*
+		 * Close all base bdev descriptors for which call has come from below
+		 * layers
+		 */
+		if ((raid_bdev->base_bdev_info[iter].base_bdev_remove_scheduled == true) &&
+		    (raid_bdev->base_bdev_info[iter].base_bdev != NULL)) {
+			spdk_bdev_module_release_bdev(raid_bdev->base_bdev_info[iter].base_bdev);
+			spdk_bdev_close(raid_bdev->base_bdev_info[iter].base_bdev_desc);
+			raid_bdev->base_bdev_info[iter].base_bdev_desc = NULL;
+			raid_bdev->base_bdev_info[iter].base_bdev = NULL;
+			assert(raid_bdev->num_base_bdevs_discovered);
+			raid_bdev->num_base_bdevs_discovered--;
+		}
+	}
+
+	if (raid_bdev->num_base_bdevs_discovered == 0) {
+		/* Free raid_bdev when there no base bdevs left */
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid bdev base bdevs is 0, going to free all in destruct\n");
+		raid_bdev_cleanup(raid_bdev_ctxt);
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_io_completion function is called by lower layers to notify raid
+ * module that particular bdev_io is completed.
+ * params:
+ * bdev_io - pointer to bdev io submitted to lower layers, like child io
+ * success - bdev_io status
+ * cb_arg - function callback context, like parent io pointer
+ * returns:
+ * none
+ */
+static void
+raid_bdev_io_completion(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+{
+	struct spdk_bdev_io         *parent_io = cb_arg;
+	struct raid_bdev_io         *raid_bdev_io = (struct raid_bdev_io *)parent_io->driver_ctx;
+
+	assert(raid_bdev_io->splits_comp_outstanding);
+	raid_bdev_io->splits_comp_outstanding--;
+	if (raid_bdev_io->status == SPDK_BDEV_IO_STATUS_SUCCESS) {
+		/*
+		 * Store failure status if any of the child bdev io. If any of the child
+		 * fails, overall parent bdev_io is considered failed but parent bdev io
+		 * status is only communicated to above layers on all child completions
+		 */
+		raid_bdev_io->status = success;
+	}
+	/* Free child bdev io */
+	spdk_bdev_free_io(bdev_io);
+
+	if (!raid_bdev_io->splits_pending && !raid_bdev_io->splits_comp_outstanding) {
+		/*
+		 * If all childs are submitted and all childs are completed, process
+		 * parent bdev io completion and complete the parent bdev io with
+		 * appropriate status. If any of the child bdev io is failed, parent
+		 * bdev io is considered failed.
+		 */
+		if (raid_bdev_io->status) {
+			spdk_bdev_io_complete(parent_io, SPDK_BDEV_IO_STATUS_SUCCESS);
+		} else {
+			spdk_bdev_io_complete(parent_io, SPDK_BDEV_IO_STATUS_FAILED);
+		}
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_send_passthru function sends the bdev_io to the underlying
+ * base device by-passing the splitting logic. This is used for optimization
+ * when the total number of base devices in a raid bdev is only 1.
+ * params:
+ * ch - pointer to io channel for this io
+ * bdev_io - pointer to bdev_io
+ * returns:
+ * 0 - success
+ * non-zero - error
+ */
+static int
+raid_bdev_send_passthru(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io)
+{
+	struct   raid_bdev_io_channel *raid_bdev_io_channel;
+	struct   raid_bdev_io         *raid_bdev_io;
+	struct   raid_bdev            *raid_bdev;
+	int                           ret;
+
+	raid_bdev_io_channel = spdk_io_channel_get_ctx(ch);
+	raid_bdev = &raid_bdev_io_channel->raid_bdev_ctxt->raid_bdev;
+	raid_bdev_io = (struct raid_bdev_io *)bdev_io->driver_ctx;
+	raid_bdev_io->status = SPDK_BDEV_IO_STATUS_SUCCESS;
+
+	if (raid_bdev->base_bdev_info[0].base_bdev_desc == NULL) {
+		SPDK_ERRLOG("base bdev desc null for pd_idx %u\n", 0);
+		assert(0);
+	}
+	raid_bdev_io->splits_pending = 0;
+	raid_bdev_io->splits_comp_outstanding = 1;
+	if (bdev_io->type == SPDK_BDEV_IO_TYPE_READ) {
+		ret = spdk_bdev_read_blocks(raid_bdev->base_bdev_info[0].base_bdev_desc,
+					    raid_bdev_io_channel->base_bdevs_io_channel[0],
+					    bdev_io->u.bdev.iovs->iov_base,
+					    bdev_io->u.bdev.offset_blocks,
+					    bdev_io->u.bdev.num_blocks, raid_bdev_io_completion,
+					    bdev_io);
+	} else if (bdev_io->type == SPDK_BDEV_IO_TYPE_WRITE) {
+		ret = spdk_bdev_write_blocks(raid_bdev->base_bdev_info[0].base_bdev_desc,
+					     raid_bdev_io_channel->base_bdevs_io_channel[0],
+					     bdev_io->u.bdev.iovs->iov_base,
+					     bdev_io->u.bdev.offset_blocks,
+					     bdev_io->u.bdev.num_blocks, raid_bdev_io_completion,
+					     bdev_io);
+	} else {
+		ret = -EINVAL;
+	}
+	if (ret != 0) {
+		/*
+		 * If failed to submit child io to bdev layer then queue the parent
+		 * bdev io with current active split information in the wait queue
+		 * for that core. This will get resume from this point only. Assume
+		 * if 4 splits are required and 2 childs are submitted, then parent
+		 * io is queued to io waitq of this core and it will get resumed and
+		 * try to submit the remaining 3 and 4 childs
+		 */
+		raid_bdev_io->splits_pending = 1;
+		raid_bdev_io->splits_comp_outstanding = 0;
+		raid_bdev_io->ch = ch;
+		return ret;
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_submit_children function is used to split the parent io and submit
+ * the childs to bdev layer. bdev layer redirects the childs to appropriate base
+ * bdev nvme module
+ * params:
+ * ch - pointer to spdk_io_channel for the raid bdev
+ * bdev_io - parent bdev io
+ * start_strip - start strip number of this io
+ * end_strip - end strip number of this io
+ * cur_strip - current strip number of this io to start processing
+ * buf - pointer to buffer for this io
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_submit_children(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io,
+			  uint64_t start_strip, uint64_t end_strip, uint64_t cur_strip, uint8_t *buf)
+{
+	struct   raid_bdev_io_channel *raid_bdev_io_channel = spdk_io_channel_get_ctx(ch);
+	struct   raid_bdev_io         *raid_bdev_io = (struct raid_bdev_io *)bdev_io->driver_ctx;
+	struct   raid_bdev            *raid_bdev = &raid_bdev_io_channel->raid_bdev_ctxt->raid_bdev;
+	uint64_t                      pd_strip;
+	uint32_t                      offset_in_strip;
+	uint64_t                      pd_lba;
+	uint64_t                      pd_blocks;
+	uint32_t                      pd_idx;
+	int                           ret;
+
+	for (uint64_t strip = cur_strip; strip <= end_strip; strip++) {
+		/*
+		 * For each strip of parent bdev io, process for each strip and submit
+		 * child io to bdev layer. Calculate base bdev level start lba, length
+		 * and buffer for this child io
+		 */
+		pd_strip = strip / raid_bdev->num_base_bdevs;
+		pd_idx = strip % raid_bdev->num_base_bdevs;
+		if (strip == start_strip) {
+			offset_in_strip = bdev_io->u.bdev.offset_blocks & (raid_bdev->strip_size - 1);
+			pd_lba = (pd_strip << raid_bdev->strip_size_shift) + offset_in_strip;
+			if (strip == end_strip) {
+				pd_blocks = bdev_io->u.bdev.num_blocks;
+			} else {
+				pd_blocks = raid_bdev->strip_size - offset_in_strip;
+			}
+		} else if (strip == end_strip) {
+			pd_lba = pd_strip << raid_bdev->strip_size_shift;
+			pd_blocks = ((bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) &
+				     (raid_bdev->strip_size - 1)) + 1;
+		} else {
+			pd_lba = pd_strip << raid_bdev->strip_size_shift;
+			pd_blocks = raid_bdev->strip_size;
+		}
+		raid_bdev_io->splits_comp_outstanding++;
+		assert(raid_bdev_io->splits_pending);
+		raid_bdev_io->splits_pending--;
+		if (raid_bdev->base_bdev_info[pd_idx].base_bdev_desc == NULL) {
+			SPDK_ERRLOG("base bdev desc null for pd_idx %u\n", pd_idx);
+			assert(0);
+		}
+
+		/*
+		 * Submit child io to bdev layer with using base bdev descriptors, base
+		 * bdev lba, base bdev child io length in blocks, buffer, completion
+		 * function and function callback context
+		 */
+		if (bdev_io->type == SPDK_BDEV_IO_TYPE_READ) {
+			ret = spdk_bdev_read_blocks(raid_bdev->base_bdev_info[pd_idx].base_bdev_desc,
+						    raid_bdev_io_channel->base_bdevs_io_channel[pd_idx],
+						    buf, pd_lba, pd_blocks, raid_bdev_io_completion,
+						    bdev_io);
+
+		} else if (bdev_io->type == SPDK_BDEV_IO_TYPE_WRITE) {
+			ret = spdk_bdev_write_blocks(raid_bdev->base_bdev_info[pd_idx].base_bdev_desc,
+						     raid_bdev_io_channel->base_bdevs_io_channel[pd_idx],
+						     buf, pd_lba, pd_blocks, raid_bdev_io_completion,
+						     bdev_io);
+		} else {
+			SPDK_ERRLOG("Recvd not supported io type %u\n", bdev_io->type);
+			assert(0);
+		}
+		if (ret != 0) {
+			/*
+			 * If failed to submit child io to bdev layer then queue the parent
+			 * bdev io with current active split information in the wait queue
+			 * for that core. This will get resume from this point only. Assume
+			 * if 4 splits are required and 2 childs are submitted, then parent
+			 * io is queued to io waitq of this core and it will get resumed and
+			 * try to submit the remaining 3 and 4 childs
+			 */
+			raid_bdev_io->buf = buf;
+			raid_bdev_io->ch = ch;
+			raid_bdev_io->splits_comp_outstanding--;
+			raid_bdev_io->splits_pending++;
+			return ret;
+		}
+		buf += (pd_blocks << raid_bdev->blocklen_shift);
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * get_curr_base_bdev_index function calculates the base bdev index
+ * which should be processed next based on splits_pending parameter
+ * params:
+ * raid_bdev - pointer to pooled bdev
+ * raid_bdev_io - pointer to parent io context
+ * returns:
+ * base bdev index
+ */
+static uint8_t
+get_curr_base_bdev_index(struct raid_bdev *raid_bdev, struct raid_bdev_io *raid_bdev_io)
+{
+	struct spdk_bdev_io *bdev_io;
+	uint64_t            start_strip;
+	uint64_t            end_strip;
+	uint64_t            cur_strip;
+
+	bdev_io = SPDK_CONTAINEROF(raid_bdev_io, struct spdk_bdev_io, driver_ctx);
+	start_strip = bdev_io->u.bdev.offset_blocks >> raid_bdev->strip_size_shift;
+	end_strip = (bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) >>
+		    raid_bdev->strip_size_shift;
+	cur_strip = start_strip + ((end_strip - start_strip + 1) - raid_bdev_io->splits_pending);
+
+	return (cur_strip % raid_bdev->num_base_bdevs);
+}
+
+/*
+ * brief:
+ * raid_bdev_io_terminate function terminates the execution of the IO. If
+ * any outstanding children are there it waits for completion, otherwise it
+ * immediately completes the IO with failure.
+ * params:
+ * bdev_io - pointer to parent io
+ * raid_bdev_io - pointer to parent io context
+ * returns:
+ * none
+ */
+static void
+raid_bdev_io_terminate(struct spdk_bdev_io *bdev_io, struct raid_bdev_io *raid_bdev_io)
+{
+	if (raid_bdev_io->splits_comp_outstanding == 0) {
+		/* If no children is outstanding, immediately fail the parent IO */
+		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
+	} else {
+		/* If any children is outstanding,
+		 * wait for them to complete but don't send further Ios */
+		raid_bdev_io->splits_pending = 0;
+		raid_bdev_io->status = SPDK_BDEV_IO_STATUS_FAILED;
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_io_submit_fail_process function processes the IO which failed to submit.
+ * It will try to queue the IOs after storing the context to bdev wait queue logic.
+ * params:
+ * bdev_io - pointer to bdev_io
+ * raid_bdev_io - pointer to raid bdev io
+ * ret - return code
+ * returns:
+ * none
+ */
+static void
+raid_bdev_io_submit_fail_process(struct raid_bdev *raid_bdev, struct spdk_bdev_io *bdev_io,
+				 struct raid_bdev_io *raid_bdev_io, int ret)
+{
+	struct   raid_bdev_io_channel *raid_bdev_io_channel;
+	uint8_t pd_idx;
+
+	if (ret != -ENOMEM) {
+		raid_bdev_io_terminate(bdev_io, raid_bdev_io);
+	} else {
+		/* Queue the IO to bdev layer wait queue */
+		pd_idx = get_curr_base_bdev_index(raid_bdev, raid_bdev_io);
+		raid_bdev_io->waitq_entry.bdev = raid_bdev->base_bdev_info[pd_idx].base_bdev;
+		raid_bdev_io->waitq_entry.cb_fn = raid_bdev_waitq_io_process;
+		raid_bdev_io->waitq_entry.cb_arg = raid_bdev_io;
+		raid_bdev_io_channel = spdk_io_channel_get_ctx(raid_bdev_io->ch);
+		if (spdk_bdev_queue_io_wait(raid_bdev->base_bdev_info[pd_idx].base_bdev,
+					    raid_bdev_io_channel->base_bdevs_io_channel[pd_idx],
+					    &raid_bdev_io->waitq_entry) != 0) {
+			SPDK_ERRLOG("bdev io waitq error, it should not happen\n");
+			assert(0);
+			raid_bdev_io_terminate(bdev_io, raid_bdev_io);
+		}
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_waitq_io_process function is the callback function
+ * registerd by raid bdev module to bdev when bdev_io was unavailable.
+ * params:
+ * ctx - pointer to raid_bdev_io
+ * returns:
+ * none
+ */
+static void
+raid_bdev_waitq_io_process(void *ctx)
+{
+	struct   raid_bdev_io         *raid_bdev_io = ctx;
+	struct   spdk_bdev_io         *bdev_io;
+	struct   raid_bdev_io_channel *raid_bdev_io_channel;
+	struct   raid_bdev            *raid_bdev;
+	int                           ret;
+	uint64_t                      start_strip;
+	uint64_t                      end_strip;
+	uint64_t                      cur_strip;
+
+	bdev_io = SPDK_CONTAINEROF(raid_bdev_io, struct spdk_bdev_io, driver_ctx);
+	/*
+	 * Try to submit childs of parent bdev io. If failed due to resource
+	 * crunch then break the loop and don't try to process other queued IOs.
+	 */
+	raid_bdev_io_channel = spdk_io_channel_get_ctx(raid_bdev_io->ch);
+	raid_bdev = &raid_bdev_io_channel->raid_bdev_ctxt->raid_bdev;
+	if (raid_bdev->num_base_bdevs > 1) {
+		start_strip = bdev_io->u.bdev.offset_blocks >> raid_bdev->strip_size_shift;
+		end_strip = (bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) >>
+			    raid_bdev->strip_size_shift;
+		cur_strip = start_strip + ((end_strip - start_strip + 1) - raid_bdev_io->splits_pending);
+		ret = raid_bdev_submit_children(raid_bdev_io->ch, bdev_io, start_strip, end_strip, cur_strip,
+						raid_bdev_io->buf);
+	} else {
+		ret = raid_bdev_send_passthru(raid_bdev_io->ch, bdev_io);
+	}
+	if (ret != 0) {
+		raid_bdev_io_submit_fail_process(raid_bdev, bdev_io, raid_bdev_io, ret);
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_submit_request function is the submit_request function pointer of
+ * raid bdev function table. This is used to submit the io on raid_bdev to below
+ * layers. If iowaitq is not empty, it will queue the parent bdev_io to the end
+ * of the queue.
+ * params:
+ * ch - pointer to raid bdev io channel
+ * bdev_io - pointer to parent bdev_io on raid bdev device
+ * returns:
+ * none
+ */
+static void
+raid_bdev_submit_request(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io)
+{
+	struct   raid_bdev_io_channel *raid_bdev_io_channel;
+	struct   raid_bdev_io         *raid_bdev_io;
+	struct   raid_bdev            *raid_bdev;
+	uint64_t                      start_strip = 0;
+	uint64_t                      end_strip = 0;
+	int                           ret;
+
+	switch (bdev_io->type) {
+	case SPDK_BDEV_IO_TYPE_READ:
+	case SPDK_BDEV_IO_TYPE_WRITE:
+		if (bdev_io->u.bdev.iovcnt != 1) {
+			SPDK_ERRLOG("iov vector count is not 1\n");
+			spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
+			break;
+		}
+		/*
+		 * IO parameters used during io split and io completion
+		 */
+		raid_bdev_io_channel = spdk_io_channel_get_ctx(ch);
+		raid_bdev = &raid_bdev_io_channel->raid_bdev_ctxt->raid_bdev;
+		raid_bdev_io = (struct raid_bdev_io *)bdev_io->driver_ctx;
+		if (raid_bdev->num_base_bdevs > 1) {
+			start_strip = bdev_io->u.bdev.offset_blocks >> raid_bdev->strip_size_shift;
+			end_strip = (bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) >>
+				    raid_bdev->strip_size_shift;
+			/*
+			 * IO parameters used during io split and io completion
+			 */
+			raid_bdev_io->splits_pending = (end_strip - start_strip + 1);
+			raid_bdev_io->splits_comp_outstanding = 0;
+			raid_bdev_io->status = SPDK_BDEV_IO_STATUS_SUCCESS;
+			ret = raid_bdev_submit_children(ch, bdev_io, start_strip, end_strip, start_strip,
+							bdev_io->u.bdev.iovs->iov_base);
+		} else {
+			ret = raid_bdev_send_passthru(ch, bdev_io);
+		}
+		if (ret != 0) {
+			raid_bdev_io_submit_fail_process(raid_bdev, bdev_io, raid_bdev_io, ret);
+		}
+		break;
+
+	case SPDK_BDEV_IO_TYPE_FLUSH:
+		// TODO: support flush if requirement comes
+		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_SUCCESS);
+		break;
+
+	default:
+		SPDK_ERRLOG("submit request, invalid io type %u\n", bdev_io->type);
+		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_FAILED);
+		break;
+	}
+
+}
+
+/*
+ * brief:
+ * raid_bdev_io_type_supported is the io_supported function for bdev function
+ * table which returns whether the particular io type is supported or not by
+ * raid bdev module
+ * params:
+ * ctx - pointer to raid bdev context
+ * type - io type
+ * returns:
+ * true - io_type is supported
+ * false - io_type is not supported
+ */
+static bool
+raid_bdev_io_type_supported(void *ctx, enum spdk_bdev_io_type io_type)
+{
+	switch (io_type) {
+	case SPDK_BDEV_IO_TYPE_READ:
+	case SPDK_BDEV_IO_TYPE_WRITE:
+	case SPDK_BDEV_IO_TYPE_FLUSH:
+		return true;
+	default:
+		return false;
+	}
+
+	return false;
+}
+
+/*
+ * brief:
+ * raid_bdev_get_io_channel is the get_io_channel function table pointer for
+ * raid bdev. This is used to return the io channel for this raid bdev
+ * params:
+ * ctxt - pointer to raid_bdev_ctxt
+ * returns:
+ * pointer to io channel for raid bdev
+ */
+static struct spdk_io_channel *
+raid_bdev_get_io_channel(void *ctxt)
+{
+	struct raid_bdev_ctxt *raid_bdev_ctxt = ctxt;
+
+	return spdk_get_io_channel(&raid_bdev_ctxt->raid_bdev);
+}
+
+/*
+ * brief:
+ * raid_bdev_dump_info_json is the function table pointer for raid bdev
+ * params:
+ * ctx - pointer to raid_bdev_ctxt
+ * w - pointer to json context
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_dump_info_json(void *ctx, struct spdk_json_write_ctx *w)
+{
+	struct raid_bdev_ctxt *raid_bdev_ctxt = ctx;
+	struct raid_bdev      *raid_bdev;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_dump_config_json\n");
+	assert(raid_bdev_ctxt != NULL);
+	raid_bdev = &raid_bdev_ctxt->raid_bdev;
+
+	/* Dump the raid bdev configuration related information */
+	spdk_json_write_name(w, "raid");
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_uint32(w, "strip_size", raid_bdev->strip_size);
+	spdk_json_write_named_uint32(w, "state", raid_bdev->state);
+	spdk_json_write_named_uint32(w, "raid_level", raid_bdev->raid_level);
+	spdk_json_write_named_uint32(w, "destruct_called", raid_bdev->destruct_called);
+	spdk_json_write_named_uint32(w, "num_base_bdevs", raid_bdev->num_base_bdevs);
+	spdk_json_write_named_uint32(w, "num_base_bdevs_discovered", raid_bdev->num_base_bdevs_discovered);
+	spdk_json_write_name(w, "base_bdevs_list");
+	spdk_json_write_array_begin(w);
+	for (uint16_t iter = 0; iter < raid_bdev->num_base_bdevs; iter++) {
+		if (raid_bdev->base_bdev_info[iter].base_bdev) {
+			spdk_json_write_string(w, raid_bdev->base_bdev_info[iter].base_bdev->name);
+		} else {
+			spdk_json_write_null(w);
+		}
+	}
+	spdk_json_write_array_end(w);
+	spdk_json_write_object_end(w);
+
+	return 0;
+}
+
+/* g_raid_bdev_fn_table is the function table for raid bdev */
+static const struct spdk_bdev_fn_table g_raid_bdev_fn_table = {
+	.destruct           = raid_bdev_destruct,
+	.submit_request     = raid_bdev_submit_request,
+	.io_type_supported  = raid_bdev_io_type_supported,
+	.get_io_channel     = raid_bdev_get_io_channel,
+	.dump_info_json     = raid_bdev_dump_info_json,
+};
+
+/*
+ * brief:
+ * raid_bdev_free is the raid bdev function table function pointer. This is
+ * called on bdev free path
+ * params:
+ * none
+ * returns:
+ * none
+ */
+static void
+raid_bdev_free(void)
+{
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_free\n");
+	for (uint32_t raid_bdev = 0; raid_bdev < g_spdk_raid_config.total_raid_bdev; raid_bdev++) {
+		if (g_spdk_raid_config.raid_bdev_config[raid_bdev].base_bdev) {
+			for (uint32_t iter = 0; iter < g_spdk_raid_config.raid_bdev_config[raid_bdev].num_base_bdevs;
+			     iter++) {
+				free(g_spdk_raid_config.raid_bdev_config[raid_bdev].base_bdev[iter].bdev_name);
+			}
+			free(g_spdk_raid_config.raid_bdev_config[raid_bdev].base_bdev);
+			g_spdk_raid_config.raid_bdev_config[raid_bdev].base_bdev = NULL;
+		}
+		free(g_spdk_raid_config.raid_bdev_config[raid_bdev].name);
+	}
+	if (g_spdk_raid_config.raid_bdev_config) {
+		if (g_spdk_raid_config.raid_bdev_config->raid_bdev_ctxt) {
+			g_spdk_raid_config.raid_bdev_config->raid_bdev_ctxt->raid_bdev.raid_bdev_config = NULL;
+		}
+		free(g_spdk_raid_config.raid_bdev_config);
+		g_spdk_raid_config.raid_bdev_config = NULL;
+		g_spdk_raid_config.total_raid_bdev = 0;
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_parse_raid is used to parse the raid bdev from config file based on
+ * pre-defined raid bdev format in config file.
+ * Format of config file:
+ *   [RAID1]
+ *   Name raid1
+ *   StripSize 64
+ *   NumDevices 2
+ *   RaidLevel 0
+ *   Devices Nvme0n1 Nvme1n1
+ *
+ *   [RAID2]
+ *   Name raid2
+ *   StripSize 64
+ *   NumDevices 3
+ *   RaidLevel 0
+ *   Devices Nvme2n1 Nvme3n1 Nvme4n1
+ *
+ * params:
+ * conf_section - pointer to config section
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_parse_raid(struct spdk_conf_section *conf_section)
+{
+	const char *raid_name;
+	int strip_size;
+	int num_base_bdevs;
+	int raid_level;
+	const char *base_bdev_name;
+	uint32_t iter;
+	void *temp_ptr;
+	struct raid_bdev_config *raid_bdev_config;
+
+	raid_name = spdk_conf_section_get_val(conf_section, "Name");
+	if (raid_name == NULL) {
+		SPDK_ERRLOG("raid_name %s is null\n", raid_name);
+		return -1;
+	}
+	strip_size = spdk_conf_section_get_intval(conf_section, "StripSize");
+	if (spdk_u32_is_pow2(strip_size) == false) {
+		SPDK_ERRLOG("Invalid strip size %d\n", strip_size);
+		return -1;
+	}
+	num_base_bdevs = spdk_conf_section_get_intval(conf_section, "NumDevices");
+	if (num_base_bdevs <= 0) {
+		SPDK_ERRLOG("Invalid base device count %d\n", num_base_bdevs);
+		return -1;
+	}
+	raid_level = spdk_conf_section_get_intval(conf_section, "RaidLevel");
+	if (raid_level != 0) {
+		SPDK_ERRLOG("invalid raid level %d, only raid level 0 is supported\n", raid_level);
+		return -1;
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "%s %d %d %d\n", raid_name, strip_size, num_base_bdevs,
+		      raid_level);
+
+	for (iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+		if (!strcmp(g_spdk_raid_config.raid_bdev_config[iter].name, raid_name)) {
+			SPDK_ERRLOG("Duplicate raid bdev name found in config file %s\n", raid_name);
+			return -1;
+		}
+	}
+	temp_ptr = realloc(g_spdk_raid_config.raid_bdev_config,
+			   sizeof(struct raid_bdev_config) * (g_spdk_raid_config.total_raid_bdev + 1));
+	if (temp_ptr == NULL) {
+		SPDK_ERRLOG("unable to allocate memory\n");
+		return -1;
+	}
+
+	g_spdk_raid_config.raid_bdev_config = temp_ptr;
+	raid_bdev_config = &g_spdk_raid_config.raid_bdev_config[g_spdk_raid_config.total_raid_bdev];
+	memset(raid_bdev_config, 0, sizeof(*raid_bdev_config));
+	raid_bdev_config->name = strdup(raid_name);
+	if (!raid_bdev_config->name) {
+		SPDK_ERRLOG("unable to allocate memory\n");
+		return -1;
+	}
+	raid_bdev_config->strip_size = strip_size;
+	raid_bdev_config->num_base_bdevs = num_base_bdevs;
+	raid_bdev_config->raid_level = raid_level;
+	g_spdk_raid_config.total_raid_bdev++;
+	raid_bdev_config->base_bdev = calloc(num_base_bdevs, sizeof(*raid_bdev_config->base_bdev));
+	if (raid_bdev_config->base_bdev == NULL) {
+		SPDK_ERRLOG("unable to allocate memory\n");
+		return -1;
+	}
+
+	for (iter = 0; true; iter++) {
+		base_bdev_name = spdk_conf_section_get_nmval(conf_section, "Devices", 0, iter);
+		if (base_bdev_name == NULL) {
+			break;
+		}
+		if (iter >= raid_bdev_config->num_base_bdevs) {
+			SPDK_ERRLOG("Number of devices mentioned is more than count\n");
+			return -1;
+		}
+		for (uint32_t iter2 = 0; iter2 < g_spdk_raid_config.total_raid_bdev; iter2++) {
+			for (uint32_t iter3 = 0; iter3 < g_spdk_raid_config.raid_bdev_config[iter2].num_base_bdevs;
+			     iter3++) {
+				if (g_spdk_raid_config.raid_bdev_config[iter2].base_bdev[iter3].bdev_name != NULL) {
+					if (!strcmp(g_spdk_raid_config.raid_bdev_config[iter2].base_bdev[iter3].bdev_name,
+						    base_bdev_name)) {
+						SPDK_ERRLOG("duplicate base bdev name %s mentioned\n", base_bdev_name);
+						return -1;
+					}
+				}
+			}
+		}
+		raid_bdev_config->base_bdev[iter].bdev_name = strdup(base_bdev_name);
+	}
+
+	if (iter != raid_bdev_config->num_base_bdevs) {
+		SPDK_ERRLOG("Number of devices mentioned is less than count\n");
+		return -1;
+	}
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_parse_config is used to find the raid bdev config section and parse it
+ * Format of config file:
+ * params:
+ * none
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_parse_config(void)
+{
+	int                      ret;
+	struct spdk_conf_section *conf_section;
+
+	conf_section = spdk_conf_first_section(NULL);
+	while (conf_section != NULL) {
+		if (spdk_conf_section_match_prefix(conf_section, "RAID")) {
+			ret = raid_bdev_parse_raid(conf_section);
+			if (ret < 0) {
+				SPDK_ERRLOG("Unable to parse raid bdev section\n");
+				return ret;
+			}
+		}
+		conf_section = spdk_conf_next_section(conf_section);
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_exit is called on raid bdev module exit time by bdev layer
+ * params:
+ * none
+ * returns:
+ * none
+ */
+static void
+raid_bdev_exit(void)
+{
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_exit\n");
+	raid_bdev_free();
+}
+
+/*
+ * brief:
+ * raid_bdev_get_ctx_size is used to return the context size of bdev_io for raid
+ * module
+ * params:
+ * none
+ * returns:
+ * size of spdk_bdev_io context for raid
+ */
+static int
+raid_bdev_get_ctx_size(void)
+{
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_get_ctx_size\n");
+	return sizeof(struct raid_bdev_io);
+}
+
+/*
+ * brief:
+ * raid_bdev_can_claim_bdev is the function to check if this base_bdev can be
+ * claimed by raid bdev or not.
+ * params:
+ * bdev_name - represents base bdev name
+ * raid_bdev_config - pointer to raid bdev config parsed from config file
+ * base_bdev_slot - if bdev can be claimed, it represents the base_bdev correct
+ * slot. This field is only valid if return value of this function is true
+ * returns:
+ * true - if bdev can be claimed
+ * false - if bdev can't be claimed
+ */
+static bool
+raid_bdev_can_claim_bdev(const char *bdev_name, struct raid_bdev_config **raid_bdev_config,
+			 uint32_t *base_bdev_slot)
+{
+	bool     rv = false;
+
+	for (uint32_t iter1 = 0; iter1 < g_spdk_raid_config.total_raid_bdev && !rv; iter1++) {
+		for (uint32_t iter2 = 0; iter2 < g_spdk_raid_config.raid_bdev_config[iter1].num_base_bdevs;
+		     iter2++) {
+			/*
+			 * Check if the base bdev name is part of raid bdev configuration.
+			 * If match is found then return true and the slot information where
+			 * this base bdev should be inserted in raid bdev
+			 */
+			if (!strcmp(bdev_name, g_spdk_raid_config.raid_bdev_config[iter1].base_bdev[iter2].bdev_name)) {
+				*raid_bdev_config = &g_spdk_raid_config.raid_bdev_config[iter1];
+				*base_bdev_slot = iter2;
+				rv = true;
+				break;
+			}
+		}
+	}
+
+	return rv;
+}
+
+
+static struct spdk_bdev_module g_raid_if = {
+	.name = "raid",
+	.module_init = raid_bdev_init,
+	.module_fini = raid_bdev_exit,
+	.get_ctx_size = raid_bdev_get_ctx_size,
+	.examine_config = raid_bdev_examine,
+	.config_text = NULL,
+	.async_init = false,
+	.async_fini = false,
+};
+SPDK_BDEV_MODULE_REGISTER(&g_raid_if)
+
+/*
+ * brief:
+ * raid_bdev_init is the initialization function for raid bdev module
+ * params:
+ * none
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+static int
+raid_bdev_init(void)
+{
+	int ret;
+
+	memset(&g_spdk_raid_config, 0, sizeof(g_spdk_raid_config));
+	TAILQ_INIT(&g_spdk_raid_bdev_configured_list);
+	TAILQ_INIT(&g_spdk_raid_bdev_configuring_list);
+	TAILQ_INIT(&g_spdk_raid_bdev_list);
+	TAILQ_INIT(&g_spdk_raid_bdev_offline_list);
+
+	/* Parse config file for raids */
+	ret = raid_bdev_parse_config();
+	if (ret < 0) {
+		SPDK_ERRLOG("raid bdev init failed parsing\n");
+		raid_bdev_free();
+		return ret;
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_init completed successfully\n");
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_remove_base_bdev function is called by below layers when base_bdev
+ * is removed. This function checks if this base bdev is part of any raid bdev
+ * or not. If yes, it takes necessary action on that particular raid bdev.
+ * params:
+ * ctx - pointer to base bdev pointer which got removed
+ * returns:
+ * none
+ */
+void
+raid_bdev_remove_base_bdev(void *ctx)
+{
+	struct    spdk_bdev       *base_bdev = ctx;
+	struct    raid_bdev       *raid_bdev;
+	struct    raid_bdev       *next_raid_bdev;
+	struct    raid_bdev_ctxt  *raid_bdev_ctxt;
+	uint16_t                  iter;
+	bool                      found = false;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_remove_base_bdev\n");
+
+	/* Find the raid_bdev which has claimed this base_bdev */
+	TAILQ_FOREACH_SAFE(raid_bdev, &g_spdk_raid_bdev_list, link_global_list, next_raid_bdev) {
+		for (iter = 0; iter < raid_bdev->num_base_bdevs; iter++) {
+			if (raid_bdev->base_bdev_info[iter].base_bdev == base_bdev) {
+				found = true;
+				break;
+			}
+		}
+		if (found == true) {
+			break;
+		}
+	}
+
+	if (found == false) {
+		SPDK_ERRLOG("bdev to remove '%s' not found\n", base_bdev->name);
+		return;
+	}
+
+	assert(raid_bdev != NULL);
+	assert(raid_bdev->base_bdev_info[iter].base_bdev);
+	assert(raid_bdev->base_bdev_info[iter].base_bdev_desc);
+	raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+	raid_bdev->base_bdev_info[iter].base_bdev_remove_scheduled = true;
+
+	if (raid_bdev->destruct_called == true && raid_bdev->base_bdev_info[iter].base_bdev != NULL) {
+		/* As raid bdev is already unregistered, so cleanup should be done here itself */
+		spdk_bdev_module_release_bdev(raid_bdev->base_bdev_info[iter].base_bdev);
+		spdk_bdev_close(raid_bdev->base_bdev_info[iter].base_bdev_desc);
+		raid_bdev->base_bdev_info[iter].base_bdev_desc = NULL;
+		raid_bdev->base_bdev_info[iter].base_bdev = NULL;
+		assert(raid_bdev->num_base_bdevs_discovered);
+		raid_bdev->num_base_bdevs_discovered--;
+		if (raid_bdev->num_base_bdevs_discovered == 0) {
+			/* Since there is no base bdev for this raid, so free the raid device */
+			raid_bdev_cleanup(raid_bdev_ctxt);
+			return;
+		}
+	}
+
+	if (raid_bdev->state == RAID_BDEV_STATE_ONLINE) {
+		/*
+		 * If raid bdev is online and registered, change the bdev state to
+		 * configuring and unregister this raid device. Queue this raid device
+		 * in configuring list
+		 */
+		assert(raid_bdev->num_base_bdevs == raid_bdev->num_base_bdevs_discovered);
+		TAILQ_REMOVE(&g_spdk_raid_bdev_configured_list, raid_bdev, link_specific_list);
+		raid_bdev->state = RAID_BDEV_STATE_OFFLINE;
+		assert(raid_bdev->num_base_bdevs_discovered);
+		TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_offline_list, raid_bdev, link_specific_list);
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid bdev state chaning from online to offline\n");
+		spdk_io_device_unregister(&raid_bdev_ctxt->raid_bdev, NULL);
+		spdk_bdev_unregister(&raid_bdev_ctxt->bdev, NULL, NULL);
+	}
+}
+
+/*
+ * brief:
+ * raid_bdev_add_base_device function is the actual function which either adds
+ * the nvme base device to existing raid bdev or create a new raid bdev. It also claims
+ * the base device and keep the open descriptor.
+ * params:
+ * bdev - pointer to base bdev
+ * returns:
+ * 0 - success
+ * non zero - failure
+ */
+int
+raid_bdev_add_base_device(struct spdk_bdev *bdev)
+{
+	struct    raid_bdev_config  *raid_bdev_config = NULL;
+	struct    raid_bdev_ctxt    *raid_bdev_ctxt;
+	struct    raid_bdev         *raid_bdev;
+	struct    spdk_bdev_desc    *desc;
+	struct    spdk_bdev         *raid_bdev_gen;
+	uint32_t                    blocklen;
+	uint64_t                    min_blockcnt;
+	uint32_t                    base_bdev_slot;
+	bool                        can_claim;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_examine %p\n", bdev);
+
+	can_claim = raid_bdev_can_claim_bdev(bdev->name, &raid_bdev_config, &base_bdev_slot);
+
+	if (!can_claim) {
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "bdev %s can't be claimed\n", bdev->name);
+		return -1;
+	}
+	assert(raid_bdev_config);
+
+	if (spdk_bdev_open(bdev, true, raid_bdev_remove_base_bdev, bdev, &desc)) {
+		SPDK_ERRLOG("Unable to create desc on bdev '%s'\n", bdev->name);
+		return -1;
+	}
+
+	if (spdk_bdev_module_claim_bdev(bdev, NULL, &g_raid_if)) {
+		SPDK_ERRLOG("Unable to claim this bdev as it is already claimed\n");
+		spdk_bdev_close(desc);
+		return -1;
+	}
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "bdev %s is claimed\n", bdev->name);
+	SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid_bdev_config->raid_bdev_ctxt %p\n",
+		      raid_bdev_config->raid_bdev_ctxt);
+
+	if (!raid_bdev_config->raid_bdev_ctxt) {
+		/* Allocate raid_bdev entity if it is not already allocated */
+		raid_bdev_ctxt = calloc(1, sizeof(*raid_bdev_ctxt));
+		if (!raid_bdev_ctxt) {
+			SPDK_ERRLOG("Unable to allocate memory for raid bdev for bdev '%s'\n", bdev->name);
+			spdk_bdev_module_release_bdev(bdev);
+			spdk_bdev_close(desc);
+			return -1;
+		}
+		raid_bdev = &raid_bdev_ctxt->raid_bdev;
+		raid_bdev->num_base_bdevs = raid_bdev_config->num_base_bdevs;
+		raid_bdev->base_bdev_info = calloc(raid_bdev->num_base_bdevs, sizeof(struct raid_base_bdev_info));
+		if (!raid_bdev->base_bdev_info) {
+			SPDK_ERRLOG("Unable able to allocate base bdev info\n");
+			free(raid_bdev_ctxt);
+			spdk_bdev_module_release_bdev(bdev);
+			spdk_bdev_close(desc);
+			return -1;
+		}
+		raid_bdev_config->raid_bdev_ctxt = raid_bdev_ctxt;
+		raid_bdev->strip_size = raid_bdev_config->strip_size;
+		raid_bdev->state = RAID_BDEV_STATE_CONFIGURING;
+		raid_bdev->raid_bdev_config = raid_bdev_config;
+		TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+		TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_list, raid_bdev, link_global_list);
+	} else {
+		raid_bdev = &raid_bdev_config->raid_bdev_ctxt->raid_bdev;
+	}
+
+	assert(raid_bdev->state != RAID_BDEV_STATE_ONLINE);
+	assert(base_bdev_slot < raid_bdev->num_base_bdevs);
+
+	raid_bdev->base_bdev_info[base_bdev_slot].base_bdev = bdev;
+	raid_bdev->base_bdev_info[base_bdev_slot].base_bdev_desc = desc;
+	raid_bdev->num_base_bdevs_discovered++;
+
+	assert(raid_bdev->num_base_bdevs_discovered <= raid_bdev->num_base_bdevs);
+
+	if (raid_bdev->num_base_bdevs_discovered == raid_bdev->num_base_bdevs) {
+		/* If raid bdev config is complete, then only register the raid bdev to
+		 * bdev layer and remove this raid bdev from configuring list and
+		 * insert the raid bdev to configured list
+		 */
+		blocklen = raid_bdev->base_bdev_info[0].base_bdev->blocklen;
+		min_blockcnt = raid_bdev->base_bdev_info[0].base_bdev->blockcnt;
+		for (uint32_t iter = 1; iter < raid_bdev->num_base_bdevs; iter++) {
+			/* Calculate minimum block count from all base bdevs */
+			if (raid_bdev->base_bdev_info[iter].base_bdev->blockcnt < min_blockcnt) {
+				min_blockcnt = raid_bdev->base_bdev_info[iter].base_bdev->blockcnt;
+			}
+
+			/* Check blocklen for all base bdevs that it should be same */
+			if (blocklen != raid_bdev->base_bdev_info[iter].base_bdev->blocklen) {
+				/*
+				 * Assumption is that all the base bdevs for any raid bdev should
+				 * have same blocklen
+				 */
+				SPDK_ERRLOG("Blocklen of various bdevs not matching\n");
+				raid_bdev->state = RAID_BDEV_STATE_OFFLINE;
+				TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+				TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_offline_list, raid_bdev, link_specific_list);
+				return -1;
+			}
+		}
+		raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+		raid_bdev_gen = &raid_bdev_ctxt->bdev;
+		raid_bdev_gen->name = strdup(raid_bdev_config->name);
+		if (!raid_bdev_gen->name) {
+			SPDK_ERRLOG("Unable to allocate name for raid\n");
+			raid_bdev->state = RAID_BDEV_STATE_OFFLINE;
+			TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+			TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_offline_list, raid_bdev, link_specific_list);
+			return -1;
+		}
+		raid_bdev_gen->product_name = "Pooled Device";
+		raid_bdev_gen->write_cache = 0;
+		raid_bdev_gen->blocklen = blocklen;
+		raid_bdev_gen->optimal_io_boundary = 0;
+		raid_bdev_gen->ctxt = raid_bdev_ctxt;
+		raid_bdev_gen->fn_table = &g_raid_bdev_fn_table;
+		raid_bdev_gen->module = &g_raid_if;
+		raid_bdev->strip_size = (raid_bdev->strip_size * 1024) / blocklen;
+		raid_bdev->strip_size_shift = spdk_u32log2(raid_bdev->strip_size);
+		raid_bdev->blocklen_shift = spdk_u32log2(blocklen);
+
+		/*
+		 * RAID bdev logic is for striping so take the minimum block count based
+		 * approach where total block count of raid bdev is the number of base
+		 * bdev times the minimum block count of any base bdev
+		 */
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "min blockcount %lu,  numbasedev %u, strip size shift %u\n",
+			      min_blockcnt,
+			      raid_bdev->num_base_bdevs, raid_bdev->strip_size_shift);
+		raid_bdev_gen->blockcnt = ((min_blockcnt >> raid_bdev->strip_size_shift) <<
+					   raid_bdev->strip_size_shift)  * raid_bdev->num_base_bdevs;
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "io device register %p\n", raid_bdev);
+		SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "blockcnt %lu, blocklen %u\n", raid_bdev_gen->blockcnt,
+			      raid_bdev_gen->blocklen);
+		if (raid_bdev->state == RAID_BDEV_STATE_CONFIGURING) {
+			raid_bdev->state = RAID_BDEV_STATE_ONLINE;
+			spdk_io_device_register(raid_bdev, raid_bdev_create_cb, raid_bdev_destroy_cb,
+						sizeof(struct raid_bdev_io_channel));
+			if (spdk_bdev_register(raid_bdev_gen)) {
+				/*
+				 * If failed to register raid bdev to bdev layer, make raid bdev offline
+				 * and add to offline list
+				 */
+				SPDK_ERRLOG("Unable to register pooled bdev\n");
+				spdk_io_device_unregister(raid_bdev, NULL);
+				raid_bdev->state = RAID_BDEV_STATE_OFFLINE;
+				TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+				TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_offline_list, raid_bdev, link_specific_list);
+				return -1;
+			}
+			SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid bdev generic %p\n", raid_bdev_gen);
+			TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+			TAILQ_INSERT_TAIL(&g_spdk_raid_bdev_configured_list, raid_bdev, link_specific_list);
+			SPDK_DEBUGLOG(SPDK_LOG_BDEV_RAID, "raid bdev is created with name %s, raid_bdev %p\n",
+				      raid_bdev_gen->name, raid_bdev);
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * brief:
+ * raid_bdev_examine function is the examine function call by the below layers
+ * like bdev_nvme layer. This function will check if this base bdev can be
+ * claimed by this raid bdev or not.
+ * params:
+ * bdev - pointer to base bdev
+ * returns:
+ * none
+ */
+static void
+raid_bdev_examine(struct spdk_bdev *bdev)
+{
+	raid_bdev_add_base_device(bdev);
+	spdk_bdev_module_examine_done(&g_raid_if);
+}
+
+/* Log component for bdev raid bdev module */
+SPDK_LOG_REGISTER_COMPONENT("bdev_raid", SPDK_LOG_BDEV_RAID)
diff --git a/lib/bdev/raid/bdev_raid.h b/lib/bdev/raid/bdev_raid.h
new file mode 100644
index 000000000..260649dae
--- /dev/null
+++ b/lib/bdev/raid/bdev_raid.h
@@ -0,0 +1,230 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef SPDK_BDEV_RAID_INTERNAL_H
+#define SPDK_BDEV_RAID_INTERNAL_H
+
+#include "spdk/bdev_module.h"
+
+/*
+ * Raid state describes the state of the raid. This raid bdev can be either in
+ * configured list or configuring list
+ */
+enum raid_bdev_state {
+	/* raid bdev is ready and is seen by upper layers */
+	RAID_BDEV_STATE_ONLINE,
+
+	/* raid bdev is configuring, not all underlying bdevs are present */
+	RAID_BDEV_STATE_CONFIGURING,
+
+	/*
+	 * In offline state, raid bdev layer will complete all incoming commands without
+	 * submitting to underlying base nvme bdevs
+	 */
+	RAID_BDEV_STATE_OFFLINE,
+
+	/* raid bdev max, new states should be added before this */
+	RAID_BDEV_MAX
+};
+
+/*
+ * raid_base_bdev_info contains information for the base bdevs which are part of some
+ * raid. This structure contains the per base bdev information. Whatever is
+ * required per base device for raid bdev will be kept here
+ */
+struct raid_base_bdev_info {
+	/* pointer to base spdk bdev */
+	struct spdk_bdev         *base_bdev;
+
+	/* pointer to base bdev descriptor opened by raid bdev */
+	struct spdk_bdev_desc    *base_bdev_desc;
+
+	/*
+	 * When underlying base device calls the hot plug function on drive removal,
+	 * this flag will be set and later after doing some processing, base device
+	 * descriptor will be closed
+	 */
+	bool                     base_bdev_remove_scheduled;
+};
+
+/*
+ * raid_bdev contains the information related to any raid bdev either configured or
+ * in configuring list
+ */
+struct raid_bdev {
+	/* link of raid bdev to link it to configured, configuring or offline list */
+	TAILQ_ENTRY(raid_bdev)      link_specific_list;
+
+	/* link of raid bdev to link it to global raid bdev list */
+	TAILQ_ENTRY(raid_bdev)      link_global_list;
+
+	/* pointer to config file entry */
+	struct raid_bdev_config     *raid_bdev_config;
+
+	/* array of base bdev info */
+	struct raid_base_bdev_info  *base_bdev_info;
+
+	/* strip size of raid bdev in blocks */
+	uint32_t                    strip_size;
+
+	/* strip size bit shift for optimized calculation */
+	uint32_t                    strip_size_shift;
+
+	/* block length bit shift for optimized calculation */
+	uint32_t                    blocklen_shift;
+
+	/* state of raid bdev */
+	enum raid_bdev_state        state;
+
+	/* number of base bdevs comprising raid bdev  */
+	uint16_t                    num_base_bdevs;
+
+	/* number of base bdevs discovered */
+	uint16_t                    num_base_bdevs_discovered;
+
+	/* Raid Level of this raid bdev */
+	uint8_t                     raid_level;
+
+	/* Set to true if destruct is called for this raid bdev */
+	bool                        destruct_called;
+};
+
+/*
+ * raid_bdev_ctxt is the single entity structure for entire bdev which is
+ * allocated for any raid bdev
+ */
+struct raid_bdev_ctxt {
+	/* raid bdev device, this will get registered in bdev layer */
+	struct spdk_bdev         bdev;
+
+	/* raid_bdev object, io device will be created on this */
+	struct raid_bdev         raid_bdev;
+};
+
+/*
+ * raid_bdev_io is the context part of bdev_io. It contains the information
+ * related to bdev_io for a pooled bdev
+ */
+struct raid_bdev_io {
+	/* WaitQ entry, used only in waitq logic */
+	struct spdk_bdev_io_wait_entry  waitq_entry;
+
+	/* Original channel for this IO, used in queuing logic */
+	struct spdk_io_channel          *ch;
+
+	/* current buffer location, used in queueing logic */
+	uint8_t                         *buf;
+
+	/* outstanding child completions */
+	uint16_t                        splits_comp_outstanding;
+
+	/* pending splits yet to happen */
+	uint16_t                        splits_pending;
+
+	/* status of parent io */
+	bool                            status;
+};
+
+/*
+ * raid_base_bdev_config is the per base bdev data structure which contains
+ * information w.r.t to per base bdev during parsing config
+ */
+struct raid_base_bdev_config {
+	/* base bdev name from config file */
+	char                        *bdev_name;
+};
+
+/*
+ * raid_bdev_config contains the raid bdev  config related information after
+ * parsing the config file
+ */
+struct raid_bdev_config {
+	/* base bdev config per underlying bdev */
+	struct raid_base_bdev_config  *base_bdev;
+
+	/* Points to already created raid bdev  */
+	struct raid_bdev_ctxt         *raid_bdev_ctxt;
+
+	char                          *name;
+
+	/* strip size of this raid bdev  in kilo bytes */
+	uint32_t                      strip_size;
+
+	/* number of base bdevs */
+	uint8_t                       num_base_bdevs;
+
+	/* raid level */
+	uint8_t                       raid_level;
+};
+
+/*
+ * raid_config is the top level structure representing the raid bdev config as read
+ * from config file for all raids
+ */
+struct raid_config {
+	/* raid bdev  context from config file */
+	struct raid_bdev_config *raid_bdev_config;
+
+	/* total raid bdev  from config file */
+	uint8_t total_raid_bdev;
+};
+
+/*
+ * raid_bdev_io_channel is the context of spdk_io_channel for raid bdev device. It
+ * contains the relationship of raid bdev io channel with base bdev io channels.
+ */
+struct raid_bdev_io_channel {
+	/* Array of IO channels of base bdevs */
+	struct spdk_io_channel      **base_bdevs_io_channel;
+
+	/* raid bdev  context pointer */
+	struct raid_bdev_ctxt       *raid_bdev_ctxt;
+};
+
+/* TAIL heads for various raid bdev lists */
+TAILQ_HEAD(spdk_raid_configured_tailq, raid_bdev);
+TAILQ_HEAD(spdk_raid_configuring_tailq, raid_bdev);
+TAILQ_HEAD(spdk_raid_all_tailq, raid_bdev);
+TAILQ_HEAD(spdk_raid_offline_tailq, raid_bdev);
+
+extern struct spdk_raid_configured_tailq    g_spdk_raid_bdev_configured_list;
+extern struct spdk_raid_configuring_tailq   g_spdk_raid_bdev_configuring_list;
+extern struct spdk_raid_all_tailq           g_spdk_raid_bdev_list;
+extern struct spdk_raid_offline_tailq       g_spdk_raid_bdev_offline_list;
+extern struct raid_config                   g_spdk_raid_config;
+
+
+void raid_bdev_remove_base_bdev(void *ctx);
+int raid_bdev_add_base_device(struct spdk_bdev *bdev);
+
+#endif // SPDK_BDEV_RAID_INTERNAL_H
diff --git a/lib/bdev/raid/bdev_raid_rpc.c b/lib/bdev/raid/bdev_raid_rpc.c
new file mode 100644
index 000000000..8c6fc0ff9
--- /dev/null
+++ b/lib/bdev/raid/bdev_raid_rpc.c
@@ -0,0 +1,632 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/rpc.h"
+#include "spdk/bdev.h"
+#include "bdev_raid.h"
+#include "spdk/util.h"
+#include "spdk/string.h"
+#include "spdk_internal/log.h"
+#include "spdk/env.h"
+
+#define RPC_MAX_BASE_BDEVS 255
+
+static void raid_bdev_config_destroy(struct raid_bdev_config *raid_bdev_config);
+
+SPDK_LOG_REGISTER_COMPONENT("raidrpc", SPDK_LOG_RAID_RPC)
+
+/*
+ * brief:
+ * check_raid_bdev_present function tells if the raid bdev with given name already
+ * exists or not.
+ * params:
+ * name - raid bdev name
+ * returns:
+ * NULL - raid bdev not present
+ * non NULL - raid bdev present, returns raid_bdev_ctxt
+ */
+static struct raid_bdev_ctxt *
+check_raid_bdev_present(char *raid_bdev_name)
+{
+	struct raid_bdev       *raid_bdev;
+	struct raid_bdev_ctxt  *raid_bdev_ctxt;
+
+	TAILQ_FOREACH(raid_bdev, &g_spdk_raid_bdev_list, link_global_list) {
+		raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(raid_bdev_ctxt->bdev.name, raid_bdev_name) == 0) {
+			/* raid bdev found */
+			return raid_bdev_ctxt;
+		}
+	}
+
+	return NULL;
+}
+
+/*
+ * Input structure for get_raid_bdevs RPC
+ */
+struct rpc_get_raid_bdevs {
+	/* category - all or online or configuring or offline */
+	char *category;
+};
+
+/*
+ * brief:
+ * free_rpc_get_raids function frees RPC get_raids related parameters
+ * params:
+ * req - pointer to RPC request
+ * returns:
+ * none
+ */
+static void
+free_rpc_get_raid_bdevs(struct rpc_get_raid_bdevs *req)
+{
+	free(req->category);
+}
+
+/*
+ * Decoder object for RPC get_raids
+ */
+static const struct spdk_json_object_decoder rpc_get_raid_bdevs_decoders[] = {
+	{"category", offsetof(struct rpc_get_raid_bdevs, category), spdk_json_decode_string},
+};
+
+/*
+ * brief:
+ * spdk_rpc_get_raids function is the RPC for get_raids. This is used to list
+ * all the raid bdev names based on the input category requested. Category should be
+ * one of "all", "online", "configuring" or "offline". "all" means all the raids
+ * whether they are online or configuring or offline. "online" is the raid bdev which
+ * is registered with bdev layer. "configuring" is the raid bdev which does not have
+ * full configuration discovered yet. "offline" is the raid bdev which is not
+ * registered with bdev as of now and it has encountered any error or user has
+ * requested to offline the raid.
+ * params:
+ * requuest - pointer to json rpc request
+ * params - pointer to request parameters
+ * returns:
+ * none
+ */
+static void
+spdk_rpc_get_raid_bdevs(struct spdk_jsonrpc_request *request, const struct spdk_json_val *params)
+{
+	struct rpc_get_raid_bdevs   req = {};
+	struct spdk_json_write_ctx  *w;
+	struct raid_bdev            *raid_bdev;
+	struct raid_bdev_ctxt       *raid_bdev_ctxt;
+
+	if (spdk_json_decode_object(params, rpc_get_raid_bdevs_decoders,
+				    SPDK_COUNTOF(rpc_get_raid_bdevs_decoders),
+				    &req)) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+		return;
+	}
+
+	if (!(strcmp(req.category, "all") == 0 ||
+	      strcmp(req.category, "online") == 0 ||
+	      strcmp(req.category, "configuring") == 0 ||
+	      strcmp(req.category, "offline") == 0)) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+		free_rpc_get_raid_bdevs(&req);
+		return;
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		free_rpc_get_raid_bdevs(&req);
+		return;
+	}
+
+	spdk_json_write_array_begin(w);
+
+	/* Get raid bdev list based on the category requested */
+	if (strcmp(req.category, "all") == 0) {
+		TAILQ_FOREACH(raid_bdev, &g_spdk_raid_bdev_list, link_global_list) {
+			raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+			spdk_json_write_string(w, raid_bdev_ctxt->bdev.name);
+		}
+	} else if (strcmp(req.category, "online") == 0) {
+		TAILQ_FOREACH(raid_bdev, &g_spdk_raid_bdev_configured_list, link_specific_list) {
+			raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+			spdk_json_write_string(w, raid_bdev_ctxt->bdev.name);
+		}
+	} else if (strcmp(req.category, "configuring") == 0) {
+		TAILQ_FOREACH(raid_bdev, &g_spdk_raid_bdev_configuring_list, link_specific_list) {
+			raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+			spdk_json_write_string(w, raid_bdev_ctxt->bdev.name);
+		}
+	} else {
+		TAILQ_FOREACH(raid_bdev, &g_spdk_raid_bdev_offline_list, link_specific_list) {
+			raid_bdev_ctxt = SPDK_CONTAINEROF(raid_bdev, struct raid_bdev_ctxt, raid_bdev);
+			spdk_json_write_string(w, raid_bdev_ctxt->bdev.name);
+		}
+	}
+	spdk_json_write_array_end(w);
+	spdk_jsonrpc_end_result(request, w);
+	free_rpc_get_raid_bdevs(&req);
+}
+SPDK_RPC_REGISTER("get_raid_bdevs", spdk_rpc_get_raid_bdevs, SPDK_RPC_RUNTIME)
+
+/*
+ * Base bdevs in RPC construct_raid
+ */
+struct rpc_construct_raid_base_bdevs {
+	/* Number of base bdevs */
+	size_t           num_base_bdevs;
+
+	/* List of base bdevs names */
+	char             *base_bdevs[RPC_MAX_BASE_BDEVS];
+};
+
+/*
+ * Input structure for RPC construct_raid
+ */
+struct rpc_construct_raid_bdev {
+	/* Raid bdev name */
+	char                                 *name;
+
+	/* RAID strip size */
+	uint32_t                             strip_size;
+
+	/* RAID raid level */
+	uint8_t                              raid_level;
+
+	/* Base bdevs information */
+	struct rpc_construct_raid_base_bdevs base_bdevs;
+};
+
+/*
+ * brief:
+ * free_rpc_construct_raid_bdev function is to free RPC construct_raid_bdev related parameters
+ * params:
+ * req - pointer to RPC request
+ * returns:
+ * none
+ */
+static void
+free_rpc_construct_raid_bdev(struct rpc_construct_raid_bdev *req)
+{
+	free(req->name);
+	for (size_t iter = 0; iter < req->base_bdevs.num_base_bdevs; iter++) {
+		free(req->base_bdevs.base_bdevs[iter]);
+	}
+}
+
+/*
+ * Decoder function for RPC construct_raid_bdev to decode base bdevs list
+ */
+static int
+decode_base_bdevs(const struct spdk_json_val *val, void *out)
+{
+	struct rpc_construct_raid_base_bdevs *base_bdevs = out;
+	return spdk_json_decode_array(val, spdk_json_decode_string, base_bdevs->base_bdevs,
+				      RPC_MAX_BASE_BDEVS, &base_bdevs->num_base_bdevs, sizeof(char *));
+}
+
+/*
+ * Decoder object for RPC construct_raid
+ */
+static const struct spdk_json_object_decoder rpc_construct_raid_bdev_decoders[] = {
+	{"name", offsetof(struct rpc_construct_raid_bdev, name), spdk_json_decode_string},
+	{"strip_size", offsetof(struct rpc_construct_raid_bdev, strip_size), spdk_json_decode_uint32},
+	{"raid_level", offsetof(struct rpc_construct_raid_bdev, raid_level), spdk_json_decode_uint32},
+	{"base_bdevs", offsetof(struct rpc_construct_raid_bdev, base_bdevs), decode_base_bdevs},
+};
+
+/*
+ * brief:
+ * raid_bdev_config_cleanup function is used to free memory for one raid_bdev in configuration
+ * params:
+ * none
+ * returns:
+ * none
+ */
+static void
+raid_bdev_config_cleanup(void)
+{
+	void       *temp_ptr;
+
+	temp_ptr = realloc(g_spdk_raid_config.raid_bdev_config,
+			   sizeof(struct raid_bdev_config) * (g_spdk_raid_config.total_raid_bdev - 1));
+	if (temp_ptr != NULL) {
+		g_spdk_raid_config.raid_bdev_config = temp_ptr;
+	} else {
+		SPDK_ERRLOG("Config memory allocation failed\n");
+		assert(0);
+	}
+	g_spdk_raid_config.total_raid_bdev--;
+}
+
+/*
+ * brief:
+ * check_and_remove_raid_bdev function free base bdev descriptors, unclaim the base
+ * bdevs and free the raid. This function is used to cleanup when raid is not
+ * able to successfully create during constructing the raid via RPC
+ * params:
+ * raid_bdev_config - pointer to raid_bdev_config structure
+ * returns:
+ * NULL - raid not present
+ * non NULL - raid present, returns raid_bdev_ctxt
+ */
+static void
+check_and_remove_raid_bdev(struct raid_bdev_config *raid_bdev_config)
+{
+	struct raid_bdev       *raid_bdev;
+	struct raid_bdev_ctxt  *raid_bdev_ctxt;
+
+	/* Get the raid structured allocated if exists */
+	raid_bdev_ctxt = raid_bdev_config->raid_bdev_ctxt;
+	if (raid_bdev_ctxt == NULL) {
+		return;
+	}
+
+	/*
+	 * raid should be in configuring state as this function is used to cleanup
+	 * the raid during unsuccessful construction of raid
+	 */
+	assert(raid_bdev_ctxt->raid_bdev.state == RAID_BDEV_STATE_CONFIGURING);
+	raid_bdev = &raid_bdev_ctxt->raid_bdev;
+	for (uint32_t iter = 0; iter < raid_bdev->num_base_bdevs; iter++) {
+		assert(raid_bdev->base_bdev_info != NULL);
+		if (raid_bdev->base_bdev_info[iter].base_bdev) {
+			/* Release base bdev related resources */
+			spdk_bdev_module_release_bdev(raid_bdev->base_bdev_info[iter].base_bdev);
+			spdk_bdev_close(raid_bdev->base_bdev_info[iter].base_bdev_desc);
+			raid_bdev->base_bdev_info[iter].base_bdev_desc = NULL;
+			raid_bdev->base_bdev_info[iter].base_bdev = NULL;
+			assert(raid_bdev->num_base_bdevs_discovered);
+			raid_bdev->num_base_bdevs_discovered--;
+		}
+	}
+	/* Free raid */
+	assert(raid_bdev->num_base_bdevs_discovered == 0);
+	TAILQ_REMOVE(&g_spdk_raid_bdev_configuring_list, raid_bdev, link_specific_list);
+	TAILQ_REMOVE(&g_spdk_raid_bdev_list, raid_bdev, link_global_list);
+	free(raid_bdev->base_bdev_info);
+	free(raid_bdev_ctxt);
+	raid_bdev_config->raid_bdev_ctxt = NULL;
+}
+
+/*
+ * brief:
+ * spdk_rpc_construct_raid_bdev function is the RPC for construct_raids. It takes
+ * input as raid bdev name, raid level, strip size in KB and list of base bdev names.
+ * params:
+ * requuest - pointer to json rpc request
+ * params - pointer to request parameters
+ * returns:
+ * none
+ */
+static void
+spdk_rpc_construct_raid_bdev(struct spdk_jsonrpc_request *request,
+			     const struct spdk_json_val *params)
+{
+	struct rpc_construct_raid_bdev req = {};
+	struct spdk_json_write_ctx     *w;
+	struct raid_bdev_ctxt          *raid_bdev_ctxt;
+	void                           *temp_ptr;
+	struct raid_base_bdev_config   *base_bdevs;
+	struct raid_bdev_config        *raid_bdev_config;
+	struct spdk_bdev               *base_bdev;
+
+	if (spdk_json_decode_object(params, rpc_construct_raid_bdev_decoders,
+				    SPDK_COUNTOF(rpc_construct_raid_bdev_decoders),
+				    &req)) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+		return;
+	}
+
+	/* Fail the command if raid bdev is already present */
+	raid_bdev_ctxt = check_raid_bdev_present(req.name);
+	if (raid_bdev_ctxt != NULL) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						 "raid bdev already present");
+		free_rpc_construct_raid_bdev(&req);
+		return;
+	}
+
+	/* Fail the command if input raid level is other than 0 */
+	if (req.raid_level != 0) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "invalid raid level");
+		free_rpc_construct_raid_bdev(&req);
+		return;
+	}
+
+	if (spdk_u32_is_pow2(req.strip_size) == false) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "invalid strip size");
+		free_rpc_construct_raid_bdev(&req);
+		return;
+	}
+
+	base_bdevs = calloc(req.base_bdevs.num_base_bdevs, sizeof(struct raid_base_bdev_config));
+	if (base_bdevs == NULL) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR, spdk_strerror(ENOMEM));
+		free_rpc_construct_raid_bdev(&req);
+		return;
+	}
+
+	/* Insert the new raid bdev config entry */
+	temp_ptr = realloc(g_spdk_raid_config.raid_bdev_config,
+			   sizeof(struct raid_bdev_config) * (g_spdk_raid_config.total_raid_bdev + 1));
+	if (temp_ptr == NULL) {
+		free(base_bdevs);
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR, spdk_strerror(ENOMEM));
+		free_rpc_construct_raid_bdev(&req);
+		return;
+	}
+	g_spdk_raid_config.raid_bdev_config = temp_ptr;
+	for (size_t iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+		g_spdk_raid_config.raid_bdev_config[iter].raid_bdev_ctxt->raid_bdev.raid_bdev_config =
+			&g_spdk_raid_config.raid_bdev_config[iter];
+	}
+	raid_bdev_config = &g_spdk_raid_config.raid_bdev_config[g_spdk_raid_config.total_raid_bdev];
+	memset(raid_bdev_config, 0, sizeof(*raid_bdev_config));
+	raid_bdev_config->name = req.name;
+	raid_bdev_config->strip_size = req.strip_size;
+	raid_bdev_config->num_base_bdevs = req.base_bdevs.num_base_bdevs;
+	raid_bdev_config->raid_level = req.raid_level;
+	g_spdk_raid_config.total_raid_bdev++;
+	raid_bdev_config->base_bdev = base_bdevs;
+	for (size_t iter = 0; iter < raid_bdev_config->num_base_bdevs; iter++) {
+		raid_bdev_config->base_bdev[iter].bdev_name = req.base_bdevs.base_bdevs[iter];
+	}
+
+	for (size_t iter = 0; iter < raid_bdev_config->num_base_bdevs; iter++) {
+		/* Check if base_bdev exists already, if not fail the command */
+		base_bdev = spdk_bdev_get_by_name(req.base_bdevs.base_bdevs[iter]);
+		if (base_bdev == NULL) {
+			check_and_remove_raid_bdev(&g_spdk_raid_config.raid_bdev_config[g_spdk_raid_config.total_raid_bdev -
+										      1]);
+			raid_bdev_config_cleanup();
+			free(base_bdevs);
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR, "base bdev not found");
+			free_rpc_construct_raid_bdev(&req);
+			return;
+		}
+
+		/*
+		 * Try to add base_bdev to this raid bdev, if not able to add fail the
+		 * command. This might be because this base_bdev may already be claimed
+		 * by some other module
+		 */
+		if (raid_bdev_add_base_device(base_bdev)) {
+			check_and_remove_raid_bdev(&g_spdk_raid_config.raid_bdev_config[g_spdk_raid_config.total_raid_bdev -
+										      1]);
+			raid_bdev_config_cleanup();
+			free(base_bdevs);
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+							 "base bdev can't be added because of either memory allocation failed or not able to claim");
+			free_rpc_construct_raid_bdev(&req);
+			return;
+		}
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("construct_raid_bdev", spdk_rpc_construct_raid_bdev, SPDK_RPC_RUNTIME)
+
+/*
+ * Input structure for RPC destroy_raid
+ */
+struct rpc_destroy_raid_bdev {
+	/* raid bdev name */
+	char *name;
+};
+
+/*
+ * brief:
+ * free_rpc_destroy_raid_bdev function is used to free RPC destroy_raid_bdev related parameters
+ * params:
+ * req - pointer to RPC request
+ * params:
+ * none
+ */
+static void
+free_rpc_destroy_raid_bdev(struct rpc_destroy_raid_bdev *req)
+{
+	free(req->name);
+}
+
+/*
+ * Decoder object for RPC destroy_raid
+ */
+static const struct spdk_json_object_decoder rpc_destroy_raid_bdev_decoders[] = {
+	{"name", offsetof(struct rpc_destroy_raid_bdev, name), spdk_json_decode_string},
+};
+
+/*
+ * brief:
+ * Since destroying raid_bdev is asynchronous operation, so this function is
+ * used to check if raid bdev still exists. If raid bdev is still there it will create
+ * event and check later, otherwise it will proceed with cleanup
+ * params:
+ * arg - pointer to raid bdev cfg
+ * returns:
+ * none
+ */
+static void
+raid_bdev_config_destroy_check_raid_bdev_exists(void *arg)
+{
+	struct raid_bdev_config  *raid_cfg = arg;
+
+	assert(raid_cfg != NULL);
+	if (raid_cfg->raid_bdev_ctxt != NULL) {
+		/* If raid bdev still exists, schedule event and come back later */
+		spdk_thread_send_msg(spdk_get_thread(), raid_bdev_config_destroy_check_raid_bdev_exists, raid_cfg);
+		return;
+	} else {
+		/* If raid bdev does not exist now, go for raid bdev config cleanup */
+		raid_bdev_config_destroy(raid_cfg);
+	}
+}
+
+/*
+ * brief:
+ * This function will destroy the raid bdev at given slot
+ * params:
+ * slot - slot number of raid bdev config to destroy
+ * returns:
+ * none
+ */
+static void
+raid_bdev_config_destroy(struct raid_bdev_config *raid_cfg)
+{
+	void                     *temp_ptr;
+	uint8_t                  iter;
+	struct raid_bdev_config  *raid_cfg_next;
+	uint8_t                  slot;
+
+	assert(raid_cfg != NULL);
+	if (raid_cfg->raid_bdev_ctxt != NULL) {
+		/*
+		 * If raid bdev exists for this config, wait for raid bdev to get
+		 * destroyed and come back later
+		 */
+		spdk_thread_send_msg(spdk_get_thread(), raid_bdev_config_destroy_check_raid_bdev_exists, raid_cfg);
+		return;
+	}
+
+	/* Destroy raid bdev config and cleanup */
+	for (uint8_t iter2 = 0; iter2 < raid_cfg->num_base_bdevs; iter2++) {
+		free(raid_cfg->base_bdev[iter2].bdev_name);
+	}
+	free(raid_cfg->base_bdev);
+	free(raid_cfg->name);
+	slot = raid_cfg - g_spdk_raid_config.raid_bdev_config;
+	assert(slot < g_spdk_raid_config.total_raid_bdev);
+	if (slot != g_spdk_raid_config.total_raid_bdev - 1) {
+		iter = slot;
+		while (iter < g_spdk_raid_config.total_raid_bdev - 1) {
+			raid_cfg = &g_spdk_raid_config.raid_bdev_config[iter];
+			raid_cfg_next = &g_spdk_raid_config.raid_bdev_config[iter + 1];
+			raid_cfg->base_bdev = raid_cfg_next->base_bdev;
+			raid_cfg->raid_bdev_ctxt = raid_cfg_next->raid_bdev_ctxt;
+			raid_cfg->name = raid_cfg_next->name;
+			raid_cfg->strip_size = raid_cfg_next->strip_size;
+			raid_cfg->num_base_bdevs = raid_cfg_next->num_base_bdevs;
+			raid_cfg->raid_level = raid_cfg_next->raid_level;
+			iter++;
+		}
+	}
+	temp_ptr = realloc(g_spdk_raid_config.raid_bdev_config,
+			   sizeof(struct raid_bdev_config) * (g_spdk_raid_config.total_raid_bdev - 1));
+	if (temp_ptr != NULL) {
+		g_spdk_raid_config.raid_bdev_config = temp_ptr;
+		g_spdk_raid_config.total_raid_bdev--;
+		for (iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+			g_spdk_raid_config.raid_bdev_config[iter].raid_bdev_ctxt->raid_bdev.raid_bdev_config =
+				&g_spdk_raid_config.raid_bdev_config[iter];
+		}
+	} else {
+		if (g_spdk_raid_config.total_raid_bdev == 1) {
+			g_spdk_raid_config.total_raid_bdev--;
+			g_spdk_raid_config.raid_bdev_config = NULL;
+		} else {
+			SPDK_ERRLOG("Config memory allocation failed\n");
+			assert(0);
+		}
+	}
+}
+
+/*
+ * brief:
+ * spdk_rpc_destroy_raid_bdev function is the RPC for destroy_raid. It takes raid
+ * name as input and destroy that raid bdev including freeing the base bdev
+ * resources.
+ * params:
+ * requuest - pointer to json rpc request
+ * params - pointer to request parameters
+ * returns:
+ * none
+ */
+static void
+spdk_rpc_destroy_raid_bdev(struct spdk_jsonrpc_request *request, const struct spdk_json_val *params)
+{
+	struct rpc_destroy_raid_bdev req = {};
+	struct spdk_json_write_ctx   *w;
+	struct raid_bdev_config      *raid_bdev_config = NULL;
+	struct spdk_bdev             *base_bdev;
+
+	if (spdk_json_decode_object(params, rpc_destroy_raid_bdev_decoders,
+				    SPDK_COUNTOF(rpc_destroy_raid_bdev_decoders),
+				    &req)) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+		return;
+	}
+
+	/* Find raid bdev config for this raid bdev */
+	for (uint32_t iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+		if (strcmp(g_spdk_raid_config.raid_bdev_config[iter].name, req.name) == 0) {
+			raid_bdev_config = &g_spdk_raid_config.raid_bdev_config[iter];
+			break;
+		}
+	}
+
+	if (raid_bdev_config == NULL) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						 "raid bdev name not found");
+		free_rpc_destroy_raid_bdev(&req);
+		return;
+	}
+
+	/* Remove all the base bdevs from this raid bdev before destroying the raid bdev */
+	for (uint32_t iter = 0; iter < raid_bdev_config->num_base_bdevs; iter++) {
+		base_bdev = spdk_bdev_get_by_name(raid_bdev_config->base_bdev[iter].bdev_name);
+		if (base_bdev != NULL) {
+			raid_bdev_remove_base_bdev(base_bdev);
+		}
+	}
+
+	/*
+	 * Call to destroy the raid bdev, but it will only destroy raid bdev if underlying
+	 * cleanup is done
+	 */
+	raid_bdev_config_destroy(raid_bdev_config);
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		free_rpc_destroy_raid_bdev(&req);
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+	free_rpc_destroy_raid_bdev(&req);
+}
+SPDK_RPC_REGISTER("destroy_raid_bdev", spdk_rpc_destroy_raid_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/rbd/bdev_rbd.c b/lib/bdev/rbd/bdev_rbd.c
index 9b6c43557..594a65d94 100644
--- a/lib/bdev/rbd/bdev_rbd.c
+++ b/lib/bdev/rbd/bdev_rbd.c
@@ -42,18 +42,20 @@
 #include "spdk/conf.h"
 #include "spdk/env.h"
 #include "spdk/bdev.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/json.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 #define SPDK_RBD_QUEUE_DEPTH 128
 
 static int bdev_rbd_count = 0;
 
+#define BDEV_RBD_POLL_US 50
+
 struct bdev_rbd {
 	struct spdk_bdev disk;
 	char *rbd_name;
@@ -155,6 +157,7 @@ bdev_rbd_init(const char *rbd_pool_name, const char *rbd_name, rbd_image_info_t
 		goto err;
 	}
 
+	rados_ioctx_destroy(io_ctx);
 	return 0;
 err:
 	rados_ioctx_destroy(io_ctx);
@@ -511,7 +514,7 @@ bdev_rbd_create_cb(void *io_device, void *ctx_buf)
 		goto err;
 	}
 
-	ch->poller = spdk_poller_register(bdev_rbd_io_poll, ch, 0);
+	ch->poller = spdk_poller_register(bdev_rbd_io_poll, ch, BDEV_RBD_POLL_US);
 
 	return 0;
 
@@ -655,6 +658,17 @@ spdk_bdev_rbd_create(const char *name, const char *pool_name, const char *rbd_na
 	return &rbd->disk;
 }
 
+void
+spdk_bdev_rbd_delete(struct spdk_bdev *bdev, spdk_delete_rbd_complete cb_fn, void *cb_arg)
+{
+	if (!bdev || bdev->module != &rbd_if) {
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	spdk_bdev_unregister(bdev, cb_fn, cb_arg);
+}
+
 static int
 bdev_rbd_library_init(void)
 {
diff --git a/lib/bdev/rbd/bdev_rbd.h b/lib/bdev/rbd/bdev_rbd.h
index 9d1701d83..dd2448e12 100644
--- a/lib/bdev/rbd/bdev_rbd.h
+++ b/lib/bdev/rbd/bdev_rbd.h
@@ -38,7 +38,18 @@
 
 #include "spdk/bdev.h"
 
+typedef void (*spdk_delete_rbd_complete)(void *cb_arg, int bdeverrno);
+
 struct spdk_bdev *spdk_bdev_rbd_create(const char *name, const char *pool_name,
 				       const char *rbd_name, uint32_t block_size);
+/**
+ * Delete rbd bdev.
+ *
+ * \param bdev Pointer to rbd bdev.
+ * \param cb_fn Function to call after deletion.
+ * \param cb_arg Argument to pass to cb_fn.
+ */
+void spdk_bdev_rbd_delete(struct spdk_bdev *bdev, spdk_delete_rbd_complete cb_fn,
+			  void *cb_arg);
 
 #endif // SPDK_BDEV_RBD_H
diff --git a/lib/bdev/rbd/bdev_rbd_rpc.c b/lib/bdev/rbd/bdev_rbd_rpc.c
index 96e081eca..745a90ed4 100644
--- a/lib/bdev/rbd/bdev_rbd_rpc.c
+++ b/lib/bdev/rbd/bdev_rbd_rpc.c
@@ -34,7 +34,7 @@
 #include "bdev_rbd.h"
 #include "spdk/rpc.h"
 #include "spdk/util.h"
-
+#include "spdk/string.h"
 #include "spdk_internal/log.h"
 
 struct rpc_construct_rbd {
@@ -86,9 +86,7 @@ spdk_rpc_construct_rbd_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
@@ -96,4 +94,64 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_construct_rbd(&req);
 }
-SPDK_RPC_REGISTER("construct_rbd_bdev", spdk_rpc_construct_rbd_bdev)
+SPDK_RPC_REGISTER("construct_rbd_bdev", spdk_rpc_construct_rbd_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_delete_rbd {
+	char *name;
+};
+
+static void
+free_rpc_delete_rbd(struct rpc_delete_rbd *req)
+{
+	free(req->name);
+}
+
+static const struct spdk_json_object_decoder rpc_delete_rbd_decoders[] = {
+	{"name", offsetof(struct rpc_delete_rbd, name), spdk_json_decode_string},
+};
+
+static void
+_spdk_rpc_delete_rbd_bdev_cb(void *cb_arg, int bdeverrno)
+{
+	struct spdk_jsonrpc_request *request = cb_arg;
+	struct spdk_json_write_ctx *w;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, bdeverrno == 0);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_delete_rbd_bdev(struct spdk_jsonrpc_request *request,
+			 const struct spdk_json_val *params)
+{
+	struct rpc_delete_rbd req = {NULL};
+	struct spdk_bdev *bdev;
+	int rc;
+
+	if (spdk_json_decode_object(params, rpc_delete_rbd_decoders,
+				    SPDK_COUNTOF(rpc_delete_rbd_decoders),
+				    &req)) {
+		rc = -EINVAL;
+		goto invalid;
+	}
+
+	bdev = spdk_bdev_get_by_name(req.name);
+	if (bdev == NULL) {
+		rc = -ENODEV;
+		goto invalid;
+	}
+
+	spdk_bdev_rbd_delete(bdev, _spdk_rpc_delete_rbd_bdev_cb, request);
+	free_rpc_delete_rbd(&req);
+	return;
+
+invalid:
+	free_rpc_delete_rbd(&req);
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, spdk_strerror(-rc));
+}
+SPDK_RPC_REGISTER("delete_rbd_bdev", spdk_rpc_delete_rbd_bdev, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/rpc/bdev_rpc.c b/lib/bdev/rpc/bdev_rpc.c
index 8b483b5cd..1c80fb3b0 100644
--- a/lib/bdev/rpc/bdev_rpc.c
+++ b/lib/bdev/rpc/bdev_rpc.c
@@ -31,12 +31,182 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include "spdk/env.h"
 #include "spdk/log.h"
 #include "spdk/rpc.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
+
+struct rpc_get_bdevs_iostat_ctx {
+	int bdev_count;
+	struct spdk_jsonrpc_request *request;
+	struct spdk_json_write_ctx *w;
+};
+
+static void
+spdk_rpc_get_bdevs_iostat_cb(struct spdk_bdev *bdev,
+			     struct spdk_bdev_io_stat *stat, void *cb_arg, int rc)
+{
+	struct rpc_get_bdevs_iostat_ctx *ctx = cb_arg;
+	struct spdk_json_write_ctx *w = ctx->w;
+	const char *bdev_name;
+
+	if (rc != 0) {
+		goto done;
+	}
+
+	bdev_name = spdk_bdev_get_name(bdev);
+	if (bdev_name != NULL) {
+		spdk_json_write_object_begin(w);
+
+		spdk_json_write_name(w, "name");
+		spdk_json_write_string(w, bdev_name);
+
+		spdk_json_write_name(w, "bytes_read");
+		spdk_json_write_uint64(w, stat->bytes_read);
+
+		spdk_json_write_name(w, "num_read_ops");
+		spdk_json_write_uint64(w, stat->num_read_ops);
+
+		spdk_json_write_name(w, "bytes_written");
+		spdk_json_write_uint64(w, stat->bytes_written);
+
+		spdk_json_write_name(w, "num_write_ops");
+		spdk_json_write_uint64(w, stat->num_write_ops);
+
+		spdk_json_write_name(w, "read_latency_ticks");
+		spdk_json_write_uint64(w, stat->read_latency_ticks);
+
+		spdk_json_write_name(w, "write_latency_ticks");
+		spdk_json_write_uint64(w, stat->write_latency_ticks);
+
+		if (spdk_bdev_get_qd_sampling_period(bdev)) {
+			spdk_json_write_name(w, "queue_depth_polling_period");
+			spdk_json_write_uint64(w, spdk_bdev_get_qd_sampling_period(bdev));
+
+			spdk_json_write_name(w, "queue_depth");
+			spdk_json_write_uint64(w, spdk_bdev_get_qd(bdev));
+		}
+
+		spdk_json_write_object_end(w);
+	}
+
+done:
+	free(stat);
+	if (--ctx->bdev_count == 0) {
+		spdk_json_write_array_end(ctx->w);
+		spdk_jsonrpc_end_result(ctx->request, ctx->w);
+		free(ctx);
+	}
+}
+
+struct rpc_get_bdevs_iostat {
+	char *name;
+};
+
+static void
+free_rpc_get_bdevs_iostat(struct rpc_get_bdevs_iostat *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder rpc_get_bdevs_iostat_decoders[] = {
+	{"name", offsetof(struct rpc_get_bdevs_iostat, name), spdk_json_decode_string, true},
+};
+
+static void
+spdk_rpc_get_bdevs_iostat(struct spdk_jsonrpc_request *request,
+			  const struct spdk_json_val *params)
+{
+	struct rpc_get_bdevs_iostat req = {};
+	struct spdk_bdev *bdev = NULL;
+	struct spdk_json_write_ctx *w;
+	struct spdk_bdev_io_stat *stat;
+	struct rpc_get_bdevs_iostat_ctx *ctx;
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, rpc_get_bdevs_iostat_decoders,
+					    SPDK_COUNTOF(rpc_get_bdevs_iostat_decoders),
+					    &req)) {
+			SPDK_ERRLOG("spdk_json_decode_object failed\n");
+			goto invalid;
+		}
+
+		if (req.name) {
+			bdev = spdk_bdev_get_by_name(req.name);
+			if (bdev == NULL) {
+				SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
+				goto invalid;
+			}
+		}
+	}
+
+	free_rpc_get_bdevs_iostat(&req);
+
+	ctx = calloc(1, sizeof(struct rpc_get_bdevs_iostat_ctx));
+	if (ctx == NULL) {
+		SPDK_ERRLOG("Failed to allocate rpc_get_bdevs_iostat_ctx struct\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR, "No memory left");
+		return;
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		free(ctx);
+		return;
+	}
+
+	/*
+	 * Increment initial bdev_count so that it will never reach 0 in the middle
+	 * of iterating.
+	 */
+	ctx->bdev_count++;
+	ctx->request = request;
+	ctx->w = w;
+
+	spdk_json_write_array_begin(w);
+
+	spdk_json_write_object_begin(w);
+	spdk_json_write_name(w, "tick_rate");
+	spdk_json_write_uint64(w, spdk_get_ticks_hz());
+	spdk_json_write_object_end(w);
+
+	if (bdev != NULL) {
+		stat = calloc(1, sizeof(struct spdk_bdev_io_stat));
+		if (stat == NULL) {
+			SPDK_ERRLOG("Failed to allocate rpc_get_bdevs_iostat_ctx struct\n");
+		} else {
+			ctx->bdev_count++;
+			spdk_bdev_get_device_stat(bdev, stat, spdk_rpc_get_bdevs_iostat_cb, ctx);
+		}
+	} else {
+		for (bdev = spdk_bdev_first(); bdev != NULL; bdev = spdk_bdev_next(bdev)) {
+			stat = calloc(1, sizeof(struct spdk_bdev_io_stat));
+			if (stat == NULL) {
+				SPDK_ERRLOG("Failed to allocate spdk_bdev_io_stat struct\n");
+				break;
+			}
+			ctx->bdev_count++;
+			spdk_bdev_get_device_stat(bdev, stat, spdk_rpc_get_bdevs_iostat_cb, ctx);
+		}
+	}
+
+	if (--ctx->bdev_count == 0) {
+		spdk_json_write_array_end(w);
+		spdk_jsonrpc_end_result(request, w);
+		free(ctx);
+	}
+
+	return;
+
+invalid:
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+
+	free_rpc_get_bdevs_iostat(&req);
+}
+SPDK_RPC_REGISTER("get_bdevs_iostat", spdk_rpc_get_bdevs_iostat, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_dump_bdev_info(struct spdk_json_write_ctx *w,
@@ -78,7 +248,7 @@ spdk_rpc_dump_bdev_info(struct spdk_json_write_ctx *w,
 	spdk_json_write_uint64(w, spdk_bdev_get_qos_ios_per_sec(bdev));
 
 	spdk_json_write_name(w, "claimed");
-	spdk_json_write_bool(w, (bdev->claim_module != NULL));
+	spdk_json_write_bool(w, (bdev->internal.claim_module != NULL));
 
 	spdk_json_write_name(w, "supported_io_types");
 	spdk_json_write_object_begin(w);
@@ -119,7 +289,7 @@ free_rpc_get_bdevs(struct rpc_get_bdevs *r)
 }
 
 static const struct spdk_json_object_decoder rpc_get_bdevs_decoders[] = {
-	{"name", offsetof(struct rpc_get_bdevs, name), spdk_json_decode_string},
+	{"name", offsetof(struct rpc_get_bdevs, name), spdk_json_decode_string, true},
 };
 
 static void
@@ -130,28 +300,22 @@ spdk_rpc_get_bdevs(struct spdk_jsonrpc_request *request,
 	struct spdk_json_write_ctx *w;
 	struct spdk_bdev *bdev = NULL;
 
-	if (params != NULL) {
-		if (spdk_json_decode_object(params, rpc_get_bdevs_decoders,
-					    SPDK_COUNTOF(rpc_get_bdevs_decoders),
-					    &req)) {
-			SPDK_ERRLOG("spdk_json_decode_object failed\n");
-			goto invalid;
-		} else {
-			if (req.name == NULL) {
-				SPDK_ERRLOG("missing name param\n");
-				goto invalid;
-			}
-
-			bdev = spdk_bdev_get_by_name(req.name);
-			if (bdev == NULL) {
-				SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
-				goto invalid;
-			}
+	if (params && spdk_json_decode_object(params, rpc_get_bdevs_decoders,
+					      SPDK_COUNTOF(rpc_get_bdevs_decoders),
+					      &req)) {
+		SPDK_ERRLOG("spdk_json_decode_object failed\n");
+		goto invalid;
+	}
 
-			free_rpc_get_bdevs(&req);
+	if (req.name) {
+		bdev = spdk_bdev_get_by_name(req.name);
+		if (bdev == NULL) {
+			SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
+			goto invalid;
 		}
 	}
 
+	free_rpc_get_bdevs(&req);
 	w = spdk_jsonrpc_begin_result(request);
 	if (w == NULL) {
 		return;
@@ -178,7 +342,7 @@ invalid:
 
 	free_rpc_get_bdevs(&req);
 }
-SPDK_RPC_REGISTER("get_bdevs", spdk_rpc_get_bdevs)
+SPDK_RPC_REGISTER("get_bdevs", spdk_rpc_get_bdevs, SPDK_RPC_RUNTIME)
 
 struct rpc_get_bdevs_config {
 	char *name;
@@ -191,7 +355,7 @@ free_rpc_get_bdevs_config(struct rpc_get_bdevs_config *r)
 }
 
 static const struct spdk_json_object_decoder rpc_dump_bdevs_config_decoders[] = {
-	{"name", offsetof(struct rpc_get_bdevs_config, name), spdk_json_decode_string},
+	{"name", offsetof(struct rpc_get_bdevs_config, name), spdk_json_decode_string, true},
 };
 
 static void
@@ -240,7 +404,7 @@ spdk_rpc_get_bdevs_config(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_bdevs_config", spdk_rpc_get_bdevs_config)
+SPDK_RPC_REGISTER("get_bdevs_config", spdk_rpc_get_bdevs_config, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_bdev {
 	char *name;
@@ -306,8 +470,73 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_delete_bdev(&req);
 }
-SPDK_RPC_REGISTER("delete_bdev", spdk_rpc_delete_bdev)
+SPDK_RPC_REGISTER("delete_bdev", spdk_rpc_delete_bdev, SPDK_RPC_RUNTIME)
+
+struct rpc_set_bdev_qd_sampling_period {
+	char *name;
+	uint64_t period;
+};
+
+static void
+free_rpc_set_bdev_qd_sampling_period(struct rpc_set_bdev_qd_sampling_period *r)
+{
+	free(r->name);
+}
+
+static const struct spdk_json_object_decoder
+	rpc_set_bdev_qd_sampling_period_decoders[] = {
+	{"name", offsetof(struct rpc_set_bdev_qd_sampling_period, name), spdk_json_decode_string},
+	{"period", offsetof(struct rpc_set_bdev_qd_sampling_period, period), spdk_json_decode_uint64},
+};
+
+static void
+spdk_rpc_set_bdev_qd_sampling_period(struct spdk_jsonrpc_request *request,
+				     const struct spdk_json_val *params)
+{
+	struct rpc_set_bdev_qd_sampling_period req = {0};
+	struct spdk_bdev *bdev;
+	struct spdk_json_write_ctx *w;
+
+	req.period = UINT64_MAX;
+
+	if (spdk_json_decode_object(params, rpc_set_bdev_qd_sampling_period_decoders,
+				    SPDK_COUNTOF(rpc_set_bdev_qd_sampling_period_decoders),
+				    &req)) {
+		SPDK_ERRLOG("spdk_json_decode_object failed\n");
+		goto invalid;
+	}
+
+	if (req.name) {
+		bdev = spdk_bdev_get_by_name(req.name);
+		if (bdev == NULL) {
+			SPDK_ERRLOG("bdev '%s' does not exist\n", req.name);
+			goto invalid;
+		}
+	} else {
+		SPDK_ERRLOG("Missing name param\n");
+		goto invalid;
+	}
 
+	if (req.period == UINT64_MAX) {
+		SPDK_ERRLOG("Missing period param");
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	spdk_bdev_set_qd_sampling_period(bdev, req.period);
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+	free_rpc_set_bdev_qd_sampling_period(&req);
+	return;
+
+invalid:
+	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
+	free_rpc_set_bdev_qd_sampling_period(&req);
+	return;
+}
+SPDK_RPC_REGISTER("set_bdev_qd_sampling_period",
+		  spdk_rpc_set_bdev_qd_sampling_period,
+		  SPDK_RPC_RUNTIME)
 
 struct rpc_set_bdev_qos_limit_iops {
 	char		*name;
@@ -377,4 +606,4 @@ invalid:
 	free_rpc_set_bdev_qos_limit_iops(&req);
 }
 
-SPDK_RPC_REGISTER("set_bdev_qos_limit_iops", spdk_rpc_set_bdev_qos_limit_iops)
+SPDK_RPC_REGISTER("set_bdev_qos_limit_iops", spdk_rpc_set_bdev_qos_limit_iops, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/scsi_nvme.c b/lib/bdev/scsi_nvme.c
index 6ee9d57d4..385b9036f 100644
--- a/lib/bdev/scsi_nvme.c
+++ b/lib/bdev/scsi_nvme.c
@@ -30,7 +30,7 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 #include "spdk/nvme_spec.h"
 
@@ -38,8 +38,8 @@ void
 spdk_scsi_nvme_translate(const struct spdk_bdev_io *bdev_io, int *sc, int *sk,
 			 int *asc, int *ascq)
 {
-	int nvme_sct = bdev_io->error.nvme.sct;
-	int nvme_sc = bdev_io->error.nvme.sc;
+	int nvme_sct = bdev_io->internal.error.nvme.sct;
+	int nvme_sc = bdev_io->internal.error.nvme.sc;
 
 	switch (nvme_sct) {
 	case SPDK_NVME_SCT_GENERIC:
diff --git a/lib/bdev/split/vbdev_split.c b/lib/bdev/split/vbdev_split.c
index 542bd6c97..663eebdb2 100644
--- a/lib/bdev/split/vbdev_split.c
+++ b/lib/bdev/split/vbdev_split.c
@@ -42,10 +42,10 @@
 #include "spdk/conf.h"
 #include "spdk/endian.h"
 #include "spdk/string.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/util.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 struct spdk_vbdev_split_config {
@@ -53,7 +53,7 @@ struct spdk_vbdev_split_config {
 	unsigned split_count;
 	uint64_t split_size_mb;
 
-	struct spdk_bdev_part_base split_base;
+	struct spdk_bdev_part_base *split_base;
 	bool removed;
 
 	TAILQ_ENTRY(spdk_vbdev_split_config) tailq;
@@ -78,18 +78,18 @@ static struct spdk_bdev_module split_if = {
 	.name = "split",
 	.module_init = vbdev_split_init,
 	.module_fini = vbdev_split_fini,
-	.examine = vbdev_split_examine,
+	.examine_config = vbdev_split_examine,
 	.config_json = vbdev_split_config_json,
 };
 
 SPDK_BDEV_MODULE_REGISTER(&split_if)
 
 static void
-vbdev_split_base_free(struct spdk_bdev_part_base *base)
+vbdev_split_base_free(void *ctx)
 {
-	struct spdk_vbdev_split_config *cfg = SPDK_CONTAINEROF(base, struct spdk_vbdev_split_config,
-					      split_base);
+	struct spdk_vbdev_split_config *cfg = ctx;
 
+	cfg->split_base = NULL;
 	if (cfg->removed) {
 		vbdev_split_del_config(cfg);
 	}
@@ -121,14 +121,16 @@ static int
 vbdev_split_dump_info_json(void *ctx, struct spdk_json_write_ctx *w)
 {
 	struct spdk_bdev_part *part = ctx;
+	struct spdk_bdev *split_base_bdev = spdk_bdev_part_get_base_bdev(part);
+	uint64_t offset_blocks = spdk_bdev_part_get_offset_blocks(part);
 
 	spdk_json_write_name(w, "split");
 	spdk_json_write_object_begin(w);
 
 	spdk_json_write_name(w, "base_bdev");
-	spdk_json_write_string(w, spdk_bdev_get_name(part->base->bdev));
+	spdk_json_write_string(w, spdk_bdev_get_name(split_base_bdev));
 	spdk_json_write_name(w, "offset_blocks");
-	spdk_json_write_uint64(w, part->offset_blocks);
+	spdk_json_write_uint64(w, offset_blocks);
 
 	spdk_json_write_object_end(w);
 
@@ -158,6 +160,8 @@ vbdev_split_create(struct spdk_vbdev_split_config *cfg)
 	int rc;
 	char *name;
 	struct spdk_bdev *base_bdev;
+	struct spdk_bdev *split_base_bdev;
+	struct bdev_part_tailq *split_base_tailq;
 
 	assert(cfg->split_count > 0);
 
@@ -193,14 +197,14 @@ vbdev_split_create(struct spdk_vbdev_split_config *cfg)
 		      " split_size_blocks: %" PRIu64 "\n",
 		      spdk_bdev_get_name(base_bdev), split_count, split_size_blocks);
 
-	rc = spdk_bdev_part_base_construct(&cfg->split_base, base_bdev,
-					   vbdev_split_base_bdev_hotremove_cb,
-					   &split_if, &vbdev_split_fn_table,
-					   &g_split_disks, vbdev_split_base_free,
-					   sizeof(struct vbdev_split_channel), NULL, NULL);
-	if (rc) {
+	cfg->split_base = spdk_bdev_part_base_construct(base_bdev,
+			  vbdev_split_base_bdev_hotremove_cb,
+			  &split_if, &vbdev_split_fn_table,
+			  &g_split_disks, vbdev_split_base_free, cfg,
+			  sizeof(struct vbdev_split_channel), NULL, NULL);
+	if (!cfg->split_base) {
 		SPDK_ERRLOG("Cannot construct bdev part base\n");
-		return rc;
+		return -ENOMEM;
 	}
 
 	offset_blocks = 0;
@@ -222,7 +226,7 @@ vbdev_split_create(struct spdk_vbdev_split_config *cfg)
 			goto err;
 		}
 
-		rc = spdk_bdev_part_construct(d, &cfg->split_base, name, offset_blocks, split_size_blocks,
+		rc = spdk_bdev_part_construct(d, cfg->split_base, name, offset_blocks, split_size_blocks,
 					      "Split Disk");
 		if (rc) {
 			SPDK_ERRLOG("could not construct bdev part\n");
@@ -237,8 +241,10 @@ vbdev_split_create(struct spdk_vbdev_split_config *cfg)
 
 	return 0;
 err:
+	split_base_bdev = spdk_bdev_part_base_get_bdev(cfg->split_base);
+	split_base_tailq = spdk_bdev_part_base_get_tailq(cfg->split_base);
 	cfg->removed = true;
-	spdk_bdev_part_base_hotremove(cfg->split_base.bdev, cfg->split_base.tailq);
+	spdk_bdev_part_base_hotremove(split_base_bdev, split_base_tailq);
 	return rc;
 }
 
@@ -253,9 +259,14 @@ vbdev_split_del_config(struct spdk_vbdev_split_config *cfg)
 static void
 vbdev_split_destruct_config(struct spdk_vbdev_split_config *cfg)
 {
+	struct spdk_bdev *split_base_bdev;
+	struct bdev_part_tailq *split_base_tailq;
+
 	cfg->removed = true;
-	if (cfg->split_base.ref) {
-		spdk_bdev_part_base_hotremove(cfg->split_base.bdev, cfg->split_base.tailq);
+	if (cfg->split_base != NULL) {
+		split_base_bdev = spdk_bdev_part_base_get_bdev(cfg->split_base);
+		split_base_tailq = spdk_bdev_part_base_get_tailq(cfg->split_base);
+		spdk_bdev_part_base_hotremove(split_base_bdev, split_base_tailq);
 	} else {
 		vbdev_split_del_config(cfg);
 	}
@@ -409,13 +420,12 @@ vbdev_split_examine(struct spdk_bdev *bdev)
 	struct spdk_vbdev_split_config *cfg = vbdev_split_config_find_by_base_name(bdev->name);
 
 	if (cfg != NULL && cfg->removed == false) {
-		assert(cfg->split_base.ref == 0);
+		assert(cfg->split_base == NULL);
 
 		if (vbdev_split_create(cfg)) {
 			SPDK_ERRLOG("could not split bdev %s\n", bdev->name);
 		}
 	}
-
 	spdk_bdev_module_examine_done(&split_if);
 }
 
diff --git a/lib/bdev/split/vbdev_split.h b/lib/bdev/split/vbdev_split.h
index b57700f25..74ea062cf 100644
--- a/lib/bdev/split/vbdev_split.h
+++ b/lib/bdev/split/vbdev_split.h
@@ -34,7 +34,7 @@
 #ifndef SPDK_VBDEV_SPLIT_H
 #define SPDK_VBDEV_SPLIT_H
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 /**
  * Add given disk name to split config. If bdev with \c base_bdev_name name
diff --git a/lib/bdev/split/vbdev_split_rpc.c b/lib/bdev/split/vbdev_split_rpc.c
index fb1307945..452e58f22 100644
--- a/lib/bdev/split/vbdev_split_rpc.c
+++ b/lib/bdev/split/vbdev_split_rpc.c
@@ -96,7 +96,7 @@ spdk_rpc_construct_split_vbdev(struct spdk_jsonrpc_request *request,
 out:
 	free(req.base_bdev);
 }
-SPDK_RPC_REGISTER("construct_split_vbdev", spdk_rpc_construct_split_vbdev)
+SPDK_RPC_REGISTER("construct_split_vbdev", spdk_rpc_construct_split_vbdev, SPDK_RPC_RUNTIME)
 
 struct rpc_destruct_split {
 	char *base_bdev;
@@ -130,14 +130,12 @@ spdk_rpc_destruct_split(struct spdk_jsonrpc_request *request,
 
 	w = spdk_jsonrpc_begin_result(request);
 	if (w == NULL) {
-		return;
+		goto out;
 	}
 
 	spdk_json_write_bool(w, true);
 	spdk_jsonrpc_end_result(request, w);
-	return;
-
 out:
 	free(req.base_bdev);
 }
-SPDK_RPC_REGISTER("destruct_split_vbdev", spdk_rpc_destruct_split)
+SPDK_RPC_REGISTER("destruct_split_vbdev", spdk_rpc_destruct_split, SPDK_RPC_RUNTIME)
diff --git a/lib/bdev/virtio/bdev_virtio_blk.c b/lib/bdev/virtio/bdev_virtio_blk.c
index fdfd2a91c..261563994 100644
--- a/lib/bdev/virtio/bdev_virtio_blk.c
+++ b/lib/bdev/virtio/bdev_virtio_blk.c
@@ -37,13 +37,13 @@
 #include "spdk/conf.h"
 #include "spdk/endian.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
 #include "spdk/json.h"
 
 #include "spdk_internal/assert.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 #include "spdk_internal/virtio.h"
 
@@ -79,7 +79,9 @@ struct bdev_virtio_blk_io_channel {
 	(1ULL << VIRTIO_BLK_F_BLK_SIZE		|	\
 	 1ULL << VIRTIO_BLK_F_TOPOLOGY		|	\
 	 1ULL << VIRTIO_BLK_F_MQ		|	\
-	 1ULL << VIRTIO_BLK_F_RO)
+	 1ULL << VIRTIO_BLK_F_RO		|	\
+	 1ULL << VIRTIO_RING_F_EVENT_IDX	|	\
+	 1ULL << VHOST_USER_F_PROTOCOL_FEATURES)
 
 static int bdev_virtio_initialize(void);
 static int bdev_virtio_blk_get_ctx_size(void);
@@ -350,8 +352,13 @@ virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
 	int rc;
 
 	if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_BLK_SIZE)) {
-		virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, blk_size),
-					   &block_size, sizeof(block_size));
+		rc = virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, blk_size),
+						&block_size, sizeof(block_size));
+		if (rc) {
+			SPDK_ERRLOG("%s: config read failed: %s\n", vdev->name, spdk_strerror(-rc));
+			return rc;
+		}
+
 		if (block_size == 0 || block_size % 512 != 0) {
 			SPDK_ERRLOG("%s: invalid block size (%"PRIu32"). Must be "
 				    "a multiple of 512.\n", vdev->name, block_size);
@@ -361,8 +368,12 @@ virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
 		block_size = 512;
 	}
 
-	virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, capacity),
-				   &capacity, sizeof(capacity));
+	rc = virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, capacity),
+					&capacity, sizeof(capacity));
+	if (rc) {
+		SPDK_ERRLOG("%s: config read failed: %s\n", vdev->name, spdk_strerror(-rc));
+		return rc;
+	}
 
 	/* `capacity` is a number of 512-byte sectors. */
 	num_blocks = capacity * 512 / block_size;
@@ -379,8 +390,12 @@ virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
 	}
 
 	if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_MQ)) {
-		virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
-					   &host_max_queues, sizeof(host_max_queues));
+		rc = virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
+						&host_max_queues, sizeof(host_max_queues));
+		if (rc) {
+			SPDK_ERRLOG("%s: config read failed: %s\n", vdev->name, spdk_strerror(-rc));
+			return rc;
+		}
 	} else {
 		host_max_queues = 1;
 	}
@@ -404,14 +419,8 @@ virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
 
 	/* bdev is tied with the virtio device; we can reuse the name */
 	bdev->name = vdev->name;
-	if (bdev->name == NULL) {
-		SPDK_ERRLOG("Couldn't alloc memory for the bdev name.\n");
-		return -ENOMEM;
-	}
-
 	rc = virtio_dev_start(vdev, max_queues, 0);
 	if (rc != 0) {
-		free(bdev->name);
 		return rc;
 	}
 
@@ -433,7 +442,6 @@ virtio_blk_dev_init(struct virtio_blk_dev *bvdev, uint16_t max_queues)
 		SPDK_ERRLOG("Failed to register bdev name=%s\n", bdev->name);
 		spdk_io_device_unregister(bvdev, NULL);
 		virtio_dev_stop(vdev);
-		free(bdev->name);
 		return rc;
 	}
 
@@ -483,8 +491,14 @@ virtio_pci_blk_dev_create(const char *name, struct virtio_pci_ctx *pci_ctx)
 
 	/* TODO: add a way to limit usable virtqueues */
 	if (virtio_dev_has_feature(vdev, VIRTIO_BLK_F_MQ)) {
-		virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
-					   &num_queues, sizeof(num_queues));
+		rc = virtio_dev_read_dev_config(vdev, offsetof(struct virtio_blk_config, num_queues),
+						&num_queues, sizeof(num_queues));
+		if (rc) {
+			SPDK_ERRLOG("%s: config read failed: %s\n", vdev->name, spdk_strerror(-rc));
+			virtio_dev_destruct(vdev);
+			free(bvdev);
+			return NULL;
+		}
 	} else {
 		num_queues = 1;
 	}
diff --git a/lib/bdev/virtio/bdev_virtio_rpc.c b/lib/bdev/virtio/bdev_virtio_rpc.c
index 286465552..2a561d156 100644
--- a/lib/bdev/virtio/bdev_virtio_rpc.c
+++ b/lib/bdev/virtio/bdev_virtio_rpc.c
@@ -140,7 +140,8 @@ invalid:
 					 spdk_strerror(-rc));
 	free_rpc_construct_virtio_scsi_dev(req);
 }
-SPDK_RPC_REGISTER("construct_virtio_user_scsi_bdev", spdk_rpc_create_virtio_user_scsi_bdev);
+SPDK_RPC_REGISTER("construct_virtio_user_scsi_bdev", spdk_rpc_create_virtio_user_scsi_bdev,
+		  SPDK_RPC_RUNTIME);
 
 static const struct spdk_json_object_decoder rpc_construct_virtio_pci_scsi_dev[] = {
 	{"pci_address", offsetof(struct rpc_construct_virtio_scsi_dev, pci_address), spdk_json_decode_string },
@@ -190,7 +191,8 @@ invalid:
 					 spdk_strerror(-rc));
 	free_rpc_construct_virtio_scsi_dev(req);
 }
-SPDK_RPC_REGISTER("construct_virtio_pci_scsi_bdev", spdk_rpc_construct_virtio_pci_scsi_dev);
+SPDK_RPC_REGISTER("construct_virtio_pci_scsi_bdev", spdk_rpc_construct_virtio_pci_scsi_dev,
+		  SPDK_RPC_RUNTIME);
 
 struct rpc_remove_virtio_scsi_dev {
 	char *name;
@@ -266,7 +268,7 @@ invalid:
 					 spdk_strerror(-rc));
 	free_rpc_remove_virtio_scsi_dev(req);
 }
-SPDK_RPC_REGISTER("remove_virtio_scsi_bdev", spdk_rpc_remove_virtio_scsi_bdev);
+SPDK_RPC_REGISTER("remove_virtio_scsi_bdev", spdk_rpc_remove_virtio_scsi_bdev, SPDK_RPC_RUNTIME);
 
 static void
 spdk_rpc_get_virtio_scsi_devs(struct spdk_jsonrpc_request *request,
@@ -288,7 +290,7 @@ spdk_rpc_get_virtio_scsi_devs(struct spdk_jsonrpc_request *request,
 	bdev_virtio_scsi_dev_list(w);
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_virtio_scsi_devs", spdk_rpc_get_virtio_scsi_devs)
+SPDK_RPC_REGISTER("get_virtio_scsi_devs", spdk_rpc_get_virtio_scsi_devs, SPDK_RPC_RUNTIME)
 
 struct rpc_construct_virtio_blk_dev {
 	char *path;
@@ -329,11 +331,13 @@ spdk_rpc_create_virtio_user_blk_bdev(struct spdk_jsonrpc_request *request,
 	if (spdk_json_decode_object(params, rpc_construct_virtio_user_blk_dev,
 				    SPDK_COUNTOF(rpc_construct_virtio_user_blk_dev),
 				    &req)) {
+		free_rpc_construct_virtio_blk_dev(&req);
 		rc = -EINVAL;
 		goto invalid;
 	}
 
 	bdev = bdev_virtio_user_blk_dev_create(req.name, req.path, req.vq_count, req.vq_size);
+	free_rpc_construct_virtio_blk_dev(&req);
 	if (bdev == NULL) {
 		rc = -EINVAL;
 		goto invalid;
@@ -344,18 +348,16 @@ spdk_rpc_create_virtio_user_blk_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
 invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
-	free_rpc_construct_virtio_blk_dev(&req);
 }
-SPDK_RPC_REGISTER("construct_virtio_user_blk_bdev", spdk_rpc_create_virtio_user_blk_bdev);
+SPDK_RPC_REGISTER("construct_virtio_user_blk_bdev", spdk_rpc_create_virtio_user_blk_bdev,
+		  SPDK_RPC_RUNTIME);
 
 static const struct spdk_json_object_decoder rpc_construct_virtio_pci_blk_dev[] = {
 	{"pci_address", offsetof(struct rpc_construct_virtio_blk_dev, pci_address), spdk_json_decode_string },
@@ -377,17 +379,20 @@ spdk_rpc_create_virtio_pci_blk_bdev(struct spdk_jsonrpc_request *request,
 	if (spdk_json_decode_object(params, rpc_construct_virtio_pci_blk_dev,
 				    SPDK_COUNTOF(rpc_construct_virtio_pci_blk_dev),
 				    &req)) {
+		free_rpc_construct_virtio_blk_dev(&req);
 		rc = -EINVAL;
 		goto invalid;
 	}
 
 	if (spdk_pci_addr_parse(&pci_addr, req.pci_address) != 0) {
 		SPDK_ERRLOG("Invalid PCI address '%s'\n", req.pci_address);
+		free_rpc_construct_virtio_blk_dev(&req);
 		rc = -EINVAL;
 		goto invalid;
 	}
 
 	bdev = bdev_virtio_pci_blk_dev_create(req.name, &pci_addr);
+	free_rpc_construct_virtio_blk_dev(&req);
 	if (bdev == NULL) {
 		rc = -EINVAL;
 		goto invalid;
@@ -398,18 +403,16 @@ spdk_rpc_create_virtio_pci_blk_bdev(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_array_begin(w);
 	spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 	return;
 
 invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
-	free_rpc_construct_virtio_blk_dev(&req);
 }
-SPDK_RPC_REGISTER("construct_virtio_pci_blk_bdev", spdk_rpc_create_virtio_pci_blk_bdev);
+SPDK_RPC_REGISTER("construct_virtio_pci_blk_bdev", spdk_rpc_create_virtio_pci_blk_bdev,
+		  SPDK_RPC_RUNTIME);
 
 struct rpc_construct_virtio_dev {
 	char *name;
@@ -554,4 +557,4 @@ spdk_rpc_create_virtio_dev(struct spdk_jsonrpc_request *request,
 invalid:
 	free_rpc_construct_virtio_dev(req);
 }
-SPDK_RPC_REGISTER("construct_virtio_dev", spdk_rpc_create_virtio_dev);
+SPDK_RPC_REGISTER("construct_virtio_dev", spdk_rpc_create_virtio_dev, SPDK_RPC_RUNTIME);
diff --git a/lib/bdev/virtio/bdev_virtio_scsi.c b/lib/bdev/virtio/bdev_virtio_scsi.c
index 1727c4ecb..957c12187 100644
--- a/lib/bdev/virtio/bdev_virtio_scsi.c
+++ b/lib/bdev/virtio/bdev_virtio_scsi.c
@@ -37,13 +37,13 @@
 #include "spdk/conf.h"
 #include "spdk/endian.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/scsi_spec.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
 #include "spdk/json.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 #include "spdk_internal/virtio.h"
 
@@ -192,7 +192,9 @@ static bool g_bdev_virtio_finish = false;
 /* Features desired/implemented by this driver. */
 #define VIRTIO_SCSI_DEV_SUPPORTED_FEATURES		\
 	(1ULL << VIRTIO_SCSI_F_INOUT		|	\
-	 1ULL << VIRTIO_SCSI_F_HOTPLUG)
+	 1ULL << VIRTIO_SCSI_F_HOTPLUG		|	\
+	 1ULL << VIRTIO_RING_F_EVENT_IDX	|	\
+	 1ULL << VHOST_USER_F_PROTOCOL_FEATURES)
 
 static void virtio_scsi_dev_unregister_cb(void *io_device);
 static void virtio_scsi_dev_remove(struct virtio_scsi_dev *svdev,
@@ -335,8 +337,14 @@ virtio_pci_scsi_dev_create(const char *name, struct virtio_pci_ctx *pci_ctx)
 		return NULL;
 	}
 
-	virtio_dev_read_dev_config(vdev, offsetof(struct virtio_scsi_config, num_queues),
-				   &num_queues, sizeof(num_queues));
+	rc = virtio_dev_read_dev_config(vdev, offsetof(struct virtio_scsi_config, num_queues),
+					&num_queues, sizeof(num_queues));
+	if (rc) {
+		SPDK_ERRLOG("%s: config read failed: %s\n", vdev->name, spdk_strerror(-rc));
+		virtio_dev_destruct(vdev);
+		free(svdev);
+		return NULL;
+	}
 
 	rc = virtio_scsi_dev_init(svdev, num_queues);
 	if (rc != 0) {
@@ -578,7 +586,7 @@ bdev_virtio_unmap(struct spdk_io_channel *ch, struct spdk_bdev_io *bdev_io)
 	uint64_t offset_blocks, num_blocks;
 	uint16_t cmd_len;
 
-	buf = bdev_io->u.bdev.iov.iov_base;
+	buf = bdev_io->u.bdev.iovs[0].iov_base;
 
 	offset_blocks = bdev_io->u.bdev.offset_blocks;
 	num_blocks = bdev_io->u.bdev.num_blocks;
@@ -1303,6 +1311,12 @@ virtio_scsi_dev_add_tgt(struct virtio_scsi_dev *svdev, struct virtio_scsi_scan_i
 		}
 	}
 
+	if (info->block_size == 0 || info->num_blocks == 0) {
+		SPDK_ERRLOG("%s: invalid target %u: bs=%"PRIu32" blocks=%"PRIu64"\n",
+			    svdev->vdev.name, info->target, info->block_size, info->num_blocks);
+		return -EINVAL;
+	}
+
 	disk = calloc(1, sizeof(*disk));
 	if (disk == NULL) {
 		SPDK_ERRLOG("could not allocate disk\n");
diff --git a/lib/blob/bdev/blob_bdev.c b/lib/blob/bdev/blob_bdev.c
index fbe516db2..c42ed70df 100644
--- a/lib/blob/bdev/blob_bdev.c
+++ b/lib/blob/bdev/blob_bdev.c
@@ -35,10 +35,10 @@
 
 #include "spdk/blob_bdev.h"
 #include "spdk/blob.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 #include "spdk/endian.h"
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 struct blob_bdev {
 	struct spdk_bs_dev	bs_dev;
diff --git a/lib/blob/blobstore.c b/lib/blob/blobstore.c
index 2de4af703..bcbd616fa 100644
--- a/lib/blob/blobstore.c
+++ b/lib/blob/blobstore.c
@@ -37,7 +37,7 @@
 #include "spdk/crc32.h"
 #include "spdk/env.h"
 #include "spdk/queue.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/bit_array.h"
 #include "spdk/likely.h"
 
@@ -51,7 +51,7 @@
 static int spdk_bs_register_md_thread(struct spdk_blob_store *bs);
 static int spdk_bs_unregister_md_thread(struct spdk_blob_store *bs);
 static void _spdk_blob_close_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno);
-void _spdk_blob_insert_cluster_on_md_thread(struct spdk_blob *blob, uint32_t cluster_num,
+static void _spdk_blob_insert_cluster_on_md_thread(struct spdk_blob *blob, uint32_t cluster_num,
 		uint64_t cluster, spdk_blob_op_complete cb_fn, void *cb_arg);
 
 static int _spdk_blob_set_xattr(struct spdk_blob *blob, const char *name, const void *value,
@@ -222,6 +222,105 @@ _spdk_blob_free(struct spdk_blob *blob)
 	free(blob);
 }
 
+struct freeze_io_ctx {
+	struct spdk_bs_cpl cpl;
+	struct spdk_blob *blob;
+};
+
+static void
+_spdk_blob_io_sync(struct spdk_io_channel_iter *i)
+{
+	spdk_for_each_channel_continue(i, 0);
+}
+
+static void
+_spdk_blob_execute_queued_io(struct spdk_io_channel_iter *i)
+{
+	struct spdk_io_channel *_ch = spdk_io_channel_iter_get_channel(i);
+	struct spdk_bs_channel *ch = spdk_io_channel_get_ctx(_ch);
+	struct freeze_io_ctx *ctx = spdk_io_channel_iter_get_ctx(i);
+	struct spdk_bs_request_set	*set;
+	struct spdk_bs_user_op_args	*args;
+	spdk_bs_user_op_t *op, *tmp;
+
+	TAILQ_FOREACH_SAFE(op, &ch->queued_io, link, tmp) {
+		set = (struct spdk_bs_request_set *)op;
+		args = &set->u.user_op;
+
+		if (args->blob == ctx->blob) {
+			TAILQ_REMOVE(&ch->queued_io, op, link);
+			spdk_bs_user_op_execute(op);
+		}
+	}
+
+	spdk_for_each_channel_continue(i, 0);
+}
+
+static void
+_spdk_blob_io_cpl(struct spdk_io_channel_iter *i, int status)
+{
+	struct freeze_io_ctx *ctx = spdk_io_channel_iter_get_ctx(i);
+
+	ctx->cpl.u.blob_basic.cb_fn(ctx->cpl.u.blob_basic.cb_arg, 0);
+
+	free(ctx);
+}
+
+static void
+_spdk_blob_freeze_io(struct spdk_blob *blob, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	struct freeze_io_ctx *ctx;
+
+	ctx = calloc(1, sizeof(*ctx));
+	if (!ctx) {
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	ctx->cpl.type = SPDK_BS_CPL_TYPE_BS_BASIC;
+	ctx->cpl.u.blob_basic.cb_fn = cb_fn;
+	ctx->cpl.u.blob_basic.cb_arg = cb_arg;
+	ctx->blob = blob;
+
+	/* Freeze I/O on blob */
+	blob->frozen_refcnt++;
+
+	if (blob->frozen_refcnt == 1) {
+		spdk_for_each_channel(blob->bs, _spdk_blob_io_sync, ctx, _spdk_blob_io_cpl);
+	} else {
+		cb_fn(cb_arg, 0);
+		free(ctx);
+	}
+}
+
+static void
+_spdk_blob_unfreeze_io(struct spdk_blob *blob, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	struct freeze_io_ctx *ctx;
+
+	ctx = calloc(1, sizeof(*ctx));
+	if (!ctx) {
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	ctx->cpl.type = SPDK_BS_CPL_TYPE_BS_BASIC;
+	ctx->cpl.u.blob_basic.cb_fn = cb_fn;
+	ctx->cpl.u.blob_basic.cb_arg = cb_arg;
+	ctx->blob = blob;
+
+	assert(blob->frozen_refcnt > 0);
+
+	blob->frozen_refcnt--;
+
+	if (blob->frozen_refcnt == 0) {
+		spdk_for_each_channel(blob->bs, _spdk_blob_execute_queued_io, ctx, _spdk_blob_io_cpl);
+	} else {
+		cb_fn(cb_arg, 0);
+		free(ctx);
+	}
+}
+
 static int
 _spdk_blob_mark_clean(struct spdk_blob *blob)
 {
@@ -234,7 +333,7 @@ _spdk_blob_mark_clean(struct spdk_blob *blob)
 		assert(blob->active.clusters);
 		clusters = calloc(blob->active.num_clusters, sizeof(*blob->active.clusters));
 		if (!clusters) {
-			return -1;
+			return -ENOMEM;
 		}
 		memcpy(clusters, blob->active.clusters, blob->active.num_clusters * sizeof(*clusters));
 	}
@@ -244,7 +343,7 @@ _spdk_blob_mark_clean(struct spdk_blob *blob)
 		pages = calloc(blob->active.num_pages, sizeof(*blob->active.pages));
 		if (!pages) {
 			free(clusters);
-			return -1;
+			return -ENOMEM;
 		}
 		memcpy(pages, blob->active.pages, blob->active.num_pages * sizeof(*pages));
 	}
@@ -374,9 +473,11 @@ _spdk_blob_parse_page(const struct spdk_blob_md_page *page, struct spdk_blob *bl
 
 			for (i = 0; i < desc_extent->length / sizeof(desc_extent->extents[0]); i++) {
 				for (j = 0; j < desc_extent->extents[i].length; j++) {
-					if (!spdk_bit_array_get(blob->bs->used_clusters,
-								desc_extent->extents[i].cluster_idx + j)) {
-						return -EINVAL;
+					if (desc_extent->extents[i].cluster_idx != 0) {
+						if (!spdk_bit_array_get(blob->bs->used_clusters,
+									desc_extent->extents[i].cluster_idx + j)) {
+							return -EINVAL;
+						}
 					}
 					cluster_count++;
 				}
@@ -566,7 +667,7 @@ _spdk_blob_serialize_extent(const struct spdk_blob *blob,
 	struct spdk_blob_md_descriptor_extent *desc;
 	size_t cur_sz;
 	uint64_t i, extent_idx;
-	uint32_t lba, lba_per_cluster, lba_count;
+	uint64_t lba, lba_per_cluster, lba_count;
 
 	/* The buffer must have room for at least one extent */
 	cur_sz = sizeof(struct spdk_blob_md_descriptor) + sizeof(desc->extents[0]);
@@ -587,6 +688,9 @@ _spdk_blob_serialize_extent(const struct spdk_blob *blob,
 		if ((lba + lba_count) == blob->active.clusters[i]) {
 			lba_count += lba_per_cluster;
 			continue;
+		} else if (lba == 0 && blob->active.clusters[i] == 0) {
+			lba_count += lba_per_cluster;
+			continue;
 		}
 		desc->extents[extent_idx].cluster_idx = lba / lba_per_cluster;
 		desc->extents[extent_idx].length = lba_count / lba_per_cluster;
@@ -678,7 +782,7 @@ _spdk_blob_serialize_xattrs(const struct spdk_blob *blob,
 				spdk_dma_free(*pages);
 				*pages = NULL;
 				*page_count = 0;
-				return -1;
+				return rc;
 			}
 		}
 
@@ -953,6 +1057,8 @@ _spdk_blob_load(spdk_bs_sequence_t *seq, struct spdk_blob *blob,
 struct spdk_blob_persist_ctx {
 	struct spdk_blob		*blob;
 
+	struct spdk_bs_super_block	*super;
+
 	struct spdk_blob_md_page	*pages;
 
 	uint64_t			idx;
@@ -1277,6 +1383,7 @@ _spdk_blob_persist_start(struct spdk_blob_persist_ctx *ctx)
 	struct spdk_blob_store *bs = blob->bs;
 	uint64_t i;
 	uint32_t page_num;
+	void *tmp;
 	int rc;
 
 	if (blob->active.num_pages == 0) {
@@ -1300,12 +1407,12 @@ _spdk_blob_persist_start(struct spdk_blob_persist_ctx *ctx)
 	assert(blob->active.num_pages >= 1);
 
 	/* Resize the cache of page indices */
-	blob->active.pages = realloc(blob->active.pages,
-				     blob->active.num_pages * sizeof(*blob->active.pages));
-	if (!blob->active.pages) {
+	tmp = realloc(blob->active.pages, blob->active.num_pages * sizeof(*blob->active.pages));
+	if (!tmp) {
 		_spdk_blob_persist_complete(seq, ctx, -ENOMEM);
 		return;
 	}
+	blob->active.pages = tmp;
 
 	/* Assign this metadata to pages. This requires two passes -
 	 * one to verify that there are enough pages and a second
@@ -1340,6 +1447,37 @@ _spdk_blob_persist_start(struct spdk_blob_persist_ctx *ctx)
 	_spdk_blob_persist_write_page_chain(seq, ctx, 0);
 }
 
+static void
+_spdk_blob_persist_dirty_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_blob_persist_ctx *ctx = cb_arg;
+
+	ctx->blob->bs->clean = 0;
+
+	spdk_dma_free(ctx->super);
+
+	_spdk_blob_persist_start(ctx);
+}
+
+static void
+_spdk_bs_write_super(spdk_bs_sequence_t *seq, struct spdk_blob_store *bs,
+		     struct spdk_bs_super_block *super, spdk_bs_sequence_cpl cb_fn, void *cb_arg);
+
+
+static void
+_spdk_blob_persist_dirty(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_blob_persist_ctx *ctx = cb_arg;
+
+	ctx->super->clean = 0;
+	if (ctx->super->size == 0) {
+		ctx->super->size = ctx->blob->bs->dev->blockcnt * ctx->blob->bs->dev->blocklen;
+	}
+
+	_spdk_bs_write_super(seq, ctx->blob->bs, ctx->super, _spdk_blob_persist_dirty_cpl, ctx);
+}
+
+
 /* Write a blob to disk */
 static void
 _spdk_blob_persist(spdk_bs_sequence_t *seq, struct spdk_blob *blob,
@@ -1364,7 +1502,20 @@ _spdk_blob_persist(spdk_bs_sequence_t *seq, struct spdk_blob *blob,
 	ctx->cb_fn = cb_fn;
 	ctx->cb_arg = cb_arg;
 
-	_spdk_blob_persist_start(ctx);
+	if (blob->bs->clean) {
+		ctx->super = spdk_dma_zmalloc(sizeof(*ctx->super), 0x1000, NULL);
+		if (!ctx->super) {
+			cb_fn(seq, cb_arg, -ENOMEM);
+			free(ctx);
+			return;
+		}
+
+		spdk_bs_sequence_read_dev(seq, ctx->super, _spdk_bs_page_to_lba(blob->bs, 0),
+					  _spdk_bs_byte_to_lba(blob->bs, sizeof(*ctx->super)),
+					  _spdk_blob_persist_dirty, ctx);
+	} else {
+		_spdk_blob_persist_start(ctx);
+	}
 }
 
 struct spdk_blob_copy_cluster_ctx {
@@ -1498,13 +1649,15 @@ _spdk_bs_allocate_and_copy_cluster(struct spdk_blob *blob,
 	ctx->blob = blob;
 	ctx->page = cluster_start_page;
 
-	ctx->buf = spdk_dma_malloc(blob->bs->cluster_sz, blob->back_bs_dev->blocklen, NULL);
-	if (!ctx->buf) {
-		SPDK_ERRLOG("DMA allocation for cluster of size = %" PRIu32 " failed.\n",
-			    blob->bs->cluster_sz);
-		free(ctx);
-		spdk_bs_user_op_abort(op);
-		return;
+	if (blob->parent_id != SPDK_BLOBID_INVALID) {
+		ctx->buf = spdk_dma_malloc(blob->bs->cluster_sz, blob->back_bs_dev->blocklen, NULL);
+		if (!ctx->buf) {
+			SPDK_ERRLOG("DMA allocation for cluster of size = %" PRIu32 " failed.\n",
+				    blob->bs->cluster_sz);
+			free(ctx);
+			spdk_bs_user_op_abort(op);
+			return;
+		}
 	}
 
 	rc = _spdk_bs_allocate_cluster(blob, cluster_number, &ctx->new_cluster, false);
@@ -1531,11 +1684,16 @@ _spdk_bs_allocate_and_copy_cluster(struct spdk_blob *blob,
 	/* Queue the user op to block other incoming operations */
 	TAILQ_INSERT_TAIL(&ch->need_cluster_alloc, op, link);
 
-	/* Read cluster from backing device */
-	spdk_bs_sequence_read_bs_dev(ctx->seq, blob->back_bs_dev, ctx->buf,
-				     _spdk_bs_dev_page_to_lba(blob->back_bs_dev, cluster_start_page),
-				     _spdk_bs_dev_byte_to_lba(blob->back_bs_dev, blob->bs->cluster_sz),
-				     _spdk_blob_write_copy, ctx);
+	if (blob->parent_id != SPDK_BLOBID_INVALID) {
+		/* Read cluster from backing device */
+		spdk_bs_sequence_read_bs_dev(ctx->seq, blob->back_bs_dev, ctx->buf,
+					     _spdk_bs_dev_page_to_lba(blob->back_bs_dev, cluster_start_page),
+					     _spdk_bs_dev_byte_to_lba(blob->back_bs_dev, blob->bs->cluster_sz),
+					     _spdk_blob_write_copy, ctx);
+	} else {
+		_spdk_blob_insert_cluster_on_md_thread(ctx->blob, cluster_number, ctx->new_cluster,
+						       _spdk_blob_insert_cluster_cpl, ctx);
+	}
 }
 
 static void
@@ -1672,6 +1830,22 @@ _spdk_blob_request_submit_op_single(struct spdk_io_channel *_ch, struct spdk_blo
 
 	_spdk_blob_calculate_lba_and_lba_count(blob, offset, length, &lba, &lba_count);
 
+	if (blob->frozen_refcnt) {
+		/* This blob I/O is frozen */
+		spdk_bs_user_op_t *op;
+		struct spdk_bs_channel *bs_channel = spdk_io_channel_get_ctx(_ch);
+
+		op = spdk_bs_user_op_alloc(_ch, &cpl, op_type, blob, payload, 0, offset, length);
+		if (!op) {
+			cb_fn(cb_arg, -ENOMEM);
+			return;
+		}
+
+		TAILQ_INSERT_TAIL(&bs_channel->queued_io, op, link);
+
+		return;
+	}
+
 	switch (op_type) {
 	case SPDK_BLOB_READ: {
 		spdk_bs_batch_t *batch;
@@ -1699,6 +1873,11 @@ _spdk_blob_request_submit_op_single(struct spdk_io_channel *_ch, struct spdk_blo
 			/* Write to the blob */
 			spdk_bs_batch_t *batch;
 
+			if (lba_count == 0) {
+				cb_fn(cb_arg, 0);
+				return;
+			}
+
 			batch = spdk_bs_batch_open(_ch, &cpl);
 			if (!batch) {
 				cb_fn(cb_arg, -ENOMEM);
@@ -1914,6 +2093,21 @@ _spdk_blob_request_submit_rw_iov(struct spdk_blob *blob, struct spdk_io_channel
 		cpl.type = SPDK_BS_CPL_TYPE_BLOB_BASIC;
 		cpl.u.blob_basic.cb_fn = cb_fn;
 		cpl.u.blob_basic.cb_arg = cb_arg;
+		if (blob->frozen_refcnt) {
+			/* This blob I/O is frozen */
+			spdk_bs_user_op_t *op;
+			struct spdk_bs_channel *bs_channel = spdk_io_channel_get_ctx(_channel);
+
+			op = spdk_bs_user_op_alloc(_channel, &cpl, read, blob, iov, iovcnt, offset, length);
+			if (!op) {
+				cb_fn(cb_arg, -ENOMEM);
+				return;
+			}
+
+			TAILQ_INSERT_TAIL(&bs_channel->queued_io, op, link);
+
+			return;
+		}
 
 		if (read) {
 			spdk_bs_sequence_t *seq;
@@ -2025,6 +2219,7 @@ _spdk_bs_channel_create(void *io_device, void *ctx_buf)
 	}
 
 	TAILQ_INIT(&channel->need_cluster_alloc);
+	TAILQ_INIT(&channel->queued_io);
 
 	return 0;
 }
@@ -2041,6 +2236,12 @@ _spdk_bs_channel_destroy(void *io_device, void *ctx_buf)
 		spdk_bs_user_op_abort(op);
 	}
 
+	while (!TAILQ_EMPTY(&channel->queued_io)) {
+		op = TAILQ_FIRST(&channel->queued_io);
+		TAILQ_REMOVE(&channel->queued_io, op, link);
+		spdk_bs_user_op_abort(op);
+	}
+
 	free(channel->req_mem);
 	channel->dev->destroy_channel(channel->dev, channel->dev_channel);
 }
@@ -2342,6 +2543,26 @@ _spdk_bs_set_mask(struct spdk_bit_array *array, struct spdk_bs_md_mask *mask)
 	}
 }
 
+static int
+_spdk_bs_load_mask(struct spdk_bit_array **array_ptr, struct spdk_bs_md_mask *mask)
+{
+	struct spdk_bit_array *array;
+	uint32_t i;
+
+	if (spdk_bit_array_resize(array_ptr, mask->length) < 0) {
+		return -ENOMEM;
+	}
+
+	array = *array_ptr;
+	for (i = 0; i < mask->length; i++) {
+		if (mask->mask[i / 8] & (1U << (i % 8))) {
+			spdk_bit_array_set(array, i);
+		}
+	}
+
+	return 0;
+}
+
 static void
 _spdk_bs_write_super(spdk_bs_sequence_t *seq, struct spdk_blob_store *bs,
 		     struct spdk_bs_super_block *super, spdk_bs_sequence_cpl cb_fn, void *cb_arg)
@@ -2479,7 +2700,6 @@ static void
 _spdk_bs_load_used_blobids_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 {
 	struct spdk_bs_load_ctx *ctx = cb_arg;
-	uint32_t i, j;
 	int rc;
 
 	/* The type must be correct */
@@ -2493,23 +2713,13 @@ _spdk_bs_load_used_blobids_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrn
 	 * (in pages) of the metadata region */
 	assert(ctx->mask->length == ctx->super->md_len);
 
-	rc = spdk_bit_array_resize(&ctx->bs->used_blobids, ctx->mask->length);
+	rc = _spdk_bs_load_mask(&ctx->bs->used_blobids, ctx->mask);
 	if (rc < 0) {
 		spdk_dma_free(ctx->mask);
-		_spdk_bs_load_ctx_fail(seq, ctx, -ENOMEM);
+		_spdk_bs_load_ctx_fail(seq, ctx, rc);
 		return;
 	}
 
-	for (i = 0; i < ctx->mask->length / 8; i++) {
-		uint8_t segment = ctx->mask->mask[i];
-		for (j = 0; segment; j++) {
-			if (segment & 1U) {
-				spdk_bit_array_set(ctx->bs->used_blobids, (i * 8) + j);
-			}
-			segment >>= 1U;
-		}
-	}
-
 	_spdk_bs_load_complete(seq, ctx, bserrno);
 }
 
@@ -2518,7 +2728,6 @@ _spdk_bs_load_used_clusters_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserr
 {
 	struct spdk_bs_load_ctx *ctx = cb_arg;
 	uint64_t		lba, lba_count, mask_size;
-	uint32_t		i, j;
 	int			rc;
 
 	/* The type must be correct */
@@ -2529,25 +2738,15 @@ _spdk_bs_load_used_clusters_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserr
 	/* The length of the mask must be exactly equal to the total number of clusters */
 	assert(ctx->mask->length == ctx->bs->total_clusters);
 
-	rc = spdk_bit_array_resize(&ctx->bs->used_clusters, ctx->bs->total_clusters);
+	rc = _spdk_bs_load_mask(&ctx->bs->used_clusters, ctx->mask);
 	if (rc < 0) {
 		spdk_dma_free(ctx->mask);
-		_spdk_bs_load_ctx_fail(seq, ctx, -ENOMEM);
+		_spdk_bs_load_ctx_fail(seq, ctx, rc);
 		return;
 	}
 
-	ctx->bs->num_free_clusters = ctx->bs->total_clusters;
-	for (i = 0; i < ctx->mask->length / 8; i++) {
-		uint8_t segment = ctx->mask->mask[i];
-		for (j = 0; segment && (j < 8); j++) {
-			if (segment & 1U) {
-				spdk_bit_array_set(ctx->bs->used_clusters, (i * 8) + j);
-				assert(ctx->bs->num_free_clusters > 0);
-				ctx->bs->num_free_clusters--;
-			}
-			segment >>= 1U;
-		}
-	}
+	ctx->bs->num_free_clusters = spdk_bit_array_count_clear(ctx->bs->used_clusters);
+	assert(ctx->bs->num_free_clusters <= ctx->bs->total_clusters);
 
 	spdk_dma_free(ctx->mask);
 
@@ -2569,7 +2768,6 @@ _spdk_bs_load_used_pages_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 {
 	struct spdk_bs_load_ctx *ctx = cb_arg;
 	uint64_t		lba, lba_count, mask_size;
-	uint32_t		i, j;
 	int			rc;
 
 	/* The type must be correct */
@@ -2580,22 +2778,13 @@ _spdk_bs_load_used_pages_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 	/* The length of the mask must be exactly equal to the size (in pages) of the metadata region */
 	assert(ctx->mask->length == ctx->super->md_len);
 
-	rc = spdk_bit_array_resize(&ctx->bs->used_md_pages, ctx->mask->length);
+	rc = _spdk_bs_load_mask(&ctx->bs->used_md_pages, ctx->mask);
 	if (rc < 0) {
 		spdk_dma_free(ctx->mask);
-		_spdk_bs_load_ctx_fail(seq, ctx, -ENOMEM);
+		_spdk_bs_load_ctx_fail(seq, ctx, rc);
 		return;
 	}
 
-	for (i = 0; i < ctx->mask->length / 8; i++) {
-		uint8_t segment = ctx->mask->mask[i];
-		for (j = 0; segment && (j < 8); j++) {
-			if (segment & 1U) {
-				spdk_bit_array_set(ctx->bs->used_md_pages, (i * 8) + j);
-			}
-			segment >>= 1U;
-		}
-	}
 	spdk_dma_free(ctx->mask);
 
 	/* Read the used clusters mask */
@@ -2612,7 +2801,7 @@ _spdk_bs_load_used_pages_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 }
 
 static void
-_spdk_bs_load_write_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+_spdk_bs_load_read_used_pages(spdk_bs_sequence_t *seq, void *cb_arg)
 {
 	struct spdk_bs_load_ctx	*ctx = cb_arg;
 	uint64_t lba, lba_count, mask_size;
@@ -2648,21 +2837,29 @@ _spdk_bs_load_replay_md_parse_page(const struct spdk_blob_md_page *page, struct
 			struct spdk_blob_md_descriptor_extent	*desc_extent;
 			unsigned int				i, j;
 			unsigned int				cluster_count = 0;
+			uint32_t				cluster_idx;
 
 			desc_extent = (struct spdk_blob_md_descriptor_extent *)desc;
 
 			for (i = 0; i < desc_extent->length / sizeof(desc_extent->extents[0]); i++) {
 				for (j = 0; j < desc_extent->extents[i].length; j++) {
-					spdk_bit_array_set(bs->used_clusters, desc_extent->extents[i].cluster_idx + j);
-					if (bs->num_free_clusters == 0) {
-						return -1;
+					cluster_idx = desc_extent->extents[i].cluster_idx;
+					/*
+					 * cluster_idx = 0 means an unallocated cluster - don't mark that
+					 * in the used cluster map.
+					 */
+					if (cluster_idx != 0) {
+						spdk_bit_array_set(bs->used_clusters, cluster_idx + j);
+						if (bs->num_free_clusters == 0) {
+							return -ENOSPC;
+						}
+						bs->num_free_clusters--;
 					}
-					bs->num_free_clusters--;
 					cluster_count++;
 				}
 			}
 			if (cluster_count == 0) {
-				return -1;
+				return -EINVAL;
 			}
 		} else if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_XATTR) {
 			/* Skip this item */
@@ -2672,7 +2869,7 @@ _spdk_bs_load_replay_md_parse_page(const struct spdk_blob_md_page *page, struct
 			/* Skip this item */
 		} else {
 			/* Error */
-			return -1;
+			return -EINVAL;
 		}
 		/* Advance to the next descriptor */
 		cur_desc += sizeof(*desc) + desc->length;
@@ -2822,16 +3019,11 @@ _spdk_bs_load_replay_md(spdk_bs_sequence_t *seq, void *cb_arg)
 }
 
 static void
-_spdk_bs_recover(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+_spdk_bs_recover(spdk_bs_sequence_t *seq, void *cb_arg)
 {
 	struct spdk_bs_load_ctx *ctx = cb_arg;
 	int		rc;
 
-	if (bserrno != 0) {
-		_spdk_bs_load_ctx_fail(seq, ctx, -EIO);
-		return;
-	}
-
 	rc = spdk_bit_array_resize(&ctx->bs->used_md_pages, ctx->super->md_len);
 	if (rc < 0) {
 		_spdk_bs_load_ctx_fail(seq, ctx, -ENOMEM);
@@ -2891,9 +3083,21 @@ _spdk_bs_load_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 		return;
 	}
 
+	if (ctx->super->size == 0) {
+		/* Update number of blocks for blobstore */
+		ctx->bs->total_clusters = ctx->bs->dev->blockcnt * ctx->bs->dev->blocklen / ctx->bs->cluster_sz;
+	} else if (ctx->super->size > ctx->bs->dev->blockcnt * ctx->bs->dev->blocklen) {
+		SPDK_NOTICELOG("Size mismatch, dev size: %lu, blobstore size: %lu\n",
+			       ctx->bs->dev->blockcnt * ctx->bs->dev->blocklen, ctx->super->size);
+		_spdk_bs_load_ctx_fail(seq, ctx, -EILSEQ);
+		return;
+	} else {
+		ctx->bs->total_clusters = ctx->super->size / ctx->bs->cluster_sz;
+	}
+
 	/* Parse the super block */
+	ctx->bs->clean = 1;
 	ctx->bs->cluster_sz = ctx->super->cluster_size;
-	ctx->bs->total_clusters = ctx->bs->dev->blockcnt / (ctx->bs->cluster_sz / ctx->bs->dev->blocklen);
 	ctx->bs->pages_per_cluster = ctx->bs->cluster_sz / SPDK_BS_PAGE_SIZE;
 	ctx->bs->md_start = ctx->super->md_start;
 	ctx->bs->md_len = ctx->super->md_len;
@@ -2902,19 +3106,10 @@ _spdk_bs_load_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
 	ctx->bs->super_blob = ctx->super->super_blob;
 	memcpy(&ctx->bs->bstype, &ctx->super->bstype, sizeof(ctx->super->bstype));
 
-	if (ctx->super->clean == 0) {
-		_spdk_bs_recover(seq, ctx, 0);
-	} else if (ctx->super->used_blobid_mask_len == 0) {
-		/*
-		 * Metadata is clean, but this is an old metadata format without
-		 *  a blobid mask.  Clear the clean bit and then build the masks
-		 *  using _spdk_bs_recover.
-		 */
-		ctx->super->clean = 0;
-		_spdk_bs_write_super(seq, ctx->bs, ctx->super, _spdk_bs_recover, ctx);
+	if (ctx->super->used_blobid_mask_len == 0 || ctx->super->clean == 0) {
+		_spdk_bs_recover(seq, ctx);
 	} else {
-		ctx->super->clean = 0;
-		_spdk_bs_write_super(seq, ctx->bs, ctx->super, _spdk_bs_load_write_super_cpl, ctx);
+		_spdk_bs_load_read_used_pages(seq, ctx);
 	}
 }
 
@@ -2973,6 +3168,7 @@ spdk_bs_load(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
 	if (!ctx->super) {
 		free(ctx);
 		_spdk_bs_free(bs);
+		cb_fn(cb_arg, NULL, -ENOMEM);
 		return;
 	}
 
@@ -2998,70 +3194,334 @@ spdk_bs_load(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
 
 /* END spdk_bs_load */
 
-/* START spdk_bs_init */
+/* START spdk_bs_dump */
 
-struct spdk_bs_init_ctx {
+struct spdk_bs_dump_ctx {
 	struct spdk_blob_store		*bs;
 	struct spdk_bs_super_block	*super;
+	uint32_t			cur_page;
+	struct spdk_blob_md_page	*page;
+	spdk_bs_sequence_t		*seq;
+	FILE				*fp;
+	spdk_bs_dump_print_xattr	print_xattr_fn;
+	char				xattr_name[4096];
 };
 
 static void
-_spdk_bs_init_persist_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+_spdk_bs_dump_finish(spdk_bs_sequence_t *seq, struct spdk_bs_dump_ctx *ctx, int bserrno)
 {
-	struct spdk_bs_init_ctx *ctx = cb_arg;
-
 	spdk_dma_free(ctx->super);
-	free(ctx);
 
-	spdk_bs_sequence_finish(seq, bserrno);
+	/*
+	 * We need to defer calling spdk_bs_call_cpl() until after
+	 * dev destuction, so tuck these away for later use.
+	 */
+	ctx->bs->unload_err = bserrno;
+	memcpy(&ctx->bs->unload_cpl, &seq->cpl, sizeof(struct spdk_bs_cpl));
+	seq->cpl.type = SPDK_BS_CPL_TYPE_NONE;
+
+	spdk_bs_sequence_finish(seq, 0);
+	_spdk_bs_free(ctx->bs);
+	free(ctx);
 }
 
+static void _spdk_bs_dump_read_md_page(spdk_bs_sequence_t *seq, void *cb_arg);
+
 static void
-_spdk_bs_init_trim_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+_spdk_bs_dump_print_md_page(struct spdk_bs_dump_ctx *ctx)
 {
-	struct spdk_bs_init_ctx *ctx = cb_arg;
+	uint32_t page_idx = ctx->cur_page;
+	struct spdk_blob_md_page *page = ctx->page;
+	struct spdk_blob_md_descriptor *desc;
+	size_t cur_desc = 0;
+	uint32_t crc;
 
-	/* Write super block */
-	spdk_bs_sequence_write_dev(seq, ctx->super, _spdk_bs_page_to_lba(ctx->bs, 0),
-				   _spdk_bs_byte_to_lba(ctx->bs, sizeof(*ctx->super)),
-				   _spdk_bs_init_persist_super_cpl, ctx);
-}
+	fprintf(ctx->fp, "=========\n");
+	fprintf(ctx->fp, "Metadata Page Index: %" PRIu32 " (0x%" PRIx32 ")\n", page_idx, page_idx);
+	fprintf(ctx->fp, "Blob ID: 0x%" PRIx64 "\n", page->id);
 
-void
-spdk_bs_init(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
-	     spdk_bs_op_with_handle_complete cb_fn, void *cb_arg)
-{
-	struct spdk_bs_init_ctx *ctx;
-	struct spdk_blob_store	*bs;
-	struct spdk_bs_cpl	cpl;
-	spdk_bs_sequence_t	*seq;
-	spdk_bs_batch_t		*batch;
-	uint64_t		num_md_lba;
-	uint64_t		num_md_pages;
-	uint64_t		num_md_clusters;
-	uint32_t		i;
-	struct spdk_bs_opts	opts = {};
-	int			rc;
+	crc = _spdk_blob_md_page_calc_crc(page);
+	fprintf(ctx->fp, "CRC: 0x%" PRIx32 " (%s)\n", page->crc, crc == page->crc ? "OK" : "Mismatch");
 
-	SPDK_DEBUGLOG(SPDK_LOG_BLOB, "Initializing blobstore on dev %p\n", dev);
+	desc = (struct spdk_blob_md_descriptor *)page->descriptors;
+	while (cur_desc < sizeof(page->descriptors)) {
+		if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_PADDING) {
+			if (desc->length == 0) {
+				/* If padding and length are 0, this terminates the page */
+				break;
+			}
+		} else if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_EXTENT) {
+			struct spdk_blob_md_descriptor_extent	*desc_extent;
+			unsigned int				i;
 
-	if ((SPDK_BS_PAGE_SIZE % dev->blocklen) != 0) {
-		SPDK_ERRLOG("unsupported dev block length of %d\n",
-			    dev->blocklen);
-		dev->destroy(dev);
-		cb_fn(cb_arg, NULL, -EINVAL);
-		return;
-	}
+			desc_extent = (struct spdk_blob_md_descriptor_extent *)desc;
 
-	if (o) {
-		opts = *o;
-	} else {
-		spdk_bs_opts_init(&opts);
-	}
+			for (i = 0; i < desc_extent->length / sizeof(desc_extent->extents[0]); i++) {
+				if (desc_extent->extents[i].cluster_idx != 0) {
+					fprintf(ctx->fp, "Allocated Extent - Start: %" PRIu32,
+						desc_extent->extents[i].cluster_idx);
+				} else {
+					fprintf(ctx->fp, "Unallocated Extent - ");
+				}
+				fprintf(ctx->fp, " Length: %" PRIu32, desc_extent->extents[i].length);
+				fprintf(ctx->fp, "\n");
+			}
+		} else if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_XATTR) {
+			struct spdk_blob_md_descriptor_xattr *desc_xattr;
+			uint32_t i;
 
-	if (_spdk_bs_opts_verify(&opts) != 0) {
-		dev->destroy(dev);
-		cb_fn(cb_arg, NULL, -EINVAL);
+			desc_xattr = (struct spdk_blob_md_descriptor_xattr *)desc;
+
+			if (desc_xattr->length !=
+			    sizeof(desc_xattr->name_length) + sizeof(desc_xattr->value_length) +
+			    desc_xattr->name_length + desc_xattr->value_length) {
+			}
+
+			memcpy(ctx->xattr_name, desc_xattr->name, desc_xattr->name_length);
+			ctx->xattr_name[desc_xattr->name_length] = '\0';
+			fprintf(ctx->fp, "XATTR: name = \"%s\"\n", ctx->xattr_name);
+			fprintf(ctx->fp, "       value = \"");
+			ctx->print_xattr_fn(ctx->fp, ctx->super->bstype.bstype, ctx->xattr_name,
+					    (void *)((uintptr_t)desc_xattr->name + desc_xattr->name_length),
+					    desc_xattr->value_length);
+			fprintf(ctx->fp, "\"\n");
+			for (i = 0; i < desc_xattr->value_length; i++) {
+				if (i % 16 == 0) {
+					fprintf(ctx->fp, "               ");
+				}
+				fprintf(ctx->fp, "%02" PRIx8 " ", *((uint8_t *)desc_xattr->name + desc_xattr->name_length + i));
+				if ((i + 1) % 16 == 0) {
+					fprintf(ctx->fp, "\n");
+				}
+			}
+			if (i % 16 != 0) {
+				fprintf(ctx->fp, "\n");
+			}
+		} else if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_XATTR_INTERNAL) {
+			/* TODO */
+		} else if (desc->type == SPDK_MD_DESCRIPTOR_TYPE_FLAGS) {
+			/* TODO */
+		} else {
+			/* Error */
+		}
+		/* Advance to the next descriptor */
+		cur_desc += sizeof(*desc) + desc->length;
+		if (cur_desc + sizeof(*desc) > sizeof(page->descriptors)) {
+			break;
+		}
+		desc = (struct spdk_blob_md_descriptor *)((uintptr_t)page->descriptors + cur_desc);
+	}
+}
+
+static void
+_spdk_bs_dump_read_md_page_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_bs_dump_ctx *ctx = cb_arg;
+
+	if (bserrno != 0) {
+		_spdk_bs_dump_finish(seq, ctx, bserrno);
+		return;
+	}
+
+	if (ctx->page->id != 0) {
+		_spdk_bs_dump_print_md_page(ctx);
+	}
+
+	ctx->cur_page++;
+
+	if (ctx->cur_page < ctx->super->md_len) {
+		_spdk_bs_dump_read_md_page(seq, cb_arg);
+	} else {
+		spdk_dma_free(ctx->page);
+		_spdk_bs_dump_finish(seq, ctx, 0);
+	}
+}
+
+static void
+_spdk_bs_dump_read_md_page(spdk_bs_sequence_t *seq, void *cb_arg)
+{
+	struct spdk_bs_dump_ctx *ctx = cb_arg;
+	uint64_t lba;
+
+	assert(ctx->cur_page < ctx->super->md_len);
+	lba = _spdk_bs_page_to_lba(ctx->bs, ctx->super->md_start + ctx->cur_page);
+	spdk_bs_sequence_read_dev(seq, ctx->page, lba,
+				  _spdk_bs_byte_to_lba(ctx->bs, SPDK_BS_PAGE_SIZE),
+				  _spdk_bs_dump_read_md_page_cpl, ctx);
+}
+
+static void
+_spdk_bs_dump_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_bs_dump_ctx *ctx = cb_arg;
+
+	fprintf(ctx->fp, "Signature: \"%.8s\" ", ctx->super->signature);
+	if (memcmp(ctx->super->signature, SPDK_BS_SUPER_BLOCK_SIG,
+		   sizeof(ctx->super->signature)) != 0) {
+		fprintf(ctx->fp, "(Mismatch)\n");
+		_spdk_bs_dump_finish(seq, ctx, bserrno);
+		return;
+	} else {
+		fprintf(ctx->fp, "(OK)\n");
+	}
+	fprintf(ctx->fp, "Version: %" PRIu32 "\n", ctx->super->version);
+	fprintf(ctx->fp, "CRC: 0x%x (%s)\n", ctx->super->crc,
+		(ctx->super->crc == _spdk_blob_md_page_calc_crc(ctx->super)) ? "OK" : "Mismatch");
+	fprintf(ctx->fp, "Blobstore Type: %.*s\n", SPDK_BLOBSTORE_TYPE_LENGTH, ctx->super->bstype.bstype);
+	fprintf(ctx->fp, "Cluster Size: %" PRIu32 "\n", ctx->super->cluster_size);
+	fprintf(ctx->fp, "Super Blob ID: ");
+	if (ctx->super->super_blob == SPDK_BLOBID_INVALID) {
+		fprintf(ctx->fp, "(None)\n");
+	} else {
+		fprintf(ctx->fp, "%" PRIu64 "\n", ctx->super->super_blob);
+	}
+	fprintf(ctx->fp, "Clean: %" PRIu32 "\n", ctx->super->clean);
+	fprintf(ctx->fp, "Used Metadata Page Mask Start: %" PRIu32 "\n", ctx->super->used_page_mask_start);
+	fprintf(ctx->fp, "Used Metadata Page Mask Length: %" PRIu32 "\n", ctx->super->used_page_mask_len);
+	fprintf(ctx->fp, "Used Cluster Mask Start: %" PRIu32 "\n", ctx->super->used_cluster_mask_start);
+	fprintf(ctx->fp, "Used Cluster Mask Length: %" PRIu32 "\n", ctx->super->used_cluster_mask_len);
+	fprintf(ctx->fp, "Used Blob ID Mask Start: %" PRIu32 "\n", ctx->super->used_blobid_mask_start);
+	fprintf(ctx->fp, "Used Blob ID Mask Length: %" PRIu32 "\n", ctx->super->used_blobid_mask_len);
+	fprintf(ctx->fp, "Metadata Start: %" PRIu32 "\n", ctx->super->md_start);
+	fprintf(ctx->fp, "Metadata Length: %" PRIu32 "\n", ctx->super->md_len);
+
+	ctx->cur_page = 0;
+	ctx->page = spdk_dma_zmalloc(SPDK_BS_PAGE_SIZE,
+				     SPDK_BS_PAGE_SIZE,
+				     NULL);
+	if (!ctx->page) {
+		_spdk_bs_dump_finish(seq, ctx, -ENOMEM);
+		return;
+	}
+	_spdk_bs_dump_read_md_page(seq, cb_arg);
+}
+
+void
+spdk_bs_dump(struct spdk_bs_dev *dev, FILE *fp, spdk_bs_dump_print_xattr print_xattr_fn,
+	     spdk_bs_op_complete cb_fn, void *cb_arg)
+{
+	struct spdk_blob_store	*bs;
+	struct spdk_bs_cpl	cpl;
+	spdk_bs_sequence_t	*seq;
+	struct spdk_bs_dump_ctx *ctx;
+	struct spdk_bs_opts	opts = {};
+
+	SPDK_DEBUGLOG(SPDK_LOG_BLOB, "Dumping blobstore from dev %p\n", dev);
+
+	spdk_bs_opts_init(&opts);
+
+	bs = _spdk_bs_alloc(dev, &opts);
+	if (!bs) {
+		dev->destroy(dev);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	ctx = calloc(1, sizeof(*ctx));
+	if (!ctx) {
+		_spdk_bs_free(bs);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	ctx->bs = bs;
+	ctx->fp = fp;
+	ctx->print_xattr_fn = print_xattr_fn;
+
+	/* Allocate memory for the super block */
+	ctx->super = spdk_dma_zmalloc(sizeof(*ctx->super), 0x1000, NULL);
+	if (!ctx->super) {
+		free(ctx);
+		_spdk_bs_free(bs);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	cpl.type = SPDK_BS_CPL_TYPE_BS_BASIC;
+	cpl.u.bs_basic.cb_fn = cb_fn;
+	cpl.u.bs_basic.cb_arg = cb_arg;
+
+	seq = spdk_bs_sequence_start(bs->md_channel, &cpl);
+	if (!seq) {
+		spdk_dma_free(ctx->super);
+		free(ctx);
+		_spdk_bs_free(bs);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	/* Read the super block */
+	spdk_bs_sequence_read_dev(seq, ctx->super, _spdk_bs_page_to_lba(bs, 0),
+				  _spdk_bs_byte_to_lba(bs, sizeof(*ctx->super)),
+				  _spdk_bs_dump_super_cpl, ctx);
+}
+
+/* END spdk_bs_dump */
+
+/* START spdk_bs_init */
+
+struct spdk_bs_init_ctx {
+	struct spdk_blob_store		*bs;
+	struct spdk_bs_super_block	*super;
+};
+
+static void
+_spdk_bs_init_persist_super_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_bs_init_ctx *ctx = cb_arg;
+
+	spdk_dma_free(ctx->super);
+	free(ctx);
+
+	spdk_bs_sequence_finish(seq, bserrno);
+}
+
+static void
+_spdk_bs_init_trim_cpl(spdk_bs_sequence_t *seq, void *cb_arg, int bserrno)
+{
+	struct spdk_bs_init_ctx *ctx = cb_arg;
+
+	/* Write super block */
+	spdk_bs_sequence_write_dev(seq, ctx->super, _spdk_bs_page_to_lba(ctx->bs, 0),
+				   _spdk_bs_byte_to_lba(ctx->bs, sizeof(*ctx->super)),
+				   _spdk_bs_init_persist_super_cpl, ctx);
+}
+
+void
+spdk_bs_init(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
+	     spdk_bs_op_with_handle_complete cb_fn, void *cb_arg)
+{
+	struct spdk_bs_init_ctx *ctx;
+	struct spdk_blob_store	*bs;
+	struct spdk_bs_cpl	cpl;
+	spdk_bs_sequence_t	*seq;
+	spdk_bs_batch_t		*batch;
+	uint64_t		num_md_lba;
+	uint64_t		num_md_pages;
+	uint64_t		num_md_clusters;
+	uint32_t		i;
+	struct spdk_bs_opts	opts = {};
+	int			rc;
+
+	SPDK_DEBUGLOG(SPDK_LOG_BLOB, "Initializing blobstore on dev %p\n", dev);
+
+	if ((SPDK_BS_PAGE_SIZE % dev->blocklen) != 0) {
+		SPDK_ERRLOG("unsupported dev block length of %d\n",
+			    dev->blocklen);
+		dev->destroy(dev);
+		cb_fn(cb_arg, NULL, -EINVAL);
+		return;
+	}
+
+	if (o) {
+		opts = *o;
+	} else {
+		spdk_bs_opts_init(&opts);
+	}
+
+	if (_spdk_bs_opts_verify(&opts) != 0) {
+		dev->destroy(dev);
+		cb_fn(cb_arg, NULL, -EINVAL);
 		return;
 	}
 
@@ -3112,6 +3572,7 @@ spdk_bs_init(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
 	if (!ctx->super) {
 		free(ctx);
 		_spdk_bs_free(bs);
+		cb_fn(cb_arg, NULL, -ENOMEM);
 		return;
 	}
 	memcpy(ctx->super->signature, SPDK_BS_SUPER_BLOCK_SIG,
@@ -3164,6 +3625,8 @@ spdk_bs_init(struct spdk_bs_dev *dev, struct spdk_bs_opts *o,
 
 	num_md_lba = _spdk_bs_page_to_lba(bs, num_md_pages);
 
+	ctx->super->size = dev->blockcnt * dev->blocklen;
+
 	ctx->super->crc = _spdk_blob_md_page_calc_crc(ctx->super);
 
 	num_md_clusters = divide_round_up(num_md_pages, bs->pages_per_cluster);
@@ -3697,6 +4160,16 @@ void spdk_bs_create_blob_ext(struct spdk_blob_store *bs, const struct spdk_blob_
 struct spdk_clone_snapshot_ctx {
 	struct spdk_bs_cpl      cpl;
 	int bserrno;
+	bool frozen;
+
+	struct spdk_io_channel *channel;
+
+	/* Current cluster for inflate operation */
+	uint64_t cluster;
+
+	/* For inflation force allocation of all unallocated clusters and remove
+	 * thin-provisioning. Otherwise only decouple parent and keep clone thin. */
+	bool allocate_all;
 
 	struct {
 		spdk_blob_id id;
@@ -3730,6 +4203,9 @@ _spdk_bs_clone_snapshot_cleanup_finish(void *cb_arg, int bserrno)
 	case SPDK_BS_CPL_TYPE_BLOBID:
 		cpl->u.blobid.cb_fn(cpl->u.blobid.cb_arg, cpl->u.blobid.blobid, ctx->bserrno);
 		break;
+	case SPDK_BS_CPL_TYPE_BLOB_BASIC:
+		cpl->u.blob_basic.cb_fn(cpl->u.blob_basic.cb_arg, ctx->bserrno);
+		break;
 	default:
 		SPDK_UNREACHABLE();
 		break;
@@ -3739,14 +4215,14 @@ _spdk_bs_clone_snapshot_cleanup_finish(void *cb_arg, int bserrno)
 }
 
 static void
-_spdk_bs_clone_snapshot_origblob_cleanup(void *cb_arg, int bserrno)
+_spdk_bs_snapshot_unfreeze_cpl(void *cb_arg, int bserrno)
 {
 	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
 	struct spdk_blob *origblob = ctx->original.blob;
 
 	if (bserrno != 0) {
 		if (ctx->bserrno != 0) {
-			SPDK_ERRLOG("Cleanup error %d\n", bserrno);
+			SPDK_ERRLOG("Unfreeze error %d\n", bserrno);
 		} else {
 			ctx->bserrno = bserrno;
 		}
@@ -3756,6 +4232,29 @@ _spdk_bs_clone_snapshot_origblob_cleanup(void *cb_arg, int bserrno)
 	spdk_blob_close(origblob, _spdk_bs_clone_snapshot_cleanup_finish, ctx);
 }
 
+static void
+_spdk_bs_clone_snapshot_origblob_cleanup(void *cb_arg, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	struct spdk_blob *origblob = ctx->original.blob;
+
+	if (bserrno != 0) {
+		if (ctx->bserrno != 0) {
+			SPDK_ERRLOG("Cleanup error %d\n", bserrno);
+		} else {
+			ctx->bserrno = bserrno;
+		}
+	}
+
+	if (ctx->frozen) {
+		/* Unfreeze any outstanding I/O */
+		_spdk_blob_unfreeze_io(origblob, _spdk_bs_snapshot_unfreeze_cpl, ctx);
+	} else {
+		_spdk_bs_snapshot_unfreeze_cpl(ctx, 0);
+	}
+
+}
+
 static void
 _spdk_bs_clone_snapshot_newblob_cleanup(void *cb_arg, int bserrno)
 {
@@ -3822,6 +4321,8 @@ _spdk_bs_snapshot_newblob_sync_cpl(void *cb_arg, int bserrno)
 		_spdk_bs_clone_snapshot_newblob_cleanup(ctx, bserrno);
 		return;
 	}
+
+	_spdk_bs_blob_list_remove(origblob);
 	origblob->parent_id = newblob->id;
 
 	/* Create new back_bs_dev for snapshot */
@@ -3845,24 +4346,37 @@ _spdk_bs_snapshot_newblob_sync_cpl(void *cb_arg, int bserrno)
 }
 
 static void
-_spdk_bs_snapshot_newblob_open_cpl(void *cb_arg, struct spdk_blob *_blob, int bserrno)
+_spdk_bs_snapshot_freeze_cpl(void *cb_arg, int rc)
 {
 	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
 	struct spdk_blob *origblob = ctx->original.blob;
-	struct spdk_blob *newblob = _blob;
+	struct spdk_blob *newblob = ctx->new.blob;
+	int bserrno;
 
-	if (bserrno != 0) {
-		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, bserrno);
+	if (rc != 0) {
+		_spdk_bs_clone_snapshot_newblob_cleanup(ctx, rc);
 		return;
 	}
 
-	ctx->new.blob = newblob;
+	ctx->frozen = true;
 
 	/* set new back_bs_dev for snapshot */
 	newblob->back_bs_dev = origblob->back_bs_dev;
 	/* Set invalid flags from origblob */
 	newblob->invalid_flags = origblob->invalid_flags;
 
+	/* inherit parent from original blob if set */
+	newblob->parent_id = origblob->parent_id;
+	if (origblob->parent_id != SPDK_BLOBID_INVALID) {
+		/* Set internal xattr for snapshot id */
+		bserrno = _spdk_blob_set_xattr(newblob, BLOB_SNAPSHOT,
+					       &origblob->parent_id, sizeof(spdk_blob_id), true);
+		if (bserrno != 0) {
+			_spdk_bs_clone_snapshot_newblob_cleanup(ctx, bserrno);
+			return;
+		}
+	}
+
 	/* Copy cluster map to snapshot */
 	memcpy(newblob->active.clusters, origblob->active.clusters,
 	       origblob->active.num_clusters * sizeof(origblob->active.clusters));
@@ -3871,6 +4385,23 @@ _spdk_bs_snapshot_newblob_open_cpl(void *cb_arg, struct spdk_blob *_blob, int bs
 	spdk_blob_sync_md(newblob, _spdk_bs_snapshot_newblob_sync_cpl, ctx);
 }
 
+static void
+_spdk_bs_snapshot_newblob_open_cpl(void *cb_arg, struct spdk_blob *_blob, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	struct spdk_blob *origblob = ctx->original.blob;
+	struct spdk_blob *newblob = _blob;
+
+	if (bserrno != 0) {
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, bserrno);
+		return;
+	}
+
+	ctx->new.blob = newblob;
+
+	_spdk_blob_freeze_io(origblob, _spdk_bs_snapshot_freeze_cpl, ctx);
+}
+
 static void
 _spdk_bs_snapshot_newblob_create_cpl(void *cb_arg, spdk_blob_id blobid, int bserrno)
 {
@@ -3959,6 +4490,7 @@ void spdk_bs_create_snapshot(struct spdk_blob_store *bs, spdk_blob_id blobid,
 	ctx->cpl.u.blobid.cb_arg = cb_arg;
 	ctx->cpl.u.blobid.blobid = SPDK_BLOBID_INVALID;
 	ctx->bserrno = 0;
+	ctx->frozen = false;
 	ctx->original.id = blobid;
 	ctx->xattrs = snapshot_xattrs;
 
@@ -4064,11 +4596,259 @@ void spdk_bs_create_clone(struct spdk_blob_store *bs, spdk_blob_id blobid,
 
 /* END spdk_bs_create_clone */
 
+/* START spdk_bs_inflate_blob */
+
+static void
+_spdk_bs_inflate_blob_set_parent_cpl(void *cb_arg, struct spdk_blob *_parent, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	struct spdk_blob *_blob = ctx->original.blob;
+
+	if (bserrno != 0) {
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, bserrno);
+		return;
+	}
+
+	assert(_parent != NULL);
+
+	_spdk_bs_blob_list_remove(_blob);
+	_blob->parent_id = _parent->id;
+	_spdk_blob_set_xattr(_blob, BLOB_SNAPSHOT, &_blob->parent_id,
+			     sizeof(spdk_blob_id), true);
+
+	_blob->back_bs_dev->destroy(_blob->back_bs_dev);
+	_blob->back_bs_dev = spdk_bs_create_blob_bs_dev(_parent);
+	_spdk_bs_blob_list_add(_blob);
+
+	spdk_blob_sync_md(_blob, _spdk_bs_clone_snapshot_origblob_cleanup, ctx);
+}
+
+static void
+_spdk_bs_inflate_blob_done(void *cb_arg, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	struct spdk_blob *_blob = ctx->original.blob;
+	struct spdk_blob *_parent;
+
+	if (bserrno != 0) {
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, bserrno);
+		return;
+	}
+
+	if (ctx->allocate_all) {
+		/* remove thin provisioning */
+		_spdk_bs_blob_list_remove(_blob);
+		_spdk_blob_remove_xattr(_blob, BLOB_SNAPSHOT, true);
+		_blob->invalid_flags = _blob->invalid_flags & ~SPDK_BLOB_THIN_PROV;
+		_blob->back_bs_dev->destroy(_blob->back_bs_dev);
+		_blob->back_bs_dev = NULL;
+		_blob->parent_id = SPDK_BLOBID_INVALID;
+	} else {
+		_parent = ((struct spdk_blob_bs_dev *)(_blob->back_bs_dev))->blob;
+		if (_parent->parent_id != SPDK_BLOBID_INVALID) {
+			/* We must change the parent of the inflated blob */
+			spdk_bs_open_blob(_blob->bs, _parent->parent_id,
+					  _spdk_bs_inflate_blob_set_parent_cpl, ctx);
+			return;
+		}
+
+		_spdk_bs_blob_list_remove(_blob);
+		_spdk_blob_remove_xattr(_blob, BLOB_SNAPSHOT, true);
+		_blob->parent_id = SPDK_BLOBID_INVALID;
+		_blob->back_bs_dev->destroy(_blob->back_bs_dev);
+		_blob->back_bs_dev = spdk_bs_create_zeroes_dev();
+	}
+
+	_blob->state = SPDK_BLOB_STATE_DIRTY;
+	spdk_blob_sync_md(_blob, _spdk_bs_clone_snapshot_origblob_cleanup, ctx);
+}
+
+/* Check if cluster needs allocation */
+static inline bool
+_spdk_bs_cluster_needs_allocation(struct spdk_blob *blob, uint64_t cluster, bool allocate_all)
+{
+	struct spdk_blob_bs_dev *b;
+
+	assert(blob != NULL);
+
+	if (blob->active.clusters[cluster] != 0) {
+		/* Cluster is already allocated */
+		return false;
+	}
+
+	if (blob->parent_id == SPDK_BLOBID_INVALID) {
+		/* Blob have no parent blob */
+		return allocate_all;
+	}
+
+	b = (struct spdk_blob_bs_dev *)blob->back_bs_dev;
+	return (allocate_all || b->blob->active.clusters[cluster] != 0);
+}
+
+static void
+_spdk_bs_inflate_blob_touch_next(void *cb_arg, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	struct spdk_blob *_blob = ctx->original.blob;
+	uint64_t offset;
+
+	if (bserrno != 0) {
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, bserrno);
+		return;
+	}
+
+	for (; ctx->cluster < _blob->active.num_clusters; ctx->cluster++) {
+		if (_spdk_bs_cluster_needs_allocation(_blob, ctx->cluster, ctx->allocate_all)) {
+			break;
+		}
+	}
+
+	if (ctx->cluster < _blob->active.num_clusters) {
+		offset = _spdk_bs_cluster_to_page(_blob->bs, ctx->cluster);
+
+		/* We may safely increment a cluster before write */
+		ctx->cluster++;
+
+		/* Use zero length write to touch a cluster */
+		spdk_blob_io_write(_blob, ctx->channel, NULL, offset, 0,
+				   _spdk_bs_inflate_blob_touch_next, ctx);
+	} else {
+		_spdk_bs_inflate_blob_done(cb_arg, bserrno);
+	}
+}
+
+static void
+_spdk_bs_inflate_blob_open_cpl(void *cb_arg, struct spdk_blob *_blob, int bserrno)
+{
+	struct spdk_clone_snapshot_ctx *ctx = (struct spdk_clone_snapshot_ctx *)cb_arg;
+	uint64_t lfc; /* lowest free cluster */
+	uint64_t i;
+
+	if (bserrno != 0) {
+		_spdk_bs_clone_snapshot_cleanup_finish(ctx, bserrno);
+		return;
+	}
+	ctx->original.blob = _blob;
+
+	if (!ctx->allocate_all && _blob->parent_id == SPDK_BLOBID_INVALID) {
+		/* This blob have no parent, so we cannot decouple it. */
+		SPDK_ERRLOG("Cannot decouple parent of blob with no parent.\n");
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, -EINVAL);
+		return;
+	}
+
+	if (spdk_blob_is_thin_provisioned(_blob) == false) {
+		/* This is not thin provisioned blob. No need to inflate. */
+		_spdk_bs_clone_snapshot_origblob_cleanup(ctx, 0);
+		return;
+	}
+
+	/* Do two passes - one to verify that we can obtain enough clusters
+	 * and another to actually claim them.
+	 */
+	lfc = 0;
+	for (i = 0; i < _blob->active.num_clusters; i++) {
+		if (_spdk_bs_cluster_needs_allocation(_blob, i, ctx->allocate_all)) {
+			lfc = spdk_bit_array_find_first_clear(_blob->bs->used_clusters, lfc);
+			if (lfc >= _blob->bs->total_clusters) {
+				/* No more free clusters. Cannot satisfy the request */
+				_spdk_bs_clone_snapshot_origblob_cleanup(ctx, -ENOSPC);
+				return;
+			}
+			lfc++;
+		}
+	}
+
+	ctx->cluster = 0;
+	_spdk_bs_inflate_blob_touch_next(ctx, 0);
+}
+
+static void
+_spdk_bs_inflate_blob(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+		      spdk_blob_id blobid, bool allocate_all, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	struct spdk_clone_snapshot_ctx *ctx = calloc(1, sizeof(*ctx));
+
+	if (!ctx) {
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+	ctx->cpl.type = SPDK_BS_CPL_TYPE_BLOB_BASIC;
+	ctx->cpl.u.bs_basic.cb_fn = cb_fn;
+	ctx->cpl.u.bs_basic.cb_arg = cb_arg;
+	ctx->bserrno = 0;
+	ctx->original.id = blobid;
+	ctx->channel = channel;
+	ctx->allocate_all = allocate_all;
+
+	spdk_bs_open_blob(bs, ctx->original.id, _spdk_bs_inflate_blob_open_cpl, ctx);
+}
+
+void
+spdk_bs_inflate_blob(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+		     spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	_spdk_bs_inflate_blob(bs, channel, blobid, true, cb_fn, cb_arg);
+}
+
+void
+spdk_bs_blob_decouple_parent(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+			     spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	_spdk_bs_inflate_blob(bs, channel, blobid, false, cb_fn, cb_arg);
+}
+/* END spdk_bs_inflate_blob */
+
 /* START spdk_blob_resize */
+struct spdk_bs_resize_ctx {
+	spdk_blob_op_complete cb_fn;
+	void *cb_arg;
+	struct spdk_blob *blob;
+	uint64_t sz;
+	int rc;
+};
+
+static void
+_spdk_bs_resize_unfreeze_cpl(void *cb_arg, int rc)
+{
+	struct spdk_bs_resize_ctx *ctx = (struct spdk_bs_resize_ctx *)cb_arg;
+
+	if (rc != 0) {
+		SPDK_ERRLOG("Unfreeze failed, rc=%d\n", rc);
+	}
+
+	if (ctx->rc != 0) {
+		SPDK_ERRLOG("Unfreeze failed, ctx->rc=%d\n", ctx->rc);
+		rc = ctx->rc;
+	}
+
+	ctx->blob->resize_in_progress = false;
+
+	ctx->cb_fn(ctx->cb_arg, rc);
+	free(ctx);
+}
+
+static void
+_spdk_bs_resize_freeze_cpl(void *cb_arg, int rc)
+{
+	struct spdk_bs_resize_ctx *ctx = (struct spdk_bs_resize_ctx *)cb_arg;
+
+	if (rc != 0) {
+		ctx->blob->resize_in_progress = false;
+		ctx->cb_fn(ctx->cb_arg, rc);
+		free(ctx);
+		return;
+	}
+
+	ctx->rc = _spdk_blob_resize(ctx->blob, ctx->sz);
+
+	_spdk_blob_unfreeze_io(ctx->blob, _spdk_bs_resize_unfreeze_cpl, ctx);
+}
+
 void
 spdk_blob_resize(struct spdk_blob *blob, uint64_t sz, spdk_blob_op_complete cb_fn, void *cb_arg)
 {
-	int			rc;
+	struct spdk_bs_resize_ctx *ctx;
 
 	_spdk_blob_verify_md_op(blob);
 
@@ -4084,8 +4864,23 @@ spdk_blob_resize(struct spdk_blob *blob, uint64_t sz, spdk_blob_op_complete cb_f
 		return;
 	}
 
-	rc = _spdk_blob_resize(blob, sz);
-	cb_fn(cb_arg, rc);
+	if (blob->resize_in_progress) {
+		cb_fn(cb_arg, -EBUSY);
+		return;
+	}
+
+	ctx = calloc(1, sizeof(*ctx));
+	if (!ctx) {
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	blob->resize_in_progress = true;
+	ctx->cb_fn = cb_fn;
+	ctx->cb_arg = cb_arg;
+	ctx->blob = blob;
+	ctx->sz = sz;
+	_spdk_blob_freeze_io(blob, _spdk_bs_resize_freeze_cpl, ctx);
 }
 
 /* END spdk_blob_resize */
@@ -4388,7 +5183,7 @@ _spdk_blob_insert_cluster_msg(void *arg)
 	_spdk_blob_sync_md(ctx->blob, _spdk_blob_insert_cluster_msg_cb, ctx);
 }
 
-void
+static void
 _spdk_blob_insert_cluster_on_md_thread(struct spdk_blob *blob, uint32_t cluster_num,
 				       uint64_t cluster, spdk_blob_op_complete cb_fn, void *cb_arg)
 {
@@ -4520,46 +5315,6 @@ void spdk_blob_io_readv(struct spdk_blob *blob, struct spdk_io_channel *channel,
 	_spdk_blob_request_submit_rw_iov(blob, channel, iov, iovcnt, offset, length, cb_fn, cb_arg, true);
 }
 
-void spdk_bs_io_unmap_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   uint64_t offset, uint64_t length, spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_unmap(blob, channel, offset, length, cb_fn, cb_arg);
-}
-
-void spdk_bs_io_write_zeroes_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-				  uint64_t offset, uint64_t length, spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_write_zeroes(blob, channel, offset, length, cb_fn, cb_arg);
-}
-
-void spdk_bs_io_write_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   void *payload, uint64_t offset, uint64_t length,
-			   spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_write(blob, channel, payload, offset, length, cb_fn, cb_arg);
-}
-
-void spdk_bs_io_read_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			  void *payload, uint64_t offset, uint64_t length,
-			  spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_read(blob, channel, payload, offset, length, cb_fn, cb_arg);
-}
-
-void spdk_bs_io_writev_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			    struct iovec *iov, int iovcnt, uint64_t offset, uint64_t length,
-			    spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_writev(blob, channel, iov, iovcnt, offset, length, cb_fn, cb_arg);
-}
-
-void spdk_bs_io_readv_blob(struct spdk_blob *blob, struct spdk_io_channel *channel,
-			   struct iovec *iov, int iovcnt, uint64_t offset, uint64_t length,
-			   spdk_blob_op_complete cb_fn, void *cb_arg)
-{
-	spdk_blob_io_readv(blob, channel, iov, iovcnt, offset, length, cb_fn, cb_arg);
-}
-
 struct spdk_bs_iter_ctx {
 	int64_t page_num;
 	struct spdk_blob_store *bs;
@@ -4680,7 +5435,7 @@ _spdk_blob_set_xattr(struct spdk_blob *blob, const char *name, const void *value
 
 	xattr = calloc(1, sizeof(*xattr));
 	if (!xattr) {
-		return -1;
+		return -ENOMEM;
 	}
 	xattr->name = strdup(name);
 	xattr->value_len = value_len;
diff --git a/lib/blob/blobstore.h b/lib/blob/blobstore.h
index bd399f1ce..61e6b38e7 100644
--- a/lib/blob/blobstore.h
+++ b/lib/blob/blobstore.h
@@ -53,11 +53,10 @@
 #define SPDK_BLOB_BLOBID_HIGH_BIT (1ULL << 32)
 
 struct spdk_xattr {
-	/* TODO: reorder for best packing */
 	uint32_t	index;
+	uint16_t	value_len;
 	char		*name;
 	void		*value;
-	uint16_t	value_len;
 	TAILQ_ENTRY(spdk_xattr)	link;
 };
 
@@ -147,6 +146,9 @@ struct spdk_blob {
 	struct spdk_xattr_tailq xattrs_internal;
 
 	TAILQ_ENTRY(spdk_blob) link;
+
+	uint32_t frozen_refcnt;
+	bool resize_in_progress;
 };
 
 struct spdk_blob_store {
@@ -170,7 +172,7 @@ struct spdk_blob_store {
 	uint64_t			total_clusters;
 	uint64_t			total_data_clusters;
 	uint64_t			num_free_clusters;
-	uint32_t			pages_per_cluster;
+	uint64_t			pages_per_cluster;
 
 	spdk_blob_id			super_blob;
 	struct spdk_bs_type		bstype;
@@ -180,6 +182,8 @@ struct spdk_blob_store {
 
 	TAILQ_HEAD(, spdk_blob)		blobs;
 	TAILQ_HEAD(, spdk_blob_list)	snapshots;
+
+	bool                            clean;
 };
 
 struct spdk_bs_channel {
@@ -192,6 +196,7 @@ struct spdk_bs_channel {
 	struct spdk_io_channel		*dev_channel;
 
 	TAILQ_HEAD(, spdk_bs_request_set) need_cluster_alloc;
+	TAILQ_HEAD(, spdk_bs_request_set) queued_io;
 };
 
 /** operation type */
@@ -338,7 +343,9 @@ struct spdk_bs_super_block {
 	uint32_t	used_blobid_mask_start; /* Offset from beginning of disk, in pages */
 	uint32_t	used_blobid_mask_len; /* Count, in pages */
 
-	uint8_t		reserved[4012];
+	uint64_t        size; /* size of blobstore in bytes */
+
+	uint8_t         reserved[4004];
 	uint32_t	crc;
 };
 SPDK_STATIC_ASSERT(sizeof(struct spdk_bs_super_block) == 0x1000, "Invalid super block size");
@@ -399,7 +406,7 @@ _spdk_bs_dev_page_to_lba(struct spdk_bs_dev *bs_dev, uint64_t page)
 	return page * SPDK_BS_PAGE_SIZE / bs_dev->blocklen;
 }
 
-static inline uint32_t
+static inline uint64_t
 _spdk_bs_lba_to_page(struct spdk_blob_store *bs, uint64_t lba)
 {
 	uint64_t	lbas_per_page;
@@ -426,7 +433,7 @@ _spdk_bs_dev_lba_to_page(struct spdk_bs_dev *bs_dev, uint64_t lba)
 static inline uint64_t
 _spdk_bs_cluster_to_page(struct spdk_blob_store *bs, uint32_t cluster)
 {
-	return cluster * bs->pages_per_cluster;
+	return (uint64_t)cluster * bs->pages_per_cluster;
 }
 
 static inline uint32_t
@@ -440,7 +447,7 @@ _spdk_bs_page_to_cluster(struct spdk_blob_store *bs, uint64_t page)
 static inline uint64_t
 _spdk_bs_cluster_to_lba(struct spdk_blob_store *bs, uint32_t cluster)
 {
-	return cluster * (bs->cluster_sz / bs->dev->blocklen);
+	return (uint64_t)cluster * (bs->cluster_sz / bs->dev->blocklen);
 }
 
 static inline uint32_t
@@ -465,7 +472,7 @@ _spdk_bs_blob_lba_from_back_dev_lba(struct spdk_blob *blob, uint64_t lba)
 
 /* End basic conversions */
 
-static inline uint32_t
+static inline uint64_t
 _spdk_bs_blobid_to_page(spdk_blob_id id)
 {
 	return id & 0xFFFFFFFF;
@@ -476,8 +483,11 @@ _spdk_bs_blobid_to_page(spdk_blob_id id)
  * code assumes blob id == page_idx.
  */
 static inline spdk_blob_id
-_spdk_bs_page_to_blobid(uint32_t page_idx)
+_spdk_bs_page_to_blobid(uint64_t page_idx)
 {
+	if (page_idx > UINT32_MAX) {
+		return SPDK_BLOBID_INVALID;
+	}
 	return SPDK_BLOB_BLOBID_HIGH_BIT | page_idx;
 }
 
@@ -485,10 +495,10 @@ _spdk_bs_page_to_blobid(uint32_t page_idx)
  * start of that page.
  */
 static inline uint64_t
-_spdk_bs_blob_page_to_lba(struct spdk_blob *blob, uint32_t page)
+_spdk_bs_blob_page_to_lba(struct spdk_blob *blob, uint64_t page)
 {
 	uint64_t	lba;
-	uint32_t	pages_per_cluster;
+	uint64_t	pages_per_cluster;
 
 	pages_per_cluster = blob->bs->pages_per_cluster;
 
@@ -504,9 +514,9 @@ _spdk_bs_blob_page_to_lba(struct spdk_blob *blob, uint32_t page)
  * next cluster boundary.
  */
 static inline uint32_t
-_spdk_bs_num_pages_to_cluster_boundary(struct spdk_blob *blob, uint32_t page)
+_spdk_bs_num_pages_to_cluster_boundary(struct spdk_blob *blob, uint64_t page)
 {
-	uint32_t	pages_per_cluster;
+	uint64_t	pages_per_cluster;
 
 	pages_per_cluster = blob->bs->pages_per_cluster;
 
@@ -515,9 +525,9 @@ _spdk_bs_num_pages_to_cluster_boundary(struct spdk_blob *blob, uint32_t page)
 
 /* Given a page offset into a blob, look up the number of pages into blob to beginning of current cluster */
 static inline uint32_t
-_spdk_bs_page_to_cluster_start(struct spdk_blob *blob, uint32_t page)
+_spdk_bs_page_to_cluster_start(struct spdk_blob *blob, uint64_t page)
 {
-	uint32_t	pages_per_cluster;
+	uint64_t	pages_per_cluster;
 
 	pages_per_cluster = blob->bs->pages_per_cluster;
 
@@ -526,10 +536,10 @@ _spdk_bs_page_to_cluster_start(struct spdk_blob *blob, uint32_t page)
 
 /* Given a page offset into a blob, look up if it is from allocated cluster. */
 static inline bool
-_spdk_bs_page_is_allocated(struct spdk_blob *blob, uint32_t page)
+_spdk_bs_page_is_allocated(struct spdk_blob *blob, uint64_t page)
 {
 	uint64_t	lba;
-	uint32_t	pages_per_cluster;
+	uint64_t	pages_per_cluster;
 
 	pages_per_cluster = blob->bs->pages_per_cluster;
 
diff --git a/lib/blob/request.c b/lib/blob/request.c
index d900e8a57..98821dde5 100644
--- a/lib/blob/request.c
+++ b/lib/blob/request.c
@@ -36,7 +36,7 @@
 #include "blobstore.h"
 #include "request.h"
 
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/queue.h"
 
 #include "spdk_internal/log.h"
diff --git a/lib/blobfs/blobfs.c b/lib/blobfs/blobfs.c
index edeeacfd9..72fc6ebad 100644
--- a/lib/blobfs/blobfs.c
+++ b/lib/blobfs/blobfs.c
@@ -38,7 +38,7 @@
 #include "blobfs_internal.h"
 
 #include "spdk/queue.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/assert.h"
 #include "spdk/env.h"
 #include "spdk/util.h"
diff --git a/lib/conf/conf.c b/lib/conf/conf.c
index e52372e90..384b088cf 100644
--- a/lib/conf/conf.c
+++ b/lib/conf/conf.c
@@ -483,13 +483,15 @@ parse_line(struct spdk_conf *cp, char *lp)
 		if (sp == NULL) {
 			sp = allocate_cf_section();
 			append_cf_section(cp, sp);
+
+			sp->name = strdup(key);
+			if (sp->name == NULL) {
+				SPDK_ERRLOG("cannot duplicate %s to sp->name\n", key);
+				return -1;
+			}
 		}
 		cp->current_section = sp;
-		sp->name = strdup(key);
-		if (sp->name == NULL) {
-			SPDK_ERRLOG("cannot duplicate %s to sp->name\n", key);
-			return -1;
-		}
+
 
 		sp->num = num;
 	} else {
diff --git a/lib/copy/copy_engine.c b/lib/copy/copy_engine.c
index f8b6fb8f0..971f0b753 100644
--- a/lib/copy/copy_engine.c
+++ b/lib/copy/copy_engine.c
@@ -38,7 +38,7 @@
 #include "spdk/env.h"
 #include "spdk/event.h"
 #include "spdk/log.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 static size_t g_max_copy_module_size = 0;
 
diff --git a/lib/copy/ioat/Makefile b/lib/copy/ioat/Makefile
index dda418796..3d19e38f2 100644
--- a/lib/copy/ioat/Makefile
+++ b/lib/copy/ioat/Makefile
@@ -35,6 +35,6 @@ SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
 LIBNAME = copy_ioat
-C_SRCS = copy_engine_ioat.c
+C_SRCS = copy_engine_ioat.c copy_engine_ioat_rpc.c
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/copy/ioat/copy_engine_ioat.c b/lib/copy/ioat/copy_engine_ioat.c
index c5dc7380e..625521a5e 100644
--- a/lib/copy/ioat/copy_engine_ioat.c
+++ b/lib/copy/ioat/copy_engine_ioat.c
@@ -31,6 +31,8 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
+#include "copy_engine_ioat.h"
+
 #include "spdk/stdinc.h"
 
 #include "spdk_internal/copy_engine.h"
@@ -39,12 +41,10 @@
 #include "spdk/env.h"
 #include "spdk/conf.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/ioat.h"
 
-#define IOAT_MAX_CHANNELS		64
-
-static bool g_ioat_disable = false;
+static bool g_ioat_enable = false;
 
 struct ioat_probe_ctx {
 	int num_whitelist_devices;
@@ -278,36 +278,103 @@ attach_cb(void *cb_ctx, struct spdk_pci_device *pci_dev, struct spdk_ioat_chan *
 	TAILQ_INSERT_TAIL(&g_devices, dev, tailq);
 }
 
+void
+copy_engine_ioat_enable_probe(void)
+{
+	g_ioat_enable = true;
+}
+
 static int
-copy_engine_ioat_init(void)
+copy_engine_ioat_add_whitelist_device(const char *pci_bdf)
+{
+	if (pci_bdf == NULL) {
+		return -1;
+	}
+
+	if (g_probe_ctx.num_whitelist_devices >= IOAT_MAX_CHANNELS) {
+		SPDK_ERRLOG("Ioat whitelist is full (max size is %d)\n",
+			    IOAT_MAX_CHANNELS);
+		return -1;
+	}
+
+	if (spdk_pci_addr_parse(&g_probe_ctx.whitelist[g_probe_ctx.num_whitelist_devices],
+				pci_bdf) < 0) {
+		SPDK_ERRLOG("Invalid address %s\n", pci_bdf);
+		return -1;
+	}
+
+	g_probe_ctx.num_whitelist_devices++;
+
+	return 0;
+}
+
+int
+copy_engine_ioat_add_whitelist_devices(const char *pci_bdfs[], size_t num_pci_bdfs)
+{
+	size_t i;
+
+	for (i = 0; i < num_pci_bdfs; i++) {
+		if (copy_engine_ioat_add_whitelist_device(pci_bdfs[i]) < 0) {
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+static int
+copy_engine_ioat_read_config_file_params(struct spdk_conf_section *sp)
 {
-	struct spdk_conf_section *sp = spdk_conf_find_section(NULL, "Ioat");
-	const char *pci_bdf;
 	int i;
+	char *val, *pci_bdf;
 
-	if (sp != NULL) {
-		if (spdk_conf_section_get_boolval(sp, "Disable", false)) {
-			g_ioat_disable = true;
-			/* Disable Ioat */
+	if (spdk_conf_section_get_boolval(sp, "Enable", false)) {
+		g_ioat_enable = true;
+		/* Enable Ioat */
+	}
+
+	val = spdk_conf_section_get_val(sp, "Disable");
+	if (val != NULL) {
+		SPDK_WARNLOG("\"Disable\" option is deprecated and will be removed in a future release.\n");
+		SPDK_WARNLOG("IOAT is now disabled by default. It may be enabled by \"Enable Yes\"\n");
+
+		if (g_ioat_enable && (strcasecmp(val, "Yes") == 0)) {
+			SPDK_ERRLOG("\"Enable Yes\" and \"Disable Yes\" cannot be set at the same time\n");
+			return -1;
+		}
+	}
+
+	/* Init the whitelist */
+	for (i = 0; ; i++) {
+		pci_bdf = spdk_conf_section_get_nmval(sp, "Whitelist", i, 0);
+		if (!pci_bdf) {
+			break;
 		}
 
-		/* Init the whitelist */
-		for (i = 0; i < IOAT_MAX_CHANNELS; i++) {
-			pci_bdf = spdk_conf_section_get_nmval(sp, "Whitelist", i, 0);
-			if (!pci_bdf) {
-				break;
-			}
-
-			if (spdk_pci_addr_parse(&g_probe_ctx.whitelist[g_probe_ctx.num_whitelist_devices],
-						pci_bdf) < 0) {
-				SPDK_ERRLOG("Invalid Ioat Whitelist address %s\n", pci_bdf);
-				return -1;
-			}
-			g_probe_ctx.num_whitelist_devices++;
+		if (copy_engine_ioat_add_whitelist_device(pci_bdf) < 0) {
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+static int
+copy_engine_ioat_init(void)
+{
+	struct spdk_conf_section *sp;
+	int rc;
+
+	sp = spdk_conf_find_section(NULL, "Ioat");
+	if (sp != NULL) {
+		rc = copy_engine_ioat_read_config_file_params(sp);
+		if (rc != 0) {
+			SPDK_ERRLOG("copy_engine_ioat_read_config_file_params() failed\n");
+			return rc;
 		}
 	}
 
-	if (g_ioat_disable) {
+	if (!g_ioat_enable) {
 		return 0;
 	}
 
@@ -329,8 +396,8 @@ copy_engine_ioat_init(void)
 "  # Users may use the whitelist to initialize specified devices, IDS\n" \
 "  #  uses BUS:DEVICE.FUNCTION to identify each Ioat channel.\n"
 
-#define COPY_ENGINE_IOAT_DISABLE_TMPL \
-"  Disable %s\n"
+#define COPY_ENGINE_IOAT_ENABLE_TMPL \
+"  Enable %s\n"
 
 #define COPY_ENGINE_IOAT_WHITELIST_TMPL \
 "  Whitelist %.4" PRIx16 ":%.2" PRIx8 ":%.2" PRIx8 ".%" PRIx8 "\n"
@@ -342,7 +409,7 @@ copy_engine_ioat_config_text(FILE *fp)
 	struct spdk_pci_addr *dev;
 
 	fprintf(fp, COPY_ENGINE_IOAT_HEADER_TMPL);
-	fprintf(fp, COPY_ENGINE_IOAT_DISABLE_TMPL, g_ioat_disable ? "Yes" : "No");
+	fprintf(fp, COPY_ENGINE_IOAT_ENABLE_TMPL, g_ioat_enable ? "Yes" : "No");
 
 	for (i = 0; i < g_probe_ctx.num_whitelist_devices; i++) {
 		dev = &g_probe_ctx.whitelist[i];
diff --git a/lib/copy/ioat/copy_engine_ioat.h b/lib/copy/ioat/copy_engine_ioat.h
new file mode 100644
index 000000000..ae69fb2d0
--- /dev/null
+++ b/lib/copy/ioat/copy_engine_ioat.h
@@ -0,0 +1,44 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef SPDK_COPY_ENGINE_IOAT_H
+#define SPDK_COPY_ENGINE_IOAT_H
+
+#include "spdk/stdinc.h"
+
+#define IOAT_MAX_CHANNELS	64
+
+int copy_engine_ioat_add_whitelist_devices(const char *pci_bdfs[], size_t num_pci_bdfs);
+void copy_engine_ioat_enable_probe(void);
+
+#endif /* SPDK_COPY_ENGINE_IOAT_H */
diff --git a/lib/copy/ioat/copy_engine_ioat_rpc.c b/lib/copy/ioat/copy_engine_ioat_rpc.c
new file mode 100644
index 000000000..ae03fdb16
--- /dev/null
+++ b/lib/copy/ioat/copy_engine_ioat_rpc.c
@@ -0,0 +1,118 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "copy_engine_ioat.h"
+
+#include "spdk/rpc.h"
+#include "spdk/util.h"
+#include "spdk/event.h"
+
+struct rpc_pci_whitelist {
+	size_t num_bdfs;
+	char *bdfs[IOAT_MAX_CHANNELS];
+};
+
+static int
+decode_rpc_pci_whitelist(const struct spdk_json_val *val, void *out)
+{
+	struct rpc_pci_whitelist *pci_whitelist = out;
+
+	return spdk_json_decode_array(val, spdk_json_decode_string, pci_whitelist->bdfs,
+				      IOAT_MAX_CHANNELS, &pci_whitelist->num_bdfs, sizeof(char *));
+}
+
+static void
+free_rpc_pci_whitelist(struct rpc_pci_whitelist *list)
+{
+	size_t i;
+
+	for (i = 0; i < list->num_bdfs; i++) {
+		free(list->bdfs[i]);
+	}
+}
+
+struct rpc_copy_engine_ioat {
+	struct rpc_pci_whitelist pci_whitelist;
+};
+
+static void
+free_rpc_copy_engine_ioat(struct rpc_copy_engine_ioat *p)
+{
+	free_rpc_pci_whitelist(&p->pci_whitelist);
+}
+
+static const struct spdk_json_object_decoder rpc_copy_engine_ioat_decoder[] = {
+	{"pci_whitelist", offsetof(struct rpc_copy_engine_ioat, pci_whitelist), decode_rpc_pci_whitelist},
+};
+
+static void
+spdk_rpc_scan_copy_engine_ioat(struct spdk_jsonrpc_request *request,
+			       const struct spdk_json_val *params)
+{
+	struct rpc_copy_engine_ioat req = {};
+	struct spdk_json_write_ctx *w;
+	int rc;
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, rpc_copy_engine_ioat_decoder,
+					    SPDK_COUNTOF(rpc_copy_engine_ioat_decoder),
+					    &req)) {
+			free_rpc_copy_engine_ioat(&req);
+			SPDK_ERRLOG("spdk_json_decode_object() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+
+		rc = copy_engine_ioat_add_whitelist_devices((const char **)req.pci_whitelist.bdfs,
+				req.pci_whitelist.num_bdfs);
+		free_rpc_copy_engine_ioat(&req);
+		if (rc < 0) {
+			SPDK_ERRLOG("copy_engine_ioat_add_whitelist_devices() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+	}
+
+	copy_engine_ioat_enable_probe();
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("scan_ioat_copy_engine", spdk_rpc_scan_copy_engine_ioat, SPDK_RPC_STARTUP)
diff --git a/lib/env_dpdk/env.c b/lib/env_dpdk/env.c
index 93f627294..02cd55730 100644
--- a/lib/env_dpdk/env.c
+++ b/lib/env_dpdk/env.c
@@ -65,6 +65,10 @@ virt_to_phys(void *vaddr)
 void *
 spdk_malloc(size_t size, size_t align, uint64_t *phys_addr, int socket_id, uint32_t flags)
 {
+	if (flags == 0) {
+		return NULL;
+	}
+
 	void *buf = rte_malloc_socket(NULL, size, align, socket_id);
 	if (buf && phys_addr) {
 		*phys_addr = virt_to_phys(buf);
@@ -129,15 +133,26 @@ spdk_dma_free(void *buf)
 }
 
 void *
-spdk_memzone_reserve(const char *name, size_t len, int socket_id, unsigned flags)
+spdk_memzone_reserve_aligned(const char *name, size_t len, int socket_id,
+			     unsigned flags, unsigned align)
 {
 	const struct rte_memzone *mz;
+	unsigned dpdk_flags = 0;
+
+#if RTE_VERSION >= RTE_VERSION_NUM(18, 05, 0, 0)
+	/* Older DPDKs do not offer such flag since their
+	 * memzones are iova-contiguous by default.
+	 */
+	if ((flags & SPDK_MEMZONE_NO_IOVA_CONTIG) == 0) {
+		dpdk_flags |= RTE_MEMZONE_IOVA_CONTIG;
+	}
+#endif
 
 	if (socket_id == SPDK_ENV_SOCKET_ID_ANY) {
 		socket_id = SOCKET_ID_ANY;
 	}
 
-	mz = rte_memzone_reserve(name, len, socket_id, flags);
+	mz = rte_memzone_reserve_aligned(name, len, socket_id, dpdk_flags, align);
 
 	if (mz != NULL) {
 		memset(mz->addr, 0, len);
@@ -147,6 +162,13 @@ spdk_memzone_reserve(const char *name, size_t len, int socket_id, unsigned flags
 	}
 }
 
+void *
+spdk_memzone_reserve(const char *name, size_t len, int socket_id, unsigned flags)
+{
+	return spdk_memzone_reserve_aligned(name, len, socket_id, flags,
+					    RTE_CACHE_LINE_SIZE);
+}
+
 void *
 spdk_memzone_lookup(const char *name)
 {
@@ -255,7 +277,7 @@ spdk_mempool_put(struct spdk_mempool *mp, void *ele)
 }
 
 void
-spdk_mempool_put_bulk(struct spdk_mempool *mp, void *const *ele_arr, size_t count)
+spdk_mempool_put_bulk(struct spdk_mempool *mp, void **ele_arr, size_t count)
 {
 	rte_mempool_put_bulk((struct rte_mempool *)mp, ele_arr, count);
 }
diff --git a/lib/env_dpdk/env.mk b/lib/env_dpdk/env.mk
index 450043c4f..a4fa95b83 100644
--- a/lib/env_dpdk/env.mk
+++ b/lib/env_dpdk/env.mk
@@ -80,14 +80,15 @@ endif
 
 DPDK_LIB = $(DPDK_LIB_LIST:%=$(DPDK_ABS_DIR)/lib/lib%$(DPDK_LIB_EXT))
 
-ENV_CFLAGS = $(DPDK_INC)
+# SPDK memory registration requires experimental (deprecated) rte_memory API for DPDK 18.05
+ENV_CFLAGS = $(DPDK_INC) -Wno-deprecated-declarations
 ENV_CXXFLAGS = $(ENV_CFLAGS)
 ENV_DPDK_FILE = $(call spdk_lib_list_to_files,env_dpdk)
 ENV_LIBS = $(ENV_DPDK_FILE) $(DPDK_LIB)
 ENV_LINKER_ARGS = $(ENV_DPDK_FILE) -Wl,--start-group -Wl,--whole-archive $(DPDK_LIB) -Wl,--end-group -Wl,--no-whole-archive
 
 ifneq (,$(wildcard $(DPDK_INC_DIR)/rte_config.h))
-ifneq (,$(shell grep "define RTE_LIBRTE_VHOST_NUMA 1" $(DPDK_INC_DIR)/rte_config.h))
+ifneq (,$(shell grep -e "define RTE_LIBRTE_VHOST_NUMA 1" -e "define RTE_EAL_NUMA_AWARE_HUGEPAGES 1" $(DPDK_INC_DIR)/rte_config.h))
 ENV_LINKER_ARGS += -lnuma
 endif
 endif
diff --git a/lib/env_dpdk/init.c b/lib/env_dpdk/init.c
index ec16a003d..f5858e44b 100644
--- a/lib/env_dpdk/init.c
+++ b/lib/env_dpdk/init.c
@@ -250,6 +250,30 @@ spdk_build_eal_cmdline(const struct spdk_env_opts *opts)
 		}
 	}
 
+	/* unlink hugepages after initialization */
+	if (opts->unlink_hugepage) {
+		args = spdk_push_arg(args, &argcount, _sprintf_alloc("--huge-unlink"));
+		if (args == NULL) {
+			return -1;
+		}
+	}
+
+	if (opts->num_pci_addr) {
+		size_t i;
+		char bdf[32];
+		struct spdk_pci_addr *pci_addr =
+				opts->pci_blacklist ? opts->pci_blacklist : opts->pci_whitelist;
+
+		for (i = 0; i < opts->num_pci_addr; i++) {
+			spdk_pci_addr_fmt(bdf, 32, &pci_addr[i]);
+			args = spdk_push_arg(args, &argcount, _sprintf_alloc("%s %s",
+					     (opts->pci_blacklist ? "-b" : "-w"), bdf));
+			if (args == NULL) {
+				return -1;
+			}
+		}
+	}
+
 #ifdef __linux__
 	if (opts->shm_id < 0) {
 		args = spdk_push_arg(args, &argcount, _sprintf_alloc("--file-prefix=spdk_pid%d",
@@ -264,8 +288,13 @@ spdk_build_eal_cmdline(const struct spdk_env_opts *opts)
 			return -1;
 		}
 
-		/* set the base virtual address */
-		args = spdk_push_arg(args, &argcount, _sprintf_alloc("--base-virtaddr=0x1000000000"));
+		/* Set the base virtual address - it must be an address that is not in the
+		 * ASAN shadow region, otherwise ASAN-enabled builds will ignore the
+		 * mmap hint.
+		 *
+		 * Ref: https://github.com/google/sanitizers/wiki/AddressSanitizerAlgorithm
+		 */
+		args = spdk_push_arg(args, &argcount, _sprintf_alloc("--base-virtaddr=0x200000000000"));
 		if (args == NULL) {
 			return -1;
 		}
diff --git a/lib/env_dpdk/memory.c b/lib/env_dpdk/memory.c
index aabec7b3d..db0ce9216 100644
--- a/lib/env_dpdk/memory.c
+++ b/lib/env_dpdk/memory.c
@@ -55,7 +55,7 @@
 #define FN_4KB_TO_2MB(fn)	(fn >> (SHIFT_2MB - SHIFT_4KB))
 
 #define MAP_256TB_IDX(vfn_2mb)	((vfn_2mb) >> (SHIFT_1GB - SHIFT_2MB))
-#define MAP_1GB_IDX(vfn_2mb)	((vfn_2mb) & ((1ULL << (SHIFT_1GB - SHIFT_2MB + 1)) - 1))
+#define MAP_1GB_IDX(vfn_2mb)	((vfn_2mb) & ((1ULL << (SHIFT_1GB - SHIFT_2MB)) - 1))
 
 /* Translation of a single 2MB page. */
 struct map_2mb {
@@ -67,14 +67,14 @@ struct map_2mb {
  * been retrieved yet.
  */
 struct map_1gb {
-	struct map_2mb map[1ULL << (SHIFT_1GB - SHIFT_2MB + 1)];
+	struct map_2mb map[1ULL << (SHIFT_1GB - SHIFT_2MB)];
 };
 
 /* Top-level map table indexed by bits [30..46] of the virtual address.
  * Each entry points to a second-level map table or NULL.
  */
 struct map_256tb {
-	struct map_1gb *map[1ULL << (SHIFT_256TB - SHIFT_1GB + 1)];
+	struct map_1gb *map[1ULL << (SHIFT_256TB - SHIFT_1GB)];
 };
 
 /* Page-granularity memory address translation */
@@ -239,7 +239,7 @@ spdk_mem_register(void *vaddr, size_t len)
 		uint64_t ref_count;
 
 		/* In g_mem_reg_map, the "translation" is the reference count */
-		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)vaddr);
+		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)vaddr, VALUE_2MB);
 		spdk_mem_map_set_translation(g_mem_reg_map, (uint64_t)vaddr, VALUE_2MB, ref_count + 1);
 
 		if (ref_count > 0) {
@@ -302,7 +302,7 @@ spdk_mem_unregister(void *vaddr, size_t len)
 	seg_vaddr = vaddr;
 	seg_len = len;
 	while (seg_len > 0) {
-		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)seg_vaddr);
+		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)seg_vaddr, VALUE_2MB);
 		if (ref_count == 0) {
 			pthread_mutex_unlock(&g_spdk_mem_map_mutex);
 			return -EINVAL;
@@ -315,7 +315,7 @@ spdk_mem_unregister(void *vaddr, size_t len)
 	seg_len = 0;
 	while (len > 0) {
 		/* In g_mem_reg_map, the "translation" is the reference count */
-		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)vaddr);
+		ref_count = spdk_mem_map_translate(g_mem_reg_map, (uint64_t)vaddr, VALUE_2MB);
 		spdk_mem_map_set_translation(g_mem_reg_map, (uint64_t)vaddr, VALUE_2MB, ref_count - 1);
 
 		if (ref_count > 1) {
@@ -360,6 +360,10 @@ spdk_mem_map_get_map_1gb(struct spdk_mem_map *map, uint64_t vfn_2mb)
 	uint64_t idx_256tb = MAP_256TB_IDX(vfn_2mb);
 	size_t i;
 
+	if (spdk_unlikely(idx_256tb >= SPDK_COUNTOF(map->map_256tb.map))) {
+		return NULL;
+	}
+
 	map_1gb = map->map_256tb.map[idx_256tb];
 
 	if (!map_1gb) {
@@ -398,12 +402,12 @@ spdk_mem_map_set_translation(struct spdk_mem_map *map, uint64_t vaddr, uint64_t
 	uint64_t idx_1gb;
 	struct map_2mb *map_2mb;
 
-	/* For now, only 2 MB-aligned registrations are supported */
 	if ((uintptr_t)vaddr & ~MASK_256TB) {
 		DEBUG_PRINT("invalid usermode virtual address %lu\n", vaddr);
 		return -EINVAL;
 	}
 
+	/* For now, only 2 MB-aligned registrations are supported */
 	if (((uintptr_t)vaddr & MASK_2MB) || (size & MASK_2MB)) {
 		DEBUG_PRINT("invalid %s parameters, vaddr=%lu len=%ju\n",
 			    __func__, vaddr, size);
@@ -438,12 +442,12 @@ spdk_mem_map_clear_translation(struct spdk_mem_map *map, uint64_t vaddr, uint64_
 	uint64_t idx_1gb;
 	struct map_2mb *map_2mb;
 
-	/* For now, only 2 MB-aligned registrations are supported */
 	if ((uintptr_t)vaddr & ~MASK_256TB) {
 		DEBUG_PRINT("invalid usermode virtual address %lu\n", vaddr);
 		return -EINVAL;
 	}
 
+	/* For now, only 2 MB-aligned registrations are supported */
 	if (((uintptr_t)vaddr & MASK_2MB) || (size & MASK_2MB)) {
 		DEBUG_PRINT("invalid %s parameters, vaddr=%lu len=%ju\n",
 			    __func__, vaddr, size);
@@ -471,7 +475,7 @@ spdk_mem_map_clear_translation(struct spdk_mem_map *map, uint64_t vaddr, uint64_
 }
 
 uint64_t
-spdk_mem_map_translate(const struct spdk_mem_map *map, uint64_t vaddr)
+spdk_mem_map_translate(const struct spdk_mem_map *map, uint64_t vaddr, uint64_t size)
 {
 	const struct map_1gb *map_1gb;
 	const struct map_2mb *map_2mb;
@@ -498,12 +502,29 @@ spdk_mem_map_translate(const struct spdk_mem_map *map, uint64_t vaddr)
 	return map_2mb->translation_2mb;
 }
 
+#if RTE_VERSION >= RTE_VERSION_NUM(18, 05, 0, 0)
+static void
+memory_hotplug_cb(enum rte_mem_event event_type,
+		  const void *addr, size_t len, void *arg)
+{
+	if (event_type == RTE_MEM_EVENT_ALLOC) {
+		spdk_mem_register((void *)addr, len);
+	} else if (event_type == RTE_MEM_EVENT_FREE) {
+		spdk_mem_unregister((void *)addr, len);
+	}
+}
+
+static int
+memory_iter_cb(const struct rte_memseg_list *msl,
+	       const struct rte_memseg *ms, size_t len, void *arg)
+{
+	return spdk_mem_register(ms->addr, len);
+}
+#endif
+
 int
 spdk_mem_map_init(void)
 {
-	struct rte_mem_config *mcfg;
-	size_t seg_idx;
-
 	g_mem_reg_map = spdk_mem_map_alloc(0, NULL, NULL);
 	if (g_mem_reg_map == NULL) {
 		DEBUG_PRINT("memory registration map allocation failed\n");
@@ -514,8 +535,14 @@ spdk_mem_map_init(void)
 	 * Walk all DPDK memory segments and register them
 	 * with the master memory map
 	 */
-	mcfg = rte_eal_get_configuration()->mem_config;
+#if RTE_VERSION >= RTE_VERSION_NUM(18, 05, 0, 0)
+	rte_mem_event_callback_register("spdk", memory_hotplug_cb, NULL);
+	rte_memseg_contig_walk(memory_iter_cb, NULL);
+#else
+	struct rte_mem_config *mcfg;
+	size_t seg_idx;
 
+	mcfg = rte_eal_get_configuration()->mem_config;
 	for (seg_idx = 0; seg_idx < RTE_MAX_MEMSEG; seg_idx++) {
 		struct rte_memseg *seg = &mcfg->memseg[seg_idx];
 
@@ -525,5 +552,6 @@ spdk_mem_map_init(void)
 
 		spdk_mem_register(seg->addr, seg->len);
 	}
+#endif
 	return 0;
 }
diff --git a/lib/env_dpdk/pci.c b/lib/env_dpdk/pci.c
index a9e51e9a9..2fbf3a292 100644
--- a/lib/env_dpdk/pci.c
+++ b/lib/env_dpdk/pci.c
@@ -207,12 +207,6 @@ spdk_pci_enumerate(struct spdk_pci_enum_ctx *ctx,
 	return 0;
 }
 
-struct spdk_pci_device *
-spdk_pci_get_device(struct spdk_pci_addr *pci_addr)
-{
-	return NULL;
-}
-
 int
 spdk_pci_device_map_bar(struct spdk_pci_device *device, uint32_t bar,
 			void **mapped_addr, uint64_t *phys_addr, uint64_t *size)
diff --git a/lib/env_dpdk/vtophys.c b/lib/env_dpdk/vtophys.c
index 254997c0a..fe483b17b 100644
--- a/lib/env_dpdk/vtophys.c
+++ b/lib/env_dpdk/vtophys.c
@@ -214,12 +214,23 @@ static uint64_t
 vtophys_get_paddr_memseg(uint64_t vaddr)
 {
 	uintptr_t paddr;
-	struct rte_mem_config *mcfg;
 	struct rte_memseg *seg;
+
+#if RTE_VERSION >= RTE_VERSION_NUM(18, 05, 0, 0)
+	seg = rte_mem_virt2memseg((void *)(uintptr_t)vaddr, NULL);
+	if (seg != NULL) {
+		paddr = seg->phys_addr;
+		if (paddr == RTE_BAD_IOVA) {
+			return SPDK_VTOPHYS_ERROR;
+		}
+		paddr += (vaddr - (uintptr_t)seg->addr);
+		return paddr;
+	}
+#else
+	struct rte_mem_config *mcfg;
 	uint32_t seg_idx;
 
 	mcfg = rte_eal_get_configuration()->mem_config;
-
 	for (seg_idx = 0; seg_idx < RTE_MAX_MEMSEG; seg_idx++) {
 		seg = &mcfg->memseg[seg_idx];
 		if (seg->addr == NULL) {
@@ -240,6 +251,7 @@ vtophys_get_paddr_memseg(uint64_t vaddr)
 			return paddr;
 		}
 	}
+#endif
 
 	return SPDK_VTOPHYS_ERROR;
 }
@@ -250,21 +262,38 @@ vtophys_get_paddr_pagemap(uint64_t vaddr)
 {
 	uintptr_t paddr;
 
-	paddr = rte_mem_virt2phy((void *)vaddr);
-	if (paddr == 0) {
+#if RTE_VERSION >= RTE_VERSION_NUM(17, 11, 0, 3)
+#define BAD_ADDR RTE_BAD_IOVA
+#define VTOPHYS rte_mem_virt2iova
+#else
+#define BAD_ADDR RTE_BAD_PHYS_ADDR
+#define VTOPHYS rte_mem_virt2phy
+#endif
+
+	/*
+	 * Note: the virt2phy/virt2iova functions have changed over time, such
+	 * that older versions may return 0 while recent versions will never
+	 * return 0 but RTE_BAD_PHYS_ADDR/IOVA instead.  To support older and
+	 * newer versions, check for both return values.
+	 */
+	paddr = VTOPHYS((void *)vaddr);
+	if (paddr == 0 || paddr == BAD_ADDR) {
 		/*
-		 * The vaddr was valid but returned 0.  Touch the page
-		 * to ensure a backing page gets assigned, then call
-		 * rte_mem_virt2phy() again.
+		 * The vaddr may be valid but doesn't have a backing page
+		 * assigned yet.  Touch the page to ensure a backing page
+		 * gets assigned, then try to translate again.
 		 */
 		rte_atomic64_read((rte_atomic64_t *)vaddr);
-		paddr = rte_mem_virt2phy((void *)vaddr);
+		paddr = VTOPHYS((void *)vaddr);
 	}
-	if (paddr == RTE_BAD_PHYS_ADDR) {
+	if (paddr == 0 || paddr == BAD_ADDR) {
 		/* Unable to get to the physical address. */
 		return SPDK_VTOPHYS_ERROR;
 	}
 
+#undef BAD_ADDR
+#undef VTOPHYS
+
 	return paddr;
 }
 
@@ -375,7 +404,7 @@ spdk_vtophys_notify(void *cb_ctx, struct spdk_mem_map *map,
 				 * we need to unmap the range from the IOMMU
 				 */
 				if (g_vfio.enabled) {
-					paddr = spdk_mem_map_translate(map, (uint64_t)vaddr);
+					paddr = spdk_mem_map_translate(map, (uint64_t)vaddr, VALUE_2MB);
 					rc = vtophys_iommu_unmap_dma(paddr, VALUE_2MB);
 					if (rc) {
 						return -EFAULT;
@@ -589,7 +618,7 @@ spdk_vtophys(void *buf)
 
 	vaddr = (uint64_t)buf;
 
-	paddr_2mb = spdk_mem_map_translate(g_vtophys_map, vaddr);
+	paddr_2mb = spdk_mem_map_translate(g_vtophys_map, vaddr, VALUE_2MB);
 
 	/*
 	 * SPDK_VTOPHYS_ERROR has all bits set, so if the lookup returned SPDK_VTOPHYS_ERROR,
diff --git a/lib/event/app.c b/lib/event/app.c
index 8e41884d9..13376c9b3 100644
--- a/lib/event/app.c
+++ b/lib/event/app.c
@@ -40,6 +40,7 @@
 #include "spdk/conf.h"
 #include "spdk/trace.h"
 #include "spdk/string.h"
+#include "spdk/rpc.h"
 
 #define SPDK_APP_DEFAULT_LOG_LEVEL		SPDK_LOG_NOTICE
 #define SPDK_APP_DEFAULT_LOG_PRINT_LEVEL	SPDK_LOG_INFO
@@ -57,13 +58,13 @@ struct spdk_app {
 };
 
 static struct spdk_app g_spdk_app;
+static struct spdk_event *g_app_start_event = NULL;
 static struct spdk_event *g_shutdown_event = NULL;
 static int g_init_lcore;
+static bool g_delay_subsystem_init = false;
 static bool g_shutdown_sig_received = false;
-
-static spdk_event_fn g_app_start_fn;
-static void *g_app_start_arg1;
-static void *g_app_start_arg2;
+static char *g_executable_name;
+static struct spdk_app_opts g_default_opts;
 
 int
 spdk_app_get_shm_id(void)
@@ -206,6 +207,7 @@ spdk_app_opts_init(struct spdk_app_opts *opts)
 	opts->max_delay_us = 0;
 	opts->print_level = SPDK_APP_DEFAULT_LOG_PRINT_LEVEL;
 	opts->rpc_addr = SPDK_DEFAULT_RPC_ADDR;
+	opts->delay_subsystem_init = false;
 }
 
 static int
@@ -266,12 +268,21 @@ spdk_app_setup_signal_handlers(struct spdk_app_opts *opts)
 }
 
 static void
-start_rpc(void *arg1, void *arg2)
+spdk_app_start_application(void)
+{
+	spdk_rpc_set_state(SPDK_RPC_RUNTIME);
+	spdk_event_call(g_app_start_event);
+}
+
+static void
+spdk_app_start_rpc(void *arg1, void *arg2)
 {
 	const char *rpc_addr = arg1;
 
 	spdk_rpc_initialize(rpc_addr);
-	g_app_start_fn(g_app_start_arg1, g_app_start_arg2);
+	if (!g_delay_subsystem_init) {
+		spdk_app_start_application();
+	}
 }
 
 static struct spdk_conf *
@@ -301,10 +312,34 @@ error:
 	return NULL;
 }
 
-static void
+static int
+spdk_app_opts_add_pci_addr(struct spdk_app_opts *opts, struct spdk_pci_addr **list, char *bdf)
+{
+	struct spdk_pci_addr *tmp = *list;
+	size_t i = opts->num_pci_addr;
+
+	tmp = realloc(tmp, sizeof(*tmp) * (i + 1));
+	if (tmp == NULL) {
+		SPDK_ERRLOG("realloc error\n");
+		return -ENOMEM;
+	}
+
+	*list = tmp;
+	if (spdk_pci_addr_parse(*list + i, bdf) < 0) {
+		SPDK_ERRLOG("Invalid address %s\n", bdf);
+		return -EINVAL;
+	}
+
+	opts->num_pci_addr++;
+	return 0;
+}
+
+static int
 spdk_app_read_config_file_global_params(struct spdk_app_opts *opts)
 {
 	struct spdk_conf_section *sp;
+	char *bdf;
+	int i, rc = 0;
 
 	sp = spdk_conf_find_section(NULL, "Global");
 
@@ -331,6 +366,43 @@ spdk_app_read_config_file_global_params(struct spdk_app_opts *opts)
 			opts->tpoint_group_mask = spdk_conf_section_get_val(sp, "TpointGroupMask");
 		}
 	}
+
+	if (sp == NULL) {
+		return 0;
+	}
+
+	for (i = 0; ; i++) {
+		bdf = spdk_conf_section_get_nmval(sp, "PciBlacklist", i, 0);
+		if (!bdf) {
+			break;
+		}
+
+		rc = spdk_app_opts_add_pci_addr(opts, &opts->pci_blacklist, bdf);
+		if (rc != 0) {
+			free(opts->pci_blacklist);
+			return rc;
+		}
+	}
+
+	for (i = 0; ; i++) {
+		bdf = spdk_conf_section_get_nmval(sp, "PciWhitelist", i, 0);
+		if (!bdf) {
+			break;
+		}
+
+		if (opts->pci_blacklist != NULL) {
+			SPDK_ERRLOG("PciBlacklist and PciWhitelist cannot be used at the same time\n");
+			free(opts->pci_blacklist);
+			return -EINVAL;
+		}
+
+		rc = spdk_app_opts_add_pci_addr(opts, &opts->pci_whitelist, bdf);
+		if (rc != 0) {
+			free(opts->pci_whitelist);
+			return rc;
+		}
+	}
+	return 0;
 }
 
 static int
@@ -347,9 +419,17 @@ spdk_app_setup_env(struct spdk_app_opts *opts)
 	env_opts.mem_channel = opts->mem_channel;
 	env_opts.master_core = opts->master_core;
 	env_opts.mem_size = opts->mem_size;
+	env_opts.hugepage_single_segments = opts->hugepage_single_segments;
+	env_opts.unlink_hugepage = opts->unlink_hugepage;
 	env_opts.no_pci = opts->no_pci;
+	env_opts.num_pci_addr = opts->num_pci_addr;
+	env_opts.pci_blacklist = opts->pci_blacklist;
+	env_opts.pci_whitelist = opts->pci_whitelist;
 
 	rc = spdk_env_init(&env_opts);
+	free(env_opts.pci_blacklist);
+	free(env_opts.pci_whitelist);
+
 	if (rc < 0) {
 		SPDK_ERRLOG("Unable to initialize SPDK env\n");
 	}
@@ -398,13 +478,18 @@ spdk_app_start(struct spdk_app_opts *opts, spdk_event_fn start_fn,
 {
 	struct spdk_conf	*config = NULL;
 	int			rc;
-	struct spdk_event	*app_start_event;
+	struct spdk_event	*rpc_start_event;
 
 	if (!opts) {
 		SPDK_ERRLOG("opts should not be NULL\n");
 		return 1;
 	}
 
+	if (!start_fn) {
+		SPDK_ERRLOG("start_fn should not be NULL\n");
+		return 1;
+	}
+
 	if (opts->print_level > SPDK_LOG_WARN &&
 	    isatty(STDERR_FILENO) &&
 	    !strncmp(ttyname(STDERR_FILENO), "/dev/tty", strlen("/dev/tty"))) {
@@ -431,7 +516,9 @@ spdk_app_start(struct spdk_app_opts *opts, spdk_event_fn start_fn,
 		goto app_start_setup_conf_err;
 	}
 
-	spdk_app_read_config_file_global_params(opts);
+	if (spdk_app_read_config_file_global_params(opts) < 0) {
+		goto app_start_setup_conf_err;
+	}
 
 	spdk_log_set_level(SPDK_APP_DEFAULT_LOG_LEVEL);
 	spdk_log_open();
@@ -473,12 +560,17 @@ spdk_app_start(struct spdk_app_opts *opts, spdk_event_fn start_fn,
 	g_spdk_app.shutdown_cb = opts->shutdown_cb;
 	g_spdk_app.rc = 0;
 	g_init_lcore = spdk_env_get_current_core();
-	g_app_start_fn = start_fn;
-	g_app_start_arg1 = arg1;
-	g_app_start_arg2 = arg2;
-	app_start_event = spdk_event_allocate(g_init_lcore, start_rpc, (void *)opts->rpc_addr, NULL);
+	g_delay_subsystem_init = opts->delay_subsystem_init;
+	g_app_start_event = spdk_event_allocate(g_init_lcore, start_fn, arg1, arg2);
 
-	spdk_subsystem_init(app_start_event);
+	rpc_start_event = spdk_event_allocate(g_init_lcore, spdk_app_start_rpc,
+					      (void *)opts->rpc_addr, NULL);
+
+	if (!g_delay_subsystem_init) {
+		spdk_subsystem_init(rpc_start_event);
+	} else {
+		spdk_event_call(rpc_start_event);
+	}
 
 	/* This blocks until spdk_app_stop is called */
 	spdk_reactors_start();
@@ -530,11 +622,11 @@ spdk_app_stop(int rc)
 }
 
 static void
-usage(char *executable_name, struct spdk_app_opts *default_opts, void (*app_usage)(void))
+usage(void (*app_usage)(void))
 {
-	printf("%s [options]\n", executable_name);
+	printf("%s [options]\n", g_executable_name);
 	printf("options:\n");
-	printf(" -c config  config file (default %s)\n", default_opts->config_file);
+	printf(" -c config  config file (default %s)\n", g_default_opts.config_file);
 	printf(" -d         disable coredump file enabling\n");
 	printf(" -e mask    tracepoint group mask for spdk trace buffers (default 0x0)\n");
 	printf(" -g         force creating just one hugetlbfs file\n");
@@ -546,14 +638,20 @@ usage(char *executable_name, struct spdk_app_opts *default_opts, void (*app_usag
 	printf(" -q         disable notice level logging to stderr\n");
 	printf(" -r         RPC listen address (default %s)\n", SPDK_DEFAULT_RPC_ADDR);
 	printf(" -s size    memory size in MB for DPDK (default: ");
-	if (default_opts->mem_size > 0) {
-		printf("%dMB)\n", default_opts->mem_size);
+	if (g_default_opts.mem_size > 0) {
+		printf("%dMB)\n", g_default_opts.mem_size);
 	} else {
 		printf("all hugepage memory)\n");
 	}
 	printf(" -u         disable PCI access.\n");
-	spdk_tracelog_usage(stdout, "-t");
-	app_usage();
+	printf(" -w         wait for RPCs to initialize subsystems\n");
+	printf(" -B addr    pci addr to blacklist\n");
+	printf(" -R         unlink huge files after initialization\n");
+	printf(" -W addr    pci addr to whitelist (-B and -W cannot be used at the same time)\n");
+	spdk_tracelog_usage(stdout, "-L");
+	if (app_usage) {
+		app_usage();
+	}
 }
 
 spdk_app_parse_args_rvals_t
@@ -562,11 +660,10 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 		    void (*app_usage)(void))
 {
 	int ch, rc;
-	struct spdk_app_opts default_opts;
 	char *getopt_str;
 	spdk_app_parse_args_rvals_t rval = SPDK_APP_PARSE_ARGS_SUCCESS;
 
-	memcpy(&default_opts, opts, sizeof(default_opts));
+	memcpy(&g_default_opts, opts, sizeof(g_default_opts));
 
 	if (opts->config_file && access(opts->config_file, F_OK) != 0) {
 		opts->config_file = NULL;
@@ -579,6 +676,8 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 		goto parse_early_fail;
 	}
 
+	g_executable_name = argv[0];
+
 	while ((ch = getopt(argc, argv, getopt_str)) != -1) {
 		switch (ch) {
 		case 'c':
@@ -594,7 +693,7 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 			opts->hugepage_single_segments = true;
 			break;
 		case 'h':
-			usage(argv[0], &default_opts, app_usage);
+			usage(app_usage);
 			rval = SPDK_APP_PARSE_ARGS_HELP;
 			goto parse_done;
 		case 'i':
@@ -634,7 +733,7 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 			rc = spdk_parse_capacity(optarg, &mem_size_mb, &mem_size_has_prefix);
 			if (rc != 0) {
 				fprintf(stderr, "invalid memory pool size `-s %s`\n", optarg);
-				usage(argv[0], &default_opts, app_usage);
+				usage(app_usage);
 				rval = SPDK_APP_PARSE_ARGS_FAIL;
 				goto parse_done;
 			}
@@ -648,7 +747,7 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 
 			if (mem_size_mb > INT_MAX) {
 				fprintf(stderr, "invalid memory pool size `-s %s`\n", optarg);
-				usage(argv[0], &default_opts, app_usage);
+				usage(app_usage);
 				rval = SPDK_APP_PARSE_ARGS_FAIL;
 				goto parse_done;
 			}
@@ -656,26 +755,64 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 			opts->mem_size = (int) mem_size_mb;
 			break;
 		}
-		case 't':
-			rc = spdk_log_set_trace_flag(optarg);
-			if (rc < 0) {
-				fprintf(stderr, "unknown flag\n");
-				usage(argv[0], &default_opts, app_usage);
+		case 'u':
+			opts->no_pci = true;
+			break;
+		case 'w':
+			opts->delay_subsystem_init = true;
+			break;
+		case 'B':
+			if (opts->pci_whitelist) {
+				free(opts->pci_whitelist);
+				fprintf(stderr, "-B and -W cannot be used at the same time\n");
+				usage(app_usage);
 				rval = SPDK_APP_PARSE_ARGS_FAIL;
 				goto parse_done;
 			}
-			opts->print_level = SPDK_LOG_DEBUG;
+
+			rc = spdk_app_opts_add_pci_addr(opts, &opts->pci_blacklist, optarg);
+			if (rc != 0) {
+				free(opts->pci_blacklist);
+				rval = SPDK_APP_PARSE_ARGS_FAIL;
+				goto parse_done;
+			}
+			break;
+		case 'L':
 #ifndef DEBUG
-			fprintf(stderr, "%s must be built with CONFIG_DEBUG=y for -t flag\n",
+			fprintf(stderr, "%s must be built with CONFIG_DEBUG=y for -L flag\n",
 				argv[0]);
-			usage(argv[0], &default_opts, app_usage);
+			usage(app_usage);
 			rval = SPDK_APP_PARSE_ARGS_FAIL;
 			goto parse_done;
 #else
+			rc = spdk_log_set_trace_flag(optarg);
+			if (rc < 0) {
+				fprintf(stderr, "unknown flag\n");
+				usage(app_usage);
+				rval = SPDK_APP_PARSE_ARGS_FAIL;
+				goto parse_done;
+			}
+			opts->print_level = SPDK_LOG_DEBUG;
 			break;
 #endif
-		case 'u':
-			opts->no_pci = true;
+		case 'R':
+			opts->unlink_hugepage = true;
+			break;
+		case 'W':
+			if (opts->pci_blacklist) {
+				free(opts->pci_blacklist);
+				fprintf(stderr, "-B and -W cannot be used at the same time\n");
+				usage(app_usage);
+				rval = SPDK_APP_PARSE_ARGS_FAIL;
+				goto parse_done;
+			}
+
+			rc = spdk_app_opts_add_pci_addr(opts, &opts->pci_whitelist, optarg);
+			if (rc != 0) {
+				free(opts->pci_whitelist);
+				rval = SPDK_APP_PARSE_ARGS_FAIL;
+				goto parse_done;
+			}
 			break;
 		case '?':
 			/*
@@ -683,7 +820,7 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 			 * in argv that is NOT in the getopt_str,
 			 * getopt() will return a '?' indicating failure.
 			 */
-			usage(argv[0], &default_opts, app_usage);
+			usage(app_usage);
 			rval = SPDK_APP_PARSE_ARGS_FAIL;
 			goto parse_done;
 		default:
@@ -691,9 +828,62 @@ spdk_app_parse_args(int argc, char **argv, struct spdk_app_opts *opts,
 		}
 	}
 
+	/* TBD: Replace warning by failure when RPCs for startup are prepared. */
+	if (opts->config_file && opts->delay_subsystem_init) {
+		fprintf(stderr,
+			"WARNING: -w and config file are used at the same time. "
+			"- Please be careful one options might overwrite others.\n");
+	}
+
 parse_done:
 	free(getopt_str);
 
 parse_early_fail:
 	return rval;
 }
+
+void
+spdk_app_usage(void)
+{
+	if (g_executable_name == NULL) {
+		fprintf(stderr, "%s not valid before calling spdk_app_parse_args()\n", __func__);
+		return;
+	}
+
+	usage(NULL);
+}
+
+static void
+spdk_rpc_start_subsystem_init_cpl(void *arg1, void *arg2)
+{
+	struct spdk_jsonrpc_request *request = arg1;
+	struct spdk_json_write_ctx *w;
+
+	spdk_app_start_application();
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+
+static void
+spdk_rpc_start_subsystem_init(struct spdk_jsonrpc_request *request,
+			      const struct spdk_json_val *params)
+{
+	struct spdk_event *cb_event;
+
+	if (params != NULL) {
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						 "start_subsystem_init requires no parameters");
+		return;
+	}
+
+	cb_event = spdk_event_allocate(g_init_lcore, spdk_rpc_start_subsystem_init_cpl,
+				       request, NULL);
+	spdk_subsystem_init(cb_event);
+}
+SPDK_RPC_REGISTER("start_subsystem_init", spdk_rpc_start_subsystem_init, SPDK_RPC_STARTUP)
diff --git a/lib/event/reactor.c b/lib/event/reactor.c
index bd4ae5f7a..a8b55b334 100644
--- a/lib/event/reactor.c
+++ b/lib/event/reactor.c
@@ -38,13 +38,13 @@
 #include "spdk_internal/log.h"
 
 #include "spdk/log.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/env.h"
+#include "spdk/util.h"
 
 #define SPDK_MAX_SOCKET		64
 
 #define SPDK_REACTOR_SPIN_TIME_USEC	1000
-#define SPDK_TIMER_POLL_ITERATIONS	5
 #define SPDK_EVENT_BATCH_SIZE		8
 #define SPDK_SEC_TO_USEC		1000000ULL
 
@@ -90,6 +90,11 @@ struct spdk_reactor {
 	/* Poller for get the rusage for the reactor. */
 	struct spdk_poller				*rusage_poller;
 
+	/* Reactor tsc stats */
+	struct spdk_reactor_tsc_stats			tsc_stats;
+
+	uint64_t					tsc_last;
+
 	/* The last known rusage values */
 	struct rusage					rusage;
 
@@ -363,6 +368,24 @@ _spdk_reactor_context_switch_monitor_stop(void *arg1, void *arg2)
 	}
 }
 
+static size_t
+_spdk_reactor_get_max_event_cnt(uint8_t socket_count)
+{
+	size_t cnt;
+
+	/* Try to make event ring fill at most 2MB of memory,
+	 * as some ring implementations may require physical address
+	 * contingency. We don't want to introduce a requirement of
+	 * at least 2 physically contiguous 2MB hugepages.
+	 */
+	cnt = spdk_min(262144 / socket_count, 262144 / 2);
+	/* Take into account one extra element required by
+	 * some ring implementations.
+	 */
+	cnt -= 1;
+	return cnt;
+}
+
 void
 spdk_reactor_enable_context_switch_monitor(bool enable)
 {
@@ -390,6 +413,41 @@ spdk_reactor_context_switch_monitor_enabled(void)
 	return g_context_switch_monitor_enabled;
 }
 
+static void
+spdk_reactor_add_tsc_stats(void *arg, int rc, uint64_t now)
+{
+	struct spdk_reactor *reactor = arg;
+	struct spdk_reactor_tsc_stats *tsc_stats = &reactor->tsc_stats;
+
+	if (rc == 0) {
+		/* Poller status idle */
+		tsc_stats->idle_tsc += now - reactor->tsc_last;
+	} else if (rc == 1) {
+		/* Poller status busy */
+		tsc_stats->busy_tsc += now - reactor->tsc_last;
+	} else {
+		/* Poller status unknown */
+		tsc_stats->unknown_tsc += now - reactor->tsc_last;
+	}
+
+	reactor->tsc_last = now;
+}
+
+int
+spdk_reactor_get_tsc_stats(struct spdk_reactor_tsc_stats *tsc_stats, uint32_t core)
+{
+	struct spdk_reactor *reactor;
+
+	if (!spdk_cpuset_get_cpu(g_spdk_app_core_mask, core)) {
+		return -1;
+	}
+
+	reactor = spdk_reactor_get(core);
+	*tsc_stats = reactor->tsc_stats;
+
+	return 0;
+}
+
 /**
  *
  * \brief This is the main function of the reactor thread.
@@ -420,7 +478,7 @@ _spdk_reactor_run(void *arg)
 	uint64_t		idle_started, now;
 	uint64_t		spin_cycles, sleep_cycles;
 	uint32_t		sleep_us;
-	uint32_t		timer_poll_count;
+	int			rc = -1;
 	char			thread_name[32];
 
 	snprintf(thread_name, sizeof(thread_name), "reactor_%u", reactor->lcore);
@@ -436,15 +494,20 @@ _spdk_reactor_run(void *arg)
 	spin_cycles = SPDK_REACTOR_SPIN_TIME_USEC * spdk_get_ticks_hz() / SPDK_SEC_TO_USEC;
 	sleep_cycles = reactor->max_delay_us * spdk_get_ticks_hz() / SPDK_SEC_TO_USEC;
 	idle_started = 0;
-	timer_poll_count = 0;
 	if (g_context_switch_monitor_enabled) {
 		_spdk_reactor_context_switch_monitor_start(reactor, NULL);
 	}
+	now = spdk_get_ticks();
+	reactor->tsc_last = now;
+
 	while (1) {
 		bool took_action = false;
 
 		event_count = _spdk_event_queue_run_batch(reactor);
 		if (event_count > 0) {
+			rc = 1;
+			now = spdk_get_ticks();
+			spdk_reactor_add_tsc_stats(reactor, rc, now);
 			took_action = true;
 		}
 
@@ -452,7 +515,9 @@ _spdk_reactor_run(void *arg)
 		if (poller) {
 			TAILQ_REMOVE(&reactor->active_pollers, poller, tailq);
 			poller->state = SPDK_POLLER_STATE_RUNNING;
-			poller->fn(poller->arg);
+			rc = poller->fn(poller->arg);
+			now = spdk_get_ticks();
+			spdk_reactor_add_tsc_stats(reactor, rc, now);
 			if (poller->state == SPDK_POLLER_STATE_UNREGISTERED) {
 				free(poller);
 			} else {
@@ -462,27 +527,32 @@ _spdk_reactor_run(void *arg)
 			took_action = true;
 		}
 
-		if (timer_poll_count >= SPDK_TIMER_POLL_ITERATIONS) {
-			poller = TAILQ_FIRST(&reactor->timer_pollers);
-			if (poller) {
+		poller = TAILQ_FIRST(&reactor->timer_pollers);
+		if (poller) {
+			if (took_action == false) {
 				now = spdk_get_ticks();
+			}
 
-				if (now >= poller->next_run_tick) {
-					TAILQ_REMOVE(&reactor->timer_pollers, poller, tailq);
-					poller->state = SPDK_POLLER_STATE_RUNNING;
-					poller->fn(poller->arg);
-					if (poller->state == SPDK_POLLER_STATE_UNREGISTERED) {
-						free(poller);
-					} else {
-						poller->state = SPDK_POLLER_STATE_WAITING;
-						_spdk_poller_insert_timer(reactor, poller, now);
-					}
-					took_action = true;
+			if (now >= poller->next_run_tick) {
+				uint64_t tmp_timer_tsc;
+
+				TAILQ_REMOVE(&reactor->timer_pollers, poller, tailq);
+				poller->state = SPDK_POLLER_STATE_RUNNING;
+				rc = poller->fn(poller->arg);
+				/* Save the tsc value from before poller->fn was executed. We want to
+				 * use the current time for idle/busy tsc value accounting, but want to
+				 * use the older time to reinsert to the timer poller below. */
+				tmp_timer_tsc = now;
+				now = spdk_get_ticks();
+				spdk_reactor_add_tsc_stats(reactor, rc, now);
+				if (poller->state == SPDK_POLLER_STATE_UNREGISTERED) {
+					free(poller);
+				} else {
+					poller->state = SPDK_POLLER_STATE_WAITING;
+					_spdk_poller_insert_timer(reactor, poller, tmp_timer_tsc);
 				}
+				took_action = true;
 			}
-			timer_poll_count = 0;
-		} else {
-			timer_poll_count++;
 		}
 
 		if (took_action) {
@@ -517,8 +587,6 @@ _spdk_reactor_run(void *arg)
 					usleep(sleep_us);
 				}
 
-				/* After sleeping, always poll for timers */
-				timer_poll_count = SPDK_TIMER_POLL_ITERATIONS;
 			}
 		}
 
@@ -663,7 +731,7 @@ spdk_reactors_init(unsigned int max_delay_us)
 		if ((1ULL << i) & socket_mask) {
 			snprintf(mempool_name, sizeof(mempool_name), "evtpool%d_%d", i, getpid());
 			g_spdk_event_mempool[i] = spdk_mempool_create(mempool_name,
-						  (262144 / socket_count),
+						  _spdk_reactor_get_max_event_cnt(socket_count),
 						  sizeof(struct spdk_event),
 						  SPDK_MEMPOOL_DEFAULT_CACHE_SIZE, i);
 
@@ -678,7 +746,7 @@ spdk_reactors_init(unsigned int max_delay_us)
 				 */
 				g_spdk_event_mempool[i] = spdk_mempool_create(
 								  mempool_name,
-								  (262144 / socket_count),
+								  _spdk_reactor_get_max_event_cnt(socket_count),
 								  sizeof(struct spdk_event),
 								  SPDK_MEMPOOL_DEFAULT_CACHE_SIZE,
 								  SPDK_ENV_SOCKET_ID_ANY);
diff --git a/lib/event/rpc.c b/lib/event/rpc.c
index 1e2f75b88..f84143496 100644
--- a/lib/event/rpc.c
+++ b/lib/event/rpc.c
@@ -35,7 +35,7 @@
 
 #include "spdk/conf.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 #include "spdk/rpc.h"
 
@@ -68,6 +68,8 @@ spdk_rpc_initialize(const char *listen_addr)
 		return;
 	}
 
+	spdk_rpc_set_state(SPDK_RPC_STARTUP);
+
 	/* Register a poller to periodically check for RPCs */
 	g_rpc_poller = spdk_poller_register(spdk_rpc_subsystem_poll, NULL, RPC_SELECT_INTERVAL);
 }
diff --git a/lib/event/rpc/app_rpc.c b/lib/event/rpc/app_rpc.c
index dcc863439..95cb0d2a3 100644
--- a/lib/event/rpc/app_rpc.c
+++ b/lib/event/rpc/app_rpc.c
@@ -108,7 +108,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_kill_instance(&req);
 }
-SPDK_RPC_REGISTER("kill_instance", spdk_rpc_kill_instance)
+SPDK_RPC_REGISTER("kill_instance", spdk_rpc_kill_instance, SPDK_RPC_RUNTIME)
 
 
 struct rpc_context_switch_monitor {
@@ -152,4 +152,4 @@ spdk_rpc_context_switch_monitor(struct spdk_jsonrpc_request *request,
 	spdk_jsonrpc_end_result(request, w);
 }
 
-SPDK_RPC_REGISTER("context_switch_monitor", spdk_rpc_context_switch_monitor)
+SPDK_RPC_REGISTER("context_switch_monitor", spdk_rpc_context_switch_monitor, SPDK_RPC_RUNTIME)
diff --git a/lib/event/rpc/subsystem_rpc.c b/lib/event/rpc/subsystem_rpc.c
index c38b371a7..1b83990f1 100644
--- a/lib/event/rpc/subsystem_rpc.c
+++ b/lib/event/rpc/subsystem_rpc.c
@@ -75,7 +75,7 @@ spdk_rpc_get_subsystems(struct spdk_jsonrpc_request *request,
 	spdk_jsonrpc_end_result(request, w);
 }
 
-SPDK_RPC_REGISTER("get_subsystems", spdk_rpc_get_subsystems)
+SPDK_RPC_REGISTER("get_subsystems", spdk_rpc_get_subsystems, SPDK_RPC_RUNTIME)
 
 struct rpc_get_subsystem_config {
 	char *name;
@@ -126,4 +126,4 @@ spdk_rpc_get_subsystem_config(struct spdk_jsonrpc_request *request,
 	}
 }
 
-SPDK_RPC_REGISTER("get_subsystem_config", spdk_rpc_get_subsystem_config)
+SPDK_RPC_REGISTER("get_subsystem_config", spdk_rpc_get_subsystem_config, SPDK_RPC_RUNTIME)
diff --git a/lib/event/subsystems/bdev/Makefile b/lib/event/subsystems/bdev/Makefile
index 58c514190..1747b7595 100644
--- a/lib/event/subsystems/bdev/Makefile
+++ b/lib/event/subsystems/bdev/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-C_SRCS = bdev.c
+C_SRCS = bdev.c bdev_rpc.c
 LIBNAME = event_bdev
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/event/subsystems/bdev/bdev.c b/lib/event/subsystems/bdev/bdev.c
index e98ba351c..5999d612a 100644
--- a/lib/event/subsystems/bdev/bdev.c
+++ b/lib/event/subsystems/bdev/bdev.c
@@ -35,7 +35,7 @@
 
 #include "spdk/bdev.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 #include "spdk_internal/event.h"
 #include "spdk/env.h"
diff --git a/lib/event/subsystems/bdev/bdev_rpc.c b/lib/event/subsystems/bdev/bdev_rpc.c
new file mode 100644
index 000000000..69ead5f25
--- /dev/null
+++ b/lib/event/subsystems/bdev/bdev_rpc.c
@@ -0,0 +1,97 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/bdev.h"
+
+#include "spdk/rpc.h"
+#include "spdk/util.h"
+#include "spdk/string.h"
+
+#include "spdk_internal/log.h"
+
+struct spdk_rpc_set_bdev_opts {
+	uint32_t bdev_io_pool_size;
+	uint32_t bdev_io_cache_size;
+};
+
+static const struct spdk_json_object_decoder rpc_set_bdev_opts_decoders[] = {
+	{"bdev_io_pool_size", offsetof(struct spdk_rpc_set_bdev_opts, bdev_io_pool_size), spdk_json_decode_uint32, true},
+	{"bdev_io_cache_size", offsetof(struct spdk_rpc_set_bdev_opts, bdev_io_cache_size), spdk_json_decode_uint32, true},
+};
+
+static void
+spdk_rpc_set_bdev_opts(struct spdk_jsonrpc_request *request, const struct spdk_json_val *params)
+{
+	struct spdk_rpc_set_bdev_opts rpc_opts;
+	struct spdk_bdev_opts bdev_opts;
+	struct spdk_json_write_ctx *w;
+	int rc;
+
+	rpc_opts.bdev_io_pool_size = UINT32_MAX;
+	rpc_opts.bdev_io_cache_size = UINT32_MAX;
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, rpc_set_bdev_opts_decoders,
+					    SPDK_COUNTOF(rpc_set_bdev_opts_decoders), &rpc_opts)) {
+			SPDK_ERRLOG("spdk_json_decode_object() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+	}
+
+	spdk_bdev_get_opts(&bdev_opts);
+	if (rpc_opts.bdev_io_pool_size != UINT32_MAX) {
+		bdev_opts.bdev_io_pool_size = rpc_opts.bdev_io_pool_size;
+	}
+	if (rpc_opts.bdev_io_cache_size != UINT32_MAX) {
+		bdev_opts.bdev_io_cache_size = rpc_opts.bdev_io_cache_size;
+	}
+	rc = spdk_bdev_set_opts(&bdev_opts);
+
+	if (rc != 0) {
+		spdk_jsonrpc_send_error_response_fmt(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+						     "Pool size %" PRIu32 " too small for cache size %" PRIu32,
+						     bdev_opts.bdev_io_pool_size, bdev_opts.bdev_io_cache_size);
+		return;
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("set_bdev_options", spdk_rpc_set_bdev_opts, SPDK_RPC_STARTUP)
diff --git a/lib/event/subsystems/iscsi/Makefile b/lib/event/subsystems/iscsi/Makefile
index d57f59467..f57d9f9cd 100644
--- a/lib/event/subsystems/iscsi/Makefile
+++ b/lib/event/subsystems/iscsi/Makefile
@@ -35,7 +35,7 @@ SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
 CFLAGS += -I$(SPDK_ROOT_DIR)/lib
-C_SRCS = iscsi.c
+C_SRCS = iscsi.c iscsi_rpc.c
 LIBNAME = event_iscsi
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/event/subsystems/iscsi/iscsi.c b/lib/event/subsystems/iscsi/iscsi.c
index 642622509..72750398e 100644
--- a/lib/event/subsystems/iscsi/iscsi.c
+++ b/lib/event/subsystems/iscsi/iscsi.c
@@ -61,11 +61,20 @@ spdk_iscsi_subsystem_fini(void)
 	spdk_iscsi_fini(spdk_iscsi_subsystem_fini_done, NULL);
 }
 
+static void
+spdk_iscsi_subsystem_config_json(struct spdk_json_write_ctx *w,
+				 struct spdk_event *done_ev)
+{
+	spdk_iscsi_config_json(w);
+	spdk_event_call(done_ev);
+}
+
 static struct spdk_subsystem g_spdk_subsystem_iscsi = {
 	.name = "iscsi",
 	.init = spdk_iscsi_subsystem_init,
 	.fini = spdk_iscsi_subsystem_fini,
 	.config = spdk_iscsi_config_text,
+	.write_config_json = spdk_iscsi_subsystem_config_json,
 };
 
 SPDK_SUBSYSTEM_REGISTER(g_spdk_subsystem_iscsi);
diff --git a/lib/event/subsystems/iscsi/iscsi_rpc.c b/lib/event/subsystems/iscsi/iscsi_rpc.c
new file mode 100644
index 000000000..64ea2204a
--- /dev/null
+++ b/lib/event/subsystems/iscsi/iscsi_rpc.c
@@ -0,0 +1,113 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "iscsi/iscsi.h"
+#include "iscsi/conn.h"
+
+#include "spdk/rpc.h"
+#include "spdk/util.h"
+#include "spdk/event.h"
+
+#include "spdk_internal/log.h"
+
+static const struct spdk_json_object_decoder rpc_set_iscsi_opts_decoders[] = {
+	{"auth_file", offsetof(struct spdk_iscsi_opts, authfile), spdk_json_decode_string, true},
+	{"node_base", offsetof(struct spdk_iscsi_opts, nodebase), spdk_json_decode_string, true},
+	{"timeout", offsetof(struct spdk_iscsi_opts, timeout), spdk_json_decode_int32, true},
+	{"nop_in_interval", offsetof(struct spdk_iscsi_opts, nopininterval), spdk_json_decode_int32, true},
+	{"no_discovery_auth", offsetof(struct spdk_iscsi_opts, no_discovery_auth), spdk_json_decode_bool, true},
+	{"req_discovery_auth", offsetof(struct spdk_iscsi_opts, req_discovery_auth), spdk_json_decode_bool, true},
+	{"req_discovery_auth_mutual", offsetof(struct spdk_iscsi_opts, req_discovery_auth_mutual), spdk_json_decode_bool, true},
+	{"discovery_auth_group", offsetof(struct spdk_iscsi_opts, discovery_auth_group), spdk_json_decode_int32, true},
+	{"max_sessions", offsetof(struct spdk_iscsi_opts, MaxSessions), spdk_json_decode_uint32, true},
+	{"max_queue_depth", offsetof(struct spdk_iscsi_opts, MaxQueueDepth), spdk_json_decode_uint32, true},
+	{"max_connections_per_session", offsetof(struct spdk_iscsi_opts, MaxConnectionsPerSession), spdk_json_decode_uint32, true},
+	{"default_time2wait", offsetof(struct spdk_iscsi_opts, DefaultTime2Wait), spdk_json_decode_uint32, true},
+	{"default_time2retain", offsetof(struct spdk_iscsi_opts, DefaultTime2Retain), spdk_json_decode_uint32, true},
+	{"immediate_data", offsetof(struct spdk_iscsi_opts, ImmediateData), spdk_json_decode_bool, true},
+	{"error_recovery_level", offsetof(struct spdk_iscsi_opts, ErrorRecoveryLevel), spdk_json_decode_uint32, true},
+	{"allow_duplicated_isid", offsetof(struct spdk_iscsi_opts, AllowDuplicateIsid), spdk_json_decode_bool, true},
+	{"min_connections_per_core", offsetof(struct spdk_iscsi_opts, min_connections_per_core), spdk_json_decode_uint32, true},
+};
+
+static void
+spdk_rpc_iscsi_set_opts(struct spdk_jsonrpc_request *request,
+			const struct spdk_json_val *params)
+{
+	struct spdk_iscsi_opts *opts;
+	struct spdk_json_write_ctx *w;
+
+	if (g_spdk_iscsi_opts != NULL) {
+		SPDK_ERRLOG("this RPC must not be called more than once.\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Must not call more than once");
+		return;
+	}
+
+	opts = spdk_iscsi_opts_alloc();
+	if (opts == NULL) {
+		SPDK_ERRLOG("spdk_iscsi_opts_alloc() failed.\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Out of memory");
+		return;
+	}
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, rpc_set_iscsi_opts_decoders,
+					    SPDK_COUNTOF(rpc_set_iscsi_opts_decoders), opts)) {
+			SPDK_ERRLOG("spdk_json_decode_object() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+	}
+
+	g_spdk_iscsi_opts = spdk_iscsi_opts_copy(opts);
+	spdk_iscsi_opts_free(opts);
+
+	if (g_spdk_iscsi_opts == NULL) {
+		SPDK_ERRLOG("spdk_iscsi_opts_copy() failed\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Out of memory");
+		return;
+	}
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("set_iscsi_options", spdk_rpc_iscsi_set_opts, SPDK_RPC_STARTUP)
diff --git a/lib/event/subsystems/nvmf/conf.c b/lib/event/subsystems/nvmf/conf.c
index ca53e0a5c..53ff4bafc 100644
--- a/lib/event/subsystems/nvmf/conf.c
+++ b/lib/event/subsystems/nvmf/conf.c
@@ -41,11 +41,10 @@
 #include "spdk/string.h"
 #include "spdk/util.h"
 
-#define ACCEPT_TIMEOUT_US		10000 /* 10ms */
-
 #define SPDK_NVMF_MAX_NAMESPACES (1 << 14)
 
-struct spdk_nvmf_tgt_conf g_spdk_nvmf_tgt_conf;
+struct spdk_nvmf_tgt_opts *g_spdk_nvmf_tgt_opts = NULL;
+struct spdk_nvmf_tgt_conf *g_spdk_nvmf_tgt_conf = NULL;
 
 static int
 spdk_add_nvmf_discovery_subsystem(void)
@@ -65,14 +64,14 @@ spdk_add_nvmf_discovery_subsystem(void)
 }
 
 static void
-spdk_nvmf_read_config_file_params(struct spdk_conf_section *sp,
-				  struct spdk_nvmf_tgt_opts *opts)
+spdk_nvmf_read_config_file_tgt_opts(struct spdk_conf_section *sp,
+				    struct spdk_nvmf_tgt_opts *opts)
 {
 	int max_queue_depth;
 	int max_queues_per_sess;
 	int in_capsule_data_size;
 	int max_io_size;
-	int acceptor_poll_rate;
+	int io_unit_size;
 
 	max_queue_depth = spdk_conf_section_get_intval(sp, "MaxQueueDepth");
 	if (max_queue_depth >= 0) {
@@ -94,28 +93,94 @@ spdk_nvmf_read_config_file_params(struct spdk_conf_section *sp,
 		opts->max_io_size = max_io_size;
 	}
 
+	io_unit_size = spdk_conf_section_get_intval(sp, "IOUnitSize");
+	if (io_unit_size >= 0) {
+		opts->io_unit_size = io_unit_size;
+	}
+}
+
+static void
+spdk_nvmf_read_config_file_tgt_conf(struct spdk_conf_section *sp,
+				    struct spdk_nvmf_tgt_conf *conf)
+{
+	int acceptor_poll_rate;
+
 	acceptor_poll_rate = spdk_conf_section_get_intval(sp, "AcceptorPollRate");
 	if (acceptor_poll_rate >= 0) {
-		g_spdk_nvmf_tgt_conf.acceptor_poll_rate = acceptor_poll_rate;
+		conf->acceptor_poll_rate = acceptor_poll_rate;
 	}
 }
 
-static int
-spdk_nvmf_parse_nvmf_tgt(void)
+static struct spdk_nvmf_tgt_opts *
+spdk_nvmf_parse_tgt_opts(void)
 {
+	struct spdk_nvmf_tgt_opts *opts;
 	struct spdk_conf_section *sp;
-	struct spdk_nvmf_tgt_opts opts;
-	int rc;
 
-	spdk_nvmf_tgt_opts_init(&opts);
-	g_spdk_nvmf_tgt_conf.acceptor_poll_rate = ACCEPT_TIMEOUT_US;
+	opts = calloc(1, sizeof(*opts));
+	if (!opts) {
+		SPDK_ERRLOG("calloc() failed for target options\n");
+		return NULL;
+	}
+
+	spdk_nvmf_tgt_opts_init(opts);
 
 	sp = spdk_conf_find_section(NULL, "Nvmf");
 	if (sp != NULL) {
-		spdk_nvmf_read_config_file_params(sp, &opts);
+		spdk_nvmf_read_config_file_tgt_opts(sp, opts);
+	}
+
+	return opts;
+}
+
+static struct spdk_nvmf_tgt_conf *
+spdk_nvmf_parse_tgt_conf(void)
+{
+	struct spdk_nvmf_tgt_conf *conf;
+	struct spdk_conf_section *sp;
+
+	conf = calloc(1, sizeof(*conf));
+	if (!conf) {
+		SPDK_ERRLOG("calloc() failed for target conf\n");
+		return NULL;
 	}
 
-	g_spdk_nvmf_tgt = spdk_nvmf_tgt_create(&opts);
+	conf->acceptor_poll_rate = ACCEPT_TIMEOUT_US;
+
+	sp = spdk_conf_find_section(NULL, "Nvmf");
+	if (sp != NULL) {
+		spdk_nvmf_read_config_file_tgt_conf(sp, conf);
+	}
+
+	return conf;
+}
+
+static int
+spdk_nvmf_parse_nvmf_tgt(void)
+{
+	int rc;
+
+	if (!g_spdk_nvmf_tgt_opts) {
+		g_spdk_nvmf_tgt_opts = spdk_nvmf_parse_tgt_opts();
+		if (!g_spdk_nvmf_tgt_opts) {
+			SPDK_ERRLOG("spdk_nvmf_parse_tgt_opts() failed\n");
+			return -1;
+		}
+	}
+
+	if (!g_spdk_nvmf_tgt_conf) {
+		g_spdk_nvmf_tgt_conf = spdk_nvmf_parse_tgt_conf();
+		if (!g_spdk_nvmf_tgt_conf) {
+			SPDK_ERRLOG("spdk_nvmf_parse_tgt_conf() failed\n");
+			return -1;
+		}
+	}
+
+	g_spdk_nvmf_tgt = spdk_nvmf_tgt_create(g_spdk_nvmf_tgt_opts);
+
+	free(g_spdk_nvmf_tgt_opts);
+	g_spdk_nvmf_tgt_opts = NULL;
+
 	if (!g_spdk_nvmf_tgt) {
 		SPDK_ERRLOG("spdk_nvmf_tgt_create() failed\n");
 		return -1;
@@ -214,6 +279,7 @@ spdk_nvmf_parse_subsystem(struct spdk_conf_section *sp)
 		struct spdk_nvmf_ns_opts ns_opts;
 		struct spdk_bdev *bdev;
 		const char *bdev_name;
+		const char *uuid_str;
 		char *nsid_str;
 
 		bdev_name = spdk_conf_section_get_nmval(sp, "Namespace", i, 0);
@@ -246,6 +312,16 @@ spdk_nvmf_parse_subsystem(struct spdk_conf_section *sp)
 			ns_opts.nsid = (uint32_t)nsid_ul;
 		}
 
+		uuid_str = spdk_conf_section_get_nmval(sp, "Namespace", i, 2);
+		if (uuid_str) {
+			if (spdk_uuid_parse(&ns_opts.uuid, uuid_str)) {
+				SPDK_ERRLOG("Invalid UUID %s\n", uuid_str);
+				spdk_nvmf_subsystem_destroy(subsystem);
+				subsystem = NULL;
+				goto done;
+			}
+		}
+
 		if (spdk_nvmf_subsystem_add_ns(subsystem, bdev, &ns_opts, sizeof(ns_opts)) == 0) {
 			SPDK_ERRLOG("Unable to add namespace\n");
 			spdk_nvmf_subsystem_destroy(subsystem);
diff --git a/lib/event/subsystems/nvmf/event_nvmf.h b/lib/event/subsystems/nvmf/event_nvmf.h
index f14cba328..543d02a59 100644
--- a/lib/event/subsystems/nvmf/event_nvmf.h
+++ b/lib/event/subsystems/nvmf/event_nvmf.h
@@ -42,11 +42,14 @@
 #include "spdk_internal/event.h"
 #include "spdk_internal/log.h"
 
+#define ACCEPT_TIMEOUT_US	10000 /* 10ms */
+
 struct spdk_nvmf_tgt_conf {
 	uint32_t acceptor_poll_rate;
 };
 
-extern struct spdk_nvmf_tgt_conf g_spdk_nvmf_tgt_conf;
+extern struct spdk_nvmf_tgt_opts *g_spdk_nvmf_tgt_opts;
+extern struct spdk_nvmf_tgt_conf *g_spdk_nvmf_tgt_conf;
 
 extern struct spdk_nvmf_tgt *g_spdk_nvmf_tgt;
 
diff --git a/lib/event/subsystems/nvmf/nvmf_rpc.c b/lib/event/subsystems/nvmf/nvmf_rpc.c
index ecc7c24eb..165a63bdf 100644
--- a/lib/event/subsystems/nvmf/nvmf_rpc.c
+++ b/lib/event/subsystems/nvmf/nvmf_rpc.c
@@ -166,6 +166,21 @@ decode_ns_eui64(const struct spdk_json_val *val, void *out)
 	return rc;
 }
 
+static int
+decode_ns_uuid(const struct spdk_json_val *val, void *out)
+{
+	char *str = NULL;
+	int rc;
+
+	rc = spdk_json_decode_string(val, &str);
+	if (rc == 0) {
+		rc = spdk_uuid_parse(out, str);
+	}
+
+	free(str);
+	return rc;
+}
+
 static void
 dump_nvmf_subsystem(struct spdk_json_write_ctx *w, struct spdk_nvmf_subsystem *subsystem)
 {
@@ -236,9 +251,16 @@ dump_nvmf_subsystem(struct spdk_json_write_ctx *w, struct spdk_nvmf_subsystem *s
 	if (spdk_nvmf_subsystem_get_type(subsystem) == SPDK_NVMF_SUBTYPE_NVME) {
 		struct spdk_nvmf_ns *ns;
 		struct spdk_nvmf_ns_opts ns_opts;
+		uint32_t max_namespaces;
 
 		spdk_json_write_name(w, "serial_number");
 		spdk_json_write_string(w, spdk_nvmf_subsystem_get_sn(subsystem));
+
+		max_namespaces = spdk_nvmf_subsystem_get_max_namespaces(subsystem);
+		if (max_namespaces != 0) {
+			spdk_json_write_named_uint32(w, "max_namespaces", max_namespaces);
+		}
+
 		spdk_json_write_name(w, "namespaces");
 		spdk_json_write_array_begin(w);
 		for (ns = spdk_nvmf_subsystem_get_first_ns(subsystem); ns != NULL;
@@ -305,7 +327,7 @@ spdk_rpc_get_nvmf_subsystems(struct spdk_jsonrpc_request *request,
 	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_nvmf_subsystems", spdk_rpc_get_nvmf_subsystems)
+SPDK_RPC_REGISTER("get_nvmf_subsystems", spdk_rpc_get_nvmf_subsystems, SPDK_RPC_RUNTIME)
 
 struct rpc_listen_address {
 	char *transport;
@@ -424,6 +446,7 @@ struct spdk_nvmf_ns_params {
 	uint32_t nsid;
 	char nguid[16];
 	char eui64[8];
+	struct spdk_uuid uuid;
 };
 
 struct rpc_namespaces {
@@ -437,6 +460,7 @@ static const struct spdk_json_object_decoder rpc_ns_params_decoders[] = {
 	{"bdev_name", offsetof(struct spdk_nvmf_ns_params, bdev_name), spdk_json_decode_string},
 	{"nguid", offsetof(struct spdk_nvmf_ns_params, nguid), decode_ns_nguid, true},
 	{"eui64", offsetof(struct spdk_nvmf_ns_params, eui64), decode_ns_eui64, true},
+	{"uuid", offsetof(struct spdk_nvmf_ns_params, uuid), decode_ns_uuid, true},
 };
 
 static void
@@ -469,7 +493,7 @@ static int
 decode_rpc_namespaces(const struct spdk_json_val *val, void *out)
 {
 	struct rpc_namespaces *namespaces = out;
-	char *names[RPC_MAX_NAMESPACES]; /* old format - array of strings (bdev names) */
+	char *names[RPC_MAX_NAMESPACES] = {0}; /* old format - array of strings (bdev names) */
 	size_t i;
 	int rc;
 
@@ -717,6 +741,10 @@ spdk_rpc_construct_nvmf_subsystem(struct spdk_jsonrpc_request *request,
 		SPDK_STATIC_ASSERT(sizeof(ns_opts.eui64) == sizeof(ns_params->eui64), "size mismatch");
 		memcpy(ns_opts.eui64, ns_params->eui64, sizeof(ns_opts.eui64));
 
+		if (!spdk_mem_all_zero(&ns_params->uuid, sizeof(ns_params->uuid))) {
+			ns_opts.uuid = ns_params->uuid;
+		}
+
 		if (spdk_nvmf_subsystem_add_ns(subsystem, bdev, &ns_opts, sizeof(ns_opts)) == 0) {
 			SPDK_ERRLOG("Unable to add namespace\n");
 			spdk_nvmf_subsystem_destroy(subsystem);
@@ -765,7 +793,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_subsystem(req);
 }
-SPDK_RPC_REGISTER("construct_nvmf_subsystem", spdk_rpc_construct_nvmf_subsystem)
+SPDK_RPC_REGISTER("construct_nvmf_subsystem", spdk_rpc_construct_nvmf_subsystem, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_subsystem {
 	char *nqn;
@@ -835,7 +863,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_delete_subsystem(&req);
 }
-SPDK_RPC_REGISTER("delete_nvmf_subsystem", spdk_rpc_delete_nvmf_subsystem)
+SPDK_RPC_REGISTER("delete_nvmf_subsystem", spdk_rpc_delete_nvmf_subsystem, SPDK_RPC_RUNTIME)
 
 enum nvmf_rpc_listen_op {
 	NVMF_RPC_LISTEN_ADD,
@@ -998,7 +1026,7 @@ nvmf_rpc_subsystem_add_listener(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_add_listener", nvmf_rpc_subsystem_add_listener);
+SPDK_RPC_REGISTER("nvmf_subsystem_add_listener", nvmf_rpc_subsystem_add_listener, SPDK_RPC_RUNTIME);
 
 static void
 nvmf_rpc_subsystem_remove_listener(struct spdk_jsonrpc_request *request,
@@ -1050,7 +1078,8 @@ nvmf_rpc_subsystem_remove_listener(struct spdk_jsonrpc_request *request,
 	}
 
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_remove_listener", nvmf_rpc_subsystem_remove_listener);
+SPDK_RPC_REGISTER("nvmf_subsystem_remove_listener", nvmf_rpc_subsystem_remove_listener,
+		  SPDK_RPC_RUNTIME);
 
 struct nvmf_rpc_ns_ctx {
 	char *nqn;
@@ -1125,6 +1154,10 @@ nvmf_rpc_ns_paused(struct spdk_nvmf_subsystem *subsystem,
 	SPDK_STATIC_ASSERT(sizeof(ns_opts.eui64) == sizeof(ctx->ns_params.eui64), "size mismatch");
 	memcpy(ns_opts.eui64, ctx->ns_params.eui64, sizeof(ns_opts.eui64));
 
+	if (!spdk_mem_all_zero(&ctx->ns_params.uuid, sizeof(ctx->ns_params.uuid))) {
+		ns_opts.uuid = ctx->ns_params.uuid;
+	}
+
 	ctx->ns_params.nsid = spdk_nvmf_subsystem_add_ns(subsystem, bdev, &ns_opts, sizeof(ns_opts));
 	if (ctx->ns_params.nsid == 0) {
 		SPDK_ERRLOG("Unable to add namespace\n");
@@ -1181,7 +1214,7 @@ nvmf_rpc_subsystem_add_ns(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_add_ns", nvmf_rpc_subsystem_add_ns)
+SPDK_RPC_REGISTER("nvmf_subsystem_add_ns", nvmf_rpc_subsystem_add_ns, SPDK_RPC_RUNTIME)
 
 struct nvmf_rpc_remove_ns_ctx {
 	char *nqn;
@@ -1304,7 +1337,7 @@ nvmf_rpc_subsystem_remove_ns(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_remove_ns", nvmf_rpc_subsystem_remove_ns)
+SPDK_RPC_REGISTER("nvmf_subsystem_remove_ns", nvmf_rpc_subsystem_remove_ns, SPDK_RPC_RUNTIME)
 
 enum nvmf_rpc_host_op {
 	NVMF_RPC_HOST_ADD,
@@ -1436,7 +1469,7 @@ nvmf_rpc_subsystem_add_host(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_add_host", nvmf_rpc_subsystem_add_host)
+SPDK_RPC_REGISTER("nvmf_subsystem_add_host", nvmf_rpc_subsystem_add_host, SPDK_RPC_RUNTIME)
 
 static void
 nvmf_rpc_subsystem_remove_host(struct spdk_jsonrpc_request *request,
@@ -1478,7 +1511,7 @@ nvmf_rpc_subsystem_remove_host(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_remove_host", nvmf_rpc_subsystem_remove_host)
+SPDK_RPC_REGISTER("nvmf_subsystem_remove_host", nvmf_rpc_subsystem_remove_host, SPDK_RPC_RUNTIME)
 
 
 static const struct spdk_json_object_decoder nvmf_rpc_subsystem_any_host_decoder[] = {
@@ -1526,4 +1559,112 @@ nvmf_rpc_subsystem_allow_any_host(struct spdk_jsonrpc_request *request,
 		return;
 	}
 }
-SPDK_RPC_REGISTER("nvmf_subsystem_allow_any_host", nvmf_rpc_subsystem_allow_any_host)
+SPDK_RPC_REGISTER("nvmf_subsystem_allow_any_host", nvmf_rpc_subsystem_allow_any_host,
+		  SPDK_RPC_RUNTIME)
+
+static const struct spdk_json_object_decoder nvmf_rpc_subsystem_tgt_opts_decoder[] = {
+	{"max_queue_depth", offsetof(struct spdk_nvmf_tgt_opts, max_queue_depth), spdk_json_decode_uint16, true},
+	{"max_qpairs_per_ctrlr", offsetof(struct spdk_nvmf_tgt_opts, max_qpairs_per_ctrlr), spdk_json_decode_uint16, true},
+	{"in_capsule_data_size", offsetof(struct spdk_nvmf_tgt_opts, in_capsule_data_size), spdk_json_decode_uint32, true},
+	{"max_io_size", offsetof(struct spdk_nvmf_tgt_opts, max_io_size), spdk_json_decode_uint32, true},
+	{"max_subsystems", offsetof(struct spdk_nvmf_tgt_opts, max_subsystems), spdk_json_decode_uint32, true},
+	{"io_unit_size", offsetof(struct spdk_nvmf_tgt_opts, io_unit_size), spdk_json_decode_uint32, true},
+};
+
+static void
+nvmf_rpc_subsystem_set_tgt_opts(struct spdk_jsonrpc_request *request,
+				const struct spdk_json_val *params)
+{
+	struct spdk_nvmf_tgt_opts *opts;
+	struct spdk_json_write_ctx *w;
+
+	if (g_spdk_nvmf_tgt_opts != NULL) {
+		SPDK_ERRLOG("this RPC must not be called more than once.\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Must not call more than once");
+		return;
+	}
+
+	opts = calloc(1, sizeof(*opts));
+	if (opts == NULL) {
+		SPDK_ERRLOG("malloc() failed for target options\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Out of memory");
+		return;
+	}
+
+	spdk_nvmf_tgt_opts_init(opts);
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, nvmf_rpc_subsystem_tgt_opts_decoder,
+					    SPDK_COUNTOF(nvmf_rpc_subsystem_tgt_opts_decoder), opts)) {
+			free(opts);
+			SPDK_ERRLOG("spdk_json_decode_object() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+	}
+
+	g_spdk_nvmf_tgt_opts = opts;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("set_nvmf_target_options", nvmf_rpc_subsystem_set_tgt_opts, SPDK_RPC_STARTUP)
+
+static const struct spdk_json_object_decoder nvmf_rpc_subsystem_tgt_conf_decoder[] = {
+	{"acceptor_poll_rate", offsetof(struct spdk_nvmf_tgt_conf, acceptor_poll_rate), spdk_json_decode_uint32, true},
+};
+
+static void
+nvmf_rpc_subsystem_set_tgt_conf(struct spdk_jsonrpc_request *request,
+				const struct spdk_json_val *params)
+{
+	struct spdk_nvmf_tgt_conf *conf;
+	struct spdk_json_write_ctx *w;
+
+	if (g_spdk_nvmf_tgt_conf != NULL) {
+		SPDK_ERRLOG("this RPC must not be called more than once.\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Must not call more than once");
+		return;
+	}
+
+	conf = calloc(1, sizeof(*conf));
+	if (conf == NULL) {
+		SPDK_ERRLOG("calloc() failed for target config\n");
+		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INTERNAL_ERROR,
+						 "Out of memory");
+		return;
+	}
+
+	conf->acceptor_poll_rate = ACCEPT_TIMEOUT_US;
+
+	if (params != NULL) {
+		if (spdk_json_decode_object(params, nvmf_rpc_subsystem_tgt_conf_decoder,
+					    SPDK_COUNTOF(nvmf_rpc_subsystem_tgt_conf_decoder), conf)) {
+			free(conf);
+			SPDK_ERRLOG("spdk_json_decode_object() failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
+	}
+
+	g_spdk_nvmf_tgt_conf = conf;
+
+	w = spdk_jsonrpc_begin_result(request);
+	if (w == NULL) {
+		return;
+	}
+
+	spdk_json_write_bool(w, true);
+	spdk_jsonrpc_end_result(request, w);
+}
+SPDK_RPC_REGISTER("set_nvmf_target_config", nvmf_rpc_subsystem_set_tgt_conf, SPDK_RPC_STARTUP)
diff --git a/lib/event/subsystems/nvmf/nvmf_tgt.c b/lib/event/subsystems/nvmf/nvmf_tgt.c
index 88d86c28b..0b197a548 100644
--- a/lib/event/subsystems/nvmf/nvmf_tgt.c
+++ b/lib/event/subsystems/nvmf/nvmf_tgt.c
@@ -35,7 +35,7 @@
 
 #include "spdk/bdev.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 #include "spdk/nvme.h"
 #include "spdk/util.h"
@@ -179,9 +179,7 @@ nvmf_tgt_create_poll_group(void *ctx)
 	assert(pg != NULL);
 
 	pg->group = spdk_nvmf_poll_group_create(g_spdk_nvmf_tgt);
-	if (pg->group == NULL) {
-		SPDK_ERRLOG("Failed to create poll group for core %u\n", spdk_env_get_current_core());
-	}
+	assert(pg->group != NULL);
 
 	g_active_poll_groups++;
 }
@@ -216,6 +214,14 @@ nvmf_tgt_subsystem_stopped(struct spdk_nvmf_subsystem *subsystem,
 	nvmf_tgt_advance_state();
 }
 
+static void
+nvmf_tgt_destroy_done(void *ctx, int status)
+{
+	g_tgt_state = NVMF_TGT_STOPPED;
+	free(g_spdk_nvmf_tgt_conf);
+	nvmf_tgt_advance_state();
+}
+
 static void
 nvmf_tgt_advance_state(void)
 {
@@ -273,7 +279,7 @@ nvmf_tgt_advance_state(void)
 		}
 		case NVMF_TGT_INIT_START_ACCEPTOR:
 			g_acceptor_poller = spdk_poller_register(acceptor_poll, g_spdk_nvmf_tgt,
-					    g_spdk_nvmf_tgt_conf.acceptor_poll_rate);
+					    g_spdk_nvmf_tgt_conf->acceptor_poll_rate);
 			SPDK_INFOLOG(SPDK_LOG_NVMF, "Acceptor running\n");
 			g_tgt_state = NVMF_TGT_RUNNING;
 			break;
@@ -303,8 +309,7 @@ nvmf_tgt_advance_state(void)
 					     nvmf_tgt_destroy_poll_group_done);
 			break;
 		case NVMF_TGT_FINI_FREE_RESOURCES:
-			spdk_nvmf_tgt_destroy(g_spdk_nvmf_tgt);
-			g_tgt_state = NVMF_TGT_STOPPED;
+			spdk_nvmf_tgt_destroy(g_spdk_nvmf_tgt, nvmf_tgt_destroy_done, NULL);
 			break;
 		case NVMF_TGT_STOPPED:
 			spdk_subsystem_fini_next();
@@ -324,10 +329,30 @@ spdk_nvmf_subsystem_init(void)
 	nvmf_tgt_advance_state();
 }
 
+static void
+spdk_nvmf_subsystem_write_config_json(struct spdk_json_write_ctx *w, struct spdk_event *done_ev)
+{
+	spdk_json_write_array_begin(w);
+
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_string(w, "method", "set_nvmf_target_config");
+
+	spdk_json_write_named_object_begin(w, "params");
+	spdk_json_write_named_uint32(w, "acceptor_poll_rate", g_spdk_nvmf_tgt_conf->acceptor_poll_rate);
+	spdk_json_write_object_end(w);
+	spdk_json_write_object_end(w);
+
+	spdk_nvmf_tgt_write_config_json(w, g_spdk_nvmf_tgt);
+	spdk_json_write_array_end(w);
+
+	spdk_event_call(done_ev);
+}
+
 static struct spdk_subsystem g_spdk_subsystem_nvmf = {
 	.name = "nvmf",
 	.init = spdk_nvmf_subsystem_init,
 	.fini = spdk_nvmf_subsystem_fini,
+	.write_config_json = spdk_nvmf_subsystem_write_config_json,
 };
 
 SPDK_SUBSYSTEM_REGISTER(g_spdk_subsystem_nvmf)
diff --git a/lib/ioat/ioat.c b/lib/ioat/ioat.c
index 065d14275..dbfda0645 100644
--- a/lib/ioat/ioat.c
+++ b/lib/ioat/ioat.c
@@ -151,13 +151,6 @@ ioat_get_ring_entry(struct spdk_ioat_chan *ioat, uint32_t index,
 	*hw_desc = &ioat->hw_ring[i];
 }
 
-static uint64_t
-ioat_get_desc_phys_addr(struct spdk_ioat_chan *ioat, uint32_t index)
-{
-	return ioat->hw_ring_phys_addr +
-	       ioat_get_ring_index(ioat, index) * sizeof(union spdk_ioat_hw_desc);
-}
-
 static void
 ioat_submit_single(struct spdk_ioat_chan *ioat)
 {
@@ -336,7 +329,7 @@ ioat_process_channel_events(struct spdk_ioat_chan *ioat)
 			desc->callback_fn(desc->callback_arg);
 		}
 
-		hw_desc_phys_addr = ioat_get_desc_phys_addr(ioat, ioat->tail);
+		hw_desc_phys_addr = desc->phys_addr;
 		ioat->tail++;
 	} while (hw_desc_phys_addr != completed_descriptor);
 
@@ -372,6 +365,7 @@ ioat_channel_start(struct spdk_ioat_chan *ioat)
 	uint64_t status;
 	int i, num_descriptors;
 	uint64_t comp_update_bus_addr = 0;
+	uint64_t phys_addr;
 
 	if (ioat_map_pci_bar(ioat) != 0) {
 		SPDK_ERRLOG("ioat_map_pci_bar() failed\n");
@@ -398,7 +392,7 @@ ioat_channel_start(struct spdk_ioat_chan *ioat)
 		/* 0 means 4 GB max transfer size. */
 		ioat->max_xfer_size = 1ULL << 32;
 	} else if (xfercap < 12) {
-		/* XFCERCAP must be at least 12 (4 KB) according to the spec. */
+		/* XFERCAP must be at least 12 (4 KB) according to the spec. */
 		SPDK_ERRLOG("invalid XFERCAP value %u\n", xfercap);
 		return -1;
 	} else {
@@ -421,13 +415,20 @@ ioat_channel_start(struct spdk_ioat_chan *ioat)
 	}
 
 	ioat->hw_ring = spdk_dma_zmalloc(num_descriptors * sizeof(union spdk_ioat_hw_desc), 64,
-					 &ioat->hw_ring_phys_addr);
+					 NULL);
 	if (!ioat->hw_ring) {
 		return -1;
 	}
 
 	for (i = 0; i < num_descriptors; i++) {
-		ioat->hw_ring[i].generic.next = ioat_get_desc_phys_addr(ioat, i + 1);
+		phys_addr = spdk_vtophys(&ioat->hw_ring[i]);
+		if (phys_addr == SPDK_VTOPHYS_ERROR) {
+			SPDK_ERRLOG("Failed to translate descriptor %u to physical address\n", i);
+			return -1;
+		}
+
+		ioat->ring[i].phys_addr = phys_addr;
+		ioat->hw_ring[ioat_get_ring_index(ioat, i - 1)].generic.next = phys_addr;
 	}
 
 	ioat->head = 0;
@@ -438,7 +439,7 @@ ioat_channel_start(struct spdk_ioat_chan *ioat)
 
 	ioat->regs->chanctrl = SPDK_IOAT_CHANCTRL_ANY_ERR_ABORT_EN;
 	ioat_write_chancmp(ioat, comp_update_bus_addr);
-	ioat_write_chainaddr(ioat, ioat->hw_ring_phys_addr);
+	ioat_write_chainaddr(ioat, ioat->ring[0].phys_addr);
 
 	ioat_prep_null(ioat);
 	ioat_flush(ioat);
@@ -465,7 +466,7 @@ ioat_channel_start(struct spdk_ioat_chan *ioat)
 
 /* Caller must hold g_ioat_driver.lock */
 static struct spdk_ioat_chan *
-ioat_attach(void *device)
+ioat_attach(struct spdk_pci_device *device)
 {
 	struct spdk_ioat_chan *ioat;
 	uint32_t cmd_reg;
@@ -673,6 +674,7 @@ spdk_ioat_submit_fill(struct spdk_ioat_chan *ioat, void *cb_arg, spdk_ioat_req_c
 
 	while (remaining) {
 		op_size = remaining;
+		op_size = spdk_min(op_size, (0x200000 - _2MB_OFFSET(vdst)));
 		op_size = spdk_min(op_size, ioat->max_xfer_size);
 		remaining -= op_size;
 
diff --git a/lib/ioat/ioat_internal.h b/lib/ioat/ioat_internal.h
index 81cffff52..19593bb00 100644
--- a/lib/ioat/ioat_internal.h
+++ b/lib/ioat/ioat_internal.h
@@ -41,10 +41,11 @@
 #include "spdk/queue.h"
 #include "spdk/mmio.h"
 
-/* Allocate 2 << 15 (32K) descriptors per channel by default. */
+/* Allocate 1 << 15 (32K) descriptors per channel by default. */
 #define IOAT_DEFAULT_ORDER			15
 
 struct ioat_descriptor {
+	uint64_t		phys_addr;
 	spdk_ioat_req_cb	callback_fn;
 	void			*callback_arg;
 };
@@ -52,7 +53,7 @@ struct ioat_descriptor {
 /* One of these per allocated PCI device. */
 struct spdk_ioat_chan {
 	/* Opaque handle to upper layer */
-	void                *device;
+	struct spdk_pci_device		*device;
 	uint64_t            max_xfer_size;
 	volatile struct spdk_ioat_registers *regs;
 
@@ -66,7 +67,6 @@ struct spdk_ioat_chan {
 
 	struct ioat_descriptor		*ring;
 	union spdk_ioat_hw_desc		*hw_ring;
-	uint64_t			hw_ring_phys_addr;
 	uint32_t			dma_capabilities;
 
 	/* tailq entry for attached_chans */
diff --git a/lib/iscsi/acceptor.c b/lib/iscsi/acceptor.c
index 2b7e64fae..9b13de309 100644
--- a/lib/iscsi/acceptor.c
+++ b/lib/iscsi/acceptor.c
@@ -35,7 +35,7 @@
 #include "spdk/stdinc.h"
 
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 #include "spdk/sock.h"
 #include "spdk/string.h"
diff --git a/lib/iscsi/conn.c b/lib/iscsi/conn.c
index 09a51a49a..00c3f27c0 100644
--- a/lib/iscsi/conn.c
+++ b/lib/iscsi/conn.c
@@ -37,7 +37,7 @@
 #include "spdk/endian.h"
 #include "spdk/env.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/queue.h"
 #include "spdk/trace.h"
 #include "spdk/net.h"
@@ -50,13 +50,11 @@
 #include "iscsi/conn.h"
 #include "iscsi/tgt_node.h"
 #include "iscsi/portal_grp.h"
-#include "spdk/scsi.h"
 
 #define SPDK_ISCSI_CONNECTION_MEMSET(conn)		\
 	memset(&(conn)->portal, 0, sizeof(*(conn)) -	\
 		offsetof(struct spdk_iscsi_conn, portal));
 
-#define SPDK_MAX_POLLERS_PER_CORE	4096
 static int g_connections_per_lcore;
 static uint32_t *g_num_connections;
 
@@ -200,6 +198,7 @@ spdk_iscsi_poll_group_add_conn(struct spdk_iscsi_conn *conn)
 {
 	struct spdk_iscsi_poll_group *poll_group = &g_spdk_iscsi.poll_group[spdk_env_get_current_core()];
 
+	conn->is_stopped = false;
 	STAILQ_INSERT_TAIL(&poll_group->connections, conn, link);
 	spdk_iscsi_poll_group_add_conn_sock(conn);
 }
@@ -209,6 +208,7 @@ spdk_iscsi_poll_group_remove_conn(struct spdk_iscsi_conn *conn)
 {
 	struct spdk_iscsi_poll_group *poll_group = &g_spdk_iscsi.poll_group[spdk_env_get_current_core()];
 
+	conn->is_stopped = true;
 	STAILQ_REMOVE(&poll_group->connections, conn, spdk_iscsi_conn, link);
 }
 
@@ -279,6 +279,7 @@ spdk_iscsi_conn_construct(struct spdk_iscsi_portal *portal,
 	TAILQ_INIT(&conn->queued_r2t_tasks);
 	TAILQ_INIT(&conn->active_r2t_tasks);
 	TAILQ_INIT(&conn->queued_datain_tasks);
+	memset(&conn->open_lun_descs, 0, sizeof(conn->open_lun_descs));
 
 	rc = spdk_sock_getaddr(sock, conn->target_addr,
 			       sizeof conn->target_addr,
@@ -358,11 +359,10 @@ spdk_iscsi_conn_free_pdu(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pd
 
 static int spdk_iscsi_conn_free_tasks(struct spdk_iscsi_conn *conn)
 {
-	struct spdk_iscsi_pdu *pdu;
-	struct spdk_iscsi_task *iscsi_task;
+	struct spdk_iscsi_pdu *pdu, *tmp_pdu;
+	struct spdk_iscsi_task *iscsi_task, *tmp_iscsi_task;
 
-	while (!TAILQ_EMPTY(&conn->write_pdu_list)) {
-		pdu = TAILQ_FIRST(&conn->write_pdu_list);
+	TAILQ_FOREACH_SAFE(pdu, &conn->write_pdu_list, tailq, tmp_pdu) {
 		TAILQ_REMOVE(&conn->write_pdu_list, pdu, tailq);
 		if (pdu->task) {
 			spdk_iscsi_task_put(pdu->task);
@@ -370,8 +370,7 @@ static int spdk_iscsi_conn_free_tasks(struct spdk_iscsi_conn *conn)
 		spdk_put_pdu(pdu);
 	}
 
-	while (!TAILQ_EMPTY(&conn->snack_pdu_list)) {
-		pdu = TAILQ_FIRST(&conn->snack_pdu_list);
+	TAILQ_FOREACH_SAFE(pdu, &conn->snack_pdu_list, tailq, tmp_pdu) {
 		TAILQ_REMOVE(&conn->snack_pdu_list, pdu, tailq);
 		if (pdu->task) {
 			spdk_iscsi_task_put(pdu->task);
@@ -379,8 +378,7 @@ static int spdk_iscsi_conn_free_tasks(struct spdk_iscsi_conn *conn)
 		spdk_put_pdu(pdu);
 	}
 
-	while (!TAILQ_EMPTY(&conn->queued_datain_tasks)) {
-		iscsi_task = TAILQ_FIRST(&conn->queued_datain_tasks);
+	TAILQ_FOREACH_SAFE(iscsi_task, &conn->queued_datain_tasks, link, tmp_iscsi_task) {
 		TAILQ_REMOVE(&conn->queued_datain_tasks, iscsi_task, link);
 		pdu = iscsi_task->pdu;
 		spdk_iscsi_task_put(iscsi_task);
@@ -392,12 +390,10 @@ static int spdk_iscsi_conn_free_tasks(struct spdk_iscsi_conn *conn)
 	}
 
 	return 0;
-
 }
 
 static void spdk_iscsi_conn_free(struct spdk_iscsi_conn *conn)
 {
-
 	if (conn == NULL) {
 		return;
 	}
@@ -462,7 +458,6 @@ static void spdk_iscsi_remove_conn(struct spdk_iscsi_conn *conn)
 		spdk_free_sess(sess);
 	}
 
-
 	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "cleanup free conn\n");
 	spdk_iscsi_conn_free(conn);
 }
@@ -588,14 +583,81 @@ spdk_iscsi_conn_check_shutdown(void *arg)
 
 	if (spdk_iscsi_get_active_conns() == 0) {
 		spdk_poller_unregister(&g_shutdown_timer);
-		event = spdk_event_allocate(spdk_env_get_current_core(), spdk_iscsi_conn_check_shutdown_cb, NULL,
-					    NULL);
+		event = spdk_event_allocate(spdk_env_get_current_core(),
+					    spdk_iscsi_conn_check_shutdown_cb, NULL, NULL);
 		spdk_event_call(event);
 	}
 
 	return -1;
 }
 
+static void
+spdk_iscsi_conn_close_lun(struct spdk_iscsi_conn *conn, int lun_id)
+{
+	struct spdk_scsi_desc *desc;
+
+	desc = conn->open_lun_descs[lun_id];
+	if (desc != NULL) {
+		spdk_scsi_lun_free_io_channel(desc);
+		spdk_scsi_lun_close(desc);
+		conn->open_lun_descs[lun_id] = NULL;
+	}
+}
+
+static void
+spdk_iscsi_conn_close_luns(struct spdk_iscsi_conn *conn)
+{
+	int i;
+
+	for (i = 0; i < SPDK_SCSI_DEV_MAX_LUN; i++) {
+		spdk_iscsi_conn_close_lun(conn, i);
+	}
+}
+
+static void
+spdk_iscsi_conn_remove_lun(struct spdk_scsi_lun *lun, void *remove_ctx)
+{
+	struct spdk_iscsi_conn *conn = remove_ctx;
+	int lun_id = spdk_scsi_lun_get_id(lun);
+
+	spdk_clear_all_transfer_task(conn, lun);
+
+	spdk_iscsi_conn_close_lun(conn, lun_id);
+}
+
+static void
+spdk_iscsi_conn_open_luns(struct spdk_iscsi_conn *conn)
+{
+	int i, rc;
+	struct spdk_scsi_lun *lun;
+	struct spdk_scsi_desc *desc;
+
+	for (i = 0; i < SPDK_SCSI_DEV_MAX_LUN; i++) {
+		lun = spdk_scsi_dev_get_lun(conn->dev, i);
+		if (lun == NULL) {
+			continue;
+		}
+
+		rc = spdk_scsi_lun_open(lun, spdk_iscsi_conn_remove_lun, conn, &desc);
+		if (rc != 0) {
+			goto error;
+		}
+
+		rc = spdk_scsi_lun_allocate_io_channel(desc);
+		if (rc != 0) {
+			spdk_scsi_lun_close(desc);
+			goto error;
+		}
+
+		conn->open_lun_descs[i] = desc;
+	}
+
+	return;
+
+error:
+	spdk_iscsi_conn_close_luns(conn);
+}
+
 /**
  *  This function will stop executing the specified connection.
  */
@@ -612,8 +674,7 @@ spdk_iscsi_conn_stop(struct spdk_iscsi_conn *conn)
 		target->num_active_conns--;
 		pthread_mutex_unlock(&target->mutex);
 
-		assert(conn->dev != NULL);
-		spdk_scsi_dev_free_io_channels(conn->dev);
+		spdk_iscsi_conn_close_luns(conn);
 	}
 
 	__sync_fetch_and_sub(&g_num_connections[spdk_env_get_current_core()], 1);
@@ -731,24 +792,26 @@ spdk_iscsi_conn_read_data(struct spdk_iscsi_conn *conn, int bytes,
 
 	if (ret > 0) {
 		spdk_trace_record(TRACE_READ_FROM_SOCKET_DONE, conn->id, ret, 0, 0);
+		return ret;
 	}
 
 	if (ret < 0) {
 		if (errno == EAGAIN || errno == EWOULDBLOCK) {
 			return 0;
+		}
+
+		/* For connect reset issue, do not output error log */
+		if (errno == ECONNRESET) {
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "spdk_sock_recv() failed, errno %d: %s\n",
+				      errno, spdk_strerror(errno));
 		} else {
 			SPDK_ERRLOG("spdk_sock_recv() failed, errno %d: %s\n",
 				    errno, spdk_strerror(errno));
 		}
-		return SPDK_ISCSI_CONNECTION_FATAL;
 	}
 
 	/* connection closed */
-	if (ret == 0) {
-		return SPDK_ISCSI_CONNECTION_FATAL;
-	}
-
-	return ret;
+	return SPDK_ISCSI_CONNECTION_FATAL;
 }
 
 void
@@ -764,15 +827,14 @@ static void
 process_completed_read_subtask_list(struct spdk_iscsi_conn *conn,
 				    struct spdk_iscsi_task *primary)
 {
-	struct spdk_iscsi_task *tmp;
-
-	while (!TAILQ_EMPTY(&primary->subtask_list)) {
-		tmp = TAILQ_FIRST(&primary->subtask_list);
-		if (tmp->scsi.offset == primary->bytes_completed) {
-			TAILQ_REMOVE(&primary->subtask_list, tmp, subtask_link);
-			primary->bytes_completed += tmp->scsi.length;
-			spdk_iscsi_task_response(conn, tmp);
-			spdk_iscsi_task_put(tmp);
+	struct spdk_iscsi_task *subtask, *tmp;
+
+	TAILQ_FOREACH_SAFE(subtask, &primary->subtask_list, subtask_link, tmp) {
+		if (subtask->scsi.offset == primary->bytes_completed) {
+			TAILQ_REMOVE(&primary->subtask_list, subtask, subtask_link);
+			primary->bytes_completed += subtask->scsi.length;
+			spdk_iscsi_task_response(conn, subtask);
+			spdk_iscsi_task_put(subtask);
 		} else {
 			break;
 		}
@@ -785,14 +847,10 @@ process_read_task_completion(struct spdk_iscsi_conn *conn,
 			     struct spdk_iscsi_task *primary)
 {
 	struct spdk_iscsi_task *tmp;
-	bool flag = false;
 
 	if (task->scsi.status != SPDK_SCSI_STATUS_GOOD) {
 		TAILQ_FOREACH(tmp, &primary->subtask_list, subtask_link) {
-			memcpy(tmp->scsi.sense_data, task->scsi.sense_data,
-			       task->scsi.sense_data_len);
-			tmp->scsi.sense_data_len = task->scsi.sense_data_len;
-			tmp->scsi.status = task->scsi.status;
+			spdk_scsi_task_copy_status(&tmp->scsi, &task->scsi);
 		}
 	}
 
@@ -801,13 +859,11 @@ process_read_task_completion(struct spdk_iscsi_conn *conn,
 		TAILQ_FOREACH(tmp, &primary->subtask_list, subtask_link) {
 			if (task->scsi.offset < tmp->scsi.offset) {
 				TAILQ_INSERT_BEFORE(tmp, task, subtask_link);
-				flag = true;
-				break;
+				return;
 			}
 		}
-		if (!flag) {
-			TAILQ_INSERT_TAIL(&primary->subtask_list, task, subtask_link);
-		}
+
+		TAILQ_INSERT_TAIL(&primary->subtask_list, task, subtask_link);
 		return;
 	}
 
@@ -840,10 +896,7 @@ spdk_iscsi_task_cpl(struct spdk_scsi_task *scsi_task)
 		primary->bytes_completed += task->scsi.length;
 		if ((task != primary) &&
 		    (task->scsi.status != SPDK_SCSI_STATUS_GOOD)) {
-			memcpy(primary->scsi.sense_data, task->scsi.sense_data,
-			       task->scsi.sense_data_len);
-			primary->scsi.sense_data_len = task->scsi.sense_data_len;
-			primary->scsi.status = task->scsi.status;
+			spdk_scsi_task_copy_status(&primary->scsi, &task->scsi);
 		}
 
 		if (primary->bytes_completed == primary->scsi.transfer_len) {
@@ -1148,6 +1201,10 @@ spdk_iscsi_conn_handle_incoming_pdus(struct spdk_iscsi_conn *conn)
 				    conn->initiator_port != NULL ? spdk_scsi_port_get_name(conn->initiator_port) : "NULL");
 			return rc;
 		}
+
+		if (conn->is_stopped) {
+			break;
+		}
 	}
 
 	return i;
@@ -1180,8 +1237,7 @@ spdk_iscsi_conn_full_feature_migrate(void *arg1, void *arg2)
 	struct spdk_iscsi_conn *conn = arg1;
 
 	if (conn->sess->session_type == SESSION_TYPE_NORMAL) {
-		assert(conn->dev != NULL);
-		spdk_scsi_dev_allocate_io_channels(conn->dev);
+		spdk_iscsi_conn_open_luns(conn);
 	}
 
 	/* The poller has been unregistered, so now we can re-register it on the new core. */
diff --git a/lib/iscsi/conn.h b/lib/iscsi/conn.h
index d6b8ceaf8..bc917a7fc 100644
--- a/lib/iscsi/conn.h
+++ b/lib/iscsi/conn.h
@@ -40,6 +40,7 @@
 #include "iscsi/iscsi.h"
 #include "spdk/queue.h"
 #include "spdk/cpuset.h"
+#include "spdk/scsi.h"
 
 /*
  * MAX_CONNECTION_PARAMS: The numbers of the params in conn_param_table
@@ -160,9 +161,12 @@ struct spdk_iscsi_conn {
 
 	STAILQ_ENTRY(spdk_iscsi_conn) link;
 	struct spdk_poller	*flush_poller;
+	bool			is_stopped;  /* Set true when connection is stopped for migration */
 	TAILQ_HEAD(queued_r2t_tasks, spdk_iscsi_task)	queued_r2t_tasks;
 	TAILQ_HEAD(active_r2t_tasks, spdk_iscsi_task)	active_r2t_tasks;
 	TAILQ_HEAD(queued_datain_tasks, spdk_iscsi_task)	queued_datain_tasks;
+
+	struct spdk_scsi_desc	*open_lun_descs[SPDK_SCSI_DEV_MAX_LUN];
 };
 
 extern struct spdk_iscsi_conn *g_conns_array;
diff --git a/lib/iscsi/init_grp.c b/lib/iscsi/init_grp.c
index ea72849b0..33b7bfc38 100644
--- a/lib/iscsi/init_grp.c
+++ b/lib/iscsi/init_grp.c
@@ -675,3 +675,112 @@ spdk_iscsi_init_grp_unregister(int tag)
 	pthread_mutex_unlock(&g_spdk_iscsi.mutex);
 	return NULL;
 }
+
+static const char *initiator_group_section = \
+		"\n"
+		"# Users must change the InitiatorGroup section(s) to match the IP\n"
+		"#  addresses and initiator configuration in their environment.\n"
+		"# Netmask can be used to specify a single IP address or a range of IP addresses\n"
+		"#  Netmask 192.168.1.20   <== single IP address\n"
+		"#  Netmask 192.168.1.0/24 <== IP range 192.168.1.*\n";
+
+#define INITIATOR_GROUP_TMPL \
+"[InitiatorGroup%d]\n" \
+"  Comment \"Initiator Group%d\"\n"
+
+#define INITIATOR_TMPL \
+"  InitiatorName "
+
+#define NETMASK_TMPL \
+"  Netmask "
+
+void
+spdk_iscsi_init_grps_config_text(FILE *fp)
+{
+	struct spdk_iscsi_init_grp *ig;
+	struct spdk_iscsi_initiator_name *iname;
+	struct spdk_iscsi_initiator_netmask *imask;
+
+	/* Create initiator group section */
+	fprintf(fp, "%s", initiator_group_section);
+
+	/* Dump initiator groups */
+	TAILQ_FOREACH(ig, &g_spdk_iscsi.ig_head, tailq) {
+		if (NULL == ig) { continue; }
+		fprintf(fp, INITIATOR_GROUP_TMPL, ig->tag, ig->tag);
+
+		/* Dump initiators */
+		fprintf(fp, INITIATOR_TMPL);
+		TAILQ_FOREACH(iname, &ig->initiator_head, tailq) {
+			fprintf(fp, "%s ", iname->name);
+		}
+		fprintf(fp, "\n");
+
+		/* Dump netmasks */
+		fprintf(fp, NETMASK_TMPL);
+		TAILQ_FOREACH(imask, &ig->netmask_head, tailq) {
+			fprintf(fp, "%s ", imask->mask);
+		}
+		fprintf(fp, "\n");
+	}
+}
+
+static void
+spdk_iscsi_init_grp_info_json(struct spdk_iscsi_init_grp *ig,
+			      struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_initiator_name *iname;
+	struct spdk_iscsi_initiator_netmask *imask;
+
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_int32(w, "tag", ig->tag);
+
+	spdk_json_write_named_array_begin(w, "initiators");
+	TAILQ_FOREACH(iname, &ig->initiator_head, tailq) {
+		spdk_json_write_string(w, iname->name);
+	}
+	spdk_json_write_array_end(w);
+
+	spdk_json_write_named_array_begin(w, "netmasks");
+	TAILQ_FOREACH(imask, &ig->netmask_head, tailq) {
+		spdk_json_write_string(w, imask->mask);
+	}
+	spdk_json_write_array_end(w);
+
+	spdk_json_write_object_end(w);
+}
+
+static void
+spdk_iscsi_init_grp_config_json(struct spdk_iscsi_init_grp *ig,
+				struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "method", "add_initiator_group");
+
+	spdk_json_write_name(w, "params");
+	spdk_iscsi_init_grp_info_json(ig, w);
+
+	spdk_json_write_object_end(w);
+}
+
+void
+spdk_iscsi_init_grps_info_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_init_grp *ig;
+
+	TAILQ_FOREACH(ig, &g_spdk_iscsi.ig_head, tailq) {
+		spdk_iscsi_init_grp_info_json(ig, w);
+	}
+}
+
+void
+spdk_iscsi_init_grps_config_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_init_grp *ig;
+
+	TAILQ_FOREACH(ig, &g_spdk_iscsi.ig_head, tailq) {
+		spdk_iscsi_init_grp_config_json(ig, w);
+	}
+}
diff --git a/lib/iscsi/init_grp.h b/lib/iscsi/init_grp.h
index b97cebdbe..ff24ee5b6 100644
--- a/lib/iscsi/init_grp.h
+++ b/lib/iscsi/init_grp.h
@@ -73,5 +73,7 @@ struct spdk_iscsi_init_grp *spdk_iscsi_init_grp_find_by_tag(int tag);
 void spdk_iscsi_init_grp_destroy(struct spdk_iscsi_init_grp *ig);
 int spdk_iscsi_parse_init_grps(void);
 void spdk_iscsi_init_grps_destroy(void);
-
+void spdk_iscsi_init_grps_config_text(FILE *fp);
+void spdk_iscsi_init_grps_info_json(struct spdk_json_write_ctx *w);
+void spdk_iscsi_init_grps_config_json(struct spdk_json_write_ctx *w);
 #endif // SPDK_INIT_GRP_H
diff --git a/lib/iscsi/iscsi.c b/lib/iscsi/iscsi.c
index a4b1e221d..90eabe647 100644
--- a/lib/iscsi/iscsi.c
+++ b/lib/iscsi/iscsi.c
@@ -87,31 +87,25 @@ static void srandomdev(void);
 static int spdk_bin2hex(char *buf, size_t len, const uint8_t *data, size_t data_len);
 static int spdk_hex2bin(uint8_t *data, size_t data_len, const char *str);
 
-
 static int spdk_add_transfer_task(struct spdk_iscsi_conn *conn,
 				  struct spdk_iscsi_task *task);
-static int
-spdk_iscsi_send_r2t(struct spdk_iscsi_conn *conn,
-		    struct spdk_iscsi_task *task, int offset,
-		    int len, uint32_t transfer_tag, uint32_t *R2TSN);
-static int
-spdk_create_iscsi_sess(struct spdk_iscsi_conn *conn,
-		       struct spdk_iscsi_tgt_node *target,
-		       enum session_type session_type);
-static int
-spdk_append_iscsi_sess(struct spdk_iscsi_conn *conn,
-		       const char *initiator_port_name, uint16_t tsih, uint16_t cid);
-static int
-spdk_iscsi_send_r2t_recovery(struct spdk_iscsi_conn *conn,
-			     struct spdk_iscsi_task *r2t_task, uint32_t r2t_sn,
-			     bool send_new_r2tsn);
-static void
-spdk_remove_acked_pdu(struct spdk_iscsi_conn *conn,
-		      uint32_t ExpStatSN);
 
-static int
-spdk_iscsi_reject(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu,
-		  int reason);
+static int spdk_iscsi_send_r2t(struct spdk_iscsi_conn *conn,
+			       struct spdk_iscsi_task *task, int offset,
+			       int len, uint32_t transfer_tag, uint32_t *R2TSN);
+static int spdk_iscsi_send_r2t_recovery(struct spdk_iscsi_conn *conn,
+					struct spdk_iscsi_task *r2t_task, uint32_t r2t_sn,
+					bool send_new_r2tsn);
+
+static int spdk_create_iscsi_sess(struct spdk_iscsi_conn *conn,
+				  struct spdk_iscsi_tgt_node *target, enum session_type session_type);
+static int spdk_append_iscsi_sess(struct spdk_iscsi_conn *conn,
+				  const char *initiator_port_name, uint16_t tsih, uint16_t cid);
+
+static void spdk_remove_acked_pdu(struct spdk_iscsi_conn *conn, uint32_t ExpStatSN);
+
+static int spdk_iscsi_reject(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu,
+			     int reason);
 
 #define DMIN32(A,B) ((uint32_t) ((uint32_t)(A) > (uint32_t)(B) ? (uint32_t)(B) : (uint32_t)(A)))
 #define DMIN64(A,B) ((uint64_t) ((A) > (B) ? (B) : (A)))
@@ -531,8 +525,7 @@ spdk_iscsi_read_pdu(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu **_pdu)
 			max_segment_len = spdk_get_immediate_data_buffer_size();
 		}
 		if (data_len > max_segment_len) {
-			SPDK_ERRLOG("Data(%d) > MaxSegment(%d)\n",
-				    data_len, max_segment_len);
+			SPDK_ERRLOG("Data(%d) > MaxSegment(%d)\n", data_len, max_segment_len);
 			rc = spdk_iscsi_reject(conn, pdu, ISCSI_REASON_PROTOCOL_ERROR);
 			spdk_put_pdu(pdu);
 
@@ -542,8 +535,7 @@ spdk_iscsi_read_pdu(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu **_pdu)
 			 * return SUCCESS here so that the caller will continue
 			 * to attempt to read PDUs.
 			 */
-			rc = (rc < 0) ? SPDK_ISCSI_CONNECTION_FATAL :
-			     SPDK_SUCCESS;
+			rc = (rc < 0) ? SPDK_ISCSI_CONNECTION_FATAL : SPDK_SUCCESS;
 			return rc;
 		}
 
@@ -638,9 +630,9 @@ spdk_iscsi_build_iovecs(struct spdk_iscsi_conn *conn, struct iovec *iovec,
 }
 
 static int
-spdk_iscsi_append_text(struct spdk_iscsi_conn *conn __attribute__((
-			       __unused__)), const char *key, const char *val, uint8_t *data, int alloc_len,
-		       int data_len)
+spdk_iscsi_append_text(struct spdk_iscsi_conn *conn __attribute__((__unused__)),
+		       const char *key, const char *val, uint8_t *data,
+		       int alloc_len, int data_len)
 {
 	int total;
 	int len;
@@ -659,8 +651,7 @@ spdk_iscsi_append_text(struct spdk_iscsi_conn *conn __attribute__((
 		SPDK_ERRLOG("data space small %d\n", alloc_len);
 		return total;
 	}
-	len = snprintf((char *) data + total, alloc_len - total, "%s=%s",
-		       key, val);
+	len = snprintf((char *) data + total, alloc_len - total, "%s=%s", key, val);
 	total += len + 1;
 
 	return total;
@@ -677,8 +668,7 @@ spdk_iscsi_append_param(struct spdk_iscsi_conn *conn, const char *key,
 	if (param == NULL) {
 		param = spdk_iscsi_param_find(conn->sess->params, key);
 		if (param == NULL) {
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "no key %.64s\n",
-				      key);
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "no key %.64s\n", key);
 			return data_len;
 		}
 	}
@@ -726,7 +716,6 @@ spdk_iscsi_chap_get_authinfo(struct iscsi_chap_auth *auth, const char *authfile,
 	while (sp != NULL) {
 		if (spdk_conf_section_match_prefix(sp, "AuthGroup")) {
 			int group = spdk_conf_section_get_num(sp);
-
 			if (group == 0) {
 				SPDK_ERRLOG("Group 0 is invalid\n");
 				spdk_conf_free(config);
@@ -738,8 +727,7 @@ spdk_iscsi_chap_get_authinfo(struct iscsi_chap_auth *auth, const char *authfile,
 
 			val = spdk_conf_section_get_val(sp, "Comment");
 			if (val != NULL) {
-				SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-					      "Comment %s\n", val);
+				SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Comment %s\n", val);
 			}
 			for (i = 0; ; i++) {
 				val = spdk_conf_section_get_nval(sp, "Auth", i);
@@ -813,8 +801,8 @@ spdk_iscsi_get_authinfo(struct spdk_iscsi_conn *conn, const char *authuser)
 
 static int
 spdk_iscsi_auth_params(struct spdk_iscsi_conn *conn,
-		       struct iscsi_param *params, const char *method, uint8_t *data, int alloc_len,
-		       int data_len)
+		       struct iscsi_param *params, const char *method, uint8_t *data,
+		       int alloc_len, int data_len)
 {
 	char *in_val;
 	char *in_next;
@@ -987,8 +975,7 @@ spdk_iscsi_auth_params(struct spdk_iscsi_conn *conn,
 			spdk_dump("MChallenge", conn->auth.chap_mchallenge,
 				  conn->auth.chap_mchallenge_len);
 #endif
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-				      "got CHAP_I/CHAP_C\n");
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "got CHAP_I/CHAP_C\n");
 
 			if (conn->auth.muser == NULL || conn->auth.msecret == NULL) {
 				//SPDK_ERRLOG("mutual auth user or secret is missing\n");
@@ -1058,14 +1045,12 @@ spdk_iscsi_reject(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu,
 		alloc_len += ISCSI_DIGEST_LEN;
 	}
 
-	data = malloc(alloc_len);
+	data = calloc(1, alloc_len);
 	if (!data) {
-		SPDK_ERRLOG("malloc() failed for data segment\n");
+		SPDK_ERRLOG("calloc() failed for data segment\n");
 		return -ENOMEM;
 	}
 
-	memset(data, 0, alloc_len);
-
 	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Reject PDU reason=%d\n", reason);
 
 	if (conn->sess != NULL) {
@@ -1155,7 +1140,6 @@ spdk_iscsi_check_values(struct spdk_iscsi_conn *conn)
 	return 0;
 }
 
-
 /*
  * The response function of spdk_iscsi_op_login
  * return:
@@ -1216,7 +1200,6 @@ spdk_iscsi_op_login_response(struct spdk_iscsi_conn *conn,
 
 	spdk_iscsi_param_free(params);
 	return 0;
-
 }
 
 /*
@@ -1274,15 +1257,13 @@ spdk_iscsi_op_login_session_discovery_chap(struct spdk_iscsi_conn *conn)
 
 	if (g_spdk_iscsi.no_discovery_auth) {
 		conn->req_auth = 0;
-		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod",
-						      "None", "None");
+		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod", "None", "None");
 		if (rc < 0) {
 			return rc;
 		}
 	} else if (g_spdk_iscsi.req_discovery_auth) {
 		conn->req_auth = 1;
-		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod",
-						      "CHAP", "CHAP");
+		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod", "CHAP", "CHAP");
 		if (rc < 0) {
 			return rc;
 		}
@@ -1292,7 +1273,6 @@ spdk_iscsi_op_login_session_discovery_chap(struct spdk_iscsi_conn *conn)
 	}
 
 	return rc;
-
 }
 
 /*
@@ -1310,15 +1290,13 @@ spdk_iscsi_op_login_negotiate_chap_param(struct spdk_iscsi_conn *conn,
 
 	if (target->disable_chap) {
 		conn->req_auth = 0;
-		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod",
-						      "None", "None");
+		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod", "None", "None");
 		if (rc < 0) {
 			return rc;
 		}
 	} else if (target->require_chap) {
 		conn->req_auth = 1;
-		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod",
-						      "CHAP", "CHAP");
+		rc = spdk_iscsi_op_login_update_param(conn, "AuthMethod", "CHAP", "CHAP");
 		if (rc < 0) {
 			return rc;
 		}
@@ -1334,8 +1312,7 @@ spdk_iscsi_op_login_negotiate_chap_param(struct spdk_iscsi_conn *conn,
 		 *  HeaderDigest values to remove "None" so that only
 		 *  initiators who support CRC32C can connect.
 		 */
-		rc = spdk_iscsi_op_login_update_param(conn, "HeaderDigest",
-						      "CRC32C", "CRC32C");
+		rc = spdk_iscsi_op_login_update_param(conn, "HeaderDigest", "CRC32C", "CRC32C");
 		if (rc < 0) {
 			return rc;
 		}
@@ -1347,8 +1324,7 @@ spdk_iscsi_op_login_negotiate_chap_param(struct spdk_iscsi_conn *conn,
 		 *  DataDigest values to remove "None" so that only
 		 *  initiators who support CRC32C can connect.
 		 */
-		rc = spdk_iscsi_op_login_update_param(conn, "DataDigest",
-						      "CRC32C", "CRC32C");
+		rc = spdk_iscsi_op_login_update_param(conn, "DataDigest", "CRC32C", "CRC32C");
 		if (rc < 0) {
 			return rc;
 		}
@@ -1392,8 +1368,7 @@ spdk_iscsi_op_login_check_session(struct spdk_iscsi_conn *conn,
 		}
 	} else if (!g_spdk_iscsi.AllowDuplicateIsid) {
 		/* new session, drop old sess by the initiator */
-		spdk_iscsi_drop_conns(conn, initiator_port_name,
-				      0 /* drop old */);
+		spdk_iscsi_drop_conns(conn, initiator_port_name, 0 /* drop old */);
 	}
 
 	return rc;
@@ -1410,7 +1385,6 @@ spdk_iscsi_op_login_check_target(struct spdk_iscsi_conn *conn,
 				 struct spdk_iscsi_pdu *rsp_pdu,
 				 const char *target_name,
 				 struct spdk_iscsi_tgt_node **target)
-
 {
 	bool result;
 	struct iscsi_bhs_login_rsp *rsph;
@@ -1482,8 +1456,7 @@ spdk_iscsi_op_login_session_normal(struct spdk_iscsi_conn *conn,
 	}
 
 	pthread_mutex_lock(&g_spdk_iscsi.mutex);
-	rc = spdk_iscsi_op_login_check_target(conn, rsp_pdu, target_name,
-					      target);
+	rc = spdk_iscsi_op_login_check_target(conn, rsp_pdu, target_name, target);
 	pthread_mutex_unlock(&g_spdk_iscsi.mutex);
 
 	if (rc < 0) {
@@ -1580,16 +1553,13 @@ spdk_iscsi_op_login_initialize_port(struct spdk_iscsi_conn *conn,
 		rsph->status_detail = ISCSI_LOGIN_MISSING_PARMS;
 		return SPDK_ISCSI_LOGIN_ERROR_RESPONSE;
 	}
-	snprintf(conn->initiator_name, sizeof(conn->initiator_name),
-		 "%s", val);
+	snprintf(conn->initiator_name, sizeof(conn->initiator_name), "%s", val);
 	snprintf(initiator_port_name, name_length,
 		 "%s,i,0x%12.12" PRIx64, val, spdk_iscsi_get_isid(rsph->isid));
 	spdk_strlwr(conn->initiator_name);
 	spdk_strlwr(initiator_port_name);
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Initiator name: %s\n",
-		      conn->initiator_name);
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Initiator port: %s\n",
-		      initiator_port_name);
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Initiator name: %s\n", conn->initiator_name);
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Initiator port: %s\n", initiator_port_name);
 
 	return 0;
 }
@@ -1627,8 +1597,8 @@ spdk_iscsi_op_login_set_conn_info(struct spdk_iscsi_conn *conn,
 
 		/* initialize parameters */
 		conn->StatSN = from_be32(&rsph->stat_sn);
-		conn->sess->initiator_port = spdk_scsi_port_create(spdk_iscsi_get_isid(rsph->isid), 0,
-					     initiator_port_name);
+		conn->sess->initiator_port = spdk_scsi_port_create(spdk_iscsi_get_isid(rsph->isid),
+					     0, initiator_port_name);
 		conn->sess->isid = spdk_iscsi_get_isid(rsph->isid);
 		conn->sess->target = target;
 
@@ -1692,8 +1662,7 @@ spdk_iscsi_op_login_set_target_info(struct spdk_iscsi_conn *conn,
 		return SPDK_ISCSI_LOGIN_ERROR_PARAMETER;
 	}
 	snprintf(buf, sizeof buf, "%d", portal->group->tag);
-	rc = spdk_iscsi_param_set(conn->sess->params, "TargetPortalGroupTag",
-				  buf);
+	rc = spdk_iscsi_param_set(conn->sess->params, "TargetPortalGroupTag", buf);
 	if (rc < 0) {
 		SPDK_ERRLOG("iscsi_param_set() failed\n");
 		return SPDK_ISCSI_LOGIN_ERROR_PARAMETER;
@@ -1702,20 +1671,20 @@ spdk_iscsi_op_login_set_target_info(struct spdk_iscsi_conn *conn,
 	/* write in response */
 	if (target != NULL) {
 		val = spdk_iscsi_param_get_val(conn->sess->params, "TargetAlias");
-		if (val != NULL && strlen(val) != 0)
+		if (val != NULL && strlen(val) != 0) {
 			rsp_pdu->data_segment_len = spdk_iscsi_append_param(conn,
 						    "TargetAlias",
 						    rsp_pdu->data,
 						    alloc_len,
 						    rsp_pdu->data_segment_len);
-
-		if (session_type == SESSION_TYPE_DISCOVERY)
+		}
+		if (session_type == SESSION_TYPE_DISCOVERY) {
 			rsp_pdu->data_segment_len = spdk_iscsi_append_param(conn,
 						    "TargetAddress",
 						    rsp_pdu->data,
 						    alloc_len,
 						    rsp_pdu->data_segment_len);
-
+		}
 		rsp_pdu->data_segment_len = spdk_iscsi_append_param(conn,
 					    "TargetPortalGroupTag",
 					    rsp_pdu->data,
@@ -1724,11 +1693,8 @@ spdk_iscsi_op_login_set_target_info(struct spdk_iscsi_conn *conn,
 	}
 
 	return rc;
-
 }
 
-
-
 /*
  * This function is used to handle the login of iscsi initiator when there is
  * no session
@@ -1754,9 +1720,7 @@ spdk_iscsi_op_login_phase_none(struct spdk_iscsi_conn *conn,
 	conn->dev = NULL;
 
 	rc = spdk_iscsi_op_login_initialize_port(conn, rsp_pdu,
-			initiator_port_name,
-			MAX_INITIATOR_NAME,
-			params);
+			initiator_port_name, MAX_INITIATOR_NAME, params);
 	if (rc < 0) {
 		return rc;
 	}
@@ -1795,8 +1759,7 @@ spdk_iscsi_op_login_phase_none(struct spdk_iscsi_conn *conn,
 		return SPDK_ISCSI_LOGIN_ERROR_RESPONSE;
 	}
 
-	rc = spdk_iscsi_op_login_set_conn_info(conn, rsp_pdu,
-					       initiator_port_name,
+	rc = spdk_iscsi_op_login_set_conn_info(conn, rsp_pdu, initiator_port_name,
 					       session_type, target, cid);
 	if (rc < 0) {
 		return rc;
@@ -1821,8 +1784,6 @@ spdk_iscsi_op_login_phase_none(struct spdk_iscsi_conn *conn,
 	}
 
 	return rc;
-
-
 }
 
 /*
@@ -1855,14 +1816,12 @@ spdk_iscsi_op_login_rsp_init(struct spdk_iscsi_conn *conn,
 		*alloc_len = conn->MaxRecvDataSegmentLength;
 	}
 
-	rsp_pdu->data = malloc(*alloc_len);
+	rsp_pdu->data = calloc(1, *alloc_len);
 	if (!rsp_pdu->data) {
-		SPDK_ERRLOG("malloc() failed for data segment\n");
+		SPDK_ERRLOG("calloc() failed for data segment\n");
 		return -ENOMEM;
 	}
 
-	memset(rsp_pdu->data, 0, *alloc_len);
-
 	reqh = (struct iscsi_bhs_login_req *)&pdu->bhs;
 	rsph->flags |= (reqh->flags & ISCSI_LOGIN_TRANSIT);
 	rsph->flags |= (reqh->flags & ISCSI_LOGIN_CONTINUE);
@@ -1949,7 +1908,6 @@ spdk_iscsi_op_login_rsp_init(struct spdk_iscsi_conn *conn,
 	return 0;
 }
 
-
 /*
  * This function is used to set the csg bit case in rsp
  * return:
@@ -1995,11 +1953,8 @@ spdk_iscsi_op_login_rsp_handle_csg_bit(struct spdk_iscsi_conn *conn,
 				/* not complete */
 				rsph->flags &= ~ISCSI_LOGIN_TRANSIT;
 			} else {
-				if (conn->auth.chap_phase !=
-				    ISCSI_CHAP_PHASE_END) {
-					SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-						      "CHAP phase not "
-						      "complete");
+				if (conn->auth.chap_phase != ISCSI_CHAP_PHASE_END) {
+					SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "CHAP phase not complete");
 				}
 			}
 
@@ -2047,7 +2002,6 @@ spdk_iscsi_op_login_rsp_handle_csg_bit(struct spdk_iscsi_conn *conn,
 	}
 
 	return 0;
-
 }
 
 /* This function is used to notify the session info
@@ -2097,7 +2051,6 @@ spdk_iscsi_op_login_notify_session_info(struct spdk_iscsi_conn *conn,
 	}
 
 	return 0;
-
 }
 
 /*
@@ -2109,7 +2062,6 @@ spdk_iscsi_op_login_notify_session_info(struct spdk_iscsi_conn *conn,
 static int
 spdk_iscsi_op_login_rsp_handle_t_bit(struct spdk_iscsi_conn *conn,
 				     struct spdk_iscsi_pdu *rsp_pdu)
-
 {
 	int rc;
 	struct iscsi_bhs_login_rsp *rsph;
@@ -2151,8 +2103,6 @@ spdk_iscsi_op_login_rsp_handle_t_bit(struct spdk_iscsi_conn *conn,
 	return 0;
 }
 
-
-
 /*
  * This function is used to set the values of the internal data structure used
  * by spdk_iscsi_op_login function
@@ -2165,7 +2115,7 @@ spdk_iscsi_op_login_rsp_handle(struct spdk_iscsi_conn *conn,
 			       struct spdk_iscsi_pdu *rsp_pdu, struct iscsi_param **params,
 			       int alloc_len)
 {
-	int rc = 0;
+	int rc;
 	struct iscsi_bhs_login_rsp *rsph;
 	rsph = (struct iscsi_bhs_login_rsp *)&rsp_pdu->bhs;
 
@@ -2211,13 +2161,11 @@ spdk_iscsi_op_login(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	int alloc_len;
 	int cid;
 
-
 	if (conn->full_feature && conn->sess != NULL &&
 	    conn->sess->session_type == SESSION_TYPE_DISCOVERY) {
 		return SPDK_ISCSI_CONNECTION_FATAL;
 	}
 
-
 	rsp_pdu = spdk_get_pdu();
 	if (rsp_pdu == NULL) {
 		return SPDK_ISCSI_CONNECTION_FATAL;
@@ -2251,7 +2199,6 @@ spdk_iscsi_op_login(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	}
 
 	rc = spdk_iscsi_op_login_response(conn, rsp_pdu, *params_p);
-
 	if (rc == 0) {
 		conn->state = ISCSI_CONN_STATE_RUNNING;
 	} else {
@@ -2259,7 +2206,6 @@ spdk_iscsi_op_login(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	}
 
 	return rc;
-
 }
 
 static int
@@ -2333,23 +2279,21 @@ spdk_iscsi_op_text(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	}
 
 	/* store incoming parameters */
-	rc = spdk_iscsi_parse_params(&params, pdu->data,
-				     pdu->data_segment_len, C_bit, &conn->partial_text_parameter);
+	rc = spdk_iscsi_parse_params(&params, pdu->data, pdu->data_segment_len,
+				     C_bit, &conn->partial_text_parameter);
 	if (rc < 0) {
 		SPDK_ERRLOG("iscsi_parse_params() failed\n");
 		spdk_iscsi_param_free(params);
 		return -1;
 	}
 
-	data = malloc(alloc_len);
+	data = calloc(1, alloc_len);
 	if (!data) {
-		SPDK_ERRLOG("malloc() failed for data segment\n");
+		SPDK_ERRLOG("calloc() failed for data segment\n");
 		spdk_iscsi_param_free(params);
 		return -ENOMEM;
 	}
 
-	memset(data, 0, alloc_len);
-
 	/* negotiate parameters */
 	data_len = spdk_iscsi_negotiate_params(conn, params_p,
 					       data, alloc_len, data_len);
@@ -2395,8 +2339,7 @@ spdk_iscsi_op_text(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 			}
 		}
 	} else {
-		if (spdk_iscsi_param_eq_val(conn->sess->params,
-					    "SessionType", "Discovery")) {
+		if (spdk_iscsi_param_eq_val(conn->sess->params, "SessionType", "Discovery")) {
 			spdk_iscsi_param_free(*params_p);
 			free(data);
 			return SPDK_ISCSI_CONNECTION_FATAL;
@@ -2495,10 +2438,8 @@ spdk_iscsi_op_logout(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	if (reqh->reason != 0 && conn->sess->session_type == SESSION_TYPE_DISCOVERY) {
 		SPDK_ERRLOG("only logout with close the session reason can be in discovery session");
 		return SPDK_ISCSI_CONNECTION_FATAL;
-
 	}
 
-
 	if (conn->sess != NULL) {
 		SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
 			      "CmdSN=%u, ExpStatSN=%u, StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
@@ -2510,8 +2451,7 @@ spdk_iscsi_op_logout(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 			/* ignore error */
 		}
 	} else {
-		SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-			      "CmdSN=%u, ExpStatSN=%u, StatSN=%u\n",
+		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "CmdSN=%u, ExpStatSN=%u, StatSN=%u\n",
 			      CmdSN, ExpStatSN, conn->StatSN);
 	}
 
@@ -2612,19 +2552,17 @@ spdk_get_scsi_task_from_ttt(struct spdk_iscsi_conn *conn,
 {
 	struct spdk_iscsi_pdu *pdu;
 	struct iscsi_bhs_data_in *datain_bhs;
-	struct spdk_iscsi_task *task = NULL;
 
 	TAILQ_FOREACH(pdu, &conn->snack_pdu_list, tailq) {
 		if (pdu->bhs.opcode == ISCSI_OP_SCSI_DATAIN) {
 			datain_bhs = (struct iscsi_bhs_data_in *)&pdu->bhs;
 			if (from_be32(&datain_bhs->ttt) == transfer_tag) {
-				task = pdu->task;
-				break;
+				return pdu->task;
 			}
 		}
 	}
 
-	return task;
+	return NULL;
 }
 
 /* This function returns the spdk_scsi_task by searching the snack list via
@@ -2635,18 +2573,16 @@ spdk_get_scsi_task_from_itt(struct spdk_iscsi_conn *conn,
 			    uint32_t task_tag, enum iscsi_op opcode)
 {
 	struct spdk_iscsi_pdu *pdu;
-	struct spdk_iscsi_task *task = NULL;
 
 	TAILQ_FOREACH(pdu, &conn->snack_pdu_list, tailq) {
 		if (pdu->bhs.opcode == opcode &&
 		    pdu->task != NULL &&
 		    pdu->task->tag == task_tag) {
-			task = pdu->task;
-			break;
+			return pdu->task;
 		}
 	}
 
-	return task;
+	return NULL;
 }
 
 static int
@@ -2778,7 +2714,7 @@ spdk_iscsi_transfer_in(struct spdk_iscsi_conn *conn,
 			}
 		} else {
 			/* handle the case that it is a primary task which has subtasks */
-			if (primary->scsi.transfer_len != task->scsi.length) {
+			if (primary->scsi.transfer_len != primary->scsi.length) {
 				conn->data_in_cnt--;
 			}
 		}
@@ -2788,20 +2724,17 @@ spdk_iscsi_transfer_in(struct spdk_iscsi_conn *conn,
 
 	if (data_len < transfer_len) {
 		/* underflow */
-		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Underflow %u/%u\n",
-			      data_len, transfer_len);
+		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Underflow %u/%u\n", data_len, transfer_len);
 		residual_len = transfer_len - data_len;
 		transfer_len = data_len;
 		datain_flag |= ISCSI_DATAIN_UNDERFLOW;
 	} else if (data_len > transfer_len) {
 		/* overflow */
-		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Overflow %u/%u\n",
-			      data_len, transfer_len);
+		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Overflow %u/%u\n", data_len, transfer_len);
 		residual_len = data_len - transfer_len;
 		datain_flag |= ISCSI_DATAIN_OVERFLOW;
 	} else {
-		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Transfer %u\n",
-			      transfer_len);
+		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Transfer %u\n", transfer_len);
 		residual_len = 0;
 	}
 
@@ -2814,47 +2747,34 @@ spdk_iscsi_transfer_in(struct spdk_iscsi_conn *conn,
 		offset = i * conn->sess->MaxBurstLength;
 		sequence_end = DMIN32(((i + 1) * conn->sess->MaxBurstLength),
 				      transfer_len);
-		datain_flag &= ~ISCSI_FLAG_FINAL;
-		datain_flag &= ~ISCSI_DATAIN_STATUS;
 
 		/* send data splitted by segment_len */
 		for (; offset < sequence_end; offset += segment_len) {
 			len = DMIN32(segment_len, (sequence_end - offset));
 
+			datain_flag &= ~ISCSI_FLAG_FINAL;
+			datain_flag &= ~ISCSI_DATAIN_STATUS;
+
 			if (offset + len == sequence_end) {
 				/* last PDU in a sequence */
 				datain_flag |= ISCSI_FLAG_FINAL;
-				datain_flag &= ~ISCSI_DATAIN_STATUS;
 				if (task->scsi.sense_data_len == 0) {
-					switch (task->scsi.status) {
-					case SPDK_SCSI_STATUS_GOOD:
-					case SPDK_SCSI_STATUS_CONDITION_MET:
-					case SPDK_SCSI_STATUS_INTERMEDIATE:
-					case SPDK_SCSI_STATUS_INTERMEDIATE_CONDITION_MET:
-						/* The last pdu in all data-in pdus */
-						if ((offset + len) == transfer_len &&
-						    (primary->bytes_completed ==
-						     primary->scsi.transfer_len)) {
-							datain_flag |= ISCSI_DATAIN_STATUS;
-							sent_status = 1;
-						}
+					/* The last pdu in all data-in pdus */
+					if ((offset + len) == transfer_len &&
+					    (primary->bytes_completed == primary->scsi.transfer_len)) {
+						datain_flag |= ISCSI_DATAIN_STATUS;
+						sent_status = 1;
 					}
 				}
-			} else {
-				datain_flag &= ~ISCSI_FLAG_FINAL;
-				datain_flag &= ~ISCSI_DATAIN_STATUS;
 			}
 
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-				      "Transfer=%d, Offset=%d, Len=%d\n",
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Transfer=%d, Offset=%d, Len=%d\n",
 				      sequence_end, offset, len);
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-				      "StatSN=%u, DataSN=%u, Offset=%u, Len=%d\n",
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "StatSN=%u, DataSN=%u, Offset=%u, Len=%d\n",
 				      conn->StatSN, DataSN, offset, len);
 
-			DataSN = spdk_iscsi_send_datain(conn, task, datain_flag,
-							residual_len, offset,
-							DataSN, len);
+			DataSN = spdk_iscsi_send_datain(conn, task, datain_flag, residual_len,
+							offset, DataSN, len);
 		}
 	}
 
@@ -2863,11 +2783,7 @@ spdk_iscsi_transfer_in(struct spdk_iscsi_conn *conn,
 	}
 	primary->datain_datasn = DataSN;
 
-	if (sent_status) {
-		return 1;
-	}
-
-	return 0;
+	return sent_status;
 }
 
 /*
@@ -2969,7 +2885,7 @@ int spdk_iscsi_conn_handle_queued_datain_tasks(struct spdk_iscsi_conn *conn)
 static int spdk_iscsi_op_scsi_read(struct spdk_iscsi_conn *conn,
 				   struct spdk_iscsi_task *task)
 {
-	int32_t remaining_size = 0;
+	int32_t remaining_size;
 
 	TAILQ_INIT(&task->subtask_list);
 	task->scsi.dxfer_dir = SPDK_SCSI_DIR_FROM_DEV;
@@ -3081,8 +2997,7 @@ spdk_iscsi_op_scsi(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 		if ((!conn->sess->ImmediateData && (pdu->data_segment_len > 0)) ||
 		    (pdu->data_segment_len > conn->sess->FirstBurstLength)) {
 			spdk_iscsi_task_put(task);
-			rc = spdk_iscsi_reject(conn, pdu,
-					       ISCSI_REASON_PROTOCOL_ERROR);
+			rc = spdk_iscsi_reject(conn, pdu, ISCSI_REASON_PROTOCOL_ERROR);
 			if (rc < 0) {
 				SPDK_ERRLOG("iscsi_reject() failed\n");
 			}
@@ -3185,7 +3100,6 @@ spdk_iscsi_task_mgmt_response(struct spdk_iscsi_conn *conn,
 	spdk_iscsi_conn_write_pdu(conn, rsp_pdu);
 }
 
-
 void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
 			      struct spdk_iscsi_task *task)
 {
@@ -3195,8 +3109,7 @@ void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
 	uint32_t transfer_len;
 	size_t residual_len;
 	size_t data_len;
-	int o_bit, u_bit, O_bit, U_bit;
-	int bidi_residual_len;
+	int O_bit, U_bit;
 	int rc;
 	struct spdk_iscsi_task *primary;
 
@@ -3219,27 +3132,24 @@ void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
 		}
 	}
 
-	o_bit = u_bit = O_bit = U_bit = 0;
-	bidi_residual_len = residual_len = 0;
-	data_len = primary->bytes_completed;
+	O_bit = U_bit = 0;
+	residual_len = 0;
+	data_len = primary->scsi.data_transferred;
 
 	if ((transfer_len != 0) &&
 	    (task->scsi.status == SPDK_SCSI_STATUS_GOOD)) {
 		if (data_len < transfer_len) {
 			/* underflow */
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Underflow %zu/%u\n",
-				      data_len, transfer_len);
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Underflow %zu/%u\n", data_len, transfer_len);
 			residual_len = transfer_len - data_len;
 			U_bit = 1;
 		} else if (data_len > transfer_len) {
 			/* overflow */
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Overflow %zu/%u\n",
-				      data_len, transfer_len);
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Overflow %zu/%u\n", data_len, transfer_len);
 			residual_len = data_len - transfer_len;
 			O_bit = 1;
 		} else {
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Transfer %u\n",
-				      transfer_len);
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Transfer %u\n", transfer_len);
 		}
 	}
 
@@ -3262,14 +3172,6 @@ void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
 	rsph->opcode = ISCSI_OP_SCSI_RSP;
 	rsph->flags |= 0x80; /* bit 0 is default to 1 */
 
-	if (o_bit) {
-		rsph->flags |= ISCSI_SCSI_BIDI_OVERFLOW;
-	}
-
-	if (u_bit) {
-		rsph->flags |= ISCSI_SCSI_BIDI_UNDERFLOW;
-	}
-
 	if (O_bit) {
 		rsph->flags |= ISCSI_SCSI_OVERFLOW;
 	}
@@ -3295,7 +3197,7 @@ void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
 	to_be32(&rsph->exp_cmd_sn, conn->sess->ExpCmdSN);
 	to_be32(&rsph->max_cmd_sn, conn->sess->MaxCmdSN);
 
-	to_be32(&rsph->bi_read_res_cnt, bidi_residual_len);
+	to_be32(&rsph->bi_read_res_cnt, 0);
 	to_be32(&rsph->res_cnt, residual_len);
 
 	spdk_iscsi_conn_write_pdu(conn, rsp_pdu);
@@ -3338,14 +3240,11 @@ spdk_iscsi_op_task(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	task_tag = from_be32(&reqh->itt);
 	ref_task_tag = from_be32(&reqh->ref_task_tag);
 
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "I=%d, func=%d, ITT=%x, ref TT=%x, LUN=0x%16.16"PRIx64"\n",
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "I=%d, func=%d, ITT=%x, ref TT=%x, LUN=0x%16.16"PRIx64"\n",
 		      reqh->immediate, function, task_tag, ref_task_tag, lun);
 
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
-		      conn->StatSN, conn->sess->ExpCmdSN,
-		      conn->sess->MaxCmdSN);
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
+		      conn->StatSN, conn->sess->ExpCmdSN, conn->sess->MaxCmdSN);
 
 	lun_i = spdk_islun2lun(lun);
 	dev = conn->dev;
@@ -3483,8 +3382,7 @@ spdk_iscsi_op_nopout(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "I=%d, ITT=%x, TTT=%x\n",
 		      I_bit, task_tag, transfer_tag);
 
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "CmdSN=%u, StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "CmdSN=%u, StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
 		      CmdSN, conn->StatSN, conn->sess->ExpCmdSN,
 		      conn->sess->MaxCmdSN);
 
@@ -3506,8 +3404,7 @@ spdk_iscsi_op_nopout(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 
 	if (task_tag == 0xffffffffU) {
 		if (I_bit == 1) {
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-				      "got NOPOUT ITT=0xffffffff\n");
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "got NOPOUT ITT=0xffffffff\n");
 			return SPDK_SUCCESS;
 		} else {
 			SPDK_ERRLOG("got NOPOUT ITT=0xffffffff, I=0\n");
@@ -3515,12 +3412,11 @@ spdk_iscsi_op_nopout(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 		}
 	}
 
-	data = malloc(data_len);
+	data = calloc(1, data_len);
 	if (!data) {
-		SPDK_ERRLOG("malloc() failed for ping data\n");
+		SPDK_ERRLOG("calloc() failed for ping data\n");
 		return SPDK_ISCSI_CONNECTION_FATAL;
 	}
-	memset(data, 0, data_len);
 
 	/* response of NOPOUT */
 	if (data_len > 0) {
@@ -3620,50 +3516,50 @@ spdk_add_transfer_task(struct spdk_iscsi_conn *conn,
 	return SPDK_SUCCESS;
 }
 
+/* If there are additional large writes queued for R2Ts, start them now.
+ *  This is called when a large write is just completed or when multiple LUNs
+ *  are attached and large write tasks for the specific LUN are cleared.
+ */
+static void
+spdk_start_queued_transfer_tasks(struct spdk_iscsi_conn *conn)
+{
+	struct spdk_iscsi_task *task, *tmp;
+
+	TAILQ_FOREACH_SAFE(task, &conn->queued_r2t_tasks, link, tmp) {
+		if (conn->pending_r2t < DEFAULT_MAXR2T) {
+			TAILQ_REMOVE(&conn->queued_r2t_tasks, task, link);
+			spdk_add_transfer_task(conn, task);
+		} else {
+			break;
+		}
+	}
+}
+
 void spdk_del_transfer_task(struct spdk_iscsi_conn *conn, uint32_t task_tag)
 {
 	struct spdk_iscsi_task *task;
-	int found = 0;
 	int i;
 
 	for (i = 0; i < conn->pending_r2t; i++) {
 		if (conn->outstanding_r2t_tasks[i]->tag == task_tag) {
 			task = conn->outstanding_r2t_tasks[i];
-			conn->outstanding_r2t_tasks[i] = NULL;
 			conn->data_out_cnt -= task->data_out_cnt;
-			found = 1;
-			break;
-		}
-	}
-
-	if (found) {
-		for (; i < conn->pending_r2t - 1; i++) {
-			conn->outstanding_r2t_tasks[i] = conn->outstanding_r2t_tasks[i + 1];
-		}
-
-		conn->pending_r2t--;
-		conn->outstanding_r2t_tasks[conn->pending_r2t] = NULL;
-	}
 
-	/*
-	 * A large write was just completed, so if there are additional large
-	 *  writes queued for R2Ts, start them now.  But first check to make
-	 *  sure each of the tasks will fit without the connection's allotment
-	 *  for total R2T tasks.
-	 */
-	while (!TAILQ_EMPTY(&conn->queued_r2t_tasks)) {
-		task = TAILQ_FIRST(&conn->queued_r2t_tasks);
-		if (conn->pending_r2t < DEFAULT_MAXR2T) {
-			TAILQ_REMOVE(&conn->queued_r2t_tasks, task, link);
-			spdk_add_transfer_task(conn, task);
-		} else {
+			conn->pending_r2t--;
+			for (; i < conn->pending_r2t; i++) {
+				conn->outstanding_r2t_tasks[i] = conn->outstanding_r2t_tasks[i + 1];
+			}
+			conn->outstanding_r2t_tasks[conn->pending_r2t] = NULL;
 			break;
 		}
 	}
+
+	spdk_start_queued_transfer_tasks(conn);
 }
 
 static void
-spdk_del_connection_queued_task(void *tailq, struct spdk_scsi_lun *lun)
+spdk_del_connection_queued_task(struct spdk_iscsi_conn *conn, void *tailq,
+				struct spdk_scsi_lun *lun)
 {
 	struct spdk_iscsi_task *task, *task_tmp;
 	/*
@@ -3676,6 +3572,10 @@ spdk_del_connection_queued_task(void *tailq, struct spdk_scsi_lun *lun)
 	TAILQ_FOREACH_SAFE(task, head, link, task_tmp) {
 		if (lun == NULL || lun == task->scsi.lun) {
 			TAILQ_REMOVE(head, task, link);
+			if (lun != NULL && spdk_scsi_lun_is_removing(lun)) {
+				spdk_scsi_task_process_null_lun(&task->scsi);
+				spdk_iscsi_task_response(conn, task);
+			}
 			spdk_iscsi_task_put(task);
 		}
 	}
@@ -3713,8 +3613,10 @@ void spdk_clear_all_transfer_task(struct spdk_iscsi_conn *conn,
 		}
 	}
 
-	spdk_del_connection_queued_task(&conn->active_r2t_tasks, lun);
-	spdk_del_connection_queued_task(&conn->queued_r2t_tasks, lun);
+	spdk_del_connection_queued_task(conn, &conn->active_r2t_tasks, lun);
+	spdk_del_connection_queued_task(conn, &conn->queued_r2t_tasks, lun);
+
+	spdk_start_queued_transfer_tasks(conn);
 }
 
 /* This function is used to handle the r2t snack */
@@ -3752,11 +3654,11 @@ spdk_iscsi_handle_r2t_snack(struct spdk_iscsi_conn *conn,
 		last_r2tsn = task->R2TSN;
 	}
 
-	for (i = beg_run; i < last_r2tsn; i++)
-		if (spdk_iscsi_send_r2t_recovery(conn, task, i, false) < 0)
-			SPDK_ERRLOG("The r2t_sn=%d of r2t_task=%p is "
-				    "not sent\n", i, task);
-
+	for (i = beg_run; i < last_r2tsn; i++) {
+		if (spdk_iscsi_send_r2t_recovery(conn, task, i, false) < 0) {
+			SPDK_ERRLOG("The r2t_sn=%d of r2t_task=%p is not sent\n", i, task);
+		}
+	}
 	return 0;
 }
 
@@ -3955,29 +3857,21 @@ spdk_iscsi_remove_r2t_pdu_from_snack_list(struct spdk_iscsi_conn *conn,
 		struct spdk_iscsi_task *task,
 		uint32_t r2t_sn)
 {
-	struct spdk_iscsi_pdu *pdu = NULL;
+	struct spdk_iscsi_pdu *pdu;
 	struct iscsi_bhs_r2t *r2t_header;
-	bool found_pdu = false;
 
 	TAILQ_FOREACH(pdu, &conn->snack_pdu_list, tailq) {
 		if (pdu->bhs.opcode == ISCSI_OP_R2T) {
 			r2t_header = (struct iscsi_bhs_r2t *)&pdu->bhs;
 			if (pdu->task == task &&
 			    from_be32(&r2t_header->r2t_sn) == r2t_sn) {
-				found_pdu = true;
-				break;
+				TAILQ_REMOVE(&conn->snack_pdu_list, pdu, tailq);
+				return pdu;
 			}
 		}
 	}
 
-	if (found_pdu) {
-		TAILQ_REMOVE(&conn->snack_pdu_list, pdu, tailq);
-	} else {
-		pdu = NULL;
-	}
-
-	return pdu;
-
+	return NULL;
 }
 
 /* This function is used re-send the r2t packet */
@@ -4076,18 +3970,15 @@ spdk_iscsi_op_snack(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 
 		task = spdk_get_scsi_task_from_itt(conn, task_tag,
 						   ISCSI_OP_SCSI_DATAIN);
-		if (task)
+		if (task) {
 			return spdk_iscsi_handle_recovery_datain(conn, task, pdu,
-					beg_run,
-					run_length,
-					task_tag);
-
+					beg_run, run_length, task_tag);
+		}
 		task = spdk_get_scsi_task_from_itt(conn, task_tag, ISCSI_OP_R2T);
-		if (task)
-			return spdk_iscsi_handle_r2t_snack(conn, task, pdu,
-							   beg_run, run_length,
-							   task_tag);
-
+		if (task) {
+			return spdk_iscsi_handle_r2t_snack(conn, task, pdu, beg_run,
+							   run_length, task_tag);
+		}
 		SPDK_ERRLOG("It is Neither datain nor r2t recovery request\n");
 		rc = -1;
 		break;
@@ -4229,8 +4120,7 @@ static int spdk_iscsi_op_data(struct spdk_iscsi_conn *conn,
 		task->acked_r2tsn++;
 		len = DMIN32(conn->sess->MaxBurstLength, (transfer_len -
 				task->next_r2t_offset));
-		rc = spdk_iscsi_send_r2t(conn, task,
-					 task->next_r2t_offset, len,
+		rc = spdk_iscsi_send_r2t(conn, task, task->next_r2t_offset, len,
 					 task->ttt, &task->R2TSN);
 		if (rc < 0) {
 			SPDK_ERRLOG("iscsi_send_r2t() failed\n");
@@ -4251,10 +4141,9 @@ static int spdk_iscsi_op_data(struct spdk_iscsi_conn *conn,
 
 send_r2t_recovery_return:
 	rc = spdk_iscsi_send_r2t_recovery(conn, task, task->acked_r2tsn, true);
-	if (rc < 0) {
-		goto reject_return;
+	if (rc == 0) {
+		return 0;
 	}
-	return rc;
 
 reject_return:
 	rc = spdk_iscsi_reject(conn, pdu, reject_reason);
@@ -4322,11 +4211,9 @@ void spdk_iscsi_send_nopin(struct spdk_iscsi_conn *conn)
 		return;
 	}
 
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "send NOPIN isid=%"PRIx64", tsih=%u, cid=%u\n",
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "send NOPIN isid=%"PRIx64", tsih=%u, cid=%u\n",
 		      conn->sess->isid, conn->sess->tsih, conn->cid);
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "StatSN=%u, ExpCmdSN=%u, MaxCmdSN=%u\n",
 		      conn->StatSN, conn->sess->ExpCmdSN,
 		      conn->sess->MaxCmdSN);
 
@@ -4432,8 +4319,7 @@ spdk_iscsi_execute(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 					    pdu->cmd_sn, sess->ExpCmdSN, sess->MaxCmdSN);
 
 				if (sess->ErrorRecoveryLevel >= 1) {
-					SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Skip the error in"
-						      " ERL 1 and 2\n");
+					SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Skip the error in ERL 1 and 2\n");
 				} else {
 					return SPDK_PDU_FATAL;
 				}
@@ -4443,8 +4329,7 @@ spdk_iscsi_execute(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 		SPDK_ERRLOG("CmdSN(%u) error ExpCmdSN=%u\n", pdu->cmd_sn, sess->ExpCmdSN);
 
 		if (sess->ErrorRecoveryLevel >= 1) {
-			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Skip the error in"
-				      " ERL 1 and 2\n");
+			SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "Skip the error in ERL 1 and 2\n");
 		} else if (opcode != ISCSI_OP_NOPOUT) {
 			/*
 			 * The Linux initiator does not send valid CmdSNs for
@@ -4457,8 +4342,7 @@ spdk_iscsi_execute(struct spdk_iscsi_conn *conn, struct spdk_iscsi_pdu *pdu)
 
 	ExpStatSN = from_be32(&reqh->exp_stat_sn);
 	if (SN32_GT(ExpStatSN, conn->StatSN)) {
-		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "StatSN(%u) advanced\n",
-			      ExpStatSN);
+		SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "StatSN(%u) advanced\n", ExpStatSN);
 		ExpStatSN = conn->StatSN;
 	}
 
@@ -4582,10 +4466,6 @@ spdk_create_iscsi_sess(struct spdk_iscsi_conn *conn,
 	/* configuration values */
 	pthread_mutex_lock(&g_spdk_iscsi.mutex);
 
-	if (target != NULL) {
-		pthread_mutex_lock(&target->mutex);
-	}
-
 	sess->MaxConnections = g_spdk_iscsi.MaxConnectionsPerSession;
 	sess->MaxOutstandingR2T = DEFAULT_MAXOUTSTANDINGR2T;
 
@@ -4599,21 +4479,16 @@ spdk_create_iscsi_sess(struct spdk_iscsi_conn *conn,
 	sess->DataSequenceInOrder = DEFAULT_DATASEQUENCEINORDER;
 	sess->ErrorRecoveryLevel = g_spdk_iscsi.ErrorRecoveryLevel;
 
-	if (target != NULL) {
-		pthread_mutex_unlock(&target->mutex);
-	}
-
 	pthread_mutex_unlock(&g_spdk_iscsi.mutex);
 
 	sess->tag = conn->portal->group->tag;
 
-	sess->conns = malloc(sizeof(*sess->conns) * sess->MaxConnections);
+	sess->conns = calloc(sess->MaxConnections, sizeof(*sess->conns));
 	if (!sess->conns) {
-		SPDK_ERRLOG("malloc() failed for connection array\n");
+		SPDK_ERRLOG("calloc() failed for connection array\n");
 		return -ENOMEM;
 	}
 
-	memset(sess->conns, 0, sizeof(*sess->conns) * sess->MaxConnections);
 	sess->connections = 0;
 
 	sess->conns[sess->connections] = conn;
@@ -4748,8 +4623,7 @@ spdk_append_iscsi_sess(struct spdk_iscsi_conn *conn,
 {
 	struct spdk_iscsi_sess *sess;
 
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI,
-		      "append session: init port name=%s, tsih=%u, cid=%u\n",
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "append session: init port name=%s, tsih=%u, cid=%u\n",
 		      initiator_port_name, tsih, cid);
 
 	sess = spdk_get_iscsi_sess_by_tsih(tsih);
diff --git a/lib/iscsi/iscsi.h b/lib/iscsi/iscsi.h
index cbd162187..beec9e5a3 100644
--- a/lib/iscsi/iscsi.h
+++ b/lib/iscsi/iscsi.h
@@ -40,7 +40,7 @@
 #include "spdk/bdev.h"
 #include "spdk/iscsi_spec.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 #include "iscsi/param.h"
 #include "iscsi/tgt_node.h"
@@ -346,8 +346,10 @@ enum spdk_error_codes {
 #define xstrdup(s) (s ? strdup(s) : (char *)NULL)
 
 extern struct spdk_iscsi_globals g_spdk_iscsi;
+extern struct spdk_iscsi_opts *g_spdk_iscsi_opts;
 
 struct spdk_iscsi_task;
+struct spdk_json_write_ctx;
 
 typedef void (*spdk_iscsi_init_cb)(void *cb_arg, int rc);
 
@@ -356,6 +358,12 @@ typedef void (*spdk_iscsi_fini_cb)(void *arg);
 void spdk_iscsi_fini(spdk_iscsi_fini_cb cb_fn, void *cb_arg);
 void spdk_shutdown_iscsi_conns_done(void);
 void spdk_iscsi_config_text(FILE *fp);
+void spdk_iscsi_config_json(struct spdk_json_write_ctx *w);
+
+struct spdk_iscsi_opts *spdk_iscsi_opts_alloc(void);
+void spdk_iscsi_opts_free(struct spdk_iscsi_opts *opts);
+struct spdk_iscsi_opts *spdk_iscsi_opts_copy(struct spdk_iscsi_opts *src);
+void spdk_iscsi_opts_info_json(struct spdk_json_write_ctx *w);
 
 void spdk_iscsi_send_nopin(struct spdk_iscsi_conn *conn);
 void spdk_iscsi_task_response(struct spdk_iscsi_conn *conn,
diff --git a/lib/iscsi/iscsi_rpc.c b/lib/iscsi/iscsi_rpc.c
index 9ec3e24a0..51ffa322c 100644
--- a/lib/iscsi/iscsi_rpc.c
+++ b/lib/iscsi/iscsi_rpc.c
@@ -44,40 +44,11 @@
 
 #include "spdk_internal/log.h"
 
-static void
-dump_initiator_group(struct spdk_json_write_ctx *w, struct spdk_iscsi_init_grp *ig)
-{
-	struct spdk_iscsi_initiator_name *iname;
-	struct spdk_iscsi_initiator_netmask *imask;
-
-	spdk_json_write_object_begin(w);
-
-	spdk_json_write_name(w, "initiators");
-	spdk_json_write_array_begin(w);
-	TAILQ_FOREACH(iname, &ig->initiator_head, tailq) {
-		spdk_json_write_string(w, iname->name);
-	}
-	spdk_json_write_array_end(w);
-
-	spdk_json_write_name(w, "tag");
-	spdk_json_write_int32(w, ig->tag);
-
-	spdk_json_write_name(w, "netmasks");
-	spdk_json_write_array_begin(w);
-	TAILQ_FOREACH(imask, &ig->netmask_head, tailq) {
-		spdk_json_write_string(w, imask->mask);
-	}
-	spdk_json_write_array_end(w);
-
-	spdk_json_write_object_end(w);
-}
-
 static void
 spdk_rpc_get_initiator_groups(struct spdk_jsonrpc_request *request,
 			      const struct spdk_json_val *params)
 {
 	struct spdk_json_write_ctx *w;
-	struct spdk_iscsi_init_grp *ig;
 
 	if (params != NULL) {
 		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
@@ -91,16 +62,12 @@ spdk_rpc_get_initiator_groups(struct spdk_jsonrpc_request *request,
 	}
 
 	spdk_json_write_array_begin(w);
-
-	TAILQ_FOREACH(ig, &g_spdk_iscsi.ig_head, tailq) {
-		dump_initiator_group(w, ig);
-	}
-
+	spdk_iscsi_init_grps_info_json(w);
 	spdk_json_write_array_end(w);
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_initiator_groups", spdk_rpc_get_initiator_groups)
+SPDK_RPC_REGISTER("get_initiator_groups", spdk_rpc_get_initiator_groups, SPDK_RPC_RUNTIME)
 
 struct rpc_initiator_list {
 	size_t num_initiators;
@@ -211,7 +178,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_initiator_group(&req);
 }
-SPDK_RPC_REGISTER("add_initiator_group", spdk_rpc_add_initiator_group)
+SPDK_RPC_REGISTER("add_initiator_group", spdk_rpc_add_initiator_group, SPDK_RPC_RUNTIME)
 
 static const struct spdk_json_object_decoder rpc_add_or_delete_initiators_decoders[] = {
 	{"tag", offsetof(struct rpc_initiator_group, tag), spdk_json_decode_int32},
@@ -256,7 +223,8 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_initiator_group(&req);
 }
-SPDK_RPC_REGISTER("add_initiators_to_initiator_group", spdk_rpc_add_initiators_to_initiator_group)
+SPDK_RPC_REGISTER("add_initiators_to_initiator_group",
+		  spdk_rpc_add_initiators_to_initiator_group, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_delete_initiators_from_initiator_group(struct spdk_jsonrpc_request *request,
@@ -296,7 +264,7 @@ invalid:
 	free_rpc_initiator_group(&req);
 }
 SPDK_RPC_REGISTER("delete_initiators_from_initiator_group",
-		  spdk_rpc_delete_initiators_from_initiator_group)
+		  spdk_rpc_delete_initiators_from_initiator_group, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_initiator_group {
 	int32_t tag;
@@ -340,85 +308,13 @@ spdk_rpc_delete_initiator_group(struct spdk_jsonrpc_request *request,
 invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 }
-SPDK_RPC_REGISTER("delete_initiator_group", spdk_rpc_delete_initiator_group)
-
-static void
-dump_target_node(struct spdk_json_write_ctx *w, struct spdk_iscsi_tgt_node *tgtnode)
-{
-	struct spdk_iscsi_pg_map *pg_map;
-	struct spdk_iscsi_ig_map *ig_map;
-	int i;
-
-	spdk_json_write_object_begin(w);
-
-	spdk_json_write_name(w, "name");
-	spdk_json_write_string(w, tgtnode->name);
-
-	if (tgtnode->alias) {
-		spdk_json_write_name(w, "alias_name");
-		spdk_json_write_string(w, tgtnode->alias);
-	}
-
-	spdk_json_write_name(w, "pg_ig_maps");
-	spdk_json_write_array_begin(w);
-	TAILQ_FOREACH(pg_map, &tgtnode->pg_map_head, tailq) {
-		TAILQ_FOREACH(ig_map, &pg_map->ig_map_head, tailq) {
-			spdk_json_write_object_begin(w);
-			spdk_json_write_name(w, "pg_tag");
-			spdk_json_write_int32(w, pg_map->pg->tag);
-			spdk_json_write_name(w, "ig_tag");
-			spdk_json_write_int32(w, ig_map->ig->tag);
-			spdk_json_write_object_end(w);
-		}
-	}
-	spdk_json_write_array_end(w);
-
-	spdk_json_write_name(w, "luns");
-	spdk_json_write_array_begin(w);
-	for (i = 0; i < SPDK_SCSI_DEV_MAX_LUN; i++) {
-		struct spdk_scsi_lun *lun = spdk_scsi_dev_get_lun(tgtnode->dev, i);
-
-		if (lun) {
-			spdk_json_write_object_begin(w);
-			spdk_json_write_name(w, "bdev_name");
-			spdk_json_write_string(w, spdk_scsi_lun_get_bdev_name(lun));
-			spdk_json_write_name(w, "id");
-			spdk_json_write_int32(w, spdk_scsi_lun_get_id(lun));
-			spdk_json_write_object_end(w);
-		}
-	}
-	spdk_json_write_array_end(w);
-
-	spdk_json_write_name(w, "queue_depth");
-	spdk_json_write_int32(w, tgtnode->queue_depth);
-
-	spdk_json_write_name(w, "disable_chap");
-	spdk_json_write_bool(w, tgtnode->disable_chap);
-
-	spdk_json_write_name(w, "require_chap");
-	spdk_json_write_bool(w, tgtnode->require_chap);
-
-	spdk_json_write_name(w, "mutual_chap");
-	spdk_json_write_bool(w, tgtnode->mutual_chap);
-
-	spdk_json_write_name(w, "chap_group");
-	spdk_json_write_int32(w, tgtnode->chap_group);
-
-	spdk_json_write_name(w, "header_digest");
-	spdk_json_write_bool(w, tgtnode->header_digest);
-
-	spdk_json_write_name(w, "data_digest");
-	spdk_json_write_bool(w, tgtnode->data_digest);
-
-	spdk_json_write_object_end(w);
-}
+SPDK_RPC_REGISTER("delete_initiator_group", spdk_rpc_delete_initiator_group, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_target_nodes(struct spdk_jsonrpc_request *request,
 			  const struct spdk_json_val *params)
 {
 	struct spdk_json_write_ctx *w;
-	struct spdk_iscsi_tgt_node *tgtnode;
 
 	if (params != NULL) {
 		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
@@ -432,16 +328,12 @@ spdk_rpc_get_target_nodes(struct spdk_jsonrpc_request *request,
 	}
 
 	spdk_json_write_array_begin(w);
-
-	TAILQ_FOREACH(tgtnode, &g_spdk_iscsi.target_head, tailq) {
-		dump_target_node(w, tgtnode);
-	}
-
+	spdk_iscsi_tgt_nodes_info_json(w);
 	spdk_json_write_array_end(w);
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_target_nodes", spdk_rpc_get_target_nodes)
+SPDK_RPC_REGISTER("get_target_nodes", spdk_rpc_get_target_nodes, SPDK_RPC_RUNTIME)
 
 struct rpc_pg_ig_map {
 	int32_t pg_tag;
@@ -631,7 +523,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_target_node(&req);
 }
-SPDK_RPC_REGISTER("construct_target_node", spdk_rpc_construct_target_node)
+SPDK_RPC_REGISTER("construct_target_node", spdk_rpc_construct_target_node, SPDK_RPC_RUNTIME)
 
 struct rpc_tgt_node_pg_ig_maps {
 	char *name;
@@ -693,7 +585,7 @@ invalid:
 					 "Invalid parameters");
 	free(req.name);
 }
-SPDK_RPC_REGISTER("add_pg_ig_maps", spdk_rpc_add_pg_ig_maps)
+SPDK_RPC_REGISTER("add_pg_ig_maps", spdk_rpc_add_pg_ig_maps, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_delete_pg_ig_maps(struct spdk_jsonrpc_request *request,
@@ -745,7 +637,7 @@ invalid:
 					 "Invalid parameters");
 	free(req.name);
 }
-SPDK_RPC_REGISTER("delete_pg_ig_maps", spdk_rpc_delete_pg_ig_maps)
+SPDK_RPC_REGISTER("delete_pg_ig_maps", spdk_rpc_delete_pg_ig_maps, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_target_node {
 	char *name;
@@ -800,41 +692,13 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_delete_target_node(&req);
 }
-SPDK_RPC_REGISTER("delete_target_node", spdk_rpc_delete_target_node)
-
-static void
-dump_portal_group(struct spdk_json_write_ctx *w, struct spdk_iscsi_portal_grp *pg)
-{
-	struct spdk_iscsi_portal *portal;
-
-	spdk_json_write_object_begin(w);
-
-	spdk_json_write_name(w, "portals");
-	spdk_json_write_array_begin(w);
-	TAILQ_FOREACH(portal, &pg->head, per_pg_tailq) {
-		spdk_json_write_object_begin(w);
-		spdk_json_write_name(w, "host");
-		spdk_json_write_string(w, portal->host);
-		spdk_json_write_name(w, "port");
-		spdk_json_write_string(w, portal->port);
-		spdk_json_write_name(w, "cpumask");
-		spdk_json_write_string_fmt(w, "0x%s", spdk_cpuset_fmt(portal->cpumask));
-		spdk_json_write_object_end(w);
-	}
-	spdk_json_write_array_end(w);
-
-	spdk_json_write_name(w, "tag");
-	spdk_json_write_int32(w, pg->tag);
-
-	spdk_json_write_object_end(w);
-}
+SPDK_RPC_REGISTER("delete_target_node", spdk_rpc_delete_target_node, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_portal_groups(struct spdk_jsonrpc_request *request,
 			   const struct spdk_json_val *params)
 {
 	struct spdk_json_write_ctx *w;
-	struct spdk_iscsi_portal_grp *pg;
 
 	if (params != NULL) {
 		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
@@ -848,16 +712,12 @@ spdk_rpc_get_portal_groups(struct spdk_jsonrpc_request *request,
 	}
 
 	spdk_json_write_array_begin(w);
-
-	TAILQ_FOREACH(pg, &g_spdk_iscsi.pg_head, tailq) {
-		dump_portal_group(w, pg);
-	}
-
+	spdk_iscsi_portal_grps_info_json(w);
 	spdk_json_write_array_end(w);
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_portal_groups", spdk_rpc_get_portal_groups)
+SPDK_RPC_REGISTER("get_portal_groups", spdk_rpc_get_portal_groups, SPDK_RPC_RUNTIME)
 
 struct rpc_portal {
 	char *host;
@@ -991,7 +851,7 @@ out:
 	}
 	free_rpc_portal_group(&req);
 }
-SPDK_RPC_REGISTER("add_portal_group", spdk_rpc_add_portal_group)
+SPDK_RPC_REGISTER("add_portal_group", spdk_rpc_add_portal_group, SPDK_RPC_RUNTIME)
 
 struct rpc_delete_portal_group {
 	int32_t tag;
@@ -1036,7 +896,7 @@ spdk_rpc_delete_portal_group(struct spdk_jsonrpc_request *request,
 invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 }
-SPDK_RPC_REGISTER("delete_portal_group", spdk_rpc_delete_portal_group)
+SPDK_RPC_REGISTER("delete_portal_group", spdk_rpc_delete_portal_group, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_iscsi_connections(struct spdk_jsonrpc_request *request,
@@ -1107,7 +967,7 @@ spdk_rpc_get_iscsi_connections(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_iscsi_connections", spdk_rpc_get_iscsi_connections)
+SPDK_RPC_REGISTER("get_iscsi_connections", spdk_rpc_get_iscsi_connections, SPDK_RPC_RUNTIME)
 
 struct rpc_target_lun {
 	char *name;
@@ -1173,7 +1033,7 @@ invalid:
 					 "Invalid parameters");
 	free_rpc_target_lun(&req);
 }
-SPDK_RPC_REGISTER("target_node_add_lun", spdk_rpc_target_node_add_lun)
+SPDK_RPC_REGISTER("target_node_add_lun", spdk_rpc_target_node_add_lun, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_iscsi_global_params(struct spdk_jsonrpc_request *request,
@@ -1192,61 +1052,8 @@ spdk_rpc_get_iscsi_global_params(struct spdk_jsonrpc_request *request,
 		return;
 	}
 
-	spdk_json_write_object_begin(w);
-
-	spdk_json_write_name(w, "auth_file");
-	spdk_json_write_string(w, g_spdk_iscsi.authfile);
-
-	spdk_json_write_name(w, "node_base");
-	spdk_json_write_string(w, g_spdk_iscsi.nodebase);
-
-	spdk_json_write_name(w, "max_sessions");
-	spdk_json_write_uint32(w, g_spdk_iscsi.MaxSessions);
-
-	spdk_json_write_name(w, "max_connections_per_session");
-	spdk_json_write_uint32(w, g_spdk_iscsi.MaxConnectionsPerSession);
-
-	spdk_json_write_name(w, "max_queue_depth");
-	spdk_json_write_uint32(w, g_spdk_iscsi.MaxQueueDepth);
-
-	spdk_json_write_name(w, "default_time2wait");
-	spdk_json_write_uint32(w, g_spdk_iscsi.DefaultTime2Wait);
-
-	spdk_json_write_name(w, "default_time2retain");
-	spdk_json_write_uint32(w, g_spdk_iscsi.DefaultTime2Retain);
-
-	spdk_json_write_name(w, "immediate_data");
-	spdk_json_write_bool(w, g_spdk_iscsi.ImmediateData);
-
-	spdk_json_write_name(w, "allow_duplicated_isid");
-	spdk_json_write_bool(w, g_spdk_iscsi.AllowDuplicateIsid);
-
-	spdk_json_write_name(w, "error_recovery_level");
-	spdk_json_write_uint32(w, g_spdk_iscsi.ErrorRecoveryLevel);
-
-	spdk_json_write_name(w, "timeout");
-	spdk_json_write_int32(w, g_spdk_iscsi.timeout);
-
-	spdk_json_write_name(w, "nop_in_interval");
-	spdk_json_write_int32(w, g_spdk_iscsi.nopininterval);
-
-	spdk_json_write_name(w, "no_discovery_auth");
-	spdk_json_write_bool(w, g_spdk_iscsi.no_discovery_auth);
-
-	spdk_json_write_name(w, "req_discovery_auth");
-	spdk_json_write_bool(w, g_spdk_iscsi.req_discovery_auth);
-
-	spdk_json_write_name(w, "req_discovery_auth_mutual");
-	spdk_json_write_bool(w, g_spdk_iscsi.req_discovery_auth_mutual);
-
-	spdk_json_write_name(w, "discovery_auth_group");
-	spdk_json_write_int32(w, g_spdk_iscsi.discovery_auth_group);
-
-	spdk_json_write_name(w, "min_connections_per_core");
-	spdk_json_write_int32(w, spdk_iscsi_conn_get_min_per_core());
-
-	spdk_json_write_object_end(w);
+	spdk_iscsi_opts_info_json(w);
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_iscsi_global_params", spdk_rpc_get_iscsi_global_params)
+SPDK_RPC_REGISTER("get_iscsi_global_params", spdk_rpc_get_iscsi_global_params, SPDK_RPC_RUNTIME)
diff --git a/lib/iscsi/iscsi_subsystem.c b/lib/iscsi/iscsi_subsystem.c
index 8b8e70231..3f19469a1 100644
--- a/lib/iscsi/iscsi_subsystem.c
+++ b/lib/iscsi/iscsi_subsystem.c
@@ -47,6 +47,8 @@
 #include "spdk_internal/event.h"
 #include "spdk_internal/log.h"
 
+struct spdk_iscsi_opts *g_spdk_iscsi_opts = NULL;
+
 static spdk_iscsi_init_cb g_init_cb_fn = NULL;
 static void *g_init_cb_arg = NULL;
 
@@ -84,7 +86,7 @@ static void *g_fini_cb_arg;
 "\n"
 
 static void
-spdk_iscsi_config_dump_section(FILE *fp)
+spdk_iscsi_globals_config_text(FILE *fp)
 {
 	const char *authmethod = "None";
 	char authgroup[32] = "None";
@@ -116,203 +118,6 @@ spdk_iscsi_config_dump_section(FILE *fp)
 		g_spdk_iscsi.ErrorRecoveryLevel);
 }
 
-
-/* Portal groups */
-static const char *portal_group_section = \
-		"\n"
-		"# Users must change the PortalGroup section(s) to match the IP addresses\n"
-		"#  for their environment.\n"
-		"# PortalGroup sections define which network portals the iSCSI target\n"
-		"# will use to listen for incoming connections.  These are also used to\n"
-		"#  determine which targets are accessible over each portal group.\n"
-		"# Up to 1024 Portal directives are allowed.  These define the network\n"
-		"#  portals of the portal group. The user must specify a IP address\n"
-		"#  for each network portal, and may optionally specify a port and\n"
-		"#  a cpumask. If the port is omitted, 3260 will be used. Cpumask will\n"
-		"#  be used to set the processor affinity of the iSCSI connection\n"
-		"#  through the portal.  If the cpumask is omitted, cpumask will be\n"
-		"#  set to all available processors.\n"
-		"#  Syntax:\n"
-		"#    Portal <Name> <IP address>[:<port>[@<cpumask>]]\n";
-
-#define PORTAL_GROUP_TMPL \
-"[PortalGroup%d]\n" \
-"  Comment \"Portal%d\"\n"
-
-#define PORTAL_TMPL \
-"  Portal DA1 %s:%s@0x%s\n"
-
-static void
-spdk_iscsi_config_dump_portal_groups(FILE *fp)
-{
-	struct spdk_iscsi_portal *p = NULL;
-	struct spdk_iscsi_portal_grp *pg = NULL;
-
-	/* Create portal group section */
-	fprintf(fp, "%s", portal_group_section);
-
-	/* Dump portal groups */
-	TAILQ_FOREACH(pg, &g_spdk_iscsi.pg_head, tailq) {
-		if (NULL == pg) { continue; }
-		fprintf(fp, PORTAL_GROUP_TMPL, pg->tag, pg->tag);
-		/* Dump portals */
-		TAILQ_FOREACH(p, &pg->head, per_pg_tailq) {
-			if (NULL == p) { continue; }
-			fprintf(fp, PORTAL_TMPL, p->host, p->port,
-				spdk_cpuset_fmt(p->cpumask));
-		}
-	}
-}
-
-/* Initiator Groups */
-static const char *initiator_group_section = \
-		"\n"
-		"# Users must change the InitiatorGroup section(s) to match the IP\n"
-		"#  addresses and initiator configuration in their environment.\n"
-		"# Netmask can be used to specify a single IP address or a range of IP addresses\n"
-		"#  Netmask 192.168.1.20   <== single IP address\n"
-		"#  Netmask 192.168.1.0/24 <== IP range 192.168.1.*\n";
-
-#define INITIATOR_GROUP_TMPL \
-"[InitiatorGroup%d]\n" \
-"  Comment \"Initiator Group%d\"\n"
-
-#define INITIATOR_TMPL \
-"  InitiatorName "
-
-#define NETMASK_TMPL \
-"  Netmask "
-
-static void
-spdk_iscsi_config_dump_initiator_groups(FILE *fp)
-{
-	struct spdk_iscsi_init_grp *ig;
-	struct spdk_iscsi_initiator_name *iname;
-	struct spdk_iscsi_initiator_netmask *imask;
-
-	/* Create initiator group section */
-	fprintf(fp, "%s", initiator_group_section);
-
-	/* Dump initiator groups */
-	TAILQ_FOREACH(ig, &g_spdk_iscsi.ig_head, tailq) {
-		if (NULL == ig) { continue; }
-		fprintf(fp, INITIATOR_GROUP_TMPL, ig->tag, ig->tag);
-
-		/* Dump initiators */
-		fprintf(fp, INITIATOR_TMPL);
-		TAILQ_FOREACH(iname, &ig->initiator_head, tailq) {
-			fprintf(fp, "%s ", iname->name);
-		}
-		fprintf(fp, "\n");
-
-		/* Dump netmasks */
-		fprintf(fp, NETMASK_TMPL);
-		TAILQ_FOREACH(imask, &ig->netmask_head, tailq) {
-			fprintf(fp, "%s ", imask->mask);
-		}
-		fprintf(fp, "\n");
-	}
-}
-
-/* Target nodes */
-static const char *target_nodes_section = \
-		"\n"
-		"# Users should change the TargetNode section(s) below to match the\n"
-		"#  desired iSCSI target node configuration.\n"
-		"# TargetName, Mapping, LUN0 are minimum required\n";
-
-#define TARGET_NODE_TMPL \
-"[TargetNode%d]\n" \
-"  Comment \"Target%d\"\n" \
-"  TargetName %s\n" \
-"  TargetAlias \"%s\"\n"
-
-#define TARGET_NODE_PGIG_MAPPING_TMPL \
-"  Mapping PortalGroup%d InitiatorGroup%d\n"
-
-#define TARGET_NODE_AUTH_TMPL \
-"  AuthMethod %s\n" \
-"  AuthGroup %s\n" \
-"  UseDigest %s\n"
-
-#define TARGET_NODE_QD_TMPL \
-"  QueueDepth %d\n\n"
-
-#define TARGET_NODE_LUN_TMPL \
-"  LUN%d %s\n"
-
-static void
-spdk_iscsi_config_dump_target_nodes(FILE *fp)
-{
-	int l = 0;
-	struct spdk_scsi_dev *dev = NULL;
-	struct spdk_iscsi_tgt_node *target = NULL;
-	struct spdk_iscsi_pg_map *pg_map;
-	struct spdk_iscsi_ig_map *ig_map;
-
-	/* Create target nodes section */
-	fprintf(fp, "%s", target_nodes_section);
-
-	TAILQ_FOREACH(target, &g_spdk_iscsi.target_head, tailq) {
-		int idx;
-		const char *authmethod = "None";
-		char authgroup[32] = "None";
-		const char *usedigest = "Auto";
-
-		dev = target->dev;
-		if (NULL == dev) { continue; }
-
-		idx = target->num;
-		fprintf(fp, TARGET_NODE_TMPL, idx, idx, target->name, spdk_scsi_dev_get_name(dev));
-
-		TAILQ_FOREACH(pg_map, &target->pg_map_head, tailq) {
-			TAILQ_FOREACH(ig_map, &pg_map->ig_map_head, tailq) {
-				fprintf(fp, TARGET_NODE_PGIG_MAPPING_TMPL,
-					pg_map->pg->tag,
-					ig_map->ig->tag);
-			}
-		}
-
-		if (target->disable_chap) {
-			authmethod = "None";
-		} else if (!target->require_chap) {
-			authmethod = "Auto";
-		} else if (target->mutual_chap) {
-			authmethod = "CHAP Mutual";
-		} else {
-			authmethod = "CHAP";
-		}
-
-		if (target->chap_group > 0) {
-			snprintf(authgroup, sizeof(authgroup), "AuthGroup%d", target->chap_group);
-		}
-
-		if (target->header_digest) {
-			usedigest = "Header";
-		} else if (target->data_digest) {
-			usedigest = "Data";
-		}
-
-		fprintf(fp, TARGET_NODE_AUTH_TMPL,
-			authmethod, authgroup, usedigest);
-
-		for (l = 0; l < SPDK_SCSI_DEV_MAX_LUN; l++) {
-			struct spdk_scsi_lun *lun = spdk_scsi_dev_get_lun(dev, l);
-
-			if (!lun) {
-				continue;
-			}
-
-			fprintf(fp, TARGET_NODE_LUN_TMPL,
-				spdk_scsi_lun_get_id(lun),
-				spdk_scsi_lun_get_bdev_name(lun));
-		}
-
-		fprintf(fp, TARGET_NODE_QD_TMPL,
-			target->queue_depth);
-	}
-}
-
 static void
 spdk_mobj_ctor(struct spdk_mempool *mp, __attribute__((unused)) void *arg,
 	       void *_m, __attribute__((unused)) unsigned i)
@@ -466,7 +271,7 @@ spdk_iscsi_check_pools(void)
 	spdk_iscsi_check_pool(iscsi->session_pool, SESSION_POOL_SIZE(iscsi));
 	spdk_iscsi_check_pool(iscsi->pdu_immediate_data_pool, IMMEDIATE_DATA_POOL_SIZE(iscsi));
 	spdk_iscsi_check_pool(iscsi->pdu_data_out_pool, DATA_OUT_POOL_SIZE(iscsi));
-	/* TODO: check the task_pool on exit */
+	spdk_iscsi_check_pool(iscsi->task_pool, DEFAULT_TASK_POOL_SIZE);
 }
 
 static void
@@ -589,19 +394,86 @@ spdk_iscsi_opts_init(struct spdk_iscsi_opts *opts)
 	opts->req_discovery_auth = false;
 	opts->req_discovery_auth_mutual = false;
 	opts->discovery_auth_group = 0;
-	opts->authfile = strdup(SPDK_ISCSI_DEFAULT_AUTHFILE);
-	opts->nodebase = strdup(SPDK_ISCSI_DEFAULT_NODEBASE);
+	opts->authfile = NULL;
+	opts->nodebase = NULL;
 	opts->min_connections_per_core = DEFAULT_CONNECTIONS_PER_LCORE;
 }
 
-static void
+struct spdk_iscsi_opts *
+spdk_iscsi_opts_alloc(void)
+{
+	struct spdk_iscsi_opts *opts;
+
+	opts = calloc(1, sizeof(*opts));
+	if (!opts) {
+		SPDK_ERRLOG("calloc() failed for iscsi options\n");
+		return NULL;
+	}
+
+	spdk_iscsi_opts_init(opts);
+
+	return opts;
+}
+
+void
 spdk_iscsi_opts_free(struct spdk_iscsi_opts *opts)
 {
 	free(opts->authfile);
 	free(opts->nodebase);
+	free(opts);
 }
 
-static void
+/* Deep copy of spdk_iscsi_opts */
+struct spdk_iscsi_opts *
+spdk_iscsi_opts_copy(struct spdk_iscsi_opts *src)
+{
+	struct spdk_iscsi_opts *dst;
+
+	dst = calloc(1, sizeof(*dst));
+	if (!dst) {
+		SPDK_ERRLOG("calloc() failed for iscsi options\n");
+		return NULL;
+	}
+
+	if (src->authfile) {
+		dst->authfile = strdup(src->authfile);
+		if (!dst->authfile) {
+			free(dst);
+			SPDK_ERRLOG("failed to strdup for auth file %s\n", src->authfile);
+			return NULL;
+		}
+	}
+
+	if (src->nodebase) {
+		dst->nodebase = strdup(src->nodebase);
+		if (!dst->nodebase) {
+			free(dst->authfile);
+			free(dst);
+			SPDK_ERRLOG("failed to strdup for nodebase %s\n", src->nodebase);
+			return NULL;
+		}
+	}
+
+	dst->MaxSessions = src->MaxSessions;
+	dst->MaxConnectionsPerSession = src->MaxConnectionsPerSession;
+	dst->MaxQueueDepth = src->MaxQueueDepth;
+	dst->DefaultTime2Wait = src->DefaultTime2Wait;
+	dst->DefaultTime2Retain = src->DefaultTime2Retain;
+	dst->ImmediateData = src->ImmediateData;
+	dst->AllowDuplicateIsid = src->AllowDuplicateIsid;
+	dst->ErrorRecoveryLevel = src->ErrorRecoveryLevel;
+	dst->timeout = src->timeout;
+	dst->nopininterval = src->nopininterval;
+	dst->no_discovery_auth = src->no_discovery_auth;
+	dst->req_discovery_auth = src->req_discovery_auth;
+	dst->req_discovery_auth_mutual = src->req_discovery_auth;
+	dst->discovery_auth_group = src->discovery_auth_group;
+	dst->min_connections_per_core = src->min_connections_per_core;
+
+	return dst;
+}
+
+static int
 spdk_iscsi_read_config_file_params(struct spdk_conf_section *sp,
 				   struct spdk_iscsi_opts *opts)
 {
@@ -625,65 +497,45 @@ spdk_iscsi_read_config_file_params(struct spdk_conf_section *sp,
 
 	val = spdk_conf_section_get_val(sp, "AuthFile");
 	if (val != NULL) {
-		free(opts->authfile);
 		opts->authfile = strdup(val);
+		if (!opts->authfile) {
+			SPDK_ERRLOG("strdup() failed for AuthFile\n");
+			return -ENOMEM;
+		}
 	}
 
 	val = spdk_conf_section_get_val(sp, "NodeBase");
 	if (val != NULL) {
-		free(opts->nodebase);
 		opts->nodebase = strdup(val);
+		if (!opts->nodebase) {
+			free(opts->authfile);
+			SPDK_ERRLOG("strdup() failed for NodeBase\n");
+			return -ENOMEM;
+		}
 	}
 
 	MaxSessions = spdk_conf_section_get_intval(sp, "MaxSessions");
 	if (MaxSessions >= 0) {
-		if (MaxSessions == 0) {
-			SPDK_ERRLOG("MaxSessions == 0 invalid, ignoring\n");
-		} else if (MaxSessions > 65535) {
-			SPDK_ERRLOG("MaxSessions == %d invalid, ignoring\n", MaxSessions);
-		} else {
-			opts->MaxSessions = MaxSessions;
-		}
+		opts->MaxSessions = MaxSessions;
 	}
 
 	MaxConnectionsPerSession = spdk_conf_section_get_intval(sp, "MaxConnectionsPerSession");
 	if (MaxConnectionsPerSession >= 0) {
-		if (MaxConnectionsPerSession == 0) {
-			SPDK_ERRLOG("MaxConnectionsPerSession == 0 invalid, ignoring\n");
-		} else if (MaxConnectionsPerSession > 65535) {
-			SPDK_ERRLOG("MaxConnectionsPerSession == %d invalid, ignoring\n",
-				    MaxConnectionsPerSession);
-		} else {
-			opts->MaxConnectionsPerSession = MaxConnectionsPerSession;
-		}
+		opts->MaxConnectionsPerSession = MaxConnectionsPerSession;
 	}
 
 	MaxQueueDepth = spdk_conf_section_get_intval(sp, "MaxQueueDepth");
 	if (MaxQueueDepth >= 0) {
-		if (MaxQueueDepth == 0) {
-			SPDK_ERRLOG("MaxQueueDepth == 0 invalid, ignoring\n");
-		} else if (MaxQueueDepth > 256) {
-			SPDK_ERRLOG("MaxQueueDepth == %d invalid, ignoring\n", MaxQueueDepth);
-		} else {
-			opts->MaxQueueDepth = MaxQueueDepth;
-		}
+		opts->MaxQueueDepth = MaxQueueDepth;
 	}
 
 	DefaultTime2Wait = spdk_conf_section_get_intval(sp, "DefaultTime2Wait");
 	if (DefaultTime2Wait >= 0) {
-		if (DefaultTime2Wait > 3600) {
-			SPDK_ERRLOG("DefaultTime2Wait == %d invalid, ignoring\n", DefaultTime2Wait);
-		} else {
-			opts->DefaultTime2Wait = DefaultTime2Wait;
-		}
+		opts->DefaultTime2Wait = DefaultTime2Wait;
 	}
 	DefaultTime2Retain = spdk_conf_section_get_intval(sp, "DefaultTime2Retain");
 	if (DefaultTime2Retain >= 0) {
-		if (DefaultTime2Retain > 3600) {
-			SPDK_ERRLOG("DefaultTime2Retain == %d invalid, ignoring\n", DefaultTime2Retain);
-		} else {
-			opts->DefaultTime2Retain = DefaultTime2Retain;
-		}
+		opts->DefaultTime2Retain = DefaultTime2Retain;
 	}
 	opts->ImmediateData = spdk_conf_section_get_boolval(sp, "ImmediateData",
 			      opts->ImmediateData);
@@ -697,12 +549,7 @@ spdk_iscsi_read_config_file_params(struct spdk_conf_section *sp,
 
 	ErrorRecoveryLevel = spdk_conf_section_get_intval(sp, "ErrorRecoveryLevel");
 	if (ErrorRecoveryLevel >= 0) {
-		if (ErrorRecoveryLevel > 2) {
-			SPDK_ERRLOG("ErrorRecoveryLevel %d not supported, keeping existing %d\n",
-				    ErrorRecoveryLevel, opts->ErrorRecoveryLevel);
-		} else {
-			opts->ErrorRecoveryLevel = ErrorRecoveryLevel;
-		}
+		opts->ErrorRecoveryLevel = ErrorRecoveryLevel;
 	}
 	timeout = spdk_conf_section_get_intval(sp, "Timeout");
 	if (timeout >= 0) {
@@ -710,11 +557,7 @@ spdk_iscsi_read_config_file_params(struct spdk_conf_section *sp,
 	}
 	nopininterval = spdk_conf_section_get_intval(sp, "NopInInterval");
 	if (nopininterval >= 0) {
-		if (nopininterval > MAX_NOPININTERVAL) {
-			SPDK_ERRLOG("NopInInterval == %d invalid, ignoring\n", nopininterval);
-		} else {
-			opts->nopininterval = nopininterval;
-		}
+		opts->nopininterval = nopininterval;
 	}
 	val = spdk_conf_section_get_val(sp, "DiscoveryAuthMethod");
 	if (val != NULL) {
@@ -758,20 +601,72 @@ spdk_iscsi_read_config_file_params(struct spdk_conf_section *sp,
 	if (min_conn_per_core >= 0) {
 		opts->min_connections_per_core = min_conn_per_core;
 	}
+
+	return 0;
 }
 
 static int
-spdk_iscsi_initialize_iscsi_globals(struct spdk_iscsi_opts *opts)
+spdk_iscsi_opts_verify(struct spdk_iscsi_opts *opts)
 {
-	int rc;
-
 	if (!opts->authfile) {
-		SPDK_ERRLOG("opts->authfile is NULL\n");
-		return -EINVAL;
+		opts->authfile = strdup(SPDK_ISCSI_DEFAULT_AUTHFILE);
+		if (opts->authfile == NULL) {
+			SPDK_ERRLOG("strdup() failed for default authfile\n");
+			return -ENOMEM;
+		}
 	}
 
 	if (!opts->nodebase) {
-		SPDK_ERRLOG("opts->nodebase is NULL\n");
+		opts->nodebase = strdup(SPDK_ISCSI_DEFAULT_NODEBASE);
+		if (opts->nodebase == NULL) {
+			SPDK_ERRLOG("strdup() failed for default nodebase\n");
+			return -ENOMEM;
+		}
+	}
+
+	if (opts->MaxSessions == 0 || opts->MaxSessions > 65535) {
+		SPDK_ERRLOG("%d is invalid. MaxSessions must be more than 0 and no more than 65535\n",
+			    opts->MaxSessions);
+		return -EINVAL;
+	}
+
+	if (opts->MaxConnectionsPerSession == 0 || opts->MaxConnectionsPerSession > 65535) {
+		SPDK_ERRLOG("%d is invalid. MaxConnectionsPerSession must be more than 0 and no more than 65535\n",
+			    opts->MaxConnectionsPerSession);
+		return -EINVAL;
+	}
+
+	if (opts->MaxQueueDepth == 0 || opts->MaxQueueDepth > 256) {
+		SPDK_ERRLOG("%d is invalid. MaxQueueDepth must be more than 0 and no more than 256\n",
+			    opts->MaxQueueDepth);
+		return -EINVAL;
+	}
+
+	if (opts->DefaultTime2Wait > 3600) {
+		SPDK_ERRLOG("%d is invalid. DefaultTime2Wait must be no more than 3600\n",
+			    opts->DefaultTime2Wait);
+		return -EINVAL;
+	}
+
+	if (opts->DefaultTime2Retain > 3600) {
+		SPDK_ERRLOG("%d is invalid. DefaultTime2Retain must be no more than 3600\n",
+			    opts->DefaultTime2Retain);
+		return -EINVAL;
+	}
+
+	if (opts->ErrorRecoveryLevel > 2) {
+		SPDK_ERRLOG("ErrorRecoveryLevel %d is not supported.\n", opts->ErrorRecoveryLevel);
+		return -EINVAL;
+	}
+
+	if (opts->timeout < 0) {
+		SPDK_ERRLOG("%d is invalid. timeout must not be less than 0\n", opts->timeout);
+		return -EINVAL;
+	}
+
+	if (opts->nopininterval < 0 || opts->nopininterval > MAX_NOPININTERVAL) {
+		SPDK_ERRLOG("%d is invalid. nopinterval must be between 0 and %d\n",
+			    opts->nopininterval, MAX_NOPININTERVAL);
 		return -EINVAL;
 	}
 
@@ -782,6 +677,50 @@ spdk_iscsi_initialize_iscsi_globals(struct spdk_iscsi_opts *opts)
 		return -EINVAL;
 	}
 
+	return 0;
+}
+
+static int
+spdk_iscsi_parse_options(struct spdk_iscsi_opts **popts)
+{
+	struct spdk_iscsi_opts *opts;
+	struct spdk_conf_section *sp;
+	int rc;
+
+	opts = spdk_iscsi_opts_alloc();
+	if (!opts) {
+		SPDK_ERRLOG("spdk_iscsi_opts_alloc_failed() failed\n");
+		return -ENOMEM;
+	}
+
+	/* Process parameters */
+	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "spdk_iscsi_read_config_file_parmas\n");
+	sp = spdk_conf_find_section(NULL, "iSCSI");
+	if (sp != NULL) {
+		rc = spdk_iscsi_read_config_file_params(sp, opts);
+		if (rc != 0) {
+			free(opts);
+			SPDK_ERRLOG("spdk_iscsi_read_config_file_params() failed\n");
+			return rc;
+		}
+	}
+
+	*popts = opts;
+
+	return 0;
+}
+
+static int
+spdk_iscsi_set_global_params(struct spdk_iscsi_opts *opts)
+{
+	int rc;
+
+	rc = spdk_iscsi_opts_verify(opts);
+	if (rc != 0) {
+		SPDK_ERRLOG("spdk_iscsi_opts_verify() failed\n");
+		return rc;
+	}
+
 	g_spdk_iscsi.authfile = strdup(opts->authfile);
 	if (!g_spdk_iscsi.authfile) {
 		SPDK_ERRLOG("failed to strdup for auth file %s\n", opts->authfile);
@@ -811,29 +750,33 @@ spdk_iscsi_initialize_iscsi_globals(struct spdk_iscsi_opts *opts)
 
 	spdk_iscsi_conn_set_min_per_core(opts->min_connections_per_core);
 
-	g_spdk_iscsi.session = spdk_dma_zmalloc(sizeof(void *) * g_spdk_iscsi.MaxSessions, 0, NULL);
-	if (!g_spdk_iscsi.session) {
-		SPDK_ERRLOG("spdk_dma_zmalloc() failed for session array\n");
-		return -1;
-	}
+	spdk_iscsi_log_globals();
 
-	/*
-	 * For now, just support same number of total connections, rather
-	 *  than MaxSessions * MaxConnectionsPerSession.  After we add better
-	 *  handling for low resource conditions from our various buffer
-	 *  pools, we can bump this up to support more connections.
-	 */
-	g_spdk_iscsi.MaxConnections = g_spdk_iscsi.MaxSessions;
+	return 0;
+}
 
-	rc = spdk_iscsi_initialize_all_pools();
+static int
+spdk_iscsi_initialize_global_params(void)
+{
+	int rc;
+
+	if (!g_spdk_iscsi_opts) {
+		rc = spdk_iscsi_parse_options(&g_spdk_iscsi_opts);
+		if (rc != 0) {
+			SPDK_ERRLOG("spdk_iscsi_parse_options() failed\n");
+			return rc;
+		}
+	}
+
+	rc = spdk_iscsi_set_global_params(g_spdk_iscsi_opts);
 	if (rc != 0) {
-		SPDK_ERRLOG("spdk_initialize_all_pools() failed\n");
-		return -1;
+		SPDK_ERRLOG("spdk_iscsi_set_global_params() failed\n");
 	}
 
-	spdk_iscsi_log_globals();
+	spdk_iscsi_opts_free(g_spdk_iscsi_opts);
+	g_spdk_iscsi_opts = NULL;
 
-	return 0;
+	return rc;
 }
 
 static void
@@ -936,7 +879,7 @@ spdk_initialize_iscsi_poll_group(spdk_thread_fn cpl)
 }
 
 static void
-spdk_iscsi_parse_iscsi_configuration(void *ctx)
+spdk_iscsi_parse_configuration(void *ctx)
 {
 	int rc;
 
@@ -962,26 +905,34 @@ end:
 }
 
 static int
-spdk_iscsi_parse_iscsi_globals(void)
+spdk_iscsi_parse_globals(void)
 {
-	struct spdk_conf_section *sp;
-	struct spdk_iscsi_opts opts;
 	int rc;
 
-	spdk_iscsi_opts_init(&opts);
+	rc = spdk_iscsi_initialize_global_params();
+	if (rc != 0) {
+		SPDK_ERRLOG("spdk_iscsi_initialize_iscsi_global_params() failed\n");
+		return rc;
+	}
 
-	/* Process parameters */
-	SPDK_DEBUGLOG(SPDK_LOG_ISCSI, "spdk_iscsi_read_config_file_parmas\n");
-	sp = spdk_conf_find_section(NULL, "iSCSI");
-	if (sp != NULL) {
-		spdk_iscsi_read_config_file_params(sp, &opts);
+	g_spdk_iscsi.session = spdk_dma_zmalloc(sizeof(void *) * g_spdk_iscsi.MaxSessions, 0, NULL);
+	if (!g_spdk_iscsi.session) {
+		SPDK_ERRLOG("spdk_dma_zmalloc() failed for session array\n");
+		return -1;
 	}
 
-	rc = spdk_iscsi_initialize_iscsi_globals(&opts);
-	spdk_iscsi_opts_free(&opts);
+	/*
+	 * For now, just support same number of total connections, rather
+	 *  than MaxSessions * MaxConnectionsPerSession.  After we add better
+	 *  handling for low resource conditions from our various buffer
+	 *  pools, we can bump this up to support more connections.
+	 */
+	g_spdk_iscsi.MaxConnections = g_spdk_iscsi.MaxSessions;
+
+	rc = spdk_iscsi_initialize_all_pools();
 	if (rc != 0) {
-		SPDK_ERRLOG("spdk_iscsi_initialize_iscsi_globals() failed\n");
-		return rc;
+		SPDK_ERRLOG("spdk_initialize_all_pools() failed\n");
+		return -1;
 	}
 
 	rc = spdk_initialize_iscsi_conns();
@@ -990,7 +941,7 @@ spdk_iscsi_parse_iscsi_globals(void)
 		return rc;
 	}
 
-	spdk_initialize_iscsi_poll_group(spdk_iscsi_parse_iscsi_configuration);
+	spdk_initialize_iscsi_poll_group(spdk_iscsi_parse_configuration);
 	return 0;
 }
 
@@ -1003,7 +954,7 @@ spdk_iscsi_init(spdk_iscsi_init_cb cb_fn, void *cb_arg)
 	g_init_cb_fn = cb_fn;
 	g_init_cb_arg = cb_arg;
 
-	rc = spdk_iscsi_parse_iscsi_globals();
+	rc = spdk_iscsi_parse_globals();
 	if (rc < 0) {
 		SPDK_ERRLOG("spdk_iscsi_parse_globals() failed\n");
 		spdk_iscsi_init_complete(-1);
@@ -1056,10 +1007,72 @@ spdk_shutdown_iscsi_conns_done(void)
 void
 spdk_iscsi_config_text(FILE *fp)
 {
-	spdk_iscsi_config_dump_section(fp);
-	spdk_iscsi_config_dump_portal_groups(fp);
-	spdk_iscsi_config_dump_initiator_groups(fp);
-	spdk_iscsi_config_dump_target_nodes(fp);
+	spdk_iscsi_globals_config_text(fp);
+	spdk_iscsi_portal_grps_config_text(fp);
+	spdk_iscsi_init_grps_config_text(fp);
+	spdk_iscsi_tgt_nodes_config_text(fp);
+}
+
+void
+spdk_iscsi_opts_info_json(struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "auth_file", g_spdk_iscsi.authfile);
+	spdk_json_write_named_string(w, "node_base", g_spdk_iscsi.nodebase);
+
+	spdk_json_write_named_uint32(w, "max_sessions", g_spdk_iscsi.MaxSessions);
+	spdk_json_write_named_uint32(w, "max_connections_per_session",
+				     g_spdk_iscsi.MaxConnectionsPerSession);
+
+	spdk_json_write_named_uint32(w, "max_queue_depth", g_spdk_iscsi.MaxQueueDepth);
+
+	spdk_json_write_named_uint32(w, "default_time2wait", g_spdk_iscsi.DefaultTime2Wait);
+	spdk_json_write_named_uint32(w, "default_time2retain", g_spdk_iscsi.DefaultTime2Retain);
+
+	spdk_json_write_named_bool(w, "immediate_data", g_spdk_iscsi.ImmediateData);
+
+	spdk_json_write_named_bool(w, "allow_duplicated_isid", g_spdk_iscsi.AllowDuplicateIsid);
+
+	spdk_json_write_named_uint32(w, "error_recovery_level", g_spdk_iscsi.ErrorRecoveryLevel);
+
+	spdk_json_write_named_uint32(w, "timeout", g_spdk_iscsi.timeout);
+	spdk_json_write_named_int32(w, "nop_in_interval", g_spdk_iscsi.nopininterval);
+
+	spdk_json_write_named_bool(w, "no_discovery_auth", g_spdk_iscsi.no_discovery_auth);
+	spdk_json_write_named_bool(w, "req_discovery_auth", g_spdk_iscsi.req_discovery_auth);
+	spdk_json_write_named_bool(w, "req_discovery_auth_mutual",
+				   g_spdk_iscsi.req_discovery_auth_mutual);
+	spdk_json_write_named_int32(w, "discovery_auth_group", g_spdk_iscsi.discovery_auth_group);
+
+	spdk_json_write_named_int32(w, "min_connections_per_core",
+				    spdk_iscsi_conn_get_min_per_core());
+
+	spdk_json_write_object_end(w);
+}
+
+static void
+spdk_iscsi_opts_config_json(struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "method", "set_iscsi_options");
+
+	spdk_json_write_name(w, "params");
+	spdk_iscsi_opts_info_json(w);
+
+	spdk_json_write_object_end(w);
+}
+
+void
+spdk_iscsi_config_json(struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_array_begin(w);
+	spdk_iscsi_opts_config_json(w);
+	spdk_iscsi_portal_grps_config_json(w);
+	spdk_iscsi_init_grps_config_json(w);
+	spdk_iscsi_tgt_nodes_config_json(w);
+	spdk_json_write_array_end(w);
 }
 
 SPDK_LOG_REGISTER_COMPONENT("iscsi", SPDK_LOG_ISCSI)
diff --git a/lib/iscsi/param.c b/lib/iscsi/param.c
index 5bfe5bf56..bbd9a8dc6 100644
--- a/lib/iscsi/param.c
+++ b/lib/iscsi/param.c
@@ -143,13 +143,12 @@ spdk_iscsi_param_add(struct iscsi_param **params, const char *key,
 		spdk_iscsi_param_del(params, key);
 	}
 
-	param = malloc(sizeof(*param));
+	param = calloc(1, sizeof(*param));
 	if (!param) {
-		SPDK_ERRLOG("malloc() failed for parameter\n");
+		SPDK_ERRLOG("calloc() failed for parameter\n");
 		return -ENOMEM;
 	}
 
-	memset(param, 0, sizeof(*param));
 	param->next = NULL;
 	param->key = xstrdup(key);
 	param->val = xstrdup(val);
@@ -307,8 +306,9 @@ spdk_iscsi_parse_params(struct iscsi_param **params, const uint8_t *data,
 
 	/* strip the partial text parameters if previous PDU have C enabled */
 	if (partial_parameter && *partial_parameter) {
-		for (i = 0; i < len && data[i] != '\0'; i++)
+		for (i = 0; i < len && data[i] != '\0'; i++) {
 			;
+		}
 		p = spdk_sprintf_alloc("%s%s", *partial_parameter, (const char *)data);
 		if (!p) {
 			return -1;
@@ -336,8 +336,9 @@ spdk_iscsi_parse_params(struct iscsi_param **params, const uint8_t *data,
 		 * reverse iterate the string from the tail not including '\0'
 		 * index of last '\0' is len -1.
 		 */
-		for (i = len - 2; data[i] != '\0' && i > 0; i--)
+		for (i = len - 2; data[i] != '\0' && i > 0; i--) {
 			;
+		}
 		*partial_parameter = xstrdup(&data[i == 0 ? 0 : i + 1]);
 		len = (i == 0 ? 0 : i + 1);
 	}
@@ -602,7 +603,6 @@ spdk_iscsi_special_param_construction(struct spdk_iscsi_conn *conn,
 static int
 spdk_iscsi_construct_data_from_param(struct iscsi_param *param, char *new_val,
 				     char *data, int alloc_len, int total)
-
 {
 	int len;
 
@@ -620,7 +620,6 @@ spdk_iscsi_construct_data_from_param(struct iscsi_param *param, char *new_val,
 		total += len + 1;
 	}
 	return total;
-
 }
 
 /**
@@ -1050,10 +1049,9 @@ spdk_iscsi_negotiate_params(struct spdk_iscsi_conn *conn,
 			/* add_param_value = 0 means updating the value of
 			 *      existed key in the connection's parameters
 			 */
-			if (add_param_value == 0)
-				spdk_iscsi_param_set(params_dst, param->key,
-						     new_val);
-
+			if (add_param_value == 0) {
+				spdk_iscsi_param_set(params_dst, param->key, new_val);
+			}
 			total = spdk_iscsi_construct_data_from_param(param,
 					new_val,
 					data,
diff --git a/lib/iscsi/portal_grp.c b/lib/iscsi/portal_grp.c
index 0a09e28b9..60a724c9f 100644
--- a/lib/iscsi/portal_grp.c
+++ b/lib/iscsi/portal_grp.c
@@ -599,3 +599,109 @@ spdk_iscsi_portal_grp_release(struct spdk_iscsi_portal_grp *pg)
 	spdk_iscsi_portal_grp_close(pg);
 	spdk_iscsi_portal_grp_destroy(pg);
 }
+
+static const char *portal_group_section = \
+		"\n"
+		"# Users must change the PortalGroup section(s) to match the IP addresses\n"
+		"#  for their environment.\n"
+		"# PortalGroup sections define which network portals the iSCSI target\n"
+		"# will use to listen for incoming connections.  These are also used to\n"
+		"#  determine which targets are accessible over each portal group.\n"
+		"# Up to 1024 Portal directives are allowed.  These define the network\n"
+		"#  portals of the portal group. The user must specify a IP address\n"
+		"#  for each network portal, and may optionally specify a port and\n"
+		"#  a cpumask. If the port is omitted, 3260 will be used. Cpumask will\n"
+		"#  be used to set the processor affinity of the iSCSI connection\n"
+		"#  through the portal.  If the cpumask is omitted, cpumask will be\n"
+		"#  set to all available processors.\n"
+		"#  Syntax:\n"
+		"#    Portal <Name> <IP address>[:<port>[@<cpumask>]]\n";
+
+#define PORTAL_GROUP_TMPL \
+"[PortalGroup%d]\n" \
+"  Comment \"Portal%d\"\n"
+
+#define PORTAL_TMPL \
+"  Portal DA1 %s:%s@0x%s\n"
+
+void
+spdk_iscsi_portal_grps_config_text(FILE *fp)
+{
+	struct spdk_iscsi_portal *p = NULL;
+	struct spdk_iscsi_portal_grp *pg = NULL;
+
+	/* Create portal group section */
+	fprintf(fp, "%s", portal_group_section);
+
+	/* Dump portal groups */
+	TAILQ_FOREACH(pg, &g_spdk_iscsi.pg_head, tailq) {
+		if (NULL == pg) { continue; }
+		fprintf(fp, PORTAL_GROUP_TMPL, pg->tag, pg->tag);
+		/* Dump portals */
+		TAILQ_FOREACH(p, &pg->head, per_pg_tailq) {
+			if (NULL == p) { continue; }
+			fprintf(fp, PORTAL_TMPL, p->host, p->port,
+				spdk_cpuset_fmt(p->cpumask));
+		}
+	}
+}
+
+static void
+spdk_iscsi_portal_grp_info_json(struct spdk_iscsi_portal_grp *pg,
+				struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_portal *portal;
+
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_int32(w, "tag", pg->tag);
+
+	spdk_json_write_named_array_begin(w, "portals");
+	TAILQ_FOREACH(portal, &pg->head, per_pg_tailq) {
+		spdk_json_write_object_begin(w);
+
+		spdk_json_write_named_string(w, "host", portal->host);
+		spdk_json_write_named_string(w, "port", portal->port);
+		spdk_json_write_named_string_fmt(w, "cpumask", "0x%s",
+						 spdk_cpuset_fmt(portal->cpumask));
+
+		spdk_json_write_object_end(w);
+	}
+	spdk_json_write_array_end(w);
+
+	spdk_json_write_object_end(w);
+}
+
+static void
+spdk_iscsi_portal_grp_config_json(struct spdk_iscsi_portal_grp *pg,
+				  struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "method", "add_portal_group");
+
+	spdk_json_write_name(w, "params");
+	spdk_iscsi_portal_grp_info_json(pg, w);
+
+	spdk_json_write_object_end(w);
+}
+
+void
+spdk_iscsi_portal_grps_info_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_portal_grp *pg;
+
+	TAILQ_FOREACH(pg, &g_spdk_iscsi.pg_head, tailq) {
+		spdk_iscsi_portal_grp_info_json(pg, w);
+	}
+}
+
+void
+spdk_iscsi_portal_grps_config_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_portal_grp *pg;
+
+	TAILQ_FOREACH(pg, &g_spdk_iscsi.pg_head, tailq) {
+		spdk_iscsi_portal_grp_config_json(pg, w);
+	}
+}
diff --git a/lib/iscsi/portal_grp.h b/lib/iscsi/portal_grp.h
index c4672ea16..08cb39926 100644
--- a/lib/iscsi/portal_grp.h
+++ b/lib/iscsi/portal_grp.h
@@ -38,6 +38,8 @@
 #include "spdk/conf.h"
 #include "spdk/cpuset.h"
 
+struct spdk_json_write_ctx;
+
 struct spdk_iscsi_portal {
 	struct spdk_iscsi_portal_grp	*group;
 	char				*host;
@@ -75,4 +77,7 @@ struct spdk_iscsi_portal_grp *spdk_iscsi_portal_grp_find_by_tag(int tag);
 int spdk_iscsi_portal_grp_open(struct spdk_iscsi_portal_grp *pg);
 
 void spdk_iscsi_portal_grp_close_all(void);
+void spdk_iscsi_portal_grps_config_text(FILE *fp);
+void spdk_iscsi_portal_grps_info_json(struct spdk_json_write_ctx *w);
+void spdk_iscsi_portal_grps_config_json(struct spdk_json_write_ctx *w);
 #endif // SPDK_PORTAL_GRP_H
diff --git a/lib/iscsi/task.h b/lib/iscsi/task.h
index 8e6f7e04e..0fee4cda2 100644
--- a/lib/iscsi/task.h
+++ b/lib/iscsi/task.h
@@ -37,6 +37,7 @@
 
 #include "iscsi/iscsi.h"
 #include "spdk/scsi.h"
+#include "spdk/util.h"
 
 struct spdk_iscsi_task {
 	struct spdk_scsi_task	scsi;
@@ -169,7 +170,7 @@ struct spdk_iscsi_task *spdk_iscsi_task_get(struct spdk_iscsi_conn *conn,
 static inline struct spdk_iscsi_task *
 spdk_iscsi_task_from_scsi_task(struct spdk_scsi_task *task)
 {
-	return (struct spdk_iscsi_task *)((uintptr_t)task - offsetof(struct spdk_iscsi_task, scsi));
+	return SPDK_CONTAINEROF(task, struct spdk_iscsi_task, scsi);
 }
 
 static inline struct spdk_iscsi_task *
diff --git a/lib/iscsi/tgt_node.c b/lib/iscsi/tgt_node.c
index cc730de2b..403892136 100644
--- a/lib/iscsi/tgt_node.c
+++ b/lib/iscsi/tgt_node.c
@@ -1331,3 +1331,188 @@ spdk_iscsi_tgt_node_add_lun(struct spdk_iscsi_tgt_node *target,
 
 	return 0;
 }
+
+static const char *target_nodes_section = \
+		"\n"
+		"# Users should change the TargetNode section(s) below to match the\n"
+		"#  desired iSCSI target node configuration.\n"
+		"# TargetName, Mapping, LUN0 are minimum required\n";
+
+#define TARGET_NODE_TMPL \
+"[TargetNode%d]\n" \
+"  Comment \"Target%d\"\n" \
+"  TargetName %s\n" \
+"  TargetAlias \"%s\"\n"
+
+#define TARGET_NODE_PGIG_MAPPING_TMPL \
+"  Mapping PortalGroup%d InitiatorGroup%d\n"
+
+#define TARGET_NODE_AUTH_TMPL \
+"  AuthMethod %s\n" \
+"  AuthGroup %s\n" \
+"  UseDigest %s\n"
+
+#define TARGET_NODE_QD_TMPL \
+"  QueueDepth %d\n\n"
+
+#define TARGET_NODE_LUN_TMPL \
+"  LUN%d %s\n"
+
+void
+spdk_iscsi_tgt_nodes_config_text(FILE *fp)
+{
+	int l = 0;
+	struct spdk_scsi_dev *dev = NULL;
+	struct spdk_iscsi_tgt_node *target = NULL;
+	struct spdk_iscsi_pg_map *pg_map;
+	struct spdk_iscsi_ig_map *ig_map;
+
+	/* Create target nodes section */
+	fprintf(fp, "%s", target_nodes_section);
+
+	TAILQ_FOREACH(target, &g_spdk_iscsi.target_head, tailq) {
+		int idx;
+		const char *authmethod = "None";
+		char authgroup[32] = "None";
+		const char *usedigest = "Auto";
+
+		dev = target->dev;
+		if (NULL == dev) { continue; }
+
+		idx = target->num;
+		fprintf(fp, TARGET_NODE_TMPL, idx, idx, target->name, spdk_scsi_dev_get_name(dev));
+
+		TAILQ_FOREACH(pg_map, &target->pg_map_head, tailq) {
+			TAILQ_FOREACH(ig_map, &pg_map->ig_map_head, tailq) {
+				fprintf(fp, TARGET_NODE_PGIG_MAPPING_TMPL,
+					pg_map->pg->tag,
+					ig_map->ig->tag);
+			}
+		}
+
+		if (target->disable_chap) {
+			authmethod = "None";
+		} else if (!target->require_chap) {
+			authmethod = "Auto";
+		} else if (target->mutual_chap) {
+			authmethod = "CHAP Mutual";
+		} else {
+			authmethod = "CHAP";
+		}
+
+		if (target->chap_group > 0) {
+			snprintf(authgroup, sizeof(authgroup), "AuthGroup%d", target->chap_group);
+		}
+
+		if (target->header_digest) {
+			usedigest = "Header";
+		} else if (target->data_digest) {
+			usedigest = "Data";
+		}
+
+		fprintf(fp, TARGET_NODE_AUTH_TMPL,
+			authmethod, authgroup, usedigest);
+
+		for (l = 0; l < SPDK_SCSI_DEV_MAX_LUN; l++) {
+			struct spdk_scsi_lun *lun = spdk_scsi_dev_get_lun(dev, l);
+
+			if (!lun) {
+				continue;
+			}
+
+			fprintf(fp, TARGET_NODE_LUN_TMPL,
+				spdk_scsi_lun_get_id(lun),
+				spdk_scsi_lun_get_bdev_name(lun));
+		}
+
+		fprintf(fp, TARGET_NODE_QD_TMPL,
+			target->queue_depth);
+	}
+}
+
+static void
+spdk_iscsi_tgt_node_info_json(struct spdk_iscsi_tgt_node *target,
+			      struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_pg_map *pg_map;
+	struct spdk_iscsi_ig_map *ig_map;
+	int i;
+
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "name", target->name);
+
+	if (target->alias) {
+		spdk_json_write_named_string(w, "alias_name", target->alias);
+	}
+
+	spdk_json_write_named_array_begin(w, "pg_ig_maps");
+	TAILQ_FOREACH(pg_map, &target->pg_map_head, tailq) {
+		TAILQ_FOREACH(ig_map, &pg_map->ig_map_head, tailq) {
+			spdk_json_write_object_begin(w);
+			spdk_json_write_named_int32(w, "pg_tag", pg_map->pg->tag);
+			spdk_json_write_named_int32(w, "ig_tag", ig_map->ig->tag);
+			spdk_json_write_object_end(w);
+		}
+	}
+	spdk_json_write_array_end(w);
+
+	spdk_json_write_named_array_begin(w, "luns");
+	for (i = 0; i < SPDK_SCSI_DEV_MAX_LUN; i++) {
+		struct spdk_scsi_lun *lun = spdk_scsi_dev_get_lun(target->dev, i);
+
+		if (lun) {
+			spdk_json_write_object_begin(w);
+			spdk_json_write_named_string(w, "bdev_name", spdk_scsi_lun_get_bdev_name(lun));
+			spdk_json_write_named_int32(w, "lun_id", spdk_scsi_lun_get_id(lun));
+			spdk_json_write_object_end(w);
+		}
+	}
+	spdk_json_write_array_end(w);
+
+	spdk_json_write_named_int32(w, "queue_depth", target->queue_depth);
+
+	spdk_json_write_named_bool(w, "disable_chap", target->disable_chap);
+	spdk_json_write_named_bool(w, "require_chap", target->require_chap);
+	spdk_json_write_named_bool(w, "mutual_chap", target->mutual_chap);
+	spdk_json_write_named_int32(w, "chap_group", target->chap_group);
+
+	spdk_json_write_named_bool(w, "header_digest", target->header_digest);
+	spdk_json_write_named_bool(w, "data_digest", target->data_digest);
+
+	spdk_json_write_object_end(w);
+}
+
+static void
+spdk_iscsi_tgt_node_config_json(struct spdk_iscsi_tgt_node *target,
+				struct spdk_json_write_ctx *w)
+{
+	spdk_json_write_object_begin(w);
+
+	spdk_json_write_named_string(w, "method", "construct_target_node");
+
+	spdk_json_write_name(w, "params");
+	spdk_iscsi_tgt_node_info_json(target, w);
+
+	spdk_json_write_object_end(w);
+}
+
+void
+spdk_iscsi_tgt_nodes_info_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_tgt_node *target;
+
+	TAILQ_FOREACH(target, &g_spdk_iscsi.target_head, tailq) {
+		spdk_iscsi_tgt_node_info_json(target, w);
+	}
+}
+
+void
+spdk_iscsi_tgt_nodes_config_json(struct spdk_json_write_ctx *w)
+{
+	struct spdk_iscsi_tgt_node *target;
+
+	TAILQ_FOREACH(target, &g_spdk_iscsi.target_head, tailq) {
+		spdk_iscsi_tgt_node_config_json(target, w);
+	}
+}
diff --git a/lib/iscsi/tgt_node.h b/lib/iscsi/tgt_node.h
index 60505ca03..f68f7d67c 100644
--- a/lib/iscsi/tgt_node.h
+++ b/lib/iscsi/tgt_node.h
@@ -43,6 +43,7 @@ struct spdk_iscsi_conn;
 struct spdk_iscsi_init_grp;
 struct spdk_iscsi_portal_grp;
 struct spdk_iscsi_portal;
+struct spdk_json_write_ctx;
 
 #define MAX_TARGET_MAP			256
 #define SPDK_TN_TAG_MAX			0x0000ffff
@@ -136,4 +137,7 @@ void spdk_iscsi_tgt_node_delete_map(struct spdk_iscsi_portal_grp *portal_group,
 				    struct spdk_iscsi_init_grp *initiator_group);
 int spdk_iscsi_tgt_node_add_lun(struct spdk_iscsi_tgt_node *target,
 				const char *bdev_name, int lun_id);
+void spdk_iscsi_tgt_nodes_config_text(FILE *fp);
+void spdk_iscsi_tgt_nodes_info_json(struct spdk_json_write_ctx *w);
+void spdk_iscsi_tgt_nodes_config_json(struct spdk_json_write_ctx *w);
 #endif /* SPDK_ISCSI_TGT_NODE_H_ */
diff --git a/lib/json/json_util.c b/lib/json/json_util.c
index 5acc2e1ed..f9669d468 100644
--- a/lib/json/json_util.c
+++ b/lib/json/json_util.c
@@ -201,6 +201,28 @@ spdk_json_number_split(const struct spdk_json_val *val, struct spdk_json_num *nu
 	return 0;
 }
 
+int
+spdk_json_number_to_uint16(const struct spdk_json_val *val, uint16_t *num)
+{
+	struct spdk_json_num split_num;
+	int rc;
+
+	rc = spdk_json_number_split(val, &split_num);
+	if (rc) {
+		return rc;
+	}
+
+	if (split_num.exponent || split_num.negative) {
+		return -ERANGE;
+	}
+
+	if (split_num.significand > UINT16_MAX) {
+		return -ERANGE;
+	}
+	*num = (uint16_t)split_num.significand;
+	return 0;
+}
+
 int
 spdk_json_number_to_int32(const struct spdk_json_val *val, int32_t *num)
 {
@@ -383,6 +405,14 @@ spdk_json_decode_bool(const struct spdk_json_val *val, void *out)
 	return 0;
 }
 
+int
+spdk_json_decode_uint16(const struct spdk_json_val *val, void *out)
+{
+	uint16_t *i = out;
+
+	return spdk_json_number_to_uint16(val, i);
+}
+
 int
 spdk_json_decode_int32(const struct spdk_json_val *val, void *out)
 {
diff --git a/lib/jsonrpc/jsonrpc_internal.h b/lib/jsonrpc/jsonrpc_internal.h
index b0ea21e29..2caaba2e7 100644
--- a/lib/jsonrpc/jsonrpc_internal.h
+++ b/lib/jsonrpc/jsonrpc_internal.h
@@ -80,13 +80,18 @@ struct spdk_jsonrpc_server_conn {
 	STAILQ_HEAD(, spdk_jsonrpc_request) send_queue;
 
 	struct spdk_jsonrpc_request *send_request;
+
+	TAILQ_ENTRY(spdk_jsonrpc_server_conn) link;
 };
 
 struct spdk_jsonrpc_server {
 	int sockfd;
 	spdk_jsonrpc_handle_request_fn handle_request;
-	struct spdk_jsonrpc_server_conn conns[SPDK_JSONRPC_MAX_CONNS];
-	int num_conns;
+
+	TAILQ_HEAD(, spdk_jsonrpc_server_conn) free_conns;
+	TAILQ_HEAD(, spdk_jsonrpc_server_conn) conns;
+
+	struct spdk_jsonrpc_server_conn conns_array[SPDK_JSONRPC_MAX_CONNS];
 };
 
 /* jsonrpc_server_tcp */
diff --git a/lib/jsonrpc/jsonrpc_server.c b/lib/jsonrpc/jsonrpc_server.c
index 0d799d341..7aa21fb52 100644
--- a/lib/jsonrpc/jsonrpc_server.c
+++ b/lib/jsonrpc/jsonrpc_server.c
@@ -52,7 +52,7 @@ capture_val(const struct spdk_json_val *val, void *out)
 }
 
 static const struct spdk_json_object_decoder jsonrpc_request_decoders[] = {
-	{"jsonrpc", offsetof(struct jsonrpc_request, version), capture_val},
+	{"jsonrpc", offsetof(struct jsonrpc_request, version), capture_val, true},
 	{"method", offsetof(struct jsonrpc_request, method), capture_val},
 	{"params", offsetof(struct jsonrpc_request, params), capture_val, true},
 	{"id", offsetof(struct jsonrpc_request, id), capture_val, true},
@@ -71,8 +71,8 @@ parse_single_request(struct spdk_jsonrpc_request *request, struct spdk_json_val
 		goto done;
 	}
 
-	if (!req.version || req.version->type != SPDK_JSON_VAL_STRING ||
-	    !spdk_json_strequal(req.version, "2.0")) {
+	if (req.version && (req.version->type != SPDK_JSON_VAL_STRING ||
+			    !spdk_json_strequal(req.version, "2.0"))) {
 		invalid = true;
 	}
 
diff --git a/lib/jsonrpc/jsonrpc_server_tcp.c b/lib/jsonrpc/jsonrpc_server_tcp.c
index 64f92f6b6..4c65dc7ca 100644
--- a/lib/jsonrpc/jsonrpc_server_tcp.c
+++ b/lib/jsonrpc/jsonrpc_server_tcp.c
@@ -40,13 +40,20 @@ spdk_jsonrpc_server_listen(int domain, int protocol,
 			   spdk_jsonrpc_handle_request_fn handle_request)
 {
 	struct spdk_jsonrpc_server *server;
-	int rc, val, flag;
+	int rc, val, flag, i;
 
 	server = calloc(1, sizeof(struct spdk_jsonrpc_server));
 	if (server == NULL) {
 		return NULL;
 	}
 
+	TAILQ_INIT(&server->free_conns);
+	TAILQ_INIT(&server->conns);
+
+	for (i = 0; i < SPDK_JSONRPC_MAX_CONNS; i++) {
+		TAILQ_INSERT_TAIL(&server->free_conns, &server->conns_array[i], link);
+	}
+
 	server->handle_request = handle_request;
 
 	server->sockfd = socket(domain, SOCK_STREAM, protocol);
@@ -93,12 +100,12 @@ spdk_jsonrpc_server_listen(int domain, int protocol,
 void
 spdk_jsonrpc_server_shutdown(struct spdk_jsonrpc_server *server)
 {
-	int i;
+	struct spdk_jsonrpc_server_conn *conn;
 
 	close(server->sockfd);
 
-	for (i = 0; i < server->num_conns; i++) {
-		close(server->conns[i].sockfd);
+	TAILQ_FOREACH(conn, &server->conns, link) {
+		close(conn->sockfd);
 	}
 
 	free(server);
@@ -119,29 +126,27 @@ static void
 spdk_jsonrpc_server_conn_remove(struct spdk_jsonrpc_server_conn *conn)
 {
 	struct spdk_jsonrpc_server *server = conn->server;
-	int conn_idx = conn - server->conns;
 
 	spdk_jsonrpc_server_conn_close(conn);
 
 	pthread_spin_destroy(&conn->queue_lock);
 	assert(STAILQ_EMPTY(&conn->send_queue));
 
-	/* Swap conn with the last entry in conns */
-	server->conns[conn_idx] = server->conns[server->num_conns - 1];
-	server->num_conns--;
+	TAILQ_REMOVE(&server->conns, conn, link);
+	TAILQ_INSERT_HEAD(&server->free_conns, conn, link);
 }
 
 static int
 spdk_jsonrpc_server_accept(struct spdk_jsonrpc_server *server)
 {
 	struct spdk_jsonrpc_server_conn *conn;
-	int rc, conn_idx, flag;
+	int rc, flag;
 
 	rc = accept(server->sockfd, NULL, NULL);
 	if (rc >= 0) {
-		assert(server->num_conns < SPDK_JSONRPC_MAX_CONNS);
-		conn_idx = server->num_conns;
-		conn = &server->conns[conn_idx];
+		conn = TAILQ_FIRST(&server->free_conns);
+		assert(conn != NULL);
+
 		conn->server = server;
 		conn->sockfd = rc;
 		conn->closed = false;
@@ -159,8 +164,8 @@ spdk_jsonrpc_server_accept(struct spdk_jsonrpc_server *server)
 			return -1;
 		}
 
-		server->num_conns++;
-
+		TAILQ_REMOVE(&server->free_conns, conn, link);
+		TAILQ_INSERT_TAIL(&server->conns, conn, link);
 		return 0;
 	}
 
@@ -332,12 +337,10 @@ more:
 int
 spdk_jsonrpc_server_poll(struct spdk_jsonrpc_server *server)
 {
-	int rc, i;
-	struct spdk_jsonrpc_server_conn *conn;
-
-	for (i = 0; i < server->num_conns; i++) {
-		conn = &server->conns[i];
+	int rc;
+	struct spdk_jsonrpc_server_conn *conn, *conn_tmp;
 
+	TAILQ_FOREACH_SAFE(conn, &server->conns, link, conn_tmp) {
 		if (conn->closed) {
 			struct spdk_jsonrpc_request *request;
 
@@ -365,13 +368,11 @@ spdk_jsonrpc_server_poll(struct spdk_jsonrpc_server *server)
 	}
 
 	/* Check listen socket */
-	if (server->num_conns < SPDK_JSONRPC_MAX_CONNS) {
+	if (!TAILQ_EMPTY(&server->free_conns)) {
 		spdk_jsonrpc_server_accept(server);
 	}
 
-	for (i = 0; i < server->num_conns; i++) {
-		conn = &server->conns[i];
-
+	TAILQ_FOREACH(conn, &server->conns, link) {
 		if (conn->closed) {
 			continue;
 		}
diff --git a/lib/log/log_flags.c b/lib/log/log_flags.c
index bd0f3a551..25c2d8d8c 100644
--- a/lib/log/log_flags.c
+++ b/lib/log/log_flags.c
@@ -87,12 +87,14 @@ spdk_log_register_trace_flag(const char *name, struct spdk_trace_flag *flag)
 
 	if (name == NULL || flag == NULL) {
 		SPDK_ERRLOG("missing spdk_trace_flag parameters\n");
-		abort();
+		assert(false);
+		return;
 	}
 
 	if (get_trace_flag(name)) {
 		SPDK_ERRLOG("duplicate spdk_trace_flag '%s'\n", name);
-		abort();
+		assert(false);
+		return;
 	}
 
 	TAILQ_FOREACH(iter, &g_trace_flags, tailq) {
@@ -169,7 +171,7 @@ spdk_tracelog_usage(FILE *f, const char *trace_arg)
 #ifdef DEBUG
 	struct spdk_trace_flag *flag;
 
-	fprintf(f, " %s flag    enable trace flag (all", trace_arg);
+	fprintf(f, " %s flag    enable debug log flag (all", trace_arg);
 
 	TAILQ_FOREACH(flag, &g_trace_flags, tailq) {
 		fprintf(f, ", %s", flag->name);
@@ -177,7 +179,7 @@ spdk_tracelog_usage(FILE *f, const char *trace_arg)
 
 	fprintf(f, ")\n");
 #else
-	fprintf(f, " %s flag    enable trace flag (not supported - must rebuild with CONFIG_DEBUG=y)\n",
+	fprintf(f, " %s flag    enable debug log flag (not supported - must rebuild with CONFIG_DEBUG=y)\n",
 		trace_arg);
 #endif
 }
diff --git a/lib/log/rpc/log_rpc.c b/lib/log/rpc/log_rpc.c
index b59c1edf0..fea7607ae 100644
--- a/lib/log/rpc/log_rpc.c
+++ b/lib/log/rpc/log_rpc.c
@@ -134,7 +134,8 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_log_level(&req);
 }
-SPDK_RPC_REGISTER("set_log_print_level", spdk_rpc_set_log_print_level)
+SPDK_RPC_REGISTER("set_log_print_level", spdk_rpc_set_log_print_level,
+		  SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_log_print_level(struct spdk_jsonrpc_request *request,
@@ -162,7 +163,8 @@ spdk_rpc_get_log_print_level(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_log_print_level", spdk_rpc_get_log_print_level)
+SPDK_RPC_REGISTER("get_log_print_level", spdk_rpc_get_log_print_level,
+		  SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_set_log_level(struct spdk_jsonrpc_request *request,
@@ -201,7 +203,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_log_level(&req);
 }
-SPDK_RPC_REGISTER("set_log_level", spdk_rpc_set_log_level)
+SPDK_RPC_REGISTER("set_log_level", spdk_rpc_set_log_level, SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_log_level(struct spdk_jsonrpc_request *request,
@@ -228,7 +230,7 @@ spdk_rpc_get_log_level(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_log_level", spdk_rpc_get_log_level)
+SPDK_RPC_REGISTER("get_log_level", spdk_rpc_get_log_level, SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_set_trace_flag(struct spdk_jsonrpc_request *request,
@@ -264,7 +266,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_trace_flag(&req);
 }
-SPDK_RPC_REGISTER("set_trace_flag", spdk_rpc_set_trace_flag)
+SPDK_RPC_REGISTER("set_trace_flag", spdk_rpc_set_trace_flag, SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_clear_trace_flag(struct spdk_jsonrpc_request *request,
@@ -300,7 +302,8 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_trace_flag(&req);
 }
-SPDK_RPC_REGISTER("clear_trace_flag", spdk_rpc_clear_trace_flag)
+SPDK_RPC_REGISTER("clear_trace_flag", spdk_rpc_clear_trace_flag,
+		  SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_trace_flags(struct spdk_jsonrpc_request *request,
@@ -330,4 +333,4 @@ spdk_rpc_get_trace_flags(struct spdk_jsonrpc_request *request,
 	spdk_json_write_object_end(w);
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_trace_flags", spdk_rpc_get_trace_flags)
+SPDK_RPC_REGISTER("get_trace_flags", spdk_rpc_get_trace_flags, SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
diff --git a/lib/lvol/lvol.c b/lib/lvol/lvol.c
index 00487ce05..a0857ab1d 100644
--- a/lib/lvol/lvol.c
+++ b/lib/lvol/lvol.c
@@ -34,7 +34,7 @@
 #include "spdk_internal/lvolstore.h"
 #include "spdk_internal/log.h"
 #include "spdk/string.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/blob_bdev.h"
 #include "spdk/util.h"
 
@@ -1423,3 +1423,90 @@ spdk_lvol_get_io_channel(struct spdk_lvol *lvol)
 {
 	return spdk_bs_alloc_io_channel(lvol->lvol_store->blobstore);
 }
+
+static void
+_spdk_lvol_inflate_cb(void *cb_arg, int lvolerrno)
+{
+	struct spdk_lvol_req *req = cb_arg;
+
+	spdk_bs_free_io_channel(req->channel);
+
+	if (lvolerrno < 0) {
+		SPDK_ERRLOG("Could not inflate lvol\n");
+	}
+
+	req->cb_fn(req->cb_arg, lvolerrno);
+	free(req);
+}
+
+void
+spdk_lvol_inflate(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg)
+{
+	struct spdk_lvol_req *req;
+	struct spdk_blob *blob = lvol->blob;
+	spdk_blob_id blob_id = spdk_blob_get_id(blob);
+
+	assert(cb_fn != NULL);
+
+	if (lvol == NULL) {
+		SPDK_ERRLOG("Lvol does not exist\n");
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	req = calloc(1, sizeof(*req));
+	if (!req) {
+		SPDK_ERRLOG("Cannot alloc memory for lvol request pointer\n");
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	req->cb_fn = cb_fn;
+	req->cb_arg = cb_arg;
+	req->channel = spdk_bs_alloc_io_channel(lvol->lvol_store->blobstore);
+	if (req->channel == NULL) {
+		SPDK_ERRLOG("Cannot alloc io channel for lvol inflate request\n");
+		free(req);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	spdk_bs_inflate_blob(lvol->lvol_store->blobstore, req->channel, blob_id, _spdk_lvol_inflate_cb,
+			     req);
+}
+
+void
+spdk_lvol_decouple_parent(struct spdk_lvol *lvol, spdk_lvol_op_complete cb_fn, void *cb_arg)
+{
+	struct spdk_lvol_req *req;
+	struct spdk_blob *blob = lvol->blob;
+	spdk_blob_id blob_id = spdk_blob_get_id(blob);
+
+	assert(cb_fn != NULL);
+
+	if (lvol == NULL) {
+		SPDK_ERRLOG("Lvol does not exist\n");
+		cb_fn(cb_arg, -ENODEV);
+		return;
+	}
+
+	req = calloc(1, sizeof(*req));
+	if (!req) {
+		SPDK_ERRLOG("Cannot alloc memory for lvol request pointer\n");
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	req->cb_fn = cb_fn;
+	req->cb_arg = cb_arg;
+	req->channel = spdk_bs_alloc_io_channel(lvol->lvol_store->blobstore);
+	if (req->channel == NULL) {
+		SPDK_ERRLOG("Cannot alloc io channel for lvol inflate request\n");
+		free(req);
+		cb_fn(cb_arg, -ENOMEM);
+		return;
+	}
+
+	spdk_bs_blob_decouple_parent(lvol->lvol_store->blobstore, req->channel, blob_id,
+				     _spdk_lvol_inflate_cb, req);
+}
diff --git a/lib/nbd/nbd.c b/lib/nbd/nbd.c
index fd9196ae8..ad635ff4d 100644
--- a/lib/nbd/nbd.c
+++ b/lib/nbd/nbd.c
@@ -43,7 +43,7 @@
 #include "spdk/env.h"
 #include "spdk/log.h"
 #include "spdk/util.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/event.h"
 
 #include "spdk_internal/log.h"
@@ -67,8 +67,6 @@ struct nbd_io {
 	enum nbd_io_state_t	state;
 
 	void			*payload;
-
-	/* NOTE: for TRIM, this represents number of bytes to trim. */
 	uint32_t		payload_size;
 
 	struct nbd_request	req;
@@ -480,7 +478,7 @@ nbd_submit_bdev_io(struct spdk_nbd_disk *nbd, struct nbd_io *io)
 #ifdef NBD_FLAG_SEND_TRIM
 	case NBD_CMD_TRIM:
 		rc = spdk_bdev_unmap(desc, ch, from_be64(&io->req.from),
-				     io->payload_size, nbd_io_done, io);
+				     from_be32(&io->req.len), nbd_io_done, io);
 		break;
 #endif
 	case NBD_CMD_DISC:
diff --git a/lib/nbd/nbd_rpc.c b/lib/nbd/nbd_rpc.c
index ee63038bd..bec64a131 100644
--- a/lib/nbd/nbd_rpc.c
+++ b/lib/nbd/nbd_rpc.c
@@ -88,15 +88,15 @@ spdk_rpc_start_nbd_disk(struct spdk_jsonrpc_request *request,
 		goto invalid;
 	}
 
-	free_rpc_start_nbd_disk(&req);
-
 	w = spdk_jsonrpc_begin_result(request);
 	if (w == NULL) {
+		free_rpc_start_nbd_disk(&req);
 		return;
 	}
 
-	spdk_json_write_bool(w, true);
+	spdk_json_write_string(w, req.nbd_device);
 	spdk_jsonrpc_end_result(request, w);
+	free_rpc_start_nbd_disk(&req);
 	return;
 
 invalid:
@@ -104,7 +104,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 }
 
-SPDK_RPC_REGISTER("start_nbd_disk", spdk_rpc_start_nbd_disk)
+SPDK_RPC_REGISTER("start_nbd_disk", spdk_rpc_start_nbd_disk, SPDK_RPC_RUNTIME)
 
 struct rpc_stop_nbd_disk {
 	char *nbd_device;
@@ -217,7 +217,7 @@ out:
 	free_rpc_stop_nbd_disk(&req);
 }
 
-SPDK_RPC_REGISTER("stop_nbd_disk", spdk_rpc_stop_nbd_disk)
+SPDK_RPC_REGISTER("stop_nbd_disk", spdk_rpc_stop_nbd_disk, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_dump_nbd_info(struct spdk_json_write_ctx *w,
@@ -245,7 +245,7 @@ free_rpc_get_nbd_disks(struct rpc_get_nbd_disks *r)
 }
 
 static const struct spdk_json_object_decoder rpc_get_nbd_disks_decoders[] = {
-	{"nbd_device", offsetof(struct rpc_get_nbd_disks, nbd_device), spdk_json_decode_string},
+	{"nbd_device", offsetof(struct rpc_get_nbd_disks, nbd_device), spdk_json_decode_string, true},
 };
 
 static void
@@ -262,12 +262,9 @@ spdk_rpc_get_nbd_disks(struct spdk_jsonrpc_request *request,
 					    &req)) {
 			SPDK_ERRLOG("spdk_json_decode_object failed\n");
 			goto invalid;
-		} else {
-			if (req.nbd_device == NULL) {
-				SPDK_ERRLOG("missing nbd_device param\n");
-				goto invalid;
-			}
+		}
 
+		if (req.nbd_device) {
 			nbd = spdk_nbd_disk_find_by_nbd_path(req.nbd_device);
 			if (nbd == NULL) {
 				SPDK_ERRLOG("nbd device '%s' does not exist\n", req.nbd_device);
@@ -304,4 +301,4 @@ invalid:
 
 	free_rpc_get_nbd_disks(&req);
 }
-SPDK_RPC_REGISTER("get_nbd_disks", spdk_rpc_get_nbd_disks)
+SPDK_RPC_REGISTER("get_nbd_disks", spdk_rpc_get_nbd_disks, SPDK_RPC_RUNTIME)
diff --git a/lib/net/Makefile b/lib/net/Makefile
index 39b52d48a..6431e7bea 100644
--- a/lib/net/Makefile
+++ b/lib/net/Makefile
@@ -34,11 +34,8 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-C_SRCS = interface.c sock.c net_framework.c net_rpc.c
+C_SRCS = interface.c net_rpc.c
 
 LIBNAME = net
 
-DIRS-y += posix
-DIRS-$(CONFIG_VPP) += vpp
-
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/net/net_rpc.c b/lib/net/net_rpc.c
index e4c0ec339..aaaf6865e 100644
--- a/lib/net/net_rpc.c
+++ b/lib/net/net_rpc.c
@@ -90,7 +90,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_ip_address(&req);
 }
-SPDK_RPC_REGISTER("add_ip_address", spdk_rpc_add_ip_address)
+SPDK_RPC_REGISTER("add_ip_address", spdk_rpc_add_ip_address, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_delete_ip_address(struct spdk_jsonrpc_request *request,
@@ -125,7 +125,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS, "Invalid parameters");
 	free_rpc_ip_address(&req);
 }
-SPDK_RPC_REGISTER("delete_ip_address", spdk_rpc_delete_ip_address)
+SPDK_RPC_REGISTER("delete_ip_address", spdk_rpc_delete_ip_address, SPDK_RPC_RUNTIME)
 
 static void
 spdk_rpc_get_interfaces(struct spdk_jsonrpc_request *request,
@@ -175,6 +175,6 @@ spdk_rpc_get_interfaces(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_interfaces", spdk_rpc_get_interfaces)
+SPDK_RPC_REGISTER("get_interfaces", spdk_rpc_get_interfaces, SPDK_RPC_RUNTIME)
 
 SPDK_LOG_REGISTER_COMPONENT("net", SPDK_LOG_NET)
diff --git a/lib/nvme/Makefile b/lib/nvme/Makefile
index fe04ad68b..1a7bb852a 100644
--- a/lib/nvme/Makefile
+++ b/lib/nvme/Makefile
@@ -34,7 +34,8 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-C_SRCS = nvme_ctrlr_cmd.c nvme_ctrlr.c nvme_ns_cmd.c nvme_ns.c nvme_pcie.c nvme_qpair.c nvme.c nvme_quirks.c nvme_transport.c nvme_uevent.c
+C_SRCS = nvme_ctrlr_cmd.c nvme_ctrlr.c nvme_fabric.c nvme_ns_cmd.c nvme_ns.c nvme_pcie.c nvme_qpair.c nvme.c nvme_quirks.c nvme_transport.c nvme_uevent.c nvme_ctrlr_ocssd_cmd.c \
+	nvme_ns_ocssd_cmd.c
 C_SRCS-$(CONFIG_RDMA) += nvme_rdma.c
 LIBNAME = nvme
 
diff --git a/lib/nvme/nvme.c b/lib/nvme/nvme.c
index 123dc8a4c..24c199472 100644
--- a/lib/nvme/nvme.c
+++ b/lib/nvme/nvme.c
@@ -37,7 +37,7 @@
 #define SPDK_NVME_DRIVER_NAME "spdk_nvme_driver"
 
 struct nvme_driver	*g_spdk_nvme_driver;
-static pid_t g_pid;
+pid_t			g_spdk_nvme_pid;
 
 int32_t			spdk_nvme_retry_count;
 
@@ -99,57 +99,47 @@ nvme_completion_poll_cb(void *arg, const struct spdk_nvme_cpl *cpl)
 	status->done = true;
 }
 
-struct nvme_request *
-nvme_allocate_request(struct spdk_nvme_qpair *qpair,
-		      const struct nvme_payload *payload, uint32_t payload_size,
-		      spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+/**
+ * Poll qpair for completions until a command completes.
+ *
+ * \param qpair queue to poll
+ * \param status completion status
+ * \param robust_mutex optional robust mutex to lock while polling qpair
+ *
+ * \return 0 if command completed without error, negative errno on failure
+ *
+ * The command to wait upon must be submitted with nvme_completion_poll_cb as the callback
+ * and status as the callback argument.
+ */
+int
+spdk_nvme_wait_for_completion_robust_lock(
+	struct spdk_nvme_qpair *qpair,
+	struct nvme_completion_poll_status *status,
+	pthread_mutex_t *robust_mutex)
 {
-	struct nvme_request *req;
-
-	req = STAILQ_FIRST(&qpair->free_req);
-	if (req == NULL) {
-		return req;
-	}
+	memset(&status->cpl, 0, sizeof(status->cpl));
+	status->done = false;
 
-	STAILQ_REMOVE_HEAD(&qpair->free_req, stailq);
-
-	/*
-	 * Only memset up to (but not including) the children
-	 *  TAILQ_ENTRY.  children, and following members, are
-	 *  only used as part of I/O splitting so we avoid
-	 *  memsetting them until it is actually needed.
-	 *  They will be initialized in nvme_request_add_child()
-	 *  if the request is split.
-	 */
-	memset(req, 0, offsetof(struct nvme_request, children));
-	req->cb_fn = cb_fn;
-	req->cb_arg = cb_arg;
-	req->payload = *payload;
-	req->payload_size = payload_size;
-	req->qpair = qpair;
-	req->pid = g_pid;
-
-	return req;
-}
+	while (status->done == false) {
+		if (robust_mutex) {
+			nvme_robust_mutex_lock(robust_mutex);
+		}
 
-struct nvme_request *
-nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair,
-			     void *buffer, uint32_t payload_size,
-			     spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	struct nvme_payload payload;
+		spdk_nvme_qpair_process_completions(qpair, 0);
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = NULL;
+		if (robust_mutex) {
+			nvme_robust_mutex_unlock(robust_mutex);
+		}
+	}
 
-	return nvme_allocate_request(qpair, &payload, payload_size, cb_fn, cb_arg);
+	return spdk_nvme_cpl_is_error(&status->cpl) ? -EIO : 0;
 }
 
-struct nvme_request *
-nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+int
+spdk_nvme_wait_for_completion(struct spdk_nvme_qpair *qpair,
+			      struct nvme_completion_poll_status *status)
 {
-	return nvme_allocate_request_contig(qpair, NULL, 0, cb_fn, cb_arg);
+	return spdk_nvme_wait_for_completion_robust_lock(qpair, status, NULL);
 }
 
 static void
@@ -160,15 +150,15 @@ nvme_user_copy_cmd_complete(void *arg, const struct spdk_nvme_cpl *cpl)
 
 	if (req->user_buffer && req->payload_size) {
 		/* Copy back to the user buffer and free the contig buffer */
-		assert(req->payload.type == NVME_PAYLOAD_TYPE_CONTIG);
+		assert(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_CONTIG);
 		xfer = spdk_nvme_opc_get_data_transfer(req->cmd.opc);
 		if (xfer == SPDK_NVME_DATA_CONTROLLER_TO_HOST ||
 		    xfer == SPDK_NVME_DATA_BIDIRECTIONAL) {
 			assert(req->pid == getpid());
-			memcpy(req->user_buffer, req->payload.u.contig, req->payload_size);
+			memcpy(req->user_buffer, req->payload.contig_or_cb_arg, req->payload_size);
 		}
 
-		spdk_dma_free(req->payload.u.contig);
+		spdk_dma_free(req->payload.contig_or_cb_arg);
 	}
 
 	/* Call the user's original callback now that the buffer has been copied */
@@ -176,7 +166,7 @@ nvme_user_copy_cmd_complete(void *arg, const struct spdk_nvme_cpl *cpl)
 }
 
 /**
- * Allocate a request as well as a physically contiguous buffer to copy to/from the user's buffer.
+ * Allocate a request as well as a DMA-capable buffer to copy to/from the user's buffer.
  *
  * This is intended for use in non-fast-path functions (admin commands, reservations, etc.)
  * where the overhead of a copy is not a problem.
@@ -187,24 +177,24 @@ nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair,
 				void *cb_arg, bool host_to_controller)
 {
 	struct nvme_request *req;
-	void *contig_buffer = NULL;
+	void *dma_buffer = NULL;
 	uint64_t phys_addr;
 
 	if (buffer && payload_size) {
-		contig_buffer = spdk_dma_zmalloc(payload_size, 4096, &phys_addr);
-		if (!contig_buffer) {
+		dma_buffer = spdk_dma_zmalloc(payload_size, 4096, &phys_addr);
+		if (!dma_buffer) {
 			return NULL;
 		}
 
 		if (host_to_controller) {
-			memcpy(contig_buffer, buffer, payload_size);
+			memcpy(dma_buffer, buffer, payload_size);
 		}
 	}
 
-	req = nvme_allocate_request_contig(qpair, contig_buffer, payload_size, nvme_user_copy_cmd_complete,
+	req = nvme_allocate_request_contig(qpair, dma_buffer, payload_size, nvme_user_copy_cmd_complete,
 					   NULL);
 	if (!req) {
-		spdk_dma_free(contig_buffer);
+		spdk_dma_free(dma_buffer);
 		return NULL;
 	}
 
@@ -216,14 +206,57 @@ nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair,
 	return req;
 }
 
-void
-nvme_free_request(struct nvme_request *req)
+/**
+ * Check if a request has exceeded the controller timeout.
+ *
+ * \param req request to check for timeout.
+ * \param cid command ID for command submitted by req (will be passed to timeout_cb_fn)
+ * \param active_proc per-process data for the controller associated with req
+ * \param now_tick current time from spdk_get_ticks()
+ * \return 0 if requests submitted more recently than req should still be checked for timeouts, or
+ * 1 if requests newer than req need not be checked.
+ *
+ * The request's timeout callback will be called if needed; the caller is only responsible for
+ * calling this function on each outstanding request.
+ */
+int
+nvme_request_check_timeout(struct nvme_request *req, uint16_t cid,
+			   struct spdk_nvme_ctrlr_process *active_proc,
+			   uint64_t now_tick)
 {
-	assert(req != NULL);
-	assert(req->num_children == 0);
-	assert(req->qpair != NULL);
+	struct spdk_nvme_qpair *qpair = req->qpair;
+	struct spdk_nvme_ctrlr *ctrlr = qpair->ctrlr;
 
-	STAILQ_INSERT_HEAD(&req->qpair->free_req, req, stailq);
+	assert(active_proc->timeout_cb_fn != NULL);
+
+	if (req->timed_out || req->submit_tick == 0) {
+		return 0;
+	}
+
+	if (req->pid != g_spdk_nvme_pid) {
+		return 0;
+	}
+
+	if (nvme_qpair_is_admin_queue(qpair) &&
+	    req->cmd.opc == SPDK_NVME_OPC_ASYNC_EVENT_REQUEST) {
+		return 0;
+	}
+
+	if (req->submit_tick + active_proc->timeout_ticks > now_tick) {
+		return 1;
+	}
+
+	req->timed_out = true;
+
+	/*
+	 * We don't want to expose the admin queue to the user,
+	 * so when we're timing out admin commands set the
+	 * qpair to NULL.
+	 */
+	active_proc->timeout_cb_fn(active_proc->timeout_cb_arg, ctrlr,
+				   nvme_qpair_is_admin_queue(qpair) ? NULL : qpair,
+				   cid);
+	return 0;
 }
 
 int
@@ -250,7 +283,7 @@ nvme_robust_mutex_init_shared(pthread_mutex_t *mtx)
 	return rc;
 }
 
-static int
+int
 nvme_driver_init(void)
 {
 	int ret = 0;
@@ -258,7 +291,7 @@ nvme_driver_init(void)
 	int socket_id = -1;
 
 	/* Each process needs its own pid. */
-	g_pid = getpid();
+	g_spdk_nvme_pid = getpid();
 
 	/*
 	 * Only one thread from one process will do this driver init work.
@@ -269,12 +302,11 @@ nvme_driver_init(void)
 	if (spdk_process_is_primary()) {
 		/* The unique named memzone already reserved. */
 		if (g_spdk_nvme_driver != NULL) {
-			assert(g_spdk_nvme_driver->initialized == true);
-
 			return 0;
 		} else {
 			g_spdk_nvme_driver = spdk_memzone_reserve(SPDK_NVME_DRIVER_NAME,
-					     sizeof(struct nvme_driver), socket_id, 0);
+					     sizeof(struct nvme_driver), socket_id,
+					     SPDK_MEMZONE_NO_IOVA_CONTIG);
 		}
 
 		if (g_spdk_nvme_driver == NULL) {
@@ -614,6 +646,8 @@ spdk_nvme_transport_id_parse_trtype(enum spdk_nvme_transport_type *trtype, const
 		*trtype = SPDK_NVME_TRANSPORT_PCIE;
 	} else if (strcasecmp(str, "RDMA") == 0) {
 		*trtype = SPDK_NVME_TRANSPORT_RDMA;
+	} else if (strcasecmp(str, "FC") == 0) {
+		*trtype = SPDK_NVME_TRANSPORT_FC;
 	} else {
 		return -ENOENT;
 	}
@@ -628,6 +662,8 @@ spdk_nvme_transport_id_trtype_str(enum spdk_nvme_transport_type trtype)
 		return "PCIe";
 	case SPDK_NVME_TRANSPORT_RDMA:
 		return "RDMA";
+	case SPDK_NVME_TRANSPORT_FC:
+		return "FC";
 	default:
 		return NULL;
 	}
diff --git a/lib/nvme/nvme_ctrlr.c b/lib/nvme/nvme_ctrlr.c
index 4d8adfa8a..3386dc494 100644
--- a/lib/nvme/nvme_ctrlr.c
+++ b/lib/nvme/nvme_ctrlr.c
@@ -62,7 +62,7 @@ nvme_ctrlr_get_cap(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_cap_register *
 					      &cap->raw);
 }
 
-static int
+int
 nvme_ctrlr_get_vs(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_vs_register *vs)
 {
 	return nvme_transport_ctrlr_get_reg_4(ctrlr, offsetof(struct spdk_nvme_registers, vs.raw),
@@ -116,15 +116,17 @@ spdk_nvme_ctrlr_get_default_ctrlr_opts(struct spdk_nvme_ctrlr_opts *opts, size_t
 		memset(opts->host_id, 0, sizeof(opts->host_id));
 	}
 
-	if (FIELD_OK(extended_host_id)) {
-		memcpy(opts->extended_host_id, &g_spdk_nvme_driver->default_extended_host_id,
-		       sizeof(opts->extended_host_id));
-	}
+	if (nvme_driver_init() == 0) {
+		if (FIELD_OK(extended_host_id)) {
+			memcpy(opts->extended_host_id, &g_spdk_nvme_driver->default_extended_host_id,
+			       sizeof(opts->extended_host_id));
+		}
 
-	if (FIELD_OK(hostnqn)) {
-		spdk_uuid_fmt_lower(host_id_str, sizeof(host_id_str),
-				    &g_spdk_nvme_driver->default_extended_host_id);
-		snprintf(opts->hostnqn, sizeof(opts->hostnqn), "2014-08.org.nvmexpress:uuid:%s", host_id_str);
+		if (FIELD_OK(hostnqn)) {
+			spdk_uuid_fmt_lower(host_id_str, sizeof(host_id_str),
+					    &g_spdk_nvme_driver->default_extended_host_id);
+			snprintf(opts->hostnqn, sizeof(opts->hostnqn), "2014-08.org.nvmexpress:uuid:%s", host_id_str);
+		}
 	}
 
 	if (FIELD_OK(src_addr)) {
@@ -134,6 +136,10 @@ spdk_nvme_ctrlr_get_default_ctrlr_opts(struct spdk_nvme_ctrlr_opts *opts, size_t
 	if (FIELD_OK(src_svcid)) {
 		memset(opts->src_svcid, 0, sizeof(opts->src_svcid));
 	}
+
+	if (FIELD_OK(command_set)) {
+		opts->command_set = SPDK_NVME_CC_CSS_NVM;
+	}
 #undef FIELD_OK
 }
 
@@ -146,15 +152,11 @@ nvme_ctrlr_proc_add_io_qpair(struct spdk_nvme_qpair *qpair)
 {
 	struct spdk_nvme_ctrlr_process	*active_proc;
 	struct spdk_nvme_ctrlr		*ctrlr = qpair->ctrlr;
-	pid_t				pid = getpid();
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			TAILQ_INSERT_TAIL(&active_proc->allocated_io_qpairs, qpair,
-					  per_process_tailq);
-			qpair->active_proc = active_proc;
-			break;
-		}
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		TAILQ_INSERT_TAIL(&active_proc->allocated_io_qpairs, qpair, per_process_tailq);
+		qpair->active_proc = active_proc;
 	}
 }
 
@@ -168,17 +170,9 @@ nvme_ctrlr_proc_remove_io_qpair(struct spdk_nvme_qpair *qpair)
 	struct spdk_nvme_ctrlr_process	*active_proc;
 	struct spdk_nvme_ctrlr		*ctrlr = qpair->ctrlr;
 	struct spdk_nvme_qpair          *active_qpair, *tmp_qpair;
-	pid_t				pid = getpid();
-	bool				proc_found = false;
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			proc_found = true;
-			break;
-		}
-	}
-
-	if (proc_found == false) {
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (!active_proc) {
 		return;
 	}
 
@@ -303,7 +297,6 @@ int
 spdk_nvme_ctrlr_free_io_qpair(struct spdk_nvme_qpair *qpair)
 {
 	struct spdk_nvme_ctrlr *ctrlr;
-	void *req_buf;
 
 	if (qpair == NULL) {
 		return 0;
@@ -329,15 +322,11 @@ spdk_nvme_ctrlr_free_io_qpair(struct spdk_nvme_qpair *qpair)
 	TAILQ_REMOVE(&ctrlr->active_io_qpairs, qpair, tailq);
 	spdk_bit_array_set(ctrlr->free_io_qids, qpair->id);
 
-	req_buf = qpair->req_buf;
-
 	if (nvme_transport_ctrlr_delete_io_qpair(ctrlr, qpair)) {
 		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
 		return -1;
 	}
 
-	spdk_dma_free(req_buf);
-
 	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
 	return 0;
 }
@@ -388,15 +377,11 @@ static int nvme_ctrlr_set_intel_support_log_pages(struct spdk_nvme_ctrlr *ctrlr)
 		return -ENXIO;
 	}
 
-	status.done = false;
 	spdk_nvme_ctrlr_cmd_get_log_page(ctrlr, SPDK_NVME_INTEL_LOG_PAGE_DIRECTORY, SPDK_NVME_GLOBAL_NS_TAG,
 					 log_page_directory, sizeof(struct spdk_nvme_intel_log_page_directory), 0,
 					 nvme_completion_poll_cb,
 					 &status);
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		spdk_dma_free(log_page_directory);
 		SPDK_ERRLOG("nvme_ctrlr_cmd_get_log_page failed!\n");
 		return -ENXIO;
@@ -565,6 +550,20 @@ nvme_ctrlr_enable(struct spdk_nvme_ctrlr *ctrlr)
 	/* Page size is 2 ^ (12 + mps). */
 	cc.bits.mps = spdk_u32log2(ctrlr->page_size) - 12;
 
+	if (ctrlr->cap.bits.css == 0) {
+		SPDK_INFOLOG(SPDK_LOG_NVME,
+			     "Drive reports no command sets supported. Assuming NVM is supported.\n");
+		ctrlr->cap.bits.css = SPDK_NVME_CAP_CSS_NVM;
+	}
+
+	if (!(ctrlr->cap.bits.css & (1u << ctrlr->opts.command_set))) {
+		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Requested I/O command set %u but supported mask is 0x%x\n",
+			      ctrlr->opts.command_set, ctrlr->cap.bits.css);
+		return -EINVAL;
+	}
+
+	cc.bits.css = ctrlr->opts.command_set;
+
 	switch (ctrlr->opts.arb_mechanism) {
 	case SPDK_NVME_CC_AMS_RR:
 		break;
@@ -667,17 +666,13 @@ nvme_ctrlr_set_doorbell_buffer_config(struct spdk_nvme_ctrlr *ctrlr)
 		goto error;
 	}
 
-	status.done = false;
 	rc = nvme_ctrlr_cmd_doorbell_buffer_config(ctrlr, prp1, prp2,
 			nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		goto error;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		goto error;
 	}
 
@@ -765,7 +760,6 @@ nvme_ctrlr_identify(struct spdk_nvme_ctrlr *ctrlr)
 	struct nvme_completion_poll_status	status;
 	int					rc;
 
-	status.done = false;
 	rc = nvme_ctrlr_cmd_identify(ctrlr, SPDK_NVME_IDENTIFY_CTRLR, 0, 0,
 				     &ctrlr->cdata, sizeof(ctrlr->cdata),
 				     nvme_completion_poll_cb, &status);
@@ -773,10 +767,7 @@ nvme_ctrlr_identify(struct spdk_nvme_ctrlr *ctrlr)
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("nvme_identify_controller failed!\n");
 		return -ENXIO;
 	}
@@ -793,6 +784,23 @@ nvme_ctrlr_identify(struct spdk_nvme_ctrlr *ctrlr)
 		SPDK_DEBUGLOG(SPDK_LOG_NVME, "MDTS max_xfer_size %u\n", ctrlr->max_xfer_size);
 	}
 
+	SPDK_DEBUGLOG(SPDK_LOG_NVME, "CNTLID 0x%04" PRIx16 "\n", ctrlr->cdata.cntlid);
+	if (ctrlr->trid.trtype == SPDK_NVME_TRANSPORT_PCIE) {
+		ctrlr->cntlid = ctrlr->cdata.cntlid;
+	} else {
+		/*
+		 * Fabrics controllers should already have CNTLID from the Connect command.
+		 *
+		 * If CNTLID from Connect doesn't match CNTLID in the Identify Controller data,
+		 * trust the one from Connect.
+		 */
+		if (ctrlr->cntlid != ctrlr->cdata.cntlid) {
+			SPDK_DEBUGLOG(SPDK_LOG_NVME,
+				      "Identify CNTLID 0x%04" PRIx16 " != Connect CNTLID 0x%04" PRIx16 "\n",
+				      ctrlr->cdata.cntlid, ctrlr->cntlid);
+		}
+	}
+
 	return 0;
 }
 
@@ -818,25 +826,20 @@ nvme_ctrlr_identify_active_ns(struct spdk_nvme_ctrlr *ctrlr)
 		SPDK_ERRLOG("Failed to allocate active_ns_list!\n");
 		return -ENOMEM;
 	}
-	status.done = false;
-	if (SPDK_NVME_VERSION(ctrlr->cdata.ver.bits.mjr, ctrlr->cdata.ver.bits.mnr,
-			      ctrlr->cdata.ver.bits.ter) >= SPDK_NVME_VERSION(1, 1, 0)) {
+
+	if (ctrlr->vs.raw >= SPDK_NVME_VERSION(1, 1, 0) && !(ctrlr->quirks & NVME_QUIRK_IDENTIFY_CNS)) {
 		/*
 		 * Iterate through the pages and fetch each chunk of 1024 namespaces until
 		 * there are no more active namespaces
 		 */
 		for (i = 0; i < num_pages; i++) {
-			status.done = false;
 			rc = nvme_ctrlr_cmd_identify(ctrlr, SPDK_NVME_IDENTIFY_ACTIVE_NS_LIST, 0, next_nsid,
 						     &new_ns_list[1024 * i], sizeof(struct spdk_nvme_ns_list),
 						     nvme_completion_poll_cb, &status);
 			if (rc != 0) {
 				goto fail;
 			}
-			while (status.done == false) {
-				spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-			}
-			if (spdk_nvme_cpl_is_error(&status.cpl)) {
+			if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 				SPDK_ERRLOG("nvme_ctrlr_cmd_identify_active_ns_list failed!\n");
 				rc = -ENXIO;
 				goto fail;
@@ -880,8 +883,6 @@ nvme_ctrlr_set_num_qpairs(struct spdk_nvme_ctrlr *ctrlr)
 	uint32_t cq_allocated, sq_allocated, min_allocated, i;
 	int rc;
 
-	status.done = false;
-
 	if (ctrlr->opts.num_io_queues > SPDK_NVME_MAX_IO_QUEUES) {
 		SPDK_NOTICELOG("Limiting requested num_io_queues %u to max %d\n",
 			       ctrlr->opts.num_io_queues, SPDK_NVME_MAX_IO_QUEUES);
@@ -897,24 +898,17 @@ nvme_ctrlr_set_num_qpairs(struct spdk_nvme_ctrlr *ctrlr)
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("Set Features - Number of Queues failed!\n");
 	}
 
 	/* Obtain the number of queues allocated using Get Features. */
-	status.done = false;
 	rc = nvme_ctrlr_cmd_get_num_queues(ctrlr, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("Get Features - Number of Queues failed!\n");
 		ctrlr->opts.num_io_queues = 0;
 	} else {
@@ -968,7 +962,6 @@ nvme_ctrlr_set_keep_alive_timeout(struct spdk_nvme_ctrlr *ctrlr)
 	}
 
 	/* Retrieve actual keep alive timeout, since the controller may have adjusted it. */
-	status.done = false;
 	rc = spdk_nvme_ctrlr_cmd_get_feature(ctrlr, SPDK_NVME_FEAT_KEEP_ALIVE_TIMER, 0, NULL, 0,
 					     nvme_completion_poll_cb, &status);
 	if (rc != 0) {
@@ -977,10 +970,7 @@ nvme_ctrlr_set_keep_alive_timeout(struct spdk_nvme_ctrlr *ctrlr)
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("Keep alive timeout Get Feature failed: SC %x SCT %x\n",
 			    status.cpl.status.sc, status.cpl.status.sct);
 		ctrlr->opts.keep_alive_timeout_ms = 0;
@@ -1044,17 +1034,13 @@ nvme_ctrlr_set_host_id(struct spdk_nvme_ctrlr *ctrlr)
 
 	SPDK_TRACEDUMP(SPDK_LOG_NVME, "host_id", host_id, host_id_size);
 
-	status.done = false;
 	rc = nvme_ctrlr_cmd_set_host_id(ctrlr, host_id, host_id_size, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		SPDK_ERRLOG("Set Features - Host ID failed: %d\n", rc);
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_WARNLOG("Set Features - Host ID failed: SC 0x%x SCT 0x%x\n",
 			     status.cpl.status.sc, status.cpl.status.sct);
 		/*
@@ -1093,9 +1079,38 @@ nvme_ctrlr_destruct_namespaces(struct spdk_nvme_ctrlr *ctrlr)
 }
 
 static int
-nvme_ctrlr_construct_namespaces(struct spdk_nvme_ctrlr *ctrlr)
+nvme_ctrlr_update_namespaces(struct spdk_nvme_ctrlr *ctrlr)
 {
 	uint32_t i, nn = ctrlr->cdata.nn;
+	struct spdk_nvme_ns_data *nsdata;
+
+	if (nvme_ctrlr_identify_active_ns(ctrlr)) {
+		return -1;
+	}
+
+	for (i = 0; i < nn; i++) {
+		struct spdk_nvme_ns	*ns = &ctrlr->ns[i];
+		uint32_t		nsid = i + 1;
+		nsdata			= &ctrlr->nsdata[nsid - 1];
+
+		if ((nsdata->ncap == 0) && spdk_nvme_ctrlr_is_active_ns(ctrlr, nsid)) {
+			if (nvme_ns_construct(ns, nsid, ctrlr) != 0) {
+				continue;
+			}
+		}
+
+		if (nsdata->ncap && !spdk_nvme_ctrlr_is_active_ns(ctrlr, nsid)) {
+			nvme_ns_destruct(ns);
+		}
+	}
+
+	return 0;
+}
+
+static int
+nvme_ctrlr_construct_namespaces(struct spdk_nvme_ctrlr *ctrlr)
+{
+	uint32_t nn = ctrlr->cdata.nn;
 	uint64_t phys_addr = 0;
 
 	/* ctrlr->num_ns may be 0 (startup) or a different number of namespaces (reset),
@@ -1124,19 +1139,9 @@ nvme_ctrlr_construct_namespaces(struct spdk_nvme_ctrlr *ctrlr)
 		ctrlr->num_ns = nn;
 	}
 
-	if (nvme_ctrlr_identify_active_ns(ctrlr)) {
+	if (nvme_ctrlr_update_namespaces(ctrlr)) {
 		goto fail;
 	}
-
-	for (i = 0; i < nn; i++) {
-		struct spdk_nvme_ns	*ns = &ctrlr->ns[i];
-		uint32_t		nsid = i + 1;
-
-		if (nvme_ns_construct(ns, nsid, ctrlr) != 0) {
-			goto fail;
-		}
-	}
-
 	return 0;
 
 fail:
@@ -1149,6 +1154,8 @@ nvme_ctrlr_async_event_cb(void *arg, const struct spdk_nvme_cpl *cpl)
 {
 	struct nvme_async_event_request	*aer = arg;
 	struct spdk_nvme_ctrlr		*ctrlr = aer->ctrlr;
+	struct spdk_nvme_ctrlr_process	*active_proc;
+	union spdk_nvme_async_event_completion	event;
 
 	if (cpl->status.sc == SPDK_NVME_SC_ABORTED_SQ_DELETION) {
 		/*
@@ -1160,8 +1167,15 @@ nvme_ctrlr_async_event_cb(void *arg, const struct spdk_nvme_cpl *cpl)
 		return;
 	}
 
-	if (ctrlr->aer_cb_fn != NULL) {
-		ctrlr->aer_cb_fn(ctrlr->aer_cb_arg, cpl);
+	event.raw = cpl->cdw0;
+	if ((event.bits.async_event_type == SPDK_NVME_ASYNC_EVENT_TYPE_NOTICE) &&
+	    (event.bits.async_event_info == SPDK_NVME_ASYNC_EVENT_NS_ATTR_CHANGED)) {
+		nvme_ctrlr_update_namespaces(ctrlr);
+	}
+
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc && active_proc->aer_cb_fn) {
+		active_proc->aer_cb_fn(active_proc->aer_cb_arg, cpl);
 	}
 
 	/*
@@ -1197,13 +1211,10 @@ nvme_ctrlr_construct_and_submit_aer(struct spdk_nvme_ctrlr *ctrlr,
 static int
 _nvme_ctrlr_configure_aer(struct spdk_nvme_ctrlr *ctrlr)
 {
-	const struct spdk_nvme_ctrlr_data		*cdata;
 	union spdk_nvme_feat_async_event_configuration	config;
 	struct nvme_completion_poll_status		status;
 	int						rc;
 
-	cdata = spdk_nvme_ctrlr_get_data(ctrlr);
-
 	config.raw = 0;
 	config.bits.crit_warn.bits.available_spare = 1;
 	config.bits.crit_warn.bits.temperature = 1;
@@ -1211,7 +1222,7 @@ _nvme_ctrlr_configure_aer(struct spdk_nvme_ctrlr *ctrlr)
 	config.bits.crit_warn.bits.read_only = 1;
 	config.bits.crit_warn.bits.volatile_memory_backup = 1;
 
-	if (cdata->ver.raw >= SPDK_NVME_VERSION(1, 2, 0)) {
+	if (ctrlr->vs.raw >= SPDK_NVME_VERSION(1, 2, 0)) {
 		if (ctrlr->cdata.oaes.ns_attribute_notices) {
 			config.bits.ns_attr_notice = 1;
 		}
@@ -1219,20 +1230,16 @@ _nvme_ctrlr_configure_aer(struct spdk_nvme_ctrlr *ctrlr)
 			config.bits.fw_activation_notice = 1;
 		}
 	}
-	if (cdata->ver.raw >= SPDK_NVME_VERSION(1, 3, 0) && cdata->lpa.telemetry) {
+	if (ctrlr->vs.raw >= SPDK_NVME_VERSION(1, 3, 0) && ctrlr->cdata.lpa.telemetry) {
 		config.bits.telemetry_log_notice = 1;
 	}
 
-	status.done = false;
 	rc = nvme_ctrlr_cmd_set_async_event_config(ctrlr, config, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		return -ENXIO;
 	}
 
@@ -1266,6 +1273,26 @@ nvme_ctrlr_configure_aer(struct spdk_nvme_ctrlr *ctrlr)
 	return 0;
 }
 
+struct spdk_nvme_ctrlr_process *
+spdk_nvme_ctrlr_get_process(struct spdk_nvme_ctrlr *ctrlr, pid_t pid)
+{
+	struct spdk_nvme_ctrlr_process	*active_proc;
+
+	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
+		if (active_proc->pid == pid) {
+			return active_proc;
+		}
+	}
+
+	return NULL;
+}
+
+struct spdk_nvme_ctrlr_process *
+spdk_nvme_ctrlr_get_current_process(struct spdk_nvme_ctrlr *ctrlr)
+{
+	return spdk_nvme_ctrlr_get_process(ctrlr, getpid());
+}
+
 /**
  * This function will be called when a process is using the controller.
  *  1. For the primary process, it is called when constructing the controller.
@@ -1275,14 +1302,12 @@ nvme_ctrlr_configure_aer(struct spdk_nvme_ctrlr *ctrlr)
 int
 nvme_ctrlr_add_process(struct spdk_nvme_ctrlr *ctrlr, void *devhandle)
 {
-	struct spdk_nvme_ctrlr_process	*ctrlr_proc, *active_proc;
+	struct spdk_nvme_ctrlr_process	*ctrlr_proc;
 	pid_t				pid = getpid();
 
 	/* Check whether the process is already added or not */
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			return 0;
-		}
+	if (spdk_nvme_ctrlr_get_process(ctrlr, pid)) {
+		return 0;
 	}
 
 	/* Initialize the per process properties for this ctrlr */
@@ -1415,17 +1440,14 @@ void
 nvme_ctrlr_proc_get_ref(struct spdk_nvme_ctrlr *ctrlr)
 {
 	struct spdk_nvme_ctrlr_process	*active_proc;
-	pid_t				pid = getpid();
 
 	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
 
 	nvme_ctrlr_remove_inactive_proc(ctrlr);
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			active_proc->ref++;
-			break;
-		}
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		active_proc->ref++;
 	}
 
 	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
@@ -1434,28 +1456,24 @@ nvme_ctrlr_proc_get_ref(struct spdk_nvme_ctrlr *ctrlr)
 void
 nvme_ctrlr_proc_put_ref(struct spdk_nvme_ctrlr *ctrlr)
 {
-	struct spdk_nvme_ctrlr_process	*active_proc, *tmp;
-	pid_t				pid = getpid();
+	struct spdk_nvme_ctrlr_process	*active_proc;
 	int				proc_count;
 
 	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
 
 	proc_count = nvme_ctrlr_remove_inactive_proc(ctrlr);
 
-	TAILQ_FOREACH_SAFE(active_proc, &ctrlr->active_procs, tailq, tmp) {
-		if (active_proc->pid == pid) {
-			active_proc->ref--;
-			assert(active_proc->ref >= 0);
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		active_proc->ref--;
+		assert(active_proc->ref >= 0);
 
-			/*
-			 * The last active process will be removed at the end of
-			 * the destruction of the controller.
-			 */
-			if (active_proc->ref == 0 && proc_count != 1) {
-				nvme_ctrlr_remove_process(ctrlr, active_proc);
-			}
-
-			break;
+		/*
+		 * The last active process will be removed at the end of
+		 * the destruction of the controller.
+		 */
+		if (active_proc->ref == 0 && proc_count != 1) {
+			nvme_ctrlr_remove_process(ctrlr, active_proc);
 		}
 	}
 
@@ -1488,16 +1506,13 @@ struct spdk_pci_device *
 nvme_ctrlr_proc_get_devhandle(struct spdk_nvme_ctrlr *ctrlr)
 {
 	struct spdk_nvme_ctrlr_process	*active_proc;
-	pid_t				pid = getpid();
 	struct spdk_pci_device		*devhandle = NULL;
 
 	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			devhandle = active_proc->devhandle;
-			break;
-		}
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		devhandle = active_proc->devhandle;
 	}
 
 	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
@@ -1574,12 +1589,12 @@ nvme_ctrlr_process_init(struct spdk_nvme_ctrlr *ctrlr)
 			nvme_ctrlr_set_state(ctrlr, NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_0, ready_timeout_in_ms);
 
 			/*
-			 * Wait 2 secsonds before accessing PCI registers.
+			 * Wait 2.5 seconds before accessing PCI registers.
 			 * Not using sleep() to avoid blocking other controller's initialization.
 			 */
 			if (ctrlr->quirks & NVME_QUIRK_DELAY_BEFORE_CHK_RDY) {
-				SPDK_DEBUGLOG(SPDK_LOG_NVME, "Applying quirk: delay 2 seconds before reading registers\n");
-				ctrlr->sleep_timeout_tsc = spdk_get_ticks() + 2 * spdk_get_ticks_hz();
+				SPDK_DEBUGLOG(SPDK_LOG_NVME, "Applying quirk: delay 2.5 seconds before reading registers\n");
+				ctrlr->sleep_timeout_tsc = spdk_get_ticks() + (2500 * spdk_get_ticks_hz() / 1000);
 			}
 			return 0;
 		} else {
@@ -1759,9 +1774,11 @@ nvme_ctrlr_construct(struct spdk_nvme_ctrlr *ctrlr)
 
 /* This function should be called once at ctrlr initialization to set up constant properties. */
 void
-nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap)
+nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap,
+		    const union spdk_nvme_vs_register *vs)
 {
 	ctrlr->cap = *cap;
+	ctrlr->vs = *vs;
 
 	ctrlr->min_page_size = 1u << (12 + ctrlr->cap.bits.mpsmin);
 
@@ -1769,6 +1786,7 @@ nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_reg
 	ctrlr->page_size = ctrlr->min_page_size;
 
 	ctrlr->opts.io_queue_size = spdk_max(ctrlr->opts.io_queue_size, SPDK_NVME_IO_QUEUE_MIN_ENTRIES);
+	ctrlr->opts.io_queue_size = spdk_min(ctrlr->opts.io_queue_size, MAX_IO_QUEUE_ENTRIES);
 	ctrlr->opts.io_queue_size = spdk_min(ctrlr->opts.io_queue_size, ctrlr->cap.bits.mqes + 1u);
 
 	ctrlr->opts.io_queue_requests = spdk_max(ctrlr->opts.io_queue_requests, ctrlr->opts.io_queue_size);
@@ -1885,12 +1903,7 @@ union spdk_nvme_cap_register spdk_nvme_ctrlr_get_regs_cap(struct spdk_nvme_ctrlr
 
 union spdk_nvme_vs_register spdk_nvme_ctrlr_get_regs_vs(struct spdk_nvme_ctrlr *ctrlr)
 {
-	union spdk_nvme_vs_register vs;
-
-	if (nvme_ctrlr_get_vs(ctrlr, &vs)) {
-		vs.raw = 0xFFFFFFFFu;
-	}
-	return vs;
+	return ctrlr->vs;
 }
 
 uint32_t
@@ -1976,33 +1989,48 @@ spdk_nvme_ctrlr_get_pci_device(struct spdk_nvme_ctrlr *ctrlr)
 	return nvme_ctrlr_proc_get_devhandle(ctrlr);
 }
 
+uint32_t
+spdk_nvme_ctrlr_get_max_xfer_size(const struct spdk_nvme_ctrlr *ctrlr)
+{
+	return ctrlr->max_xfer_size;
+}
+
 void
 spdk_nvme_ctrlr_register_aer_callback(struct spdk_nvme_ctrlr *ctrlr,
 				      spdk_nvme_aer_cb aer_cb_fn,
 				      void *aer_cb_arg)
 {
-	ctrlr->aer_cb_fn = aer_cb_fn;
-	ctrlr->aer_cb_arg = aer_cb_arg;
+	struct spdk_nvme_ctrlr_process *active_proc;
+
+	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
+
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		active_proc->aer_cb_fn = aer_cb_fn;
+		active_proc->aer_cb_arg = aer_cb_arg;
+	}
+
+	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
 }
 
 void
 spdk_nvme_ctrlr_register_timeout_callback(struct spdk_nvme_ctrlr *ctrlr,
-		uint32_t nvme_timeout, spdk_nvme_timeout_cb cb_fn, void *cb_arg)
+		uint64_t timeout_us, spdk_nvme_timeout_cb cb_fn, void *cb_arg)
 {
-	struct spdk_nvme_ctrlr_process	*active_proc = NULL;
-	pid_t				pid = getpid();
+	struct spdk_nvme_ctrlr_process	*active_proc;
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == pid) {
-			break;
-		}
+	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
+
+	active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (active_proc) {
+		active_proc->timeout_ticks = timeout_us * spdk_get_ticks_hz() / 1000000ULL;
+		active_proc->timeout_cb_fn = cb_fn;
+		active_proc->timeout_cb_arg = cb_arg;
 	}
 
-	assert(active_proc != NULL);
+	ctrlr->timeout_enabled = true;
 
-	active_proc->timeout_ticks = nvme_timeout * spdk_get_ticks_hz();
-	active_proc->timeout_cb_fn = cb_fn;
-	active_proc->timeout_cb_arg = cb_arg;
+	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
 }
 
 bool
@@ -2027,24 +2055,25 @@ spdk_nvme_ctrlr_attach_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
 {
 	struct nvme_completion_poll_status	status;
 	int					res;
+	struct spdk_nvme_ns			*ns;
 
-	status.done = false;
 	res = nvme_ctrlr_cmd_attach_ns(ctrlr, nsid, payload,
 				       nvme_completion_poll_cb, &status);
 	if (res) {
 		return res;
 	}
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 		SPDK_ERRLOG("spdk_nvme_ctrlr_attach_ns failed!\n");
 		return -ENXIO;
 	}
 
-	return spdk_nvme_ctrlr_reset(ctrlr);
+	res = nvme_ctrlr_identify_active_ns(ctrlr);
+	if (res) {
+		return res;
+	}
+
+	ns = &ctrlr->ns[nsid - 1];
+	return nvme_ns_construct(ns, nsid, ctrlr);
 }
 
 int
@@ -2053,24 +2082,28 @@ spdk_nvme_ctrlr_detach_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
 {
 	struct nvme_completion_poll_status	status;
 	int					res;
+	struct spdk_nvme_ns			*ns;
 
-	status.done = false;
 	res = nvme_ctrlr_cmd_detach_ns(ctrlr, nsid, payload,
 				       nvme_completion_poll_cb, &status);
 	if (res) {
 		return res;
 	}
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 		SPDK_ERRLOG("spdk_nvme_ctrlr_detach_ns failed!\n");
 		return -ENXIO;
 	}
 
-	return spdk_nvme_ctrlr_reset(ctrlr);
+	res = nvme_ctrlr_identify_active_ns(ctrlr);
+	if (res) {
+		return res;
+	}
+
+	ns = &ctrlr->ns[nsid - 1];
+	/* Inactive NS */
+	nvme_ns_destruct(ns);
+
+	return 0;
 }
 
 uint32_t
@@ -2078,29 +2111,28 @@ spdk_nvme_ctrlr_create_ns(struct spdk_nvme_ctrlr *ctrlr, struct spdk_nvme_ns_dat
 {
 	struct nvme_completion_poll_status	status;
 	int					res;
+	uint32_t				nsid;
+	struct spdk_nvme_ns			*ns;
 
-	status.done = false;
 	res = nvme_ctrlr_cmd_create_ns(ctrlr, payload, nvme_completion_poll_cb, &status);
 	if (res) {
 		return 0;
 	}
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 		SPDK_ERRLOG("spdk_nvme_ctrlr_create_ns failed!\n");
 		return 0;
 	}
 
-	res = spdk_nvme_ctrlr_reset(ctrlr);
+	nsid = status.cpl.cdw0;
+	ns = &ctrlr->ns[nsid - 1];
+	/* Inactive NS */
+	res = nvme_ns_construct(ns, nsid, ctrlr);
 	if (res) {
 		return 0;
 	}
 
 	/* Return the namespace ID that was created */
-	return status.cpl.cdw0;
+	return nsid;
 }
 
 int
@@ -2108,23 +2140,26 @@ spdk_nvme_ctrlr_delete_ns(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid)
 {
 	struct nvme_completion_poll_status	status;
 	int					res;
+	struct spdk_nvme_ns			*ns;
 
-	status.done = false;
 	res = nvme_ctrlr_cmd_delete_ns(ctrlr, nsid, nvme_completion_poll_cb, &status);
 	if (res) {
 		return res;
 	}
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 		SPDK_ERRLOG("spdk_nvme_ctrlr_delete_ns failed!\n");
 		return -ENXIO;
 	}
 
-	return spdk_nvme_ctrlr_reset(ctrlr);
+	res = nvme_ctrlr_identify_active_ns(ctrlr);
+	if (res) {
+		return res;
+	}
+
+	ns = &ctrlr->ns[nsid - 1];
+	nvme_ns_destruct(ns);
+
+	return 0;
 }
 
 int
@@ -2134,18 +2169,12 @@ spdk_nvme_ctrlr_format(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
 	struct nvme_completion_poll_status	status;
 	int					res;
 
-	status.done = false;
 	res = nvme_ctrlr_cmd_format(ctrlr, nsid, format, nvme_completion_poll_cb,
 				    &status);
 	if (res) {
 		return res;
 	}
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 		SPDK_ERRLOG("spdk_nvme_ctrlr_format failed!\n");
 		return -ENXIO;
 	}
@@ -2190,7 +2219,6 @@ spdk_nvme_ctrlr_update_firmware(struct spdk_nvme_ctrlr *ctrlr, void *payload, ui
 
 	while (size_remaining > 0) {
 		transfer = spdk_min(size_remaining, ctrlr->min_page_size);
-		status.done = false;
 
 		res = nvme_ctrlr_cmd_fw_image_download(ctrlr, transfer, offset, p,
 						       nvme_completion_poll_cb,
@@ -2199,12 +2227,7 @@ spdk_nvme_ctrlr_update_firmware(struct spdk_nvme_ctrlr *ctrlr, void *payload, ui
 			return res;
 		}
 
-		while (status.done == false) {
-			nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-			spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-			nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-		}
-		if (spdk_nvme_cpl_is_error(&status.cpl)) {
+		if (spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock)) {
 			SPDK_ERRLOG("spdk_nvme_ctrlr_fw_image_download failed!\n");
 			return -ENXIO;
 		}
@@ -2218,21 +2241,17 @@ spdk_nvme_ctrlr_update_firmware(struct spdk_nvme_ctrlr *ctrlr, void *payload, ui
 	fw_commit.fs = slot;
 	fw_commit.ca = commit_action;
 
-	status.done = false;
-
 	res = nvme_ctrlr_cmd_fw_commit(ctrlr, &fw_commit, nvme_completion_poll_cb,
 				       &status);
 	if (res) {
 		return res;
 	}
 
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
-	}
+	res = spdk_nvme_wait_for_completion_robust_lock(ctrlr->adminq, &status, &ctrlr->ctrlr_lock);
+
 	memcpy(completion_status, &status.cpl.status, sizeof(struct spdk_nvme_status));
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+
+	if (res) {
 		if (status.cpl.status.sct != SPDK_NVME_SCT_COMMAND_SPECIFIC ||
 		    status.cpl.status.sc != SPDK_NVME_SC_FIRMWARE_REQ_NVM_RESET) {
 			if (status.cpl.status.sct == SPDK_NVME_SCT_COMMAND_SPECIFIC  &&
diff --git a/lib/nvme/nvme_ctrlr_cmd.c b/lib/nvme/nvme_ctrlr_cmd.c
index 857165c50..2b6b23b14 100644
--- a/lib/nvme/nvme_ctrlr_cmd.c
+++ b/lib/nvme/nvme_ctrlr_cmd.c
@@ -63,9 +63,7 @@ spdk_nvme_ctrlr_cmd_io_raw_with_md(struct spdk_nvme_ctrlr *ctrlr,
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buf;
-	payload.md = md_buf;
+	payload = NVME_PAYLOAD_CONTIG(buf, md_buf);
 
 	req = nvme_allocate_request(qpair, &payload, len, cb_fn, cb_arg);
 	if (req == NULL) {
@@ -342,6 +340,66 @@ spdk_nvme_ctrlr_cmd_get_feature(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
 	return rc;
 }
 
+int
+spdk_nvme_ctrlr_cmd_get_feature_ns(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
+				   uint32_t cdw11, void *payload,
+				   uint32_t payload_size, spdk_nvme_cmd_cb cb_fn,
+				   void *cb_arg, uint32_t ns_id)
+{
+	struct nvme_request *req;
+	struct spdk_nvme_cmd *cmd;
+	int rc;
+
+	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
+	req = nvme_allocate_request_user_copy(ctrlr->adminq, payload, payload_size, cb_fn, cb_arg,
+					      false);
+	if (req == NULL) {
+		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = SPDK_NVME_OPC_GET_FEATURES;
+	cmd->cdw10 = feature;
+	cmd->cdw11 = cdw11;
+	cmd->nsid = ns_id;
+
+	rc = nvme_ctrlr_submit_admin_request(ctrlr, req);
+	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
+
+	return rc;
+}
+
+int spdk_nvme_ctrlr_cmd_set_feature_ns(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
+				       uint32_t cdw11, uint32_t cdw12, void *payload,
+				       uint32_t payload_size, spdk_nvme_cmd_cb cb_fn,
+				       void *cb_arg, uint32_t ns_id)
+{
+	struct nvme_request *req;
+	struct spdk_nvme_cmd *cmd;
+	int rc;
+
+	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
+	req = nvme_allocate_request_user_copy(ctrlr->adminq, payload, payload_size, cb_fn, cb_arg,
+					      true);
+	if (req == NULL) {
+		nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = SPDK_NVME_OPC_SET_FEATURES;
+	cmd->cdw10 = feature;
+	cmd->cdw11 = cdw11;
+	cmd->cdw12 = cdw12;
+	cmd->nsid = ns_id;
+
+	rc = nvme_ctrlr_submit_admin_request(ctrlr, req);
+	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
+
+	return rc;
+}
+
 int
 nvme_ctrlr_cmd_set_num_queues(struct spdk_nvme_ctrlr *ctrlr,
 			      uint32_t num_queues, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
@@ -467,11 +525,11 @@ spdk_nvme_ctrlr_cmd_abort_cpl(void *ctx, const struct spdk_nvme_cpl *cpl)
 		rc = nvme_ctrlr_submit_admin_request(ctrlr, next);
 		if (rc < 0) {
 			SPDK_ERRLOG("Failed to submit queued abort.\n");
+			memset(&next->cpl, 0, sizeof(next->cpl));
 			next->cpl.status.sct = SPDK_NVME_SCT_GENERIC;
 			next->cpl.status.sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
 			next->cpl.status.dnr = 1;
-			next->cb_fn(next->cb_arg, &req->cpl);
-
+			nvme_complete_request(next, &req->cpl);
 			nvme_free_request(next);
 		} else {
 			/* If the first abort succeeds, stop iterating. */
diff --git a/lib/nvme/nvme_ctrlr_ocssd_cmd.c b/lib/nvme/nvme_ctrlr_ocssd_cmd.c
new file mode 100644
index 000000000..80de53281
--- /dev/null
+++ b/lib/nvme/nvme_ctrlr_ocssd_cmd.c
@@ -0,0 +1,83 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/nvme_ocssd.h"
+#include "nvme_internal.h"
+
+bool
+spdk_nvme_ctrlr_is_ocssd_supported(struct spdk_nvme_ctrlr *ctrlr)
+{
+	if (ctrlr->quirks & NVME_QUIRK_OCSSD) {
+		// TODO: There isn't a standardized way to identify Open-Channel SSD
+		// different verdors may have different conditions.
+
+		/*
+		 * Current QEMU OpenChannel Device needs to check nsdata->vs[0].
+		 * Here check nsdata->vs[0] of the first namespace.
+		 */
+		if (ctrlr->cdata.vid == SPDK_PCI_VID_CNEXLABS) {
+			if (ctrlr->num_ns && ctrlr->nsdata[0].vendor_specific[0] == 0x1) {
+				return true;
+			}
+		}
+	}
+	return false;
+}
+
+
+int
+spdk_nvme_ocssd_ctrlr_cmd_geometry(struct spdk_nvme_ctrlr *ctrlr, uint32_t nsid,
+				   void *payload, uint32_t payload_size,
+				   spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+{
+	struct nvme_request *req;
+	struct spdk_nvme_cmd *cmd;
+
+	if (!payload || (payload_size != sizeof(struct spdk_ocssd_geometry_data))) {
+		return -EINVAL;
+	}
+
+	nvme_robust_mutex_lock(&ctrlr->ctrlr_lock);
+	req = nvme_allocate_request_user_copy(ctrlr->adminq,
+					      payload, payload_size, cb_fn, cb_arg, false);
+	if (req == NULL) {
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = SPDK_OCSSD_OPC_GEOMETRY;
+	cmd->nsid = nsid;
+	nvme_robust_mutex_unlock(&ctrlr->ctrlr_lock);
+
+	return nvme_ctrlr_submit_admin_request(ctrlr, req);
+}
diff --git a/lib/nvme/nvme_fabric.c b/lib/nvme/nvme_fabric.c
new file mode 100644
index 000000000..4589596ab
--- /dev/null
+++ b/lib/nvme/nvme_fabric.c
@@ -0,0 +1,340 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * NVMe over Fabrics transport-independent functions
+ */
+
+#include "nvme_internal.h"
+
+#include "spdk/endian.h"
+#include "spdk/string.h"
+
+static int
+nvme_fabric_prop_set_cmd(struct spdk_nvme_ctrlr *ctrlr,
+			 uint32_t offset, uint8_t size, uint64_t value)
+{
+	struct spdk_nvmf_fabric_prop_set_cmd cmd = {};
+	struct nvme_completion_poll_status status;
+	int rc;
+
+	assert(size == SPDK_NVMF_PROP_SIZE_4 || size == SPDK_NVMF_PROP_SIZE_8);
+
+	cmd.opcode = SPDK_NVME_OPC_FABRIC;
+	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_PROPERTY_SET;
+	cmd.ofst = offset;
+	cmd.attrib.size = size;
+	cmd.value.u64 = value;
+
+	rc = spdk_nvme_ctrlr_cmd_admin_raw(ctrlr, (struct spdk_nvme_cmd *)&cmd,
+					   NULL, 0,
+					   nvme_completion_poll_cb, &status);
+	if (rc < 0) {
+		return rc;
+	}
+
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
+		SPDK_ERRLOG("Property Set failed\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static int
+nvme_fabric_prop_get_cmd(struct spdk_nvme_ctrlr *ctrlr,
+			 uint32_t offset, uint8_t size, uint64_t *value)
+{
+	struct spdk_nvmf_fabric_prop_set_cmd cmd = {};
+	struct nvme_completion_poll_status status;
+	struct spdk_nvmf_fabric_prop_get_rsp *response;
+	int rc;
+
+	assert(size == SPDK_NVMF_PROP_SIZE_4 || size == SPDK_NVMF_PROP_SIZE_8);
+
+	cmd.opcode = SPDK_NVME_OPC_FABRIC;
+	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_PROPERTY_GET;
+	cmd.ofst = offset;
+	cmd.attrib.size = size;
+
+	rc = spdk_nvme_ctrlr_cmd_admin_raw(ctrlr, (struct spdk_nvme_cmd *)&cmd,
+					   NULL, 0, nvme_completion_poll_cb,
+					   &status);
+	if (rc < 0) {
+		return rc;
+	}
+
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
+		SPDK_ERRLOG("Property Get failed\n");
+		return -1;
+	}
+
+	response = (struct spdk_nvmf_fabric_prop_get_rsp *)&status.cpl;
+
+	if (size == SPDK_NVMF_PROP_SIZE_4) {
+		*value = response->value.u32.low;
+	} else {
+		*value = response->value.u64;
+	}
+
+	return 0;
+}
+
+int
+nvme_fabric_ctrlr_set_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t value)
+{
+	return nvme_fabric_prop_set_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_4, value);
+}
+
+int
+nvme_fabric_ctrlr_set_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t value)
+{
+	return nvme_fabric_prop_set_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_8, value);
+}
+
+int
+nvme_fabric_ctrlr_get_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t *value)
+{
+	uint64_t tmp_value;
+	int rc;
+	rc = nvme_fabric_prop_get_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_4, &tmp_value);
+
+	if (!rc) {
+		*value = (uint32_t)tmp_value;
+	}
+	return rc;
+}
+
+int
+nvme_fabric_ctrlr_get_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t *value)
+{
+	return nvme_fabric_prop_get_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_8, value);
+}
+
+static void
+nvme_fabric_discover_probe(struct spdk_nvmf_discovery_log_page_entry *entry,
+			   void *cb_ctx, spdk_nvme_probe_cb probe_cb)
+{
+	struct spdk_nvme_transport_id trid;
+	uint8_t *end;
+	size_t len;
+
+	memset(&trid, 0, sizeof(trid));
+
+	if (entry->subtype == SPDK_NVMF_SUBTYPE_DISCOVERY) {
+		SPDK_WARNLOG("Skipping unsupported discovery service referral\n");
+		return;
+	} else if (entry->subtype != SPDK_NVMF_SUBTYPE_NVME) {
+		SPDK_WARNLOG("Skipping unknown subtype %u\n", entry->subtype);
+		return;
+	}
+
+	trid.trtype = entry->trtype;
+	if (!spdk_nvme_transport_available(trid.trtype)) {
+		SPDK_WARNLOG("NVMe transport type %u not available; skipping probe\n",
+			     trid.trtype);
+		return;
+	}
+
+	trid.adrfam = entry->adrfam;
+
+	/* Ensure that subnqn is null terminated. */
+	end = memchr(entry->subnqn, '\0', SPDK_NVMF_NQN_MAX_LEN + 1);
+	if (!end) {
+		SPDK_ERRLOG("Discovery entry SUBNQN is not null terminated\n");
+		return;
+	}
+	len = end - entry->subnqn;
+	memcpy(trid.subnqn, entry->subnqn, len);
+	trid.subnqn[len] = '\0';
+
+	/* Convert traddr to a null terminated string. */
+	len = spdk_strlen_pad(entry->traddr, sizeof(entry->traddr), ' ');
+	memcpy(trid.traddr, entry->traddr, len);
+	if (spdk_str_chomp(trid.traddr) != 0) {
+		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Trailing newlines removed from discovery TRADDR\n");
+	}
+
+	/* Convert trsvcid to a null terminated string. */
+	len = spdk_strlen_pad(entry->trsvcid, sizeof(entry->trsvcid), ' ');
+	memcpy(trid.trsvcid, entry->trsvcid, len);
+	if (spdk_str_chomp(trid.trsvcid) != 0) {
+		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Trailing newlines removed from discovery TRSVCID\n");
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_NVME, "subnqn=%s, trtype=%u, traddr=%s, trsvcid=%s\n",
+		      trid.subnqn, trid.trtype,
+		      trid.traddr, trid.trsvcid);
+
+	nvme_ctrlr_probe(&trid, NULL, probe_cb, cb_ctx);
+}
+
+static int
+nvme_fabric_get_discovery_log_page(struct spdk_nvme_ctrlr *ctrlr,
+				   void *log_page, uint32_t size, uint64_t offset)
+{
+	struct nvme_completion_poll_status status;
+	int rc;
+
+	rc = spdk_nvme_ctrlr_cmd_get_log_page(ctrlr, SPDK_NVME_LOG_DISCOVERY, 0, log_page, size, offset,
+					      nvme_completion_poll_cb, &status);
+	if (rc < 0) {
+		return -1;
+	}
+
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
+		return -1;
+	}
+
+	return 0;
+}
+
+int
+nvme_fabric_ctrlr_discover(struct spdk_nvme_ctrlr *ctrlr,
+			   void *cb_ctx, spdk_nvme_probe_cb probe_cb)
+{
+	struct spdk_nvmf_discovery_log_page *log_page;
+	struct spdk_nvmf_discovery_log_page_entry *log_page_entry;
+	char buffer[4096];
+	int rc;
+	uint64_t i, numrec, buffer_max_entries_first, buffer_max_entries, log_page_offset = 0;
+	uint64_t remaining_num_rec = 0;
+	uint16_t recfmt;
+
+	memset(buffer, 0x0, 4096);
+	buffer_max_entries_first = (sizeof(buffer) - offsetof(struct spdk_nvmf_discovery_log_page,
+				    entries[0])) /
+				   sizeof(struct spdk_nvmf_discovery_log_page_entry);
+	buffer_max_entries = sizeof(buffer) / sizeof(struct spdk_nvmf_discovery_log_page_entry);
+	do {
+		rc = nvme_fabric_get_discovery_log_page(ctrlr, buffer, sizeof(buffer), log_page_offset);
+		if (rc < 0) {
+			SPDK_DEBUGLOG(SPDK_LOG_NVME, "Get Log Page - Discovery error\n");
+			return rc;
+		}
+
+		if (!remaining_num_rec) {
+			log_page = (struct spdk_nvmf_discovery_log_page *)buffer;
+			recfmt = from_le16(&log_page->recfmt);
+			if (recfmt != 0) {
+				SPDK_ERRLOG("Unrecognized discovery log record format %" PRIu16 "\n", recfmt);
+				return -EPROTO;
+			}
+			remaining_num_rec = log_page->numrec;
+			log_page_offset = offsetof(struct spdk_nvmf_discovery_log_page, entries[0]);
+			log_page_entry = &log_page->entries[0];
+			numrec = spdk_min(remaining_num_rec, buffer_max_entries_first);
+		} else {
+			numrec = spdk_min(remaining_num_rec, buffer_max_entries);
+			log_page_entry = (struct spdk_nvmf_discovery_log_page_entry *)buffer;
+		}
+
+		for (i = 0; i < numrec; i++) {
+			nvme_fabric_discover_probe(log_page_entry++, cb_ctx, probe_cb);
+		}
+		remaining_num_rec -= numrec;
+		log_page_offset += numrec * sizeof(struct spdk_nvmf_discovery_log_page_entry);
+	} while (remaining_num_rec != 0);
+
+	return 0;
+}
+
+int
+nvme_fabric_qpair_connect(struct spdk_nvme_qpair *qpair, uint32_t num_entries)
+{
+	struct nvme_completion_poll_status status;
+	struct spdk_nvmf_fabric_connect_rsp *rsp;
+	struct spdk_nvmf_fabric_connect_cmd cmd;
+	struct spdk_nvmf_fabric_connect_data *nvmf_data;
+	struct spdk_nvme_ctrlr *ctrlr;
+	int rc;
+
+	if (num_entries == 0 || num_entries > SPDK_NVME_IO_QUEUE_MAX_ENTRIES) {
+		return -EINVAL;
+	}
+
+	ctrlr = qpair->ctrlr;
+	if (!ctrlr) {
+		return -EINVAL;
+	}
+
+	nvmf_data = spdk_dma_zmalloc(sizeof(*nvmf_data), 0, NULL);
+	if (!nvmf_data) {
+		SPDK_ERRLOG("nvmf_data allocation error\n");
+		return -ENOMEM;
+	}
+
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.opcode = SPDK_NVME_OPC_FABRIC;
+	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_CONNECT;
+	cmd.qid = qpair->id;
+	cmd.sqsize = num_entries - 1;
+	cmd.kato = ctrlr->opts.keep_alive_timeout_ms;
+
+	if (nvme_qpair_is_admin_queue(qpair)) {
+		nvmf_data->cntlid = 0xFFFF;
+	} else {
+		nvmf_data->cntlid = ctrlr->cntlid;
+	}
+
+	SPDK_STATIC_ASSERT(sizeof(nvmf_data->hostid) == sizeof(ctrlr->opts.extended_host_id),
+			   "host ID size mismatch");
+	memcpy(nvmf_data->hostid, ctrlr->opts.extended_host_id, sizeof(nvmf_data->hostid));
+	snprintf(nvmf_data->hostnqn, sizeof(nvmf_data->hostnqn), "%s", ctrlr->opts.hostnqn);
+	snprintf(nvmf_data->subnqn, sizeof(nvmf_data->subnqn), "%s", ctrlr->trid.subnqn);
+
+	rc = spdk_nvme_ctrlr_cmd_io_raw(ctrlr, qpair,
+					(struct spdk_nvme_cmd *)&cmd,
+					nvmf_data, sizeof(*nvmf_data),
+					nvme_completion_poll_cb, &status);
+	if (rc < 0) {
+		SPDK_ERRLOG("Connect command failed\n");
+		spdk_dma_free(nvmf_data);
+		return rc;
+	}
+
+	if (spdk_nvme_wait_for_completion(qpair, &status)) {
+		SPDK_ERRLOG("Connect command failed\n");
+		spdk_dma_free(nvmf_data);
+		return -EIO;
+	}
+
+	if (nvme_qpair_is_admin_queue(qpair)) {
+		rsp = (struct spdk_nvmf_fabric_connect_rsp *)&status.cpl;
+		ctrlr->cntlid = rsp->status_code_specific.success.cntlid;
+		SPDK_DEBUGLOG(SPDK_LOG_NVME, "CNTLID 0x%04" PRIx16 "\n", ctrlr->cntlid);
+	}
+
+	spdk_dma_free(nvmf_data);
+	return 0;
+}
diff --git a/lib/nvme/nvme_internal.h b/lib/nvme/nvme_internal.h
index 56c0f0d5d..aca8d716d 100644
--- a/lib/nvme/nvme_internal.h
+++ b/lib/nvme/nvme_internal.h
@@ -34,6 +34,7 @@
 #ifndef __NVME_INTERNAL_H__
 #define __NVME_INTERNAL_H__
 
+#include "spdk/likely.h"
 #include "spdk/stdinc.h"
 
 #include "spdk/nvme.h"
@@ -55,6 +56,8 @@
 #include "spdk_internal/assert.h"
 #include "spdk_internal/log.h"
 
+extern pid_t g_spdk_nvme_pid;
+
 /*
  * Some Intel devices support vendor-unique read latency log page even
  * though the log page directory says otherwise.
@@ -92,6 +95,18 @@
  */
 #define NVME_QUIRK_READ_ZERO_AFTER_DEALLOCATE 0x20
 
+/*
+ * The controller doesn't handle Identify value others than 0 or 1 correctly.
+ */
+#define NVME_QUIRK_IDENTIFY_CNS 0x40
+
+/*
+ * The controller supports Open Channel command set if matching additional
+ * condition, like the first byte (value 0x1) in the vendor specific
+ * bits of the namespace identify structure is set.
+ */
+#define NVME_QUIRK_OCSSD 0x80
+
 #define NVME_MAX_ASYNC_EVENTS	(8)
 
 #define NVME_MIN_TIMEOUT_PERIOD		(5)
@@ -111,6 +126,13 @@
 #define DEFAULT_ADMIN_QUEUE_REQUESTS	(32)
 #define DEFAULT_IO_QUEUE_REQUESTS	(512)
 
+/* We want to fit submission and completion rings each in a single 2MB
+ * hugepage to ensure physical address contiguity.
+ */
+#define MAX_IO_QUEUE_ENTRIES		(0x200000 / spdk_max( \
+						sizeof(struct spdk_nvme_cmd), \
+						sizeof(struct spdk_nvme_cpl)))
+
 enum nvme_payload_type {
 	NVME_PAYLOAD_TYPE_INVALID = 0,
 
@@ -130,47 +152,69 @@ enum spdk_nvme_ctrlr_flags {
 
 /**
  * Descriptor for a request data payload.
- *
- * This struct is arranged so that it fits nicely in struct nvme_request.
  */
-struct __attribute__((packed)) nvme_payload {
-	union {
-		/** Virtual memory address of a single physically contiguous buffer */
-		void *contig;
-
-		/**
-		 * Functions for retrieving physical addresses for scattered payloads.
-		 */
-		struct nvme_sgl_args {
-			spdk_nvme_req_reset_sgl_cb reset_sgl_fn;
-			spdk_nvme_req_next_sge_cb next_sge_fn;
-			void *cb_arg;
-		} sgl;
-	} u;
-
-	/** Virtual memory address of a single physically contiguous metadata buffer */
+struct nvme_payload {
+	/**
+	 * Functions for retrieving physical addresses for scattered payloads.
+	 */
+	spdk_nvme_req_reset_sgl_cb reset_sgl_fn;
+	spdk_nvme_req_next_sge_cb next_sge_fn;
+
+	/**
+	 * If reset_sgl_fn == NULL, this is a contig payload, and contig_or_cb_arg contains the
+	 * virtual memory address of a single virtually contiguous buffer.
+	 *
+	 * If reset_sgl_fn != NULL, this is a SGL payload, and contig_or_cb_arg contains the
+	 * cb_arg that will be passed to the SGL callback functions.
+	 */
+	void *contig_or_cb_arg;
+
+	/** Virtual memory address of a single virtually contiguous metadata buffer */
 	void *md;
+};
+
+#define NVME_PAYLOAD_CONTIG(contig_, md_) \
+	(struct nvme_payload) { \
+		.reset_sgl_fn = NULL, \
+		.next_sge_fn = NULL, \
+		.contig_or_cb_arg = (contig_), \
+		.md = (md_), \
+	}
+
+#define NVME_PAYLOAD_SGL(reset_sgl_fn_, next_sge_fn_, cb_arg_, md_) \
+	(struct nvme_payload) { \
+		.reset_sgl_fn = (reset_sgl_fn_), \
+		.next_sge_fn = (next_sge_fn_), \
+		.contig_or_cb_arg = (cb_arg_), \
+		.md = (md_), \
+	}
 
-	/** \ref nvme_payload_type */
-	uint8_t type;
+static inline enum nvme_payload_type
+nvme_payload_type(const struct nvme_payload *payload) {
+	return payload->reset_sgl_fn ? NVME_PAYLOAD_TYPE_SGL : NVME_PAYLOAD_TYPE_CONTIG;
+}
+
+struct nvme_error_cmd {
+	bool				do_not_submit;
+	uint64_t			timeout_tsc;
+	uint32_t			err_count;
+	uint8_t				opc;
+	struct spdk_nvme_status		status;
+	TAILQ_ENTRY(nvme_error_cmd)	link;
 };
 
 struct nvme_request {
 	struct spdk_nvme_cmd		cmd;
 
-	/**
-	 * Data payload for this request's command.
-	 */
-	struct nvme_payload		payload;
-
 	uint8_t				retries;
 
+	bool				timed_out;
+
 	/**
 	 * Number of children requests still outstanding for this
 	 *  request which was split into multiple child requests.
 	 */
 	uint16_t			num_children;
-	uint32_t			payload_size;
 
 	/**
 	 * Offset in bytes from the beginning of payload for this request.
@@ -179,12 +223,31 @@ struct nvme_request {
 	uint32_t			payload_offset;
 	uint32_t			md_offset;
 
+	uint32_t			payload_size;
+
+	/**
+	 * Timeout ticks for error injection requests, can be extended in future
+	 * to support per-request timeout feature.
+	 */
+	uint64_t			timeout_tsc;
+
+	/**
+	 * Data payload for this request's command.
+	 */
+	struct nvme_payload		payload;
+
 	spdk_nvme_cmd_cb		cb_fn;
 	void				*cb_arg;
 	STAILQ_ENTRY(nvme_request)	stailq;
 
 	struct spdk_nvme_qpair		*qpair;
 
+	/*
+	 * The value of spdk_get_ticks() when the request was submitted to the hardware.
+	 * Only set if ctrlr->timeout_enabled is true.
+	 */
+	uint64_t			submit_tick;
+
 	/**
 	 * The active admin request can be moved to a per process pending
 	 *  list based on the saved pid to tell which process it belongs
@@ -253,6 +316,10 @@ struct nvme_async_event_request {
 struct spdk_nvme_qpair {
 	STAILQ_HEAD(, nvme_request)	free_req;
 	STAILQ_HEAD(, nvme_request)	queued_req;
+	/** Commands opcode in this list will return error */
+	TAILQ_HEAD(, nvme_error_cmd)	err_cmd_head;
+	/** Requests in this list will return error */
+	STAILQ_HEAD(, nvme_request)	err_req_head;
 
 	enum spdk_nvme_transport_type	trtype;
 
@@ -370,6 +437,9 @@ struct spdk_nvme_ctrlr_process {
 	/** Allocated IO qpairs */
 	TAILQ_HEAD(, spdk_nvme_qpair)			allocated_io_qpairs;
 
+	spdk_nvme_aer_cb				aer_cb_fn;
+	void						*aer_cb_arg;
+
 	/**
 	 * A function pointer to timeout callback function
 	 */
@@ -397,14 +467,19 @@ struct spdk_nvme_ctrlr {
 
 	bool				is_failed;
 
+	bool				timeout_enabled;
+
 	uint16_t			max_sges;
 
+	uint16_t			cntlid;
+
 	/** Controller support flags */
 	uint64_t			flags;
 
 	/* Cold data (not accessed in normal I/O path) is after this point. */
 
 	union spdk_nvme_cap_register	cap;
+	union spdk_nvme_vs_register	vs;
 
 	enum nvme_ctrlr_state		state;
 	uint64_t			state_timeout_tsc;
@@ -431,8 +506,6 @@ struct spdk_nvme_ctrlr {
 
 	uint32_t			num_aers;
 	struct nvme_async_event_request	aer[NVME_MAX_ASYNC_EVENTS];
-	spdk_nvme_aer_cb		aer_cb_fn;
-	void				*aer_cb_arg;
 
 	/** guards access to the controller itself, including admin queues */
 	pthread_mutex_t			ctrlr_lock;
@@ -492,6 +565,8 @@ struct nvme_driver {
 
 extern struct nvme_driver *g_spdk_nvme_driver;
 
+int nvme_driver_init(void);
+
 /*
  * Used for the spdk_nvme_connect() public API to save user specified opts.
  */
@@ -569,7 +644,15 @@ int	nvme_ctrlr_cmd_fw_image_download(struct spdk_nvme_ctrlr *ctrlr,
 		uint32_t size, uint32_t offset, void *payload,
 		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
 void	nvme_completion_poll_cb(void *arg, const struct spdk_nvme_cpl *cpl);
-
+int	spdk_nvme_wait_for_completion(struct spdk_nvme_qpair *qpair,
+				      struct nvme_completion_poll_status *status);
+int	spdk_nvme_wait_for_completion_robust_lock(struct spdk_nvme_qpair *qpair,
+		struct nvme_completion_poll_status *status,
+		pthread_mutex_t *robust_mutex);
+
+struct spdk_nvme_ctrlr_process *spdk_nvme_ctrlr_get_process(struct spdk_nvme_ctrlr *ctrlr,
+		pid_t pid);
+struct spdk_nvme_ctrlr_process *spdk_nvme_ctrlr_get_current_process(struct spdk_nvme_ctrlr *ctrlr);
 int	nvme_ctrlr_add_process(struct spdk_nvme_ctrlr *ctrlr, void *devhandle);
 void	nvme_ctrlr_free_processes(struct spdk_nvme_ctrlr *ctrlr);
 struct spdk_pci_device *nvme_ctrlr_proc_get_devhandle(struct spdk_nvme_ctrlr *ctrlr);
@@ -588,11 +671,14 @@ void	nvme_ctrlr_connected(struct spdk_nvme_ctrlr *ctrlr);
 int	nvme_ctrlr_submit_admin_request(struct spdk_nvme_ctrlr *ctrlr,
 					struct nvme_request *req);
 int	nvme_ctrlr_get_cap(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_cap_register *cap);
-void	nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap);
+int	nvme_ctrlr_get_vs(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_vs_register *vs);
+void	nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap,
+			    const union spdk_nvme_vs_register *vs);
 int	nvme_qpair_init(struct spdk_nvme_qpair *qpair, uint16_t id,
 			struct spdk_nvme_ctrlr *ctrlr,
 			enum spdk_nvme_qprio qprio,
 			uint32_t num_requests);
+void	nvme_qpair_deinit(struct spdk_nvme_qpair *qpair);
 void	nvme_qpair_enable(struct spdk_nvme_qpair *qpair);
 void	nvme_qpair_disable(struct spdk_nvme_qpair *qpair);
 int	nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair,
@@ -603,19 +689,122 @@ int	nvme_ns_construct(struct spdk_nvme_ns *ns, uint32_t id,
 			  struct spdk_nvme_ctrlr *ctrlr);
 void	nvme_ns_destruct(struct spdk_nvme_ns *ns);
 
-struct nvme_request *nvme_allocate_request(struct spdk_nvme_qpair *qpair,
-		const struct nvme_payload *payload,
-		uint32_t payload_size, spdk_nvme_cmd_cb cb_fn, void *cb_arg);
-struct nvme_request *nvme_allocate_request_null(struct spdk_nvme_qpair *qpair,
-		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
-struct nvme_request *nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair,
-		void *buffer, uint32_t payload_size,
-		spdk_nvme_cmd_cb cb_fn, void *cb_arg);
+int	nvme_fabric_ctrlr_set_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t value);
+int	nvme_fabric_ctrlr_set_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t value);
+int	nvme_fabric_ctrlr_get_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t *value);
+int	nvme_fabric_ctrlr_get_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t *value);
+int	nvme_fabric_ctrlr_discover(struct spdk_nvme_ctrlr *ctrlr, void *cb_ctx,
+				   spdk_nvme_probe_cb probe_cb);
+int	nvme_fabric_qpair_connect(struct spdk_nvme_qpair *qpair, uint32_t num_entries);
+
+static inline struct nvme_request *
+nvme_allocate_request(struct spdk_nvme_qpair *qpair,
+		      const struct nvme_payload *payload, uint32_t payload_size,
+		      spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+{
+	struct nvme_request *req;
+
+	req = STAILQ_FIRST(&qpair->free_req);
+	if (req == NULL) {
+		return req;
+	}
+
+	STAILQ_REMOVE_HEAD(&qpair->free_req, stailq);
+
+	/*
+	 * Only memset/zero fields that need it.  All other fields
+	 *  will be initialized appropriately either later in this
+	 *  function, or before they are needed later in the
+	 *  submission patch.  For example, the children
+	 *  TAILQ_ENTRY and following members are
+	 *  only used as part of I/O splitting so we avoid
+	 *  memsetting them until it is actually needed.
+	 *  They will be initialized in nvme_request_add_child()
+	 *  if the request is split.
+	 */
+	memset(req, 0, offsetof(struct nvme_request, payload_size));
+
+	req->cb_fn = cb_fn;
+	req->cb_arg = cb_arg;
+	req->payload = *payload;
+	req->payload_size = payload_size;
+	req->qpair = qpair;
+	req->pid = g_spdk_nvme_pid;
+
+	return req;
+}
+
+static inline struct nvme_request *
+nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair,
+			     void *buffer, uint32_t payload_size,
+			     spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+{
+	struct nvme_payload payload;
+
+	payload = NVME_PAYLOAD_CONTIG(buffer, NULL);
+
+	return nvme_allocate_request(qpair, &payload, payload_size, cb_fn, cb_arg);
+}
+
+static inline struct nvme_request *
+nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+{
+	return nvme_allocate_request_contig(qpair, NULL, 0, cb_fn, cb_arg);
+}
+
 struct nvme_request *nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair,
 		void *buffer, uint32_t payload_size,
 		spdk_nvme_cmd_cb cb_fn, void *cb_arg, bool host_to_controller);
-void	nvme_free_request(struct nvme_request *req);
+
+static inline void
+nvme_complete_request(struct nvme_request *req, struct spdk_nvme_cpl *cpl)
+{
+	struct spdk_nvme_qpair          *qpair = req->qpair;
+	struct spdk_nvme_cpl            err_cpl;
+	struct nvme_error_cmd           *cmd;
+
+	/* error injection at completion path,
+	 * only inject for successful completed commands
+	 */
+	if (spdk_unlikely(!TAILQ_EMPTY(&qpair->err_cmd_head) &&
+			  !spdk_nvme_cpl_is_error(cpl))) {
+		TAILQ_FOREACH(cmd, &qpair->err_cmd_head, link) {
+
+			if (cmd->do_not_submit) {
+				continue;
+			}
+
+			if ((cmd->opc == req->cmd.opc) && cmd->err_count) {
+
+				err_cpl = *cpl;
+				err_cpl.status.sct = cmd->status.sct;
+				err_cpl.status.sc = cmd->status.sc;
+
+				cpl = &err_cpl;
+				cmd->err_count--;
+				break;
+			}
+		}
+	}
+
+	if (req->cb_fn) {
+		req->cb_fn(req->cb_arg, cpl);
+	}
+}
+
+static inline void
+nvme_free_request(struct nvme_request *req)
+{
+	assert(req != NULL);
+	assert(req->num_children == 0);
+	assert(req->qpair != NULL);
+
+	STAILQ_INSERT_HEAD(&req->qpair->free_req, req, stailq);
+}
+
 void	nvme_request_remove_child(struct nvme_request *parent, struct nvme_request *child);
+int	nvme_request_check_timeout(struct nvme_request *req, uint16_t cid,
+				   struct spdk_nvme_ctrlr_process *active_proc, uint64_t now_tick);
 uint64_t nvme_get_quirks(const struct spdk_pci_id *id);
 
 int	nvme_robust_mutex_init_shared(pthread_mutex_t *mtx);
diff --git a/lib/nvme/nvme_ns.c b/lib/nvme/nvme_ns.c
index 05e3f4da8..e61b3700c 100644
--- a/lib/nvme/nvme_ns.c
+++ b/lib/nvme/nvme_ns.c
@@ -47,7 +47,6 @@ int nvme_ns_identify_update(struct spdk_nvme_ns *ns)
 	int					rc;
 
 	nsdata = _nvme_ns_get_data(ns);
-	status.done = false;
 	rc = nvme_ctrlr_cmd_identify(ns->ctrlr, SPDK_NVME_IDENTIFY_NS, 0, ns->id,
 				     nsdata, sizeof(*nsdata),
 				     nvme_completion_poll_cb, &status);
@@ -55,22 +54,11 @@ int nvme_ns_identify_update(struct spdk_nvme_ns *ns)
 		return rc;
 	}
 
-	while (status.done == false) {
-		nvme_robust_mutex_lock(&ns->ctrlr->ctrlr_lock);
-		spdk_nvme_qpair_process_completions(ns->ctrlr->adminq, 0);
-		nvme_robust_mutex_unlock(&ns->ctrlr->ctrlr_lock);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion_robust_lock(ns->ctrlr->adminq, &status,
+			&ns->ctrlr->ctrlr_lock)) {
 		/* This can occur if the namespace is not active. Simply zero the
 		 * namespace data and continue. */
-		memset(nsdata, 0, sizeof(*nsdata));
-		ns->sector_size = 0;
-		ns->extended_lba_size = 0;
-		ns->md_size = 0;
-		ns->pi_type = 0;
-		ns->sectors_per_max_io = 0;
-		ns->sectors_per_stripe = 0;
-		ns->flags = 0;
+		nvme_ns_destruct(ns);
 		return 0;
 	}
 
@@ -124,18 +112,14 @@ int nvme_ns_identify_update(struct spdk_nvme_ns *ns)
 	}
 
 	memset(ns->id_desc_list, 0, sizeof(ns->id_desc_list));
-	if (ns->ctrlr->cdata.ver.raw >= SPDK_NVME_VERSION(1, 3, 0)) {
+	if (ns->ctrlr->vs.raw >= SPDK_NVME_VERSION(1, 3, 0) &&
+	    !(ns->ctrlr->quirks & NVME_QUIRK_IDENTIFY_CNS)) {
 		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Attempting to retrieve NS ID Descriptor List\n");
-		status.done = false;
 		rc = nvme_ctrlr_cmd_identify(ns->ctrlr, SPDK_NVME_IDENTIFY_NS_ID_DESCRIPTOR_LIST, 0, ns->id,
 					     ns->id_desc_list, sizeof(ns->id_desc_list),
 					     nvme_completion_poll_cb, &status);
 		if (rc == 0) {
-			while (status.done == false) {
-				nvme_robust_mutex_lock(&ns->ctrlr->ctrlr_lock);
-				spdk_nvme_qpair_process_completions(ns->ctrlr->adminq, 0);
-				nvme_robust_mutex_unlock(&ns->ctrlr->ctrlr_lock);
-			}
+			rc = spdk_nvme_wait_for_completion_robust_lock(ns->ctrlr->adminq, &status, &ns->ctrlr->ctrlr_lock);
 		}
 
 		if (rc != 0 || spdk_nvme_cpl_is_error(&status.cpl)) {
@@ -309,5 +293,19 @@ int nvme_ns_construct(struct spdk_nvme_ns *ns, uint32_t id,
 
 void nvme_ns_destruct(struct spdk_nvme_ns *ns)
 {
+	struct spdk_nvme_ns_data *nsdata;
 
+	if (!ns->id) {
+		return;
+	}
+
+	nsdata = _nvme_ns_get_data(ns);
+	memset(nsdata, 0, sizeof(*nsdata));
+	ns->sector_size = 0;
+	ns->extended_lba_size = 0;
+	ns->md_size = 0;
+	ns->pi_type = 0;
+	ns->sectors_per_max_io = 0;
+	ns->sectors_per_stripe = 0;
+	ns->flags = 0;
 }
diff --git a/lib/nvme/nvme_ns_cmd.c b/lib/nvme/nvme_ns_cmd.c
index 7f39a71f0..5a694ad57 100644
--- a/lib/nvme/nvme_ns_cmd.c
+++ b/lib/nvme/nvme_ns_cmd.c
@@ -39,6 +39,24 @@ static struct nvme_request *_nvme_ns_cmd_rw(struct spdk_nvme_ns *ns, struct spdk
 		void *cb_arg, uint32_t opc, uint32_t io_flags,
 		uint16_t apptag_mask, uint16_t apptag, bool check_sgl);
 
+
+static bool
+spdk_nvme_ns_check_request_length(uint32_t lba_count, uint32_t sectors_per_max_io,
+				  uint32_t sectors_per_stripe, uint32_t qdepth)
+{
+	uint32_t child_per_io;
+
+	if (sectors_per_stripe > 0) {
+		child_per_io = (lba_count + sectors_per_stripe - 1) / sectors_per_stripe;
+	} else {
+		child_per_io = (lba_count + sectors_per_max_io - 1) / sectors_per_max_io;
+	}
+
+	SPDK_DEBUGLOG(SPDK_LOG_NVME, "checking maximum i/o length %d\n", child_per_io);
+
+	return child_per_io >= qdepth;
+}
+
 static void
 nvme_cb_complete_child(void *child_arg, const struct spdk_nvme_cpl *cpl)
 {
@@ -52,9 +70,7 @@ nvme_cb_complete_child(void *child_arg, const struct spdk_nvme_cpl *cpl)
 	}
 
 	if (parent->num_children == 0) {
-		if (parent->cb_fn) {
-			parent->cb_fn(parent->cb_arg, &parent->parent_status);
-		}
+		nvme_complete_request(parent, &parent->parent_status);
 		nvme_free_request(parent);
 	}
 }
@@ -218,7 +234,9 @@ _nvme_ns_cmd_split_request_prp(struct spdk_nvme_ns *ns,
 			       uint32_t io_flags, struct nvme_request *req,
 			       uint16_t apptag_mask, uint16_t apptag)
 {
-	struct nvme_sgl_args *args;
+	spdk_nvme_req_reset_sgl_cb reset_sgl_fn = req->payload.reset_sgl_fn;
+	spdk_nvme_req_next_sge_cb next_sge_fn = req->payload.next_sge_fn;
+	void *sgl_cb_arg = req->payload.contig_or_cb_arg;
 	bool start_valid, end_valid, last_sge, child_equals_parent;
 	uint64_t child_lba = lba;
 	uint32_t req_current_length = 0;
@@ -227,10 +245,8 @@ _nvme_ns_cmd_split_request_prp(struct spdk_nvme_ns *ns,
 	uint32_t page_size = qpair->ctrlr->page_size;
 	uintptr_t address;
 
-	args = &req->payload.u.sgl;
-
-	args->reset_sgl_fn(args->cb_arg, payload_offset);
-	args->next_sge_fn(args->cb_arg, (void **)&address, &sge_length);
+	reset_sgl_fn(sgl_cb_arg, payload_offset);
+	next_sge_fn(sgl_cb_arg, (void **)&address, &sge_length);
 	while (req_current_length < req->payload_size) {
 
 		if (sge_length == 0) {
@@ -273,7 +289,7 @@ _nvme_ns_cmd_split_request_prp(struct spdk_nvme_ns *ns,
 			child_length += sge_length;
 			req_current_length += sge_length;
 			if (req_current_length < req->payload_size) {
-				args->next_sge_fn(args->cb_arg, (void **)&address, &sge_length);
+				next_sge_fn(sgl_cb_arg, (void **)&address, &sge_length);
 			}
 			/*
 			 * If the next SGE is not page aligned, we will need to create a child
@@ -340,7 +356,9 @@ _nvme_ns_cmd_split_request_sgl(struct spdk_nvme_ns *ns,
 			       uint32_t io_flags, struct nvme_request *req,
 			       uint16_t apptag_mask, uint16_t apptag)
 {
-	struct nvme_sgl_args *args;
+	spdk_nvme_req_reset_sgl_cb reset_sgl_fn = req->payload.reset_sgl_fn;
+	spdk_nvme_req_next_sge_cb next_sge_fn = req->payload.next_sge_fn;
+	void *sgl_cb_arg = req->payload.contig_or_cb_arg;
 	uint64_t child_lba = lba;
 	uint32_t req_current_length = 0;
 	uint32_t child_length = 0;
@@ -348,14 +366,13 @@ _nvme_ns_cmd_split_request_sgl(struct spdk_nvme_ns *ns,
 	uint16_t max_sges, num_sges;
 	uintptr_t address;
 
-	args = &req->payload.u.sgl;
 	max_sges = ns->ctrlr->max_sges;
 
-	args->reset_sgl_fn(args->cb_arg, payload_offset);
+	reset_sgl_fn(sgl_cb_arg, payload_offset);
 	num_sges = 0;
 
 	while (req_current_length < req->payload_size) {
-		args->next_sge_fn(args->cb_arg, (void **)&address, &sge_length);
+		next_sge_fn(sgl_cb_arg, (void **)&address, &sge_length);
 
 		if (req_current_length + sge_length > req->payload_size) {
 			sge_length = req->payload_size - req_current_length;
@@ -466,7 +483,7 @@ _nvme_ns_cmd_rw(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 						  cb_fn,
 						  cb_arg, opc,
 						  io_flags, req, sectors_per_max_io, 0, apptag_mask, apptag);
-	} else if (req->payload.type == NVME_PAYLOAD_TYPE_SGL && check_sgl) {
+	} else if (nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL && check_sgl) {
 		if (ns->ctrlr->flags & SPDK_NVME_CTRLR_SGL_SUPPORTED) {
 			return _nvme_ns_cmd_split_request_sgl(ns, qpair, payload, payload_offset, md_offset,
 							      lba, lba_count, cb_fn, cb_arg, opc, io_flags,
@@ -491,9 +508,7 @@ spdk_nvme_ns_cmd_compare(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = NULL;
+	payload = NVME_PAYLOAD_CONTIG(buffer, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg,
 			      SPDK_NVME_OPC_COMPARE,
@@ -501,6 +516,11 @@ spdk_nvme_ns_cmd_compare(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 			      0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -517,9 +537,7 @@ spdk_nvme_ns_cmd_compare_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = metadata;
+	payload = NVME_PAYLOAD_CONTIG(buffer, metadata);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg,
 			      SPDK_NVME_OPC_COMPARE,
@@ -527,6 +545,11 @@ spdk_nvme_ns_cmd_compare_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair
 			      apptag_mask, apptag, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -546,17 +569,18 @@ spdk_nvme_ns_cmd_comparev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair
 		return -EINVAL;
 	}
 
-	payload.type = NVME_PAYLOAD_TYPE_SGL;
-	payload.md = NULL;
-	payload.u.sgl.reset_sgl_fn = reset_sgl_fn;
-	payload.u.sgl.next_sge_fn = next_sge_fn;
-	payload.u.sgl.cb_arg = cb_arg;
+	payload = NVME_PAYLOAD_SGL(reset_sgl_fn, next_sge_fn, cb_arg, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg,
 			      SPDK_NVME_OPC_COMPARE,
 			      io_flags, 0, 0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -571,15 +595,18 @@ spdk_nvme_ns_cmd_read(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair, vo
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = NULL;
+	payload = NVME_PAYLOAD_CONTIG(buffer, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_READ,
 			      io_flags, 0,
 			      0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -595,15 +622,18 @@ spdk_nvme_ns_cmd_read_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *q
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = metadata;
+	payload = NVME_PAYLOAD_CONTIG(buffer, metadata);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_READ,
 			      io_flags,
 			      apptag_mask, apptag, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -623,16 +653,48 @@ spdk_nvme_ns_cmd_readv(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 		return -EINVAL;
 	}
 
-	payload.type = NVME_PAYLOAD_TYPE_SGL;
-	payload.md = NULL;
-	payload.u.sgl.reset_sgl_fn = reset_sgl_fn;
-	payload.u.sgl.next_sge_fn = next_sge_fn;
-	payload.u.sgl.cb_arg = cb_arg;
+	payload = NVME_PAYLOAD_SGL(reset_sgl_fn, next_sge_fn, cb_arg, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_READ,
 			      io_flags, 0, 0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
+	} else {
+		return -ENOMEM;
+	}
+}
+
+int
+spdk_nvme_ns_cmd_readv_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
+			       uint64_t lba, uint32_t lba_count,
+			       spdk_nvme_cmd_cb cb_fn, void *cb_arg, uint32_t io_flags,
+			       spdk_nvme_req_reset_sgl_cb reset_sgl_fn,
+			       spdk_nvme_req_next_sge_cb next_sge_fn, void *metadata,
+			       uint16_t apptag_mask, uint16_t apptag)
+{
+	struct nvme_request *req;
+	struct nvme_payload payload;
+
+	if (reset_sgl_fn == NULL || next_sge_fn == NULL) {
+		return -EINVAL;
+	}
+
+	payload = NVME_PAYLOAD_SGL(reset_sgl_fn, next_sge_fn, cb_arg, metadata);
+
+	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_READ,
+			      io_flags, apptag_mask, apptag, true);
+	if (req != NULL) {
+		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -647,14 +709,17 @@ spdk_nvme_ns_cmd_write(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = NULL;
+	payload = NVME_PAYLOAD_CONTIG(buffer, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_WRITE,
 			      io_flags, 0, 0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -669,14 +734,17 @@ spdk_nvme_ns_cmd_write_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *
 	struct nvme_request *req;
 	struct nvme_payload payload;
 
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = metadata;
+	payload = NVME_PAYLOAD_CONTIG(buffer, metadata);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_WRITE,
 			      io_flags, apptag_mask, apptag, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
@@ -696,16 +764,48 @@ spdk_nvme_ns_cmd_writev(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
 		return -EINVAL;
 	}
 
-	payload.type = NVME_PAYLOAD_TYPE_SGL;
-	payload.md = NULL;
-	payload.u.sgl.reset_sgl_fn = reset_sgl_fn;
-	payload.u.sgl.next_sge_fn = next_sge_fn;
-	payload.u.sgl.cb_arg = cb_arg;
+	payload = NVME_PAYLOAD_SGL(reset_sgl_fn, next_sge_fn, cb_arg, NULL);
 
 	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_WRITE,
 			      io_flags, 0, 0, true);
 	if (req != NULL) {
 		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
+	} else {
+		return -ENOMEM;
+	}
+}
+
+int
+spdk_nvme_ns_cmd_writev_with_md(struct spdk_nvme_ns *ns, struct spdk_nvme_qpair *qpair,
+				uint64_t lba, uint32_t lba_count,
+				spdk_nvme_cmd_cb cb_fn, void *cb_arg, uint32_t io_flags,
+				spdk_nvme_req_reset_sgl_cb reset_sgl_fn,
+				spdk_nvme_req_next_sge_cb next_sge_fn, void *metadata,
+				uint16_t apptag_mask, uint16_t apptag)
+{
+	struct nvme_request *req;
+	struct nvme_payload payload;
+
+	if (reset_sgl_fn == NULL || next_sge_fn == NULL) {
+		return -EINVAL;
+	}
+
+	payload = NVME_PAYLOAD_SGL(reset_sgl_fn, next_sge_fn, cb_arg, metadata);
+
+	req = _nvme_ns_cmd_rw(ns, qpair, &payload, 0, 0, lba, lba_count, cb_fn, cb_arg, SPDK_NVME_OPC_WRITE,
+			      io_flags, apptag_mask, apptag, true);
+	if (req != NULL) {
+		return nvme_qpair_submit_request(qpair, req);
+	} else if (spdk_nvme_ns_check_request_length(lba_count,
+			ns->sectors_per_max_io,
+			ns->sectors_per_stripe,
+			qpair->ctrlr->opts.io_queue_requests)) {
+		return -EINVAL;
 	} else {
 		return -ENOMEM;
 	}
diff --git a/lib/nvme/nvme_ns_ocssd_cmd.c b/lib/nvme/nvme_ns_ocssd_cmd.c
new file mode 100644
index 000000000..35bf63c7c
--- /dev/null
+++ b/lib/nvme/nvme_ns_ocssd_cmd.c
@@ -0,0 +1,232 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/nvme_ocssd.h"
+#include "nvme_internal.h"
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_reset(struct spdk_nvme_ns *ns,
+				    struct spdk_nvme_qpair *qpair,
+				    uint64_t *lba_list, uint32_t num_lbas,
+				    struct spdk_ocssd_chunk_information *chunk_info,
+				    spdk_nvme_cmd_cb cb_fn, void *cb_arg)
+{
+	struct nvme_request	*req;
+	struct spdk_nvme_cmd	*cmd;
+
+	if (!lba_list || (num_lbas == 0) ||
+	    (num_lbas > SPDK_NVME_OCSSD_MAX_LBAL_ENTRIES)) {
+		return -EINVAL;
+	}
+
+	req = nvme_allocate_request_null(qpair, cb_fn, cb_arg);
+	if (req == NULL) {
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = SPDK_OCSSD_OPC_VECTOR_RESET;
+	cmd->nsid = ns->id;
+
+	if (chunk_info != NULL) {
+		cmd->mptr = spdk_vtophys(chunk_info);
+	}
+
+	/*
+	 * Dword 10 and 11 store a pointer to the list of logical block addresses.
+	 * If there is a single entry in the LBA list, the logical block
+	 * address should be stored instead.
+	 */
+	if (num_lbas == 1) {
+		*(uint64_t *)&cmd->cdw10 = *lba_list;
+	} else {
+		*(uint64_t *)&cmd->cdw10 = spdk_vtophys(lba_list);
+	}
+
+	cmd->cdw12 = num_lbas - 1;
+
+	return nvme_qpair_submit_request(qpair, req);
+}
+
+static int
+_nvme_ocssd_ns_cmd_vector_rw_with_md(struct spdk_nvme_ns *ns,
+				     struct spdk_nvme_qpair *qpair,
+				     void *buffer, void *metadata,
+				     uint64_t *lba_list, uint32_t num_lbas,
+				     spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				     enum spdk_ocssd_io_opcode opc,
+				     uint32_t io_flags)
+{
+	struct nvme_request	*req;
+	struct spdk_nvme_cmd	*cmd;
+	struct nvme_payload	payload;
+	uint32_t valid_flags = SPDK_OCSSD_IO_FLAGS_LIMITED_RETRY;
+
+	if (io_flags & ~valid_flags) {
+		return -EINVAL;
+	}
+
+	if (!buffer || !lba_list || (num_lbas == 0) ||
+	    (num_lbas > SPDK_NVME_OCSSD_MAX_LBAL_ENTRIES)) {
+		return -EINVAL;
+	}
+
+	payload = NVME_PAYLOAD_CONTIG(buffer, metadata);
+
+	req = nvme_allocate_request(qpair, &payload, num_lbas * ns->sector_size, cb_fn, cb_arg);
+	if (req == NULL) {
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = opc;
+	cmd->nsid = ns->id;
+
+	/*
+	 * Dword 10 and 11 store a pointer to the list of logical block addresses.
+	 * If there is a single entry in the LBA list, the logical block
+	 * address should be stored instead.
+	 */
+	if (num_lbas == 1) {
+		*(uint64_t *)&cmd->cdw10 = *lba_list;
+	} else {
+		*(uint64_t *)&cmd->cdw10 = spdk_vtophys(lba_list);
+	}
+
+	cmd->cdw12 = num_lbas - 1;
+	cmd->cdw12 |= io_flags;
+
+	return nvme_qpair_submit_request(qpair, req);
+}
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_write_with_md(struct spdk_nvme_ns *ns,
+		struct spdk_nvme_qpair *qpair,
+		void *buffer, void *metadata,
+		uint64_t *lba_list, uint32_t num_lbas,
+		spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+		uint32_t io_flags)
+{
+	return _nvme_ocssd_ns_cmd_vector_rw_with_md(ns, qpair, buffer, metadata, lba_list,
+			num_lbas, cb_fn, cb_arg, SPDK_OCSSD_OPC_VECTOR_WRITE, io_flags);
+}
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_write(struct spdk_nvme_ns *ns,
+				    struct spdk_nvme_qpair *qpair,
+				    void *buffer,
+				    uint64_t *lba_list, uint32_t num_lbas,
+				    spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				    uint32_t io_flags)
+{
+	return _nvme_ocssd_ns_cmd_vector_rw_with_md(ns, qpair, buffer, NULL, lba_list,
+			num_lbas, cb_fn, cb_arg, SPDK_OCSSD_OPC_VECTOR_WRITE, io_flags);
+}
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_read_with_md(struct spdk_nvme_ns *ns,
+		struct spdk_nvme_qpair *qpair,
+		void *buffer, void *metadata,
+		uint64_t *lba_list, uint32_t num_lbas,
+		spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+		uint32_t io_flags)
+{
+	return _nvme_ocssd_ns_cmd_vector_rw_with_md(ns, qpair, buffer, metadata, lba_list,
+			num_lbas, cb_fn, cb_arg, SPDK_OCSSD_OPC_VECTOR_READ, io_flags);
+}
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_read(struct spdk_nvme_ns *ns,
+				   struct spdk_nvme_qpair *qpair,
+				   void *buffer,
+				   uint64_t *lba_list, uint32_t num_lbas,
+				   spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				   uint32_t io_flags)
+{
+	return _nvme_ocssd_ns_cmd_vector_rw_with_md(ns, qpair, buffer, NULL, lba_list,
+			num_lbas, cb_fn, cb_arg, SPDK_OCSSD_OPC_VECTOR_READ, io_flags);
+}
+
+int
+spdk_nvme_ocssd_ns_cmd_vector_copy(struct spdk_nvme_ns *ns,
+				   struct spdk_nvme_qpair *qpair,
+				   uint64_t *dst_lba_list,
+				   uint64_t *src_lba_list,
+				   uint32_t num_lbas,
+				   spdk_nvme_cmd_cb cb_fn, void *cb_arg,
+				   uint32_t io_flags)
+{
+	struct nvme_request	*req;
+	struct spdk_nvme_cmd	*cmd;
+
+	uint32_t valid_flags = SPDK_OCSSD_IO_FLAGS_LIMITED_RETRY;
+
+	if (io_flags & ~valid_flags) {
+		return -EINVAL;
+	}
+
+	if (!dst_lba_list || !src_lba_list || (num_lbas == 0) ||
+	    (num_lbas > SPDK_NVME_OCSSD_MAX_LBAL_ENTRIES)) {
+		return -EINVAL;
+	}
+
+	req = nvme_allocate_request_null(qpair, cb_fn, cb_arg);
+	if (req == NULL) {
+		return -ENOMEM;
+	}
+
+	cmd = &req->cmd;
+	cmd->opc = SPDK_OCSSD_OPC_VECTOR_COPY;
+	cmd->nsid = ns->id;
+
+	/*
+	 * Dword 10 and 11 store a pointer to the list of source logical
+	 * block addresses.
+	 * Dword 14 and 15 store a pointer to the list of destination logical
+	 * block addresses.
+	 * If there is a single entry in the LBA list, the logical block
+	 * address should be stored instead.
+	 */
+	if (num_lbas == 1) {
+		*(uint64_t *)&cmd->cdw10 = *src_lba_list;
+		*(uint64_t *)&cmd->cdw14 = *dst_lba_list;
+	} else {
+		*(uint64_t *)&cmd->cdw10 = spdk_vtophys(src_lba_list);
+		*(uint64_t *)&cmd->cdw14 = spdk_vtophys(dst_lba_list);
+	}
+
+	cmd->cdw12 = num_lbas - 1;
+	cmd->cdw12 |= io_flags;
+
+	return nvme_qpair_submit_request(qpair, req);
+}
diff --git a/lib/nvme/nvme_pcie.c b/lib/nvme/nvme_pcie.c
index 860bbe163..6bf282a0d 100644
--- a/lib/nvme/nvme_pcie.c
+++ b/lib/nvme/nvme_pcie.c
@@ -115,14 +115,12 @@ struct nvme_tracker {
 	struct nvme_request		*req;
 	uint16_t			cid;
 
-	uint16_t			rsvd1: 14;
-	uint16_t			timed_out: 1;
+	uint16_t			rsvd1: 15;
 	uint16_t			active: 1;
 
 	uint32_t			rsvd2;
 
-	/* The value of spdk_get_ticks() when the tracker was submitted to the hardware. */
-	uint64_t			submit_tick;
+	uint64_t			rsvd3;
 
 	uint64_t			prp_sgl_bus_addr;
 
@@ -256,6 +254,7 @@ _nvme_pcie_hotplug_monitor(void *cb_ctx, spdk_nvme_probe_cb probe_cb,
 	struct spdk_uevent event;
 	struct spdk_pci_addr pci_addr;
 	union spdk_nvme_csts_register csts;
+	struct spdk_nvme_ctrlr_process *proc;
 
 	while (spdk_get_uevent(hotplug_fd, &event) > 0) {
 		if (event.subsystem == SPDK_NVME_UEVENT_SUBSYSTEM_UIO ||
@@ -296,13 +295,17 @@ _nvme_pcie_hotplug_monitor(void *cb_ctx, spdk_nvme_probe_cb probe_cb,
 
 	/* This is a work around for vfio-attached device hot remove detection. */
 	TAILQ_FOREACH_SAFE(ctrlr, &g_spdk_nvme_driver->shared_attached_ctrlrs, tailq, tmp) {
-		csts = spdk_nvme_ctrlr_get_regs_csts(ctrlr);
-		if (csts.raw == 0xffffffffU) {
-			nvme_ctrlr_fail(ctrlr, true);
-			if (remove_cb) {
-				nvme_robust_mutex_unlock(&g_spdk_nvme_driver->lock);
-				remove_cb(cb_ctx, ctrlr);
-				nvme_robust_mutex_lock(&g_spdk_nvme_driver->lock);
+		/* NVMe controller BAR must be mapped to secondary process space before any access. */
+		proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+		if (proc) {
+			csts = spdk_nvme_ctrlr_get_regs_csts(ctrlr);
+			if (csts.raw == 0xffffffffU) {
+				nvme_ctrlr_fail(ctrlr, true);
+				if (remove_cb) {
+					nvme_robust_mutex_unlock(&g_spdk_nvme_driver->lock);
+					remove_cb(cb_ctx, ctrlr);
+					nvme_robust_mutex_lock(&g_spdk_nvme_driver->lock);
+				}
 			}
 		}
 	}
@@ -313,14 +316,14 @@ static inline struct nvme_pcie_ctrlr *
 nvme_pcie_ctrlr(struct spdk_nvme_ctrlr *ctrlr)
 {
 	assert(ctrlr->trid.trtype == SPDK_NVME_TRANSPORT_PCIE);
-	return (struct nvme_pcie_ctrlr *)((uintptr_t)ctrlr - offsetof(struct nvme_pcie_ctrlr, ctrlr));
+	return SPDK_CONTAINEROF(ctrlr, struct nvme_pcie_ctrlr, ctrlr);
 }
 
 static inline struct nvme_pcie_qpair *
 nvme_pcie_qpair(struct spdk_nvme_qpair *qpair)
 {
 	assert(qpair->trtype == SPDK_NVME_TRANSPORT_PCIE);
-	return (struct nvme_pcie_qpair *)((uintptr_t)qpair - offsetof(struct nvme_pcie_qpair, qpair));
+	return SPDK_CONTAINEROF(qpair, struct nvme_pcie_qpair, qpair);
 }
 
 static volatile void *
@@ -774,6 +777,7 @@ struct spdk_nvme_ctrlr *nvme_pcie_ctrlr_construct(const struct spdk_nvme_transpo
 	struct spdk_pci_device *pci_dev = devhandle;
 	struct nvme_pcie_ctrlr *pctrlr;
 	union spdk_nvme_cap_register cap;
+	union spdk_nvme_vs_register vs;
 	uint32_t cmd_reg;
 	int rc, claim_fd;
 	struct spdk_pci_id pci_id;
@@ -824,7 +828,14 @@ struct spdk_nvme_ctrlr *nvme_pcie_ctrlr_construct(const struct spdk_nvme_transpo
 		return NULL;
 	}
 
-	nvme_ctrlr_init_cap(&pctrlr->ctrlr, &cap);
+	if (nvme_ctrlr_get_vs(&pctrlr->ctrlr, &vs)) {
+		SPDK_ERRLOG("get_vs() failed\n");
+		close(claim_fd);
+		spdk_dma_free(pctrlr);
+		return NULL;
+	}
+
+	nvme_ctrlr_init_cap(&pctrlr->ctrlr, &cap, &vs);
 
 	/* Doorbell stride is 2 ^ (dstrd + 2),
 	 * but we want multiples of 4, so drop the + 2 */
@@ -958,10 +969,9 @@ nvme_pcie_qpair_construct(struct spdk_nvme_qpair *qpair)
 	struct nvme_tracker	*tr;
 	uint16_t		i;
 	volatile uint32_t	*doorbell_base;
-	uint64_t		phys_addr = 0;
 	uint64_t		offset;
 	uint16_t		num_trackers;
-	size_t			page_size = sysconf(_SC_PAGESIZE);
+	size_t			page_align = 0x200000;
 
 	/*
 	 * Limit the maximum number of completions to return per call to prevent wraparound,
@@ -983,15 +993,19 @@ nvme_pcie_qpair_construct(struct spdk_nvme_qpair *qpair)
 	/* cmd and cpl rings must be aligned on page size boundaries. */
 	if (ctrlr->opts.use_cmb_sqs) {
 		if (nvme_pcie_ctrlr_alloc_cmb(ctrlr, pqpair->num_entries * sizeof(struct spdk_nvme_cmd),
-					      page_size, &offset) == 0) {
+					      sysconf(_SC_PAGESIZE), &offset) == 0) {
 			pqpair->cmd = pctrlr->cmb_bar_virt_addr + offset;
 			pqpair->cmd_bus_addr = pctrlr->cmb_bar_phys_addr + offset;
 			pqpair->sq_in_cmb = true;
 		}
 	}
+
+	/* To ensure physical address contiguity we make each ring occupy
+	 * a single hugepage only. See MAX_IO_QUEUE_ENTRIES.
+	 */
 	if (pqpair->sq_in_cmb == false) {
 		pqpair->cmd = spdk_dma_zmalloc(pqpair->num_entries * sizeof(struct spdk_nvme_cmd),
-					       page_size,
+					       page_align,
 					       &pqpair->cmd_bus_addr);
 		if (pqpair->cmd == NULL) {
 			SPDK_ERRLOG("alloc qpair_cmd failed\n");
@@ -1000,7 +1014,7 @@ nvme_pcie_qpair_construct(struct spdk_nvme_qpair *qpair)
 	}
 
 	pqpair->cpl = spdk_dma_zmalloc(pqpair->num_entries * sizeof(struct spdk_nvme_cpl),
-				       page_size,
+				       page_align,
 				       &pqpair->cpl_bus_addr);
 	if (pqpair->cpl == NULL) {
 		SPDK_ERRLOG("alloc qpair_cpl failed\n");
@@ -1017,7 +1031,7 @@ nvme_pcie_qpair_construct(struct spdk_nvme_qpair *qpair)
 	 *   This ensures the PRP list embedded in the nvme_tracker object will not span a
 	 *   4KB boundary, while allowing access to trackers in tr[] via normal array indexing.
 	 */
-	pqpair->tr = spdk_dma_zmalloc(num_trackers * sizeof(*tr), sizeof(*tr), &phys_addr);
+	pqpair->tr = spdk_dma_zmalloc(num_trackers * sizeof(*tr), sizeof(*tr), NULL);
 	if (pqpair->tr == NULL) {
 		SPDK_ERRLOG("nvme_tr failed\n");
 		return -ENOMEM;
@@ -1028,9 +1042,8 @@ nvme_pcie_qpair_construct(struct spdk_nvme_qpair *qpair)
 
 	for (i = 0; i < num_trackers; i++) {
 		tr = &pqpair->tr[i];
-		nvme_qpair_construct_tracker(tr, i, phys_addr);
+		nvme_qpair_construct_tracker(tr, i, spdk_vtophys(tr));
 		TAILQ_INSERT_HEAD(&pqpair->free_tr, tr, tq_list);
-		phys_addr += sizeof(struct nvme_tracker);
 	}
 
 	nvme_pcie_qpair_reset(qpair);
@@ -1071,7 +1084,6 @@ nvme_pcie_qpair_insert_pending_admin_request(struct spdk_nvme_qpair *qpair,
 	struct spdk_nvme_ctrlr		*ctrlr = qpair->ctrlr;
 	struct nvme_request		*active_req = req;
 	struct spdk_nvme_ctrlr_process	*active_proc;
-	bool				pending_on_proc = false;
 
 	/*
 	 * The admin request is from another process. Move to the per
@@ -1080,19 +1092,13 @@ nvme_pcie_qpair_insert_pending_admin_request(struct spdk_nvme_qpair *qpair,
 	assert(nvme_qpair_is_admin_queue(qpair));
 	assert(active_req->pid != getpid());
 
-	TAILQ_FOREACH(active_proc, &ctrlr->active_procs, tailq) {
-		if (active_proc->pid == active_req->pid) {
-			/* Saved the original completion information */
-			memcpy(&active_req->cpl, cpl, sizeof(*cpl));
-			STAILQ_INSERT_TAIL(&active_proc->active_reqs, active_req, stailq);
-			pending_on_proc = true;
-
-			break;
-		}
-	}
-
-	if (pending_on_proc == false) {
-		SPDK_ERRLOG("The owning process (pid %d) is not found. Drop the request.\n",
+	active_proc = spdk_nvme_ctrlr_get_process(ctrlr, active_req->pid);
+	if (active_proc) {
+		/* Save the original completion information */
+		memcpy(&active_req->cpl, cpl, sizeof(*cpl));
+		STAILQ_INSERT_TAIL(&active_proc->active_reqs, active_req, stailq);
+	} else {
+		SPDK_ERRLOG("The owning process (pid %d) is not found. Dropping the request.\n",
 			    active_req->pid);
 
 		nvme_free_request(active_req);
@@ -1107,7 +1113,6 @@ nvme_pcie_qpair_complete_pending_admin_request(struct spdk_nvme_qpair *qpair)
 {
 	struct spdk_nvme_ctrlr		*ctrlr = qpair->ctrlr;
 	struct nvme_request		*req, *tmp_req;
-	bool				proc_found = false;
 	pid_t				pid = getpid();
 	struct spdk_nvme_ctrlr_process	*proc;
 
@@ -1117,17 +1122,11 @@ nvme_pcie_qpair_complete_pending_admin_request(struct spdk_nvme_qpair *qpair)
 	 */
 	assert(nvme_qpair_is_admin_queue(qpair));
 
-	TAILQ_FOREACH(proc, &ctrlr->active_procs, tailq) {
-		if (proc->pid == pid) {
-			proc_found = true;
-
-			break;
-		}
-	}
-
-	if (proc_found == false) {
+	proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	if (!proc) {
 		SPDK_ERRLOG("the active process (pid %d) is not found for this controller.\n", pid);
-		assert(proc_found);
+		assert(proc);
+		return;
 	}
 
 	STAILQ_FOREACH_SAFE(req, &proc->active_reqs, stailq, tmp_req) {
@@ -1135,10 +1134,7 @@ nvme_pcie_qpair_complete_pending_admin_request(struct spdk_nvme_qpair *qpair)
 
 		assert(req->pid == pid);
 
-		if (req->cb_fn) {
-			req->cb_fn(req->cb_arg, &req->cpl);
-		}
-
+		nvme_complete_request(req, &req->cpl);
 		nvme_free_request(req);
 	}
 }
@@ -1177,12 +1173,15 @@ nvme_pcie_qpair_submit_tracker(struct spdk_nvme_qpair *qpair, struct nvme_tracke
 	struct nvme_pcie_qpair	*pqpair = nvme_pcie_qpair(qpair);
 	struct nvme_pcie_ctrlr	*pctrlr = nvme_pcie_ctrlr(qpair->ctrlr);
 
-	tr->timed_out = 0;
-	if (spdk_unlikely(qpair->active_proc && qpair->active_proc->timeout_cb_fn != NULL)) {
-		tr->submit_tick = spdk_get_ticks();
+	req = tr->req;
+	assert(req != NULL);
+	req->timed_out = false;
+	if (spdk_unlikely(pctrlr->ctrlr.timeout_enabled)) {
+		req->submit_tick = spdk_get_ticks();
+	} else {
+		req->submit_tick = 0;
 	}
 
-	req = tr->req;
 	pqpair->tr[tr->cid].active = true;
 
 	/* Copy the command from the tracker to the submission queue. */
@@ -1197,14 +1196,14 @@ nvme_pcie_qpair_submit_tracker(struct spdk_nvme_qpair *qpair, struct nvme_tracke
 	}
 
 	spdk_wmb();
-	g_thread_mmio_ctrlr = pctrlr;
 	if (spdk_likely(nvme_pcie_qpair_update_mmio_required(qpair,
 			pqpair->sq_tail,
 			pqpair->sq_shadow_tdbl,
 			pqpair->sq_eventidx))) {
+		g_thread_mmio_ctrlr = pctrlr;
 		spdk_mmio_write_4(pqpair->sq_tdbl, pqpair->sq_tail);
+		g_thread_mmio_ctrlr = NULL;
 	}
-	g_thread_mmio_ctrlr = NULL;
 }
 
 static void
@@ -1244,9 +1243,7 @@ nvme_pcie_qpair_complete_tracker(struct spdk_nvme_qpair *qpair, struct nvme_trac
 				req_from_current_proc = false;
 				nvme_pcie_qpair_insert_pending_admin_request(qpair, req, cpl);
 			} else {
-				if (req->cb_fn) {
-					req->cb_fn(req->cb_arg, cpl);
-				}
+				nvme_complete_request(req, cpl);
 			}
 		}
 
@@ -1346,6 +1343,8 @@ nvme_pcie_qpair_destroy(struct spdk_nvme_qpair *qpair)
 		spdk_dma_free(pqpair->tr);
 	}
 
+	nvme_qpair_deinit(qpair);
+
 	spdk_dma_free(pqpair);
 
 	return 0;
@@ -1527,40 +1526,29 @@ _nvme_pcie_ctrlr_create_io_qpair(struct spdk_nvme_ctrlr *ctrlr, struct spdk_nvme
 	struct nvme_completion_poll_status	status;
 	int					rc;
 
-	status.done = false;
 	rc = nvme_pcie_ctrlr_cmd_create_io_cq(ctrlr, qpair, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("nvme_create_io_cq failed!\n");
 		return -1;
 	}
 
-	status.done = false;
 	rc = nvme_pcie_ctrlr_cmd_create_io_sq(qpair->ctrlr, qpair, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("nvme_create_io_sq failed!\n");
 		/* Attempt to delete the completion queue */
-		status.done = false;
 		rc = nvme_pcie_ctrlr_cmd_delete_io_cq(qpair->ctrlr, qpair, nvme_completion_poll_cb, &status);
 		if (rc != 0) {
 			return -1;
 		}
-		while (status.done == false) {
-			spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-		}
+		spdk_nvme_wait_for_completion(ctrlr->adminq, &status);
 		return -1;
 	}
 
@@ -1636,15 +1624,11 @@ nvme_pcie_ctrlr_delete_io_qpair(struct spdk_nvme_ctrlr *ctrlr, struct spdk_nvme_
 	}
 
 	/* Delete the I/O submission queue */
-	status.done = false;
 	rc = nvme_pcie_ctrlr_cmd_delete_io_sq(ctrlr, qpair, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		return -1;
 	}
 
@@ -1657,15 +1641,11 @@ nvme_pcie_ctrlr_delete_io_qpair(struct spdk_nvme_ctrlr *ctrlr, struct spdk_nvme_
 	}
 
 	/* Delete the completion queue */
-	status.done = false;
 	rc = nvme_pcie_ctrlr_cmd_delete_io_cq(ctrlr, qpair, nvme_completion_poll_cb, &status);
 	if (rc != 0) {
 		return rc;
 	}
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(ctrlr->adminq, &status)) {
 		return -1;
 	}
 
@@ -1773,7 +1753,7 @@ nvme_pcie_qpair_build_contig_request(struct spdk_nvme_qpair *qpair, struct nvme_
 	uint32_t prp_index = 0;
 	int rc;
 
-	rc = nvme_pcie_prp_list_append(tr, &prp_index, req->payload.u.contig + req->payload_offset,
+	rc = nvme_pcie_prp_list_append(tr, &prp_index, req->payload.contig_or_cb_arg + req->payload_offset,
 				       req->payload_size, qpair->ctrlr->page_size);
 	if (rc) {
 		nvme_pcie_fail_request_bad_vtophys(qpair, tr);
@@ -1783,6 +1763,8 @@ nvme_pcie_qpair_build_contig_request(struct spdk_nvme_qpair *qpair, struct nvme_
 	return 0;
 }
 
+#define _2MB_OFFSET(ptr)	(((uintptr_t)(ptr)) &  (0x200000 - 1))
+
 /**
  * Build SGL list describing scattered payload buffer.
  */
@@ -1793,7 +1775,7 @@ nvme_pcie_qpair_build_hw_sgl_request(struct spdk_nvme_qpair *qpair, struct nvme_
 	int rc;
 	void *virt_addr;
 	uint64_t phys_addr;
-	uint32_t remaining_transfer_len, length;
+	uint32_t remaining_transfer_len, remaining_user_sge_len, length;
 	struct spdk_nvme_sgl_descriptor *sgl;
 	uint32_t nseg = 0;
 
@@ -1801,10 +1783,10 @@ nvme_pcie_qpair_build_hw_sgl_request(struct spdk_nvme_qpair *qpair, struct nvme_
 	 * Build scattered payloads.
 	 */
 	assert(req->payload_size != 0);
-	assert(req->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	assert(req->payload.u.sgl.reset_sgl_fn != NULL);
-	assert(req->payload.u.sgl.next_sge_fn != NULL);
-	req->payload.u.sgl.reset_sgl_fn(req->payload.u.sgl.cb_arg, req->payload_offset);
+	assert(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL);
+	assert(req->payload.reset_sgl_fn != NULL);
+	assert(req->payload.next_sge_fn != NULL);
+	req->payload.reset_sgl_fn(req->payload.contig_or_cb_arg, req->payload_offset);
 
 	sgl = tr->u.sgl;
 	req->cmd.psdt = SPDK_NVME_PSDT_SGL_MPTR_CONTIG;
@@ -1813,33 +1795,46 @@ nvme_pcie_qpair_build_hw_sgl_request(struct spdk_nvme_qpair *qpair, struct nvme_
 	remaining_transfer_len = req->payload_size;
 
 	while (remaining_transfer_len > 0) {
-		if (nseg >= NVME_MAX_SGL_DESCRIPTORS) {
-			nvme_pcie_fail_request_bad_vtophys(qpair, tr);
-			return -1;
-		}
-
-		rc = req->payload.u.sgl.next_sge_fn(req->payload.u.sgl.cb_arg, &virt_addr, &length);
+		rc = req->payload.next_sge_fn(req->payload.contig_or_cb_arg,
+					      &virt_addr, &remaining_user_sge_len);
 		if (rc) {
 			nvme_pcie_fail_request_bad_vtophys(qpair, tr);
 			return -1;
 		}
 
-		phys_addr = spdk_vtophys(virt_addr);
-		if (phys_addr == SPDK_VTOPHYS_ERROR) {
-			nvme_pcie_fail_request_bad_vtophys(qpair, tr);
-			return -1;
-		}
+		remaining_user_sge_len = spdk_min(remaining_user_sge_len, remaining_transfer_len);
+		remaining_transfer_len -= remaining_user_sge_len;
+		while (remaining_user_sge_len > 0) {
+			if (nseg >= NVME_MAX_SGL_DESCRIPTORS) {
+				nvme_pcie_fail_request_bad_vtophys(qpair, tr);
+				return -1;
+			}
 
-		length = spdk_min(remaining_transfer_len, length);
-		remaining_transfer_len -= length;
+			phys_addr = spdk_vtophys(virt_addr);
+			if (phys_addr == SPDK_VTOPHYS_ERROR) {
+				nvme_pcie_fail_request_bad_vtophys(qpair, tr);
+				return -1;
+			}
+
+			length = spdk_min(remaining_user_sge_len, 0x200000 - _2MB_OFFSET(virt_addr));
+			remaining_user_sge_len -= length;
+			virt_addr += length;
+
+			if (nseg > 0 && phys_addr ==
+			    (*(sgl - 1)).address + (*(sgl - 1)).unkeyed.length) {
+				/* extend previous entry */
+				(*(sgl - 1)).unkeyed.length += length;
+				continue;
+			}
 
-		sgl->unkeyed.type = SPDK_NVME_SGL_TYPE_DATA_BLOCK;
-		sgl->unkeyed.length = length;
-		sgl->address = phys_addr;
-		sgl->unkeyed.subtype = 0;
+			sgl->unkeyed.type = SPDK_NVME_SGL_TYPE_DATA_BLOCK;
+			sgl->unkeyed.length = length;
+			sgl->address = phys_addr;
+			sgl->unkeyed.subtype = 0;
 
-		sgl++;
-		nseg++;
+			sgl++;
+			nseg++;
+		}
 	}
 
 	if (nseg == 1) {
@@ -1878,14 +1873,14 @@ nvme_pcie_qpair_build_prps_sgl_request(struct spdk_nvme_qpair *qpair, struct nvm
 	/*
 	 * Build scattered payloads.
 	 */
-	assert(req->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	assert(req->payload.u.sgl.reset_sgl_fn != NULL);
-	req->payload.u.sgl.reset_sgl_fn(req->payload.u.sgl.cb_arg, req->payload_offset);
+	assert(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL);
+	assert(req->payload.reset_sgl_fn != NULL);
+	req->payload.reset_sgl_fn(req->payload.contig_or_cb_arg, req->payload_offset);
 
 	remaining_transfer_len = req->payload_size;
 	while (remaining_transfer_len > 0) {
-		assert(req->payload.u.sgl.next_sge_fn != NULL);
-		rc = req->payload.u.sgl.next_sge_fn(req->payload.u.sgl.cb_arg, &virt_addr, &length);
+		assert(req->payload.next_sge_fn != NULL);
+		rc = req->payload.next_sge_fn(req->payload.contig_or_cb_arg, &virt_addr, &length);
 		if (rc) {
 			nvme_pcie_fail_request_bad_vtophys(qpair, tr);
 			return -1;
@@ -1975,9 +1970,9 @@ nvme_pcie_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_reques
 	if (req->payload_size == 0) {
 		/* Null payload - leave PRP fields zeroed */
 		rc = 0;
-	} else if (req->payload.type == NVME_PAYLOAD_TYPE_CONTIG) {
+	} else if (nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_CONTIG) {
 		rc = nvme_pcie_qpair_build_contig_request(qpair, req, tr);
-	} else if (req->payload.type == NVME_PAYLOAD_TYPE_SGL) {
+	} else if (nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL) {
 		if (ctrlr->flags & SPDK_NVME_CTRLR_SGL_SUPPORTED) {
 			rc = nvme_pcie_qpair_build_hw_sgl_request(qpair, req, tr);
 		} else {
@@ -2010,34 +2005,35 @@ nvme_pcie_qpair_check_timeout(struct spdk_nvme_qpair *qpair)
 	struct nvme_tracker *tr, *tmp;
 	struct nvme_pcie_qpair *pqpair = nvme_pcie_qpair(qpair);
 	struct spdk_nvme_ctrlr *ctrlr = qpair->ctrlr;
+	struct spdk_nvme_ctrlr_process *active_proc;
 
-	t02 = spdk_get_ticks();
-	TAILQ_FOREACH_SAFE(tr, &pqpair->outstanding_tr, tq_list, tmp) {
-		if (tr->timed_out) {
-			continue;
-		}
+	/* Don't check timeouts during controller initialization. */
+	if (ctrlr->state != NVME_CTRLR_STATE_READY) {
+		return;
+	}
 
-		if (nvme_qpair_is_admin_queue(qpair)) {
-			if (tr->req->pid != getpid()) {
-				continue;
-			}
+	if (nvme_qpair_is_admin_queue(qpair)) {
+		active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	} else {
+		active_proc = qpair->active_proc;
+	}
 
-			if (tr->req->cmd.opc == SPDK_NVME_OPC_ASYNC_EVENT_REQUEST) {
-				continue;
-			}
-		}
+	/* Only check timeouts if the current process has a timeout callback. */
+	if (active_proc == NULL || active_proc->timeout_cb_fn == NULL) {
+		return;
+	}
+
+	t02 = spdk_get_ticks();
+	TAILQ_FOREACH_SAFE(tr, &pqpair->outstanding_tr, tq_list, tmp) {
+		assert(tr->req != NULL);
 
-		if (tr->submit_tick + qpair->active_proc->timeout_ticks > t02) {
-			/* The trackers are in order, so as soon as one has not timed out,
+		if (nvme_request_check_timeout(tr->req, tr->cid, active_proc, t02)) {
+			/*
+			 * The requests are in order, so as soon as one has not timed out,
 			 * stop iterating.
 			 */
 			break;
 		}
-
-		tr->timed_out = 1;
-		qpair->active_proc->timeout_cb_fn(qpair->active_proc->timeout_cb_arg, ctrlr,
-						  nvme_qpair_is_admin_queue(qpair) ? NULL : qpair,
-						  tr->cid);
 	}
 }
 
@@ -2089,6 +2085,11 @@ nvme_pcie_qpair_process_completions(struct spdk_nvme_qpair *qpair, uint32_t max_
 		spdk_mb();
 #endif
 
+		if (spdk_unlikely(++pqpair->cq_head == pqpair->num_entries)) {
+			pqpair->cq_head = 0;
+			pqpair->phase = !pqpair->phase;
+		}
+
 		tr = &pqpair->tr[cpl->cid];
 		pqpair->sq_head = cpl->sqhd;
 
@@ -2100,32 +2101,22 @@ nvme_pcie_qpair_process_completions(struct spdk_nvme_qpair *qpair, uint32_t max_
 			assert(0);
 		}
 
-		if (spdk_unlikely(++pqpair->cq_head == pqpair->num_entries)) {
-			pqpair->cq_head = 0;
-			pqpair->phase = !pqpair->phase;
-		}
-
 		if (++num_completions == max_completions) {
 			break;
 		}
 	}
 
 	if (num_completions > 0) {
-		g_thread_mmio_ctrlr = pctrlr;
 		if (spdk_likely(nvme_pcie_qpair_update_mmio_required(qpair, pqpair->cq_head,
 				pqpair->cq_shadow_hdbl,
 				pqpair->cq_eventidx))) {
+			g_thread_mmio_ctrlr = pctrlr;
 			spdk_mmio_write_4(pqpair->cq_hdbl, pqpair->cq_head);
+			g_thread_mmio_ctrlr = NULL;
 		}
-		g_thread_mmio_ctrlr = NULL;
 	}
 
-	/* We don't want to expose the admin queue to the user,
-	 * so when we're timing out admin commands set the
-	 * qpair to NULL.
-	 */
-	if (!nvme_qpair_is_admin_queue(qpair) && spdk_unlikely(qpair->active_proc->timeout_cb_fn != NULL) &&
-	    qpair->ctrlr->state == NVME_CTRLR_STATE_READY) {
+	if (spdk_unlikely(ctrlr->timeout_enabled)) {
 		/*
 		 * User registered for timeout callback
 		 */
diff --git a/lib/nvme/nvme_qpair.c b/lib/nvme/nvme_qpair.c
index 3a32b2c8d..750f4139b 100644
--- a/lib/nvme/nvme_qpair.c
+++ b/lib/nvme/nvme_qpair.c
@@ -249,6 +249,14 @@ static const struct nvme_string media_error_status[] = {
 	{ 0xFFFF, "MEDIA ERROR" }
 };
 
+static const struct nvme_string path_status[] = {
+	{ SPDK_NVME_SC_INTERNAL_PATH_ERROR, "INTERNAL PATH ERROR" },
+	{ SPDK_NVME_SC_CONTROLLER_PATH_ERROR, "CONTROLLER PATH ERROR" },
+	{ SPDK_NVME_SC_HOST_PATH_ERROR, "HOST PATH ERROR" },
+	{ SPDK_NVME_SC_ABORTED_BY_HOST, "ABORTED BY HOST" },
+	{ 0xFFFF, "PATH ERROR" }
+};
+
 static const char *
 get_status_string(uint16_t sct, uint16_t sc)
 {
@@ -264,6 +272,9 @@ get_status_string(uint16_t sct, uint16_t sc)
 	case SPDK_NVME_SCT_MEDIA_ERROR:
 		entry = media_error_status;
 		break;
+	case SPDK_NVME_SCT_PATH:
+		entry = path_status;
+		break;
 	case SPDK_NVME_SCT_VENDOR_SPECIFIC:
 		return "VENDOR SPECIFIC";
 	default:
@@ -319,6 +330,17 @@ nvme_completion_is_retry(const struct spdk_nvme_cpl *cpl)
 		default:
 			return false;
 		}
+	case SPDK_NVME_SCT_PATH:
+		/*
+		 * Per NVMe TP 4028 (Path and Transport Error Enhancments), retries should be
+		 * based on the setting of the DNR bit for Internal Path Error
+		 */
+		switch ((int)cpl->status.sc) {
+		case SPDK_NVME_SC_INTERNAL_PATH_ERROR:
+			return !cpl->status.dnr;
+		default:
+			return false;
+		}
 	case SPDK_NVME_SCT_COMMAND_SPECIFIC:
 	case SPDK_NVME_SCT_MEDIA_ERROR:
 	case SPDK_NVME_SCT_VENDOR_SPECIFIC:
@@ -343,14 +365,12 @@ nvme_qpair_manual_complete_request(struct spdk_nvme_qpair *qpair,
 	error = spdk_nvme_cpl_is_error(&cpl);
 
 	if (error && print_on_error) {
+		SPDK_NOTICELOG("Command completed manually:\n");
 		nvme_qpair_print_command(qpair, &req->cmd);
 		nvme_qpair_print_completion(qpair, &cpl);
 	}
 
-	if (req->cb_fn) {
-		req->cb_fn(req->cb_arg, &cpl);
-	}
-
+	nvme_complete_request(req, &cpl);
 	nvme_free_request(req);
 }
 
@@ -358,12 +378,25 @@ int32_t
 spdk_nvme_qpair_process_completions(struct spdk_nvme_qpair *qpair, uint32_t max_completions)
 {
 	int32_t ret;
+	struct nvme_request *req, *tmp;
 
 	if (qpair->ctrlr->is_failed) {
 		nvme_qpair_fail(qpair);
 		return 0;
 	}
 
+	/* error injection for those queued error requests */
+	if (spdk_unlikely(!STAILQ_EMPTY(&qpair->err_req_head))) {
+		STAILQ_FOREACH_SAFE(req, &qpair->err_req_head, stailq, tmp) {
+			if (spdk_get_ticks() - req->submit_tick > req->timeout_tsc) {
+				STAILQ_REMOVE(&qpair->err_req_head, req, nvme_request, stailq);
+				nvme_qpair_manual_complete_request(qpair, req,
+								   req->cpl.status.sct,
+								   req->cpl.status.sc, true);
+			}
+		}
+	}
+
 	qpair->in_completion_context = 1;
 	ret = nvme_transport_qpair_process_completions(qpair, max_completions);
 	qpair->in_completion_context = 0;
@@ -398,6 +431,8 @@ nvme_qpair_init(struct spdk_nvme_qpair *qpair, uint16_t id,
 
 	STAILQ_INIT(&qpair->free_req);
 	STAILQ_INIT(&qpair->queued_req);
+	TAILQ_INIT(&qpair->err_cmd_head);
+	STAILQ_INIT(&qpair->err_req_head);
 
 	req_size_padded = (sizeof(struct nvme_request) + 63) & ~(size_t)63;
 
@@ -415,11 +450,34 @@ nvme_qpair_init(struct spdk_nvme_qpair *qpair, uint16_t id,
 	return 0;
 }
 
+void
+nvme_qpair_deinit(struct spdk_nvme_qpair *qpair)
+{
+	struct nvme_request *req;
+	struct nvme_error_cmd *cmd, *entry;
+
+	while (!STAILQ_EMPTY(&qpair->err_req_head)) {
+		req = STAILQ_FIRST(&qpair->err_req_head);
+		STAILQ_REMOVE_HEAD(&qpair->err_req_head, stailq);
+		nvme_qpair_manual_complete_request(qpair, req,
+						   req->cpl.status.sct,
+						   req->cpl.status.sc, true);
+	}
+
+	TAILQ_FOREACH_SAFE(cmd, &qpair->err_cmd_head, link, entry) {
+		TAILQ_REMOVE(&qpair->err_cmd_head, cmd, link);
+		spdk_dma_free(cmd);
+	}
+
+	spdk_dma_free(qpair->req_buf);
+}
+
 int
 nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_request *req)
 {
 	int			rc = 0;
 	struct nvme_request	*child_req, *tmp;
+	struct nvme_error_cmd	*cmd;
 	struct spdk_nvme_ctrlr	*ctrlr = qpair->ctrlr;
 	bool			child_req_failed = false;
 
@@ -448,6 +506,26 @@ nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_request *re
 		return rc;
 	}
 
+	/* queue those requests which matches with opcode in err_cmd list */
+	if (spdk_unlikely(!TAILQ_EMPTY(&qpair->err_cmd_head))) {
+		TAILQ_FOREACH(cmd, &qpair->err_cmd_head, link) {
+			if (!cmd->do_not_submit) {
+				continue;
+			}
+
+			if ((cmd->opc == req->cmd.opc) && cmd->err_count) {
+				/* add to error request list and set cpl */
+				req->timeout_tsc = cmd->timeout_tsc;
+				req->submit_tick = spdk_get_ticks();
+				req->cpl.status.sct = cmd->status.sct;
+				req->cpl.status.sc = cmd->status.sc;
+				STAILQ_INSERT_TAIL(&qpair->err_req_head, req, stailq);
+				cmd->err_count--;
+				return 0;
+			}
+		}
+	}
+
 	return nvme_transport_qpair_submit_request(qpair, req);
 }
 
@@ -479,6 +557,16 @@ nvme_qpair_enable(struct spdk_nvme_qpair *qpair)
 void
 nvme_qpair_disable(struct spdk_nvme_qpair *qpair)
 {
+	struct nvme_request		*req;
+
+	while (!STAILQ_EMPTY(&qpair->err_req_head)) {
+		req = STAILQ_FIRST(&qpair->err_req_head);
+		STAILQ_REMOVE_HEAD(&qpair->err_req_head, stailq);
+		nvme_qpair_manual_complete_request(qpair, req,
+						   req->cpl.status.sct,
+						   req->cpl.status.sc, true);
+	}
+
 	nvme_transport_qpair_disable(qpair);
 }
 
@@ -497,3 +585,64 @@ nvme_qpair_fail(struct spdk_nvme_qpair *qpair)
 
 	nvme_transport_qpair_fail(qpair);
 }
+
+int
+spdk_nvme_qpair_add_cmd_error_injection(struct spdk_nvme_ctrlr *ctrlr,
+					struct spdk_nvme_qpair *qpair,
+					uint8_t opc, bool do_not_submit,
+					uint64_t timeout_in_us,
+					uint32_t err_count,
+					uint8_t sct, uint8_t sc)
+{
+	struct nvme_error_cmd *entry, *cmd = NULL;
+
+	if (qpair == NULL) {
+		qpair = ctrlr->adminq;
+	}
+
+	TAILQ_FOREACH(entry, &qpair->err_cmd_head, link) {
+		if (entry->opc == opc) {
+			cmd = entry;
+			break;
+		}
+	}
+
+	if (cmd == NULL) {
+		cmd = spdk_dma_zmalloc(sizeof(*cmd), 64, NULL);
+		if (!cmd) {
+			return -ENOMEM;
+		}
+		TAILQ_INSERT_TAIL(&qpair->err_cmd_head, cmd, link);
+	}
+
+	cmd->do_not_submit = do_not_submit;
+	cmd->err_count = err_count;
+	cmd->timeout_tsc = timeout_in_us * spdk_get_ticks_hz() / 1000000ULL;
+	cmd->opc = opc;
+	cmd->status.sct = sct;
+	cmd->status.sc = sc;
+
+	return 0;
+}
+
+void
+spdk_nvme_qpair_remove_cmd_error_injection(struct spdk_nvme_ctrlr *ctrlr,
+		struct spdk_nvme_qpair *qpair,
+		uint8_t opc)
+{
+	struct nvme_error_cmd *cmd, *entry;
+
+	if (qpair == NULL) {
+		qpair = ctrlr->adminq;
+	}
+
+	TAILQ_FOREACH_SAFE(cmd, &qpair->err_cmd_head, link, entry) {
+		if (cmd->opc == opc) {
+			TAILQ_REMOVE(&qpair->err_cmd_head, cmd, link);
+			spdk_dma_free(cmd);
+			return;
+		}
+	}
+
+	return;
+}
diff --git a/lib/nvme/nvme_quirks.c b/lib/nvme/nvme_quirks.c
index 19f7affcd..73dc76442 100644
--- a/lib/nvme/nvme_quirks.c
+++ b/lib/nvme/nvme_quirks.c
@@ -66,9 +66,22 @@ static const struct nvme_quirk nvme_quirks[] = {
 	{	{SPDK_PCI_VID_MEMBLAZE, 0x0540, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
 		NVME_QUIRK_DELAY_BEFORE_CHK_RDY
 	},
+	{	{SPDK_PCI_VID_SAMSUNG, 0xa821, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
+		NVME_QUIRK_DELAY_BEFORE_CHK_RDY
+	},
+	{	{SPDK_PCI_VID_SAMSUNG, 0xa822, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
+		NVME_QUIRK_DELAY_BEFORE_CHK_RDY
+	},
 	{	{SPDK_PCI_VID_VIRTUALBOX, 0x4e56, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
 		NVME_QUIRK_DELAY_AFTER_QUEUE_ALLOC
 	},
+	{	{SPDK_PCI_VID_INTEL, 0x5845, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
+		NVME_QUIRK_IDENTIFY_CNS
+	},
+	{	{SPDK_PCI_VID_CNEXLABS, 0x1f1f, SPDK_PCI_ANY_ID, SPDK_PCI_ANY_ID},
+		NVME_QUIRK_IDENTIFY_CNS |
+		NVME_QUIRK_OCSSD
+	},
 	{	{0x0000, 0x0000, 0x0000, 0x0000}, 0}
 };
 
@@ -113,6 +126,8 @@ nvme_get_quirks(const struct spdk_pci_id *id)
 			PRINT_QUIRK(NVME_INTEL_QUIRK_STRIPING);
 			PRINT_QUIRK(NVME_QUIRK_DELAY_AFTER_QUEUE_ALLOC);
 			PRINT_QUIRK(NVME_QUIRK_READ_ZERO_AFTER_DEALLOCATE);
+			PRINT_QUIRK(NVME_QUIRK_IDENTIFY_CNS);
+			PRINT_QUIRK(NVME_QUIRK_OCSSD);
 
 			return quirk->flags;
 		}
diff --git a/lib/nvme/nvme_rdma.c b/lib/nvme/nvme_rdma.c
index 9678305de..d2743d418 100644
--- a/lib/nvme/nvme_rdma.c
+++ b/lib/nvme/nvme_rdma.c
@@ -50,6 +50,7 @@
 #include "spdk/nvmf_spec.h"
 #include "spdk/string.h"
 #include "spdk/endian.h"
+#include "spdk/likely.h"
 
 #include "nvme_internal.h"
 
@@ -73,8 +74,6 @@ struct spdk_nvme_rdma_mr_map {
 /* NVMe RDMA transport extensions for spdk_nvme_ctrlr */
 struct nvme_rdma_ctrlr {
 	struct spdk_nvme_ctrlr			ctrlr;
-
-	uint16_t				cntlid;
 };
 
 /* NVMe RDMA qpair extensions for spdk_nvme_qpair */
@@ -111,7 +110,8 @@ struct nvme_rdma_qpair {
 
 	struct spdk_nvme_rdma_mr_map		*mr_map;
 
-	STAILQ_HEAD(, spdk_nvme_rdma_req)	free_reqs;
+	TAILQ_HEAD(, spdk_nvme_rdma_req)	free_reqs;
+	TAILQ_HEAD(, spdk_nvme_rdma_req)	outstanding_reqs;
 };
 
 struct spdk_nvme_rdma_req {
@@ -123,7 +123,7 @@ struct spdk_nvme_rdma_req {
 
 	struct ibv_sge				send_sgl;
 
-	STAILQ_ENTRY(spdk_nvme_rdma_req)	link;
+	TAILQ_ENTRY(spdk_nvme_rdma_req)		link;
 };
 
 static const char *rdma_cm_event_str[] = {
@@ -154,14 +154,14 @@ static inline struct nvme_rdma_qpair *
 nvme_rdma_qpair(struct spdk_nvme_qpair *qpair)
 {
 	assert(qpair->trtype == SPDK_NVME_TRANSPORT_RDMA);
-	return (struct nvme_rdma_qpair *)((uintptr_t)qpair - offsetof(struct nvme_rdma_qpair, qpair));
+	return SPDK_CONTAINEROF(qpair, struct nvme_rdma_qpair, qpair);
 }
 
 static inline struct nvme_rdma_ctrlr *
 nvme_rdma_ctrlr(struct spdk_nvme_ctrlr *ctrlr)
 {
 	assert(ctrlr->trid.trtype == SPDK_NVME_TRANSPORT_RDMA);
-	return (struct nvme_rdma_ctrlr *)((uintptr_t)ctrlr - offsetof(struct nvme_rdma_ctrlr, ctrlr));
+	return SPDK_CONTAINEROF(ctrlr, struct nvme_rdma_ctrlr, ctrlr);
 }
 
 static struct spdk_nvme_rdma_req *
@@ -169,9 +169,10 @@ nvme_rdma_req_get(struct nvme_rdma_qpair *rqpair)
 {
 	struct spdk_nvme_rdma_req *rdma_req;
 
-	rdma_req = STAILQ_FIRST(&rqpair->free_reqs);
+	rdma_req = TAILQ_FIRST(&rqpair->free_reqs);
 	if (rdma_req) {
-		STAILQ_REMOVE_HEAD(&rqpair->free_reqs, link);
+		TAILQ_REMOVE(&rqpair->free_reqs, rdma_req, link);
+		TAILQ_INSERT_TAIL(&rqpair->outstanding_reqs, rdma_req, link);
 	}
 
 	return rdma_req;
@@ -180,14 +181,15 @@ nvme_rdma_req_get(struct nvme_rdma_qpair *rqpair)
 static void
 nvme_rdma_req_put(struct nvme_rdma_qpair *rqpair, struct spdk_nvme_rdma_req *rdma_req)
 {
-	STAILQ_INSERT_HEAD(&rqpair->free_reqs, rdma_req, link);
+	TAILQ_REMOVE(&rqpair->outstanding_reqs, rdma_req, link);
+	TAILQ_INSERT_HEAD(&rqpair->free_reqs, rdma_req, link);
 }
 
 static void
 nvme_rdma_req_complete(struct nvme_request *req,
 		       struct spdk_nvme_cpl *rsp)
 {
-	req->cb_fn(req->cb_arg, rsp);
+	nvme_complete_request(req, rsp);
 	nvme_free_request(req);
 }
 
@@ -400,7 +402,8 @@ nvme_rdma_alloc_reqs(struct nvme_rdma_qpair *rqpair)
 		goto fail;
 	}
 
-	STAILQ_INIT(&rqpair->free_reqs);
+	TAILQ_INIT(&rqpair->free_reqs);
+	TAILQ_INIT(&rqpair->outstanding_reqs);
 	for (i = 0; i < rqpair->num_entries; i++) {
 		struct spdk_nvme_rdma_req	*rdma_req;
 		struct spdk_nvme_cmd		*cmd;
@@ -422,7 +425,7 @@ nvme_rdma_alloc_reqs(struct nvme_rdma_qpair *rqpair)
 		rdma_req->send_wr.num_sge = 1;
 		rdma_req->send_wr.imm_data = 0;
 
-		STAILQ_INSERT_TAIL(&rqpair->free_reqs, rdma_req, link);
+		TAILQ_INSERT_TAIL(&rqpair->free_reqs, rdma_req, link);
 	}
 
 	return 0;
@@ -511,7 +514,6 @@ nvme_rdma_connect(struct nvme_rdma_qpair *rqpair)
 	int						ret;
 	struct rdma_cm_event				*event;
 	struct spdk_nvme_ctrlr				*ctrlr;
-	struct nvme_rdma_ctrlr				*rctrlr;
 
 	ret = ibv_query_device(rqpair->cm_id->verbs, &attr);
 	if (ret != 0) {
@@ -526,12 +528,10 @@ nvme_rdma_connect(struct nvme_rdma_qpair *rqpair)
 		return -1;
 	}
 
-	rctrlr = nvme_rdma_ctrlr(ctrlr);
-
 	request_data.qid = rqpair->qpair.id;
 	request_data.hrqsize = rqpair->num_entries;
 	request_data.hsqsize = rqpair->num_entries - 1;
-	request_data.cntlid = rctrlr->cntlid;
+	request_data.cntlid = ctrlr->cntlid;
 
 	param.private_data = &request_data;
 	param.private_data_len = sizeof(request_data);
@@ -595,80 +595,6 @@ nvme_rdma_parse_addr(struct sockaddr_storage *sa, int family, const char *addr,
 	return ret;
 }
 
-static int
-nvme_rdma_qpair_fabric_connect(struct nvme_rdma_qpair *rqpair)
-{
-	struct nvme_completion_poll_status status;
-	struct spdk_nvmf_fabric_connect_rsp *rsp;
-	struct spdk_nvmf_fabric_connect_cmd cmd;
-	struct spdk_nvmf_fabric_connect_data *nvmf_data;
-	struct spdk_nvme_ctrlr *ctrlr;
-	struct nvme_rdma_ctrlr *rctrlr;
-	int rc = 0;
-
-	ctrlr = rqpair->qpair.ctrlr;
-	if (!ctrlr) {
-		return -1;
-	}
-
-	rctrlr = nvme_rdma_ctrlr(ctrlr);
-
-	nvmf_data = spdk_dma_zmalloc(sizeof(*nvmf_data), 0, NULL);
-	if (!nvmf_data) {
-		SPDK_ERRLOG("nvmf_data allocation error\n");
-		rc = -1;
-		return rc;
-	}
-
-	memset(&cmd, 0, sizeof(cmd));
-	memset(&status, 0, sizeof(struct nvme_completion_poll_status));
-
-	cmd.opcode = SPDK_NVME_OPC_FABRIC;
-	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_CONNECT;
-	cmd.qid = rqpair->qpair.id;
-	cmd.sqsize = rqpair->num_entries - 1;
-	cmd.kato = ctrlr->opts.keep_alive_timeout_ms;
-
-	if (nvme_qpair_is_admin_queue(&rqpair->qpair)) {
-		nvmf_data->cntlid = 0xFFFF;
-	} else {
-		nvmf_data->cntlid = rctrlr->cntlid;
-	}
-
-	SPDK_STATIC_ASSERT(sizeof(nvmf_data->hostid) == sizeof(ctrlr->opts.extended_host_id),
-			   "host ID size mismatch");
-	memcpy(nvmf_data->hostid, ctrlr->opts.extended_host_id, sizeof(nvmf_data->hostid));
-	snprintf(nvmf_data->hostnqn, sizeof(nvmf_data->hostnqn), "%s", ctrlr->opts.hostnqn);
-	snprintf(nvmf_data->subnqn, sizeof(nvmf_data->subnqn), "%s", ctrlr->trid.subnqn);
-
-	rc = spdk_nvme_ctrlr_cmd_io_raw(ctrlr, &rqpair->qpair,
-					(struct spdk_nvme_cmd *)&cmd,
-					nvmf_data, sizeof(*nvmf_data),
-					nvme_completion_poll_cb, &status);
-	if (rc < 0) {
-		SPDK_ERRLOG("spdk_nvme_rdma_req_fabric_connect failed\n");
-		rc = -1;
-		goto ret;
-	}
-
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(&rqpair->qpair, 0);
-	}
-
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
-		SPDK_ERRLOG("Connect command failed\n");
-		return -1;
-	}
-
-	if (nvme_qpair_is_admin_queue(&rqpair->qpair)) {
-		rsp = (struct spdk_nvmf_fabric_connect_rsp *)&status.cpl;
-		rctrlr->cntlid = rsp->status_code_specific.success.cntlid;
-	}
-ret:
-	spdk_dma_free(nvmf_data);
-	return rc;
-}
-
 static int
 nvme_rdma_mr_map_notify(void *cb_ctx, struct spdk_mem_map *map,
 			enum spdk_mem_map_notify_action action,
@@ -692,7 +618,7 @@ nvme_rdma_mr_map_notify(void *cb_ctx, struct spdk_mem_map *map,
 		}
 		break;
 	case SPDK_MEM_MAP_NOTIFY_UNREGISTER:
-		mr = (struct ibv_mr *)spdk_mem_map_translate(map, (uint64_t)vaddr);
+		mr = (struct ibv_mr *)spdk_mem_map_translate(map, (uint64_t)vaddr, size);
 		rc = spdk_mem_map_clear_translation(map, (uint64_t)vaddr, size);
 		if (mr) {
 			ibv_dereg_mr(mr);
@@ -875,7 +801,7 @@ nvme_rdma_qpair_connect(struct nvme_rdma_qpair *rqpair)
 		return -1;
 	}
 
-	rc = nvme_rdma_qpair_fabric_connect(rqpair);
+	rc = nvme_fabric_qpair_connect(&rqpair->qpair, rqpair->num_entries);
 	if (rc < 0) {
 		SPDK_ERRLOG("Failed to send an NVMe-oF Fabric CONNECT command\n");
 		return -1;
@@ -910,13 +836,14 @@ nvme_rdma_build_null_request(struct nvme_request *req)
 static int
 nvme_rdma_build_contig_request(struct nvme_rdma_qpair *rqpair, struct nvme_request *req)
 {
-	void *payload = req->payload.u.contig + req->payload_offset;
+	void *payload = req->payload.contig_or_cb_arg + req->payload_offset;
 	struct ibv_mr *mr;
 
 	assert(req->payload_size != 0);
-	assert(req->payload.type == NVME_PAYLOAD_TYPE_CONTIG);
+	assert(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_CONTIG);
 
-	mr = (struct ibv_mr *)spdk_mem_map_translate(rqpair->mr_map->map, (uint64_t)payload);
+	mr = (struct ibv_mr *)spdk_mem_map_translate(rqpair->mr_map->map, (uint64_t)payload,
+			req->payload_size);
 	if (mr == NULL) {
 		return -1;
 	}
@@ -943,13 +870,13 @@ nvme_rdma_build_sgl_request(struct nvme_rdma_qpair *rqpair, struct nvme_request
 	uint32_t length;
 
 	assert(req->payload_size != 0);
-	assert(req->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	assert(req->payload.u.sgl.reset_sgl_fn != NULL);
-	assert(req->payload.u.sgl.next_sge_fn != NULL);
-	req->payload.u.sgl.reset_sgl_fn(req->payload.u.sgl.cb_arg, req->payload_offset);
+	assert(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL);
+	assert(req->payload.reset_sgl_fn != NULL);
+	assert(req->payload.next_sge_fn != NULL);
+	req->payload.reset_sgl_fn(req->payload.contig_or_cb_arg, req->payload_offset);
 
 	/* TODO: for now, we only support a single SGL entry */
-	rc = req->payload.u.sgl.next_sge_fn(req->payload.u.sgl.cb_arg, &virt_addr, &length);
+	rc = req->payload.next_sge_fn(req->payload.contig_or_cb_arg, &virt_addr, &length);
 	if (rc) {
 		return -1;
 	}
@@ -959,7 +886,8 @@ nvme_rdma_build_sgl_request(struct nvme_rdma_qpair *rqpair, struct nvme_request
 		return -1;
 	}
 
-	mr = (struct ibv_mr *)spdk_mem_map_translate(rqpair->mr_map->map, (uint64_t)virt_addr);
+	mr = (struct ibv_mr *)spdk_mem_map_translate(rqpair->mr_map->map, (uint64_t)virt_addr,
+			req->payload_size);
 	if (mr == NULL) {
 		return -1;
 	}
@@ -985,9 +913,9 @@ nvme_rdma_req_init(struct nvme_rdma_qpair *rqpair, struct nvme_request *req,
 
 	if (req->payload_size == 0) {
 		rc = nvme_rdma_build_null_request(req);
-	} else if (req->payload.type == NVME_PAYLOAD_TYPE_CONTIG) {
+	} else if (nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_CONTIG) {
 		rc = nvme_rdma_build_contig_request(rqpair, req);
-	} else if (req->payload.type == NVME_PAYLOAD_TYPE_SGL) {
+	} else if (nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_SGL) {
 		rc = nvme_rdma_build_sgl_request(rqpair, req);
 	} else {
 		rc = -1;
@@ -1001,84 +929,6 @@ nvme_rdma_req_init(struct nvme_rdma_qpair *rqpair, struct nvme_request *req,
 	return 0;
 }
 
-static int
-nvme_rdma_fabric_prop_set_cmd(struct spdk_nvme_ctrlr *ctrlr,
-			      uint32_t offset, uint8_t size, uint64_t value)
-{
-	struct spdk_nvmf_fabric_prop_set_cmd cmd = {};
-	struct nvme_completion_poll_status status = {};
-	int rc;
-
-	cmd.opcode = SPDK_NVME_OPC_FABRIC;
-	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_PROPERTY_SET;
-	cmd.ofst = offset;
-	cmd.attrib.size = size;
-	cmd.value.u64 = value;
-
-	rc = spdk_nvme_ctrlr_cmd_admin_raw(ctrlr, (struct spdk_nvme_cmd *)&cmd,
-					   NULL, 0,
-					   nvme_completion_poll_cb, &status);
-
-	if (rc < 0) {
-		SPDK_ERRLOG("failed to send nvmf_fabric_prop_set_cmd\n");
-		return -1;
-	}
-
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
-		SPDK_ERRLOG("nvme_rdma_fabric_prop_get_cmd failed\n");
-		return -1;
-	}
-
-	return 0;
-}
-
-static int
-nvme_rdma_fabric_prop_get_cmd(struct spdk_nvme_ctrlr *ctrlr,
-			      uint32_t offset, uint8_t size, uint64_t *value)
-{
-	struct spdk_nvmf_fabric_prop_set_cmd cmd = {};
-	struct nvme_completion_poll_status status = {};
-	struct spdk_nvmf_fabric_prop_get_rsp *response;
-	int rc;
-
-	cmd.opcode = SPDK_NVME_OPC_FABRIC;
-	cmd.fctype = SPDK_NVMF_FABRIC_COMMAND_PROPERTY_GET;
-	cmd.ofst = offset;
-	cmd.attrib.size = size;
-
-	rc = spdk_nvme_ctrlr_cmd_admin_raw(ctrlr, (struct spdk_nvme_cmd *)&cmd,
-					   NULL, 0, nvme_completion_poll_cb,
-					   &status);
-
-	if (rc < 0) {
-		SPDK_ERRLOG("failed to send nvme_rdma_fabric_prop_get_cmd\n");
-		return -1;
-	}
-
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
-		SPDK_ERRLOG("nvme_rdma_fabric_prop_get_cmd failed\n");
-		return -1;
-	}
-
-	response = (struct spdk_nvmf_fabric_prop_get_rsp *)&status.cpl;
-
-	if (!size) {
-		*value = response->value.u32.low;
-	} else {
-		*value = response->value.u64;
-	}
-
-	return 0;
-}
-
 static struct spdk_nvme_qpair *
 nvme_rdma_ctrlr_create_qpair(struct spdk_nvme_ctrlr *ctrlr,
 			     uint16_t qid, uint32_t qsize,
@@ -1121,6 +971,7 @@ nvme_rdma_qpair_destroy(struct spdk_nvme_qpair *qpair)
 	if (!qpair) {
 		return -1;
 	}
+	nvme_qpair_deinit(qpair);
 
 	rqpair = nvme_rdma_qpair(qpair);
 
@@ -1163,89 +1014,6 @@ nvme_rdma_ctrlr_enable(struct spdk_nvme_ctrlr *ctrlr)
 	return 0;
 }
 
-static int
-nvme_fabrics_get_log_discovery_page(struct spdk_nvme_ctrlr *ctrlr,
-				    void *log_page, uint32_t size, uint64_t offset)
-{
-	struct nvme_completion_poll_status status;
-	int rc;
-
-	status.done = false;
-	rc = spdk_nvme_ctrlr_cmd_get_log_page(ctrlr, SPDK_NVME_LOG_DISCOVERY, 0, log_page, size, offset,
-					      nvme_completion_poll_cb, &status);
-	if (rc < 0) {
-		return -1;
-	}
-
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(ctrlr->adminq, 0);
-	}
-
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
-		return -1;
-	}
-
-	return 0;
-}
-
-static void
-nvme_rdma_discovery_probe(struct spdk_nvmf_discovery_log_page_entry *entry,
-			  void *cb_ctx, spdk_nvme_probe_cb probe_cb)
-{
-	struct spdk_nvme_transport_id trid;
-	uint8_t *end;
-	size_t len;
-
-	memset(&trid, 0, sizeof(trid));
-
-	if (entry->subtype == SPDK_NVMF_SUBTYPE_DISCOVERY) {
-		SPDK_WARNLOG("Skipping unsupported discovery service referral\n");
-		return;
-	} else if (entry->subtype != SPDK_NVMF_SUBTYPE_NVME) {
-		SPDK_WARNLOG("Skipping unknown subtype %u\n", entry->subtype);
-		return;
-	}
-
-	trid.trtype = entry->trtype;
-	if (!spdk_nvme_transport_available(trid.trtype)) {
-		SPDK_WARNLOG("NVMe transport type %u not available; skipping probe\n",
-			     trid.trtype);
-		return;
-	}
-
-	trid.adrfam = entry->adrfam;
-
-	/* Ensure that subnqn is null terminated. */
-	end = memchr(entry->subnqn, '\0', SPDK_NVMF_NQN_MAX_LEN + 1);
-	if (!end) {
-		SPDK_ERRLOG("Discovery entry SUBNQN is not null terminated\n");
-		return;
-	}
-	len = end - entry->subnqn;
-	memcpy(trid.subnqn, entry->subnqn, len);
-	trid.subnqn[len] = '\0';
-
-	/* Convert traddr to a null terminated string. */
-	len = spdk_strlen_pad(entry->traddr, sizeof(entry->traddr), ' ');
-	memcpy(trid.traddr, entry->traddr, len);
-	if (spdk_str_chomp(trid.traddr) != 0) {
-		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Trailing newlines removed from discovery TRADDR\n");
-	}
-
-	/* Convert trsvcid to a null terminated string. */
-	len = spdk_strlen_pad(entry->trsvcid, sizeof(entry->trsvcid), ' ');
-	memcpy(trid.trsvcid, entry->trsvcid, len);
-	if (spdk_str_chomp(trid.trsvcid) != 0) {
-		SPDK_DEBUGLOG(SPDK_LOG_NVME, "Trailing newlines removed from discovery TRSVCID\n");
-	}
-
-	SPDK_DEBUGLOG(SPDK_LOG_NVME, "subnqn=%s, trtype=%u, traddr=%s, trsvcid=%s\n",
-		      trid.subnqn, trid.trtype,
-		      trid.traddr, trid.trsvcid);
-
-	nvme_ctrlr_probe(&trid, NULL, probe_cb, cb_ctx);
-}
-
 /* This function must only be called while holding g_spdk_nvme_driver->lock */
 int
 nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
@@ -1256,14 +1024,8 @@ nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
 {
 	struct spdk_nvme_ctrlr_opts discovery_opts;
 	struct spdk_nvme_ctrlr *discovery_ctrlr;
-	struct spdk_nvmf_discovery_log_page *log_page;
-	struct spdk_nvmf_discovery_log_page_entry *log_page_entry;
 	union spdk_nvme_cc_register cc;
-	char buffer[4096];
 	int rc;
-	uint64_t i, numrec, buffer_max_entries_first, buffer_max_entries, log_page_offset = 0;
-	uint64_t remaining_num_rec = 0;
-	uint16_t recfmt;
 	struct nvme_completion_poll_status status;
 
 	if (strcmp(discovery_trid->subnqn, SPDK_NVMF_DISCOVERY_NQN) != 0) {
@@ -1276,7 +1038,6 @@ nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
 	/* For discovery_ctrlr set the timeout to 0 */
 	discovery_opts.keep_alive_timeout_ms = 0;
 
-	memset(buffer, 0x0, 4096);
 	discovery_ctrlr = nvme_rdma_ctrlr_construct(discovery_trid, &discovery_opts, NULL);
 	if (discovery_ctrlr == NULL) {
 		return -1;
@@ -1296,7 +1057,6 @@ nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
 	}
 
 	/* get the cdata info */
-	status.done = false;
 	rc = nvme_ctrlr_cmd_identify(discovery_ctrlr, SPDK_NVME_IDENTIFY_CTRLR, 0, 0,
 				     &discovery_ctrlr->cdata, sizeof(discovery_ctrlr->cdata),
 				     nvme_completion_poll_cb, &status);
@@ -1305,10 +1065,7 @@ nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
 		return rc;
 	}
 
-	while (status.done == false) {
-		spdk_nvme_qpair_process_completions(discovery_ctrlr->adminq, 0);
-	}
-	if (spdk_nvme_cpl_is_error(&status.cpl)) {
+	if (spdk_nvme_wait_for_completion(discovery_ctrlr->adminq, &status)) {
 		SPDK_ERRLOG("nvme_identify_controller failed!\n");
 		return -ENXIO;
 	}
@@ -1322,45 +1079,9 @@ nvme_rdma_ctrlr_scan(const struct spdk_nvme_transport_id *discovery_trid,
 		return 0;
 	}
 
-	buffer_max_entries_first = (sizeof(buffer) - offsetof(struct spdk_nvmf_discovery_log_page,
-				    entries[0])) /
-				   sizeof(struct spdk_nvmf_discovery_log_page_entry);
-	buffer_max_entries = sizeof(buffer) / sizeof(struct spdk_nvmf_discovery_log_page_entry);
-	do {
-		rc = nvme_fabrics_get_log_discovery_page(discovery_ctrlr, buffer, sizeof(buffer), log_page_offset);
-		if (rc < 0) {
-			SPDK_DEBUGLOG(SPDK_LOG_NVME, "nvme_fabrics_get_log_discovery_page error\n");
-			nvme_ctrlr_destruct(discovery_ctrlr);
-			return rc;
-		}
-
-		if (!remaining_num_rec) {
-			log_page = (struct spdk_nvmf_discovery_log_page *)buffer;
-			recfmt = from_le16(&log_page->recfmt);
-			if (recfmt != 0) {
-				SPDK_ERRLOG("Unrecognized discovery log record format %" PRIu16 "\n", recfmt);
-				nvme_ctrlr_destruct(discovery_ctrlr);
-				return -EPROTO;
-			}
-			remaining_num_rec = log_page->numrec;
-			log_page_offset = offsetof(struct spdk_nvmf_discovery_log_page, entries[0]);
-			log_page_entry = &log_page->entries[0];
-			numrec = spdk_min(remaining_num_rec, buffer_max_entries_first);
-		} else {
-			numrec = spdk_min(remaining_num_rec, buffer_max_entries);
-			log_page_entry = (struct spdk_nvmf_discovery_log_page_entry *)buffer;
-		}
-
-
-		for (i = 0; i < numrec; i++) {
-			nvme_rdma_discovery_probe(log_page_entry++, cb_ctx, probe_cb);
-		}
-		remaining_num_rec -= numrec;
-		log_page_offset += numrec * sizeof(struct spdk_nvmf_discovery_log_page_entry);
-	} while (remaining_num_rec != 0);
-
+	rc = nvme_fabric_ctrlr_discover(discovery_ctrlr, cb_ctx, probe_cb);
 	nvme_ctrlr_destruct(discovery_ctrlr);
-	return 0;
+	return rc;
 }
 
 struct spdk_nvme_ctrlr *nvme_rdma_ctrlr_construct(const struct spdk_nvme_transport_id *trid,
@@ -1369,6 +1090,7 @@ struct spdk_nvme_ctrlr *nvme_rdma_ctrlr_construct(const struct spdk_nvme_transpo
 {
 	struct nvme_rdma_ctrlr *rctrlr;
 	union spdk_nvme_cap_register cap;
+	union spdk_nvme_vs_register vs;
 	int rc;
 
 	rctrlr = calloc(1, sizeof(struct nvme_rdma_ctrlr));
@@ -1400,7 +1122,19 @@ struct spdk_nvme_ctrlr *nvme_rdma_ctrlr_construct(const struct spdk_nvme_transpo
 		return NULL;
 	}
 
-	nvme_ctrlr_init_cap(&rctrlr->ctrlr, &cap);
+	if (nvme_ctrlr_get_vs(&rctrlr->ctrlr, &vs)) {
+		SPDK_ERRLOG("get_vs() failed\n");
+		nvme_ctrlr_destruct(&rctrlr->ctrlr);
+		return NULL;
+	}
+
+	if (nvme_ctrlr_add_process(&rctrlr->ctrlr, 0) != 0) {
+		SPDK_ERRLOG("nvme_ctrlr_add_process() failed\n");
+		nvme_ctrlr_destruct(&rctrlr->ctrlr);
+		return NULL;
+	}
+
+	nvme_ctrlr_init_cap(&rctrlr->ctrlr, &cap, &vs);
 
 	SPDK_DEBUGLOG(SPDK_LOG_NVME, "succesully initialized the nvmf ctrlr\n");
 	return &rctrlr->ctrlr;
@@ -1425,32 +1159,25 @@ nvme_rdma_ctrlr_destruct(struct spdk_nvme_ctrlr *ctrlr)
 int
 nvme_rdma_ctrlr_set_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t value)
 {
-	return nvme_rdma_fabric_prop_set_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_4, value);
+	return nvme_fabric_ctrlr_set_reg_4(ctrlr, offset, value);
 }
 
 int
 nvme_rdma_ctrlr_set_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t value)
 {
-	return nvme_rdma_fabric_prop_set_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_8, value);
+	return nvme_fabric_ctrlr_set_reg_8(ctrlr, offset, value);
 }
 
 int
 nvme_rdma_ctrlr_get_reg_4(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint32_t *value)
 {
-	uint64_t tmp_value;
-	int rc;
-	rc = nvme_rdma_fabric_prop_get_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_4, &tmp_value);
-
-	if (!rc) {
-		*value = (uint32_t)tmp_value;
-	}
-	return rc;
+	return nvme_fabric_ctrlr_get_reg_4(ctrlr, offset, value);
 }
 
 int
 nvme_rdma_ctrlr_get_reg_8(struct spdk_nvme_ctrlr *ctrlr, uint32_t offset, uint64_t *value)
 {
-	return nvme_rdma_fabric_prop_get_cmd(ctrlr, offset, SPDK_NVMF_PROP_SIZE_8, value);
+	return nvme_fabric_ctrlr_get_reg_8(ctrlr, offset, value);
 }
 
 int
@@ -1481,6 +1208,13 @@ nvme_rdma_qpair_submit_request(struct spdk_nvme_qpair *qpair,
 		return -1;
 	}
 
+	req->timed_out = false;
+	if (spdk_unlikely(rqpair->qpair.ctrlr->timeout_enabled)) {
+		req->submit_tick = spdk_get_ticks();
+	} else {
+		req->submit_tick = 0;
+	}
+
 	wr = &rdma_req->send_wr;
 
 	nvme_rdma_trace_ibv_sge(wr->sg_list);
@@ -1533,6 +1267,45 @@ nvme_rdma_qpair_fail(struct spdk_nvme_qpair *qpair)
 	return 0;
 }
 
+static void
+nvme_rdma_qpair_check_timeout(struct spdk_nvme_qpair *qpair)
+{
+	uint64_t t02;
+	struct spdk_nvme_rdma_req *rdma_req, *tmp;
+	struct nvme_rdma_qpair *rqpair = nvme_rdma_qpair(qpair);
+	struct spdk_nvme_ctrlr *ctrlr = qpair->ctrlr;
+	struct spdk_nvme_ctrlr_process *active_proc;
+
+	/* Don't check timeouts during controller initialization. */
+	if (ctrlr->state != NVME_CTRLR_STATE_READY) {
+		return;
+	}
+
+	if (nvme_qpair_is_admin_queue(qpair)) {
+		active_proc = spdk_nvme_ctrlr_get_current_process(ctrlr);
+	} else {
+		active_proc = qpair->active_proc;
+	}
+
+	/* Only check timeouts if the current process has a timeout callback. */
+	if (active_proc == NULL || active_proc->timeout_cb_fn == NULL) {
+		return;
+	}
+
+	t02 = spdk_get_ticks();
+	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->outstanding_reqs, link, tmp) {
+		assert(rdma_req->req != NULL);
+
+		if (nvme_request_check_timeout(rdma_req->req, rdma_req->id, active_proc, t02)) {
+			/*
+			 * The requests are in order, so as soon as one has not timed out,
+			 * stop iterating.
+			 */
+			break;
+		}
+	}
+}
+
 #define MAX_COMPLETIONS_PER_POLL 128
 
 int
@@ -1601,6 +1374,10 @@ nvme_rdma_qpair_process_completions(struct spdk_nvme_qpair *qpair,
 		}
 	} while (reaped < max_completions);
 
+	if (spdk_unlikely(rqpair->qpair.ctrlr->timeout_enabled)) {
+		nvme_rdma_qpair_check_timeout(qpair);
+	}
+
 	return reaped;
 }
 
diff --git a/lib/nvme/nvme_transport.c b/lib/nvme/nvme_transport.c
index 76e826e6e..56052a0fc 100644
--- a/lib/nvme/nvme_transport.c
+++ b/lib/nvme/nvme_transport.c
@@ -57,11 +57,13 @@ nvme_transport_unknown(enum spdk_nvme_transport_type trtype)
 #define TRANSPORT_FABRICS_RDMA(func_name, args)	case SPDK_NVME_TRANSPORT_RDMA: SPDK_UNREACHABLE();
 #define TRANSPORT_RDMA_AVAILABLE		false
 #endif
+#define TRANSPORT_FABRICS_FC(func_name, args)	case SPDK_NVME_TRANSPORT_FC: SPDK_UNREACHABLE();
 #define NVME_TRANSPORT_CALL(trtype, func_name, args)		\
 	do {							\
 		switch (trtype) {				\
 		TRANSPORT_PCIE(func_name, args)			\
 		TRANSPORT_FABRICS_RDMA(func_name, args)		\
+		TRANSPORT_FABRICS_FC(func_name, args)		\
 		TRANSPORT_DEFAULT(trtype)			\
 		}						\
 		SPDK_UNREACHABLE();				\
@@ -76,6 +78,9 @@ spdk_nvme_transport_available(enum spdk_nvme_transport_type trtype)
 
 	case SPDK_NVME_TRANSPORT_RDMA:
 		return TRANSPORT_RDMA_AVAILABLE;
+
+	case SPDK_NVME_TRANSPORT_FC:
+		return false;
 	}
 
 	return false;
diff --git a/lib/nvmf/ctrlr.c b/lib/nvmf/ctrlr.c
index 0aa8193c1..ee4fb4459 100644
--- a/lib/nvmf/ctrlr.c
+++ b/lib/nvmf/ctrlr.c
@@ -36,8 +36,9 @@
 #include "nvmf_internal.h"
 #include "transport.h"
 
+#include "spdk/bit_array.h"
 #include "spdk/endian.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/trace.h"
 #include "spdk/nvme_spec.h"
 #include "spdk/string.h"
@@ -76,14 +77,34 @@ ctrlr_add_qpair_and_update_rsp(struct spdk_nvmf_qpair *qpair,
 			       struct spdk_nvmf_ctrlr *ctrlr,
 			       struct spdk_nvmf_fabric_connect_rsp *rsp)
 {
+	pthread_mutex_lock(&ctrlr->mtx);
+	/* check if we would exceed ctrlr connection limit */
+	if (qpair->qid >= spdk_bit_array_capacity(ctrlr->qpair_mask)) {
+		SPDK_ERRLOG("Requested QID %u but Max QID is %u\n",
+			    qpair->qid, spdk_bit_array_capacity(ctrlr->qpair_mask) - 1);
+		rsp->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
+		rsp->status.sc = SPDK_NVME_SC_INVALID_QUEUE_IDENTIFIER;
+		pthread_mutex_unlock(&ctrlr->mtx);
+		return;
+	}
+
+	if (spdk_bit_array_get(ctrlr->qpair_mask, qpair->qid)) {
+		SPDK_ERRLOG("Got I/O connect with duplicate QID %u\n", qpair->qid);
+		rsp->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
+		rsp->status.sc = SPDK_NVME_SC_INVALID_QUEUE_IDENTIFIER;
+		pthread_mutex_unlock(&ctrlr->mtx);
+		return;
+	}
+
 	qpair->ctrlr = ctrlr;
-	ctrlr->num_qpairs++;
-	TAILQ_INSERT_HEAD(&ctrlr->qpairs, qpair, link);
+	spdk_bit_array_set(ctrlr->qpair_mask, qpair->qid);
 
 	rsp->status.sc = SPDK_NVME_SC_SUCCESS;
 	rsp->status_code_specific.success.cntlid = ctrlr->cntlid;
 	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "connect capsule response: cntlid = 0x%04x\n",
 		      rsp->status_code_specific.success.cntlid);
+
+	pthread_mutex_unlock(&ctrlr->mtx);
 }
 
 static void
@@ -145,18 +166,27 @@ spdk_nvmf_ctrlr_create(struct spdk_nvmf_subsystem *subsystem,
 	}
 
 	req->qpair->ctrlr = ctrlr;
-	TAILQ_INIT(&ctrlr->qpairs);
-	ctrlr->num_qpairs = 0;
 	ctrlr->subsys = subsystem;
-	ctrlr->max_qpairs_allowed = tgt->opts.max_qpairs_per_ctrlr;
+
+	if (pthread_mutex_init(&ctrlr->mtx, NULL) != 0) {
+		SPDK_ERRLOG("Failed to initialize controller mutex\n");
+		free(ctrlr);
+		return NULL;
+	}
+	ctrlr->qpair_mask = spdk_bit_array_create(tgt->opts.max_qpairs_per_ctrlr);
+	if (!ctrlr->qpair_mask) {
+		SPDK_ERRLOG("Failed to allocate controller qpair mask\n");
+		free(ctrlr);
+		return NULL;
+	}
 
 	ctrlr->feat.keep_alive_timer.bits.kato = connect_cmd->kato;
 	ctrlr->feat.async_event_configuration.bits.ns_attr_notice = 1;
 	ctrlr->feat.volatile_write_cache.bits.wce = 1;
 
 	/* Subtract 1 for admin queue, 1 for 0's based */
-	ctrlr->feat.number_of_queues.bits.ncqr = ctrlr->max_qpairs_allowed - 1 - 1;
-	ctrlr->feat.number_of_queues.bits.nsqr = ctrlr->max_qpairs_allowed - 1 - 1;
+	ctrlr->feat.number_of_queues.bits.ncqr = tgt->opts.max_qpairs_per_ctrlr - 1 - 1;
+	ctrlr->feat.number_of_queues.bits.nsqr = tgt->opts.max_qpairs_per_ctrlr - 1 - 1;
 
 	memcpy(ctrlr->hostid, connect_data->hostid, sizeof(ctrlr->hostid));
 
@@ -166,7 +196,7 @@ spdk_nvmf_ctrlr_create(struct spdk_nvmf_subsystem *subsystem,
 	ctrlr->vcprop.cap.bits.ams = 0; /* optional arb mechanisms */
 	ctrlr->vcprop.cap.bits.to = 1; /* ready timeout - 500 msec units */
 	ctrlr->vcprop.cap.bits.dstrd = 0; /* fixed to 0 for NVMe-oF */
-	ctrlr->vcprop.cap.bits.css_nvm = 1; /* NVM command set */
+	ctrlr->vcprop.cap.bits.css = SPDK_NVME_CAP_CSS_NVM; /* NVM command set */
 	ctrlr->vcprop.cap.bits.mpsmin = 0; /* 2 ^ (12 + mpsmin) == 4k */
 	ctrlr->vcprop.cap.bits.mpsmax = 0; /* 2 ^ (12 + mpsmax) == 4k */
 
@@ -191,33 +221,22 @@ spdk_nvmf_ctrlr_create(struct spdk_nvmf_subsystem *subsystem,
 	return ctrlr;
 }
 
-static void ctrlr_destruct(void *ctx)
-{
-	struct spdk_nvmf_ctrlr *ctrlr = ctx;
-
-	spdk_nvmf_subsystem_remove_ctrlr(ctrlr->subsys, ctrlr);
-	free(ctrlr);
-}
-
 void
 spdk_nvmf_ctrlr_destruct(struct spdk_nvmf_ctrlr *ctrlr)
 {
-	while (!TAILQ_EMPTY(&ctrlr->qpairs)) {
-		struct spdk_nvmf_qpair *qpair = TAILQ_FIRST(&ctrlr->qpairs);
+	/* TODO: Verify that qpair mask has been cleared. */
 
-		TAILQ_REMOVE(&ctrlr->qpairs, qpair, link);
-		ctrlr->num_qpairs--;
-		spdk_nvmf_transport_qpair_fini(qpair);
-	}
+	spdk_bit_array_free(&ctrlr->qpair_mask);
+
+	spdk_nvmf_subsystem_remove_ctrlr(ctrlr->subsys, ctrlr);
 
-	ctrlr_destruct(ctrlr);
+	free(ctrlr);
 }
 
 static void
 spdk_nvmf_ctrlr_add_io_qpair(void *ctx)
 {
 	struct spdk_nvmf_request *req = ctx;
-	struct spdk_nvmf_fabric_connect_cmd *cmd = &req->cmd->connect_cmd;
 	struct spdk_nvmf_fabric_connect_rsp *rsp = &req->rsp->connect_rsp;
 	struct spdk_nvmf_qpair *qpair = req->qpair;
 	struct spdk_nvmf_ctrlr *ctrlr = qpair->ctrlr;
@@ -253,52 +272,12 @@ spdk_nvmf_ctrlr_add_io_qpair(void *ctx)
 		goto end;
 	}
 
-	if (spdk_nvmf_ctrlr_get_qpair(ctrlr, cmd->qid)) {
-		SPDK_ERRLOG("Got I/O connect with duplicate QID %u\n", cmd->qid);
-		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
-		rsp->status.sc = SPDK_NVME_SC_COMMAND_SEQUENCE_ERROR;
-		goto end;
-	}
-
-	/* check if we would exceed ctrlr connection limit */
-	if (ctrlr->num_qpairs >= ctrlr->max_qpairs_allowed) {
-		SPDK_ERRLOG("qpair limit %d\n", ctrlr->num_qpairs);
-		rsp->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
-		rsp->status.sc = SPDK_NVMF_FABRIC_SC_CONTROLLER_BUSY;
-		goto end;
-	}
-
 	ctrlr_add_qpair_and_update_rsp(qpair, ctrlr, rsp);
 
 end:
 	spdk_thread_send_msg(qpair->group->thread, _spdk_nvmf_request_complete, req);
 }
 
-static void
-ctrlr_delete_qpair(void *ctx)
-{
-	struct spdk_nvmf_qpair *qpair = ctx;
-	struct spdk_nvmf_ctrlr *ctrlr = qpair->ctrlr;
-
-	assert(ctrlr != NULL);
-	assert(ctrlr->num_qpairs > 0);
-	/* Defer the admin qpair deletion since there are still io qpairs */
-	if ((ctrlr->num_qpairs > 1) && (qpair == ctrlr->admin_qpair)) {
-		spdk_thread_send_msg(qpair->group->thread, ctrlr_delete_qpair, qpair);
-		return;
-	}
-
-	ctrlr->num_qpairs--;
-	TAILQ_REMOVE(&ctrlr->qpairs, qpair, link);
-	spdk_nvmf_transport_qpair_fini(qpair);
-
-	if (ctrlr->num_qpairs == 0) {
-		assert(ctrlr->subsys != NULL);
-		assert(ctrlr->subsys->thread != NULL);
-		spdk_thread_send_msg(ctrlr->subsys->thread, ctrlr_destruct, ctrlr);
-	}
-}
-
 static void
 _spdk_nvmf_ctrlr_add_io_qpair(void *ctx)
 {
@@ -442,38 +421,6 @@ spdk_nvmf_ctrlr_connect(struct spdk_nvmf_request *req)
 	}
 }
 
-void
-spdk_nvmf_ctrlr_disconnect(struct spdk_nvmf_qpair *qpair)
-{
-	struct spdk_nvmf_ctrlr *ctrlr = qpair->ctrlr;
-	struct spdk_nvmf_qpair *admin_qpair = ctrlr->admin_qpair;
-
-	assert(admin_qpair != NULL);
-	assert(admin_qpair->group != NULL);
-	assert(admin_qpair->group->thread != NULL);
-	spdk_thread_send_msg(admin_qpair->group->thread, ctrlr_delete_qpair, qpair);
-}
-
-struct spdk_nvmf_qpair *
-spdk_nvmf_ctrlr_get_qpair(struct spdk_nvmf_ctrlr *ctrlr, uint16_t qid)
-{
-	struct spdk_nvmf_qpair *qpair;
-
-	TAILQ_FOREACH(qpair, &ctrlr->qpairs, link) {
-		if (qpair->qid == qid) {
-			return qpair;
-		}
-	}
-	return NULL;
-}
-
-static struct spdk_nvmf_request *
-spdk_nvmf_qpair_get_request(struct spdk_nvmf_qpair *qpair, uint16_t cid)
-{
-	/* TODO: track list of outstanding requests in qpair? */
-	return NULL;
-}
-
 static uint64_t
 nvmf_prop_get_cap(struct spdk_nvmf_ctrlr *ctrlr)
 {
@@ -623,6 +570,7 @@ spdk_nvmf_property_get(struct spdk_nvmf_request *req)
 	if (cmd->attrib.size != SPDK_NVMF_PROP_SIZE_4 &&
 	    cmd->attrib.size != SPDK_NVMF_PROP_SIZE_8) {
 		SPDK_ERRLOG("Invalid size value %d\n", cmd->attrib.size);
+		response->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
 		response->status.sc = SPDK_NVMF_FABRIC_SC_INVALID_PARAM;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
@@ -637,6 +585,7 @@ spdk_nvmf_property_get(struct spdk_nvmf_request *req)
 	if (cmd->attrib.size != prop->size) {
 		SPDK_ERRLOG("offset 0x%x size mismatch: cmd %u, prop %u\n",
 			    cmd->ofst, cmd->attrib.size, prop->size);
+		response->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
 		response->status.sc = SPDK_NVMF_FABRIC_SC_INVALID_PARAM;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
@@ -662,6 +611,7 @@ spdk_nvmf_property_set(struct spdk_nvmf_request *req)
 	prop = find_prop(cmd->ofst);
 	if (prop == NULL || prop->set_cb == NULL) {
 		SPDK_ERRLOG("Invalid offset 0x%x\n", cmd->ofst);
+		response->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
 		response->status.sc = SPDK_NVMF_FABRIC_SC_INVALID_PARAM;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
@@ -670,6 +620,7 @@ spdk_nvmf_property_set(struct spdk_nvmf_request *req)
 	if (cmd->attrib.size != prop->size) {
 		SPDK_ERRLOG("offset 0x%x size mismatch: cmd %u, prop %u\n",
 			    cmd->ofst, cmd->attrib.size, prop->size);
+		response->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
 		response->status.sc = SPDK_NVMF_FABRIC_SC_INVALID_PARAM;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
@@ -681,6 +632,7 @@ spdk_nvmf_property_set(struct spdk_nvmf_request *req)
 
 	if (!prop->set_cb(ctrlr, value)) {
 		SPDK_ERRLOG("prop set_cb failed\n");
+		response->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
 		response->status.sc = SPDK_NVMF_FABRIC_SC_INVALID_PARAM;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
@@ -919,12 +871,17 @@ spdk_nvmf_ctrlr_set_features_number_of_queues(struct spdk_nvmf_request *req)
 {
 	struct spdk_nvmf_ctrlr *ctrlr = req->qpair->ctrlr;
 	struct spdk_nvme_cpl *rsp = &req->rsp->nvme_cpl;
+	uint32_t count;
 
 	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Set Features - Number of Queues, cdw11 0x%x\n",
 		      req->cmd->nvme_cmd.cdw11);
 
+	pthread_mutex_lock(&ctrlr->mtx);
+	count = spdk_bit_array_count_set(ctrlr->qpair_mask);
+	pthread_mutex_unlock(&ctrlr->mtx);
+
 	/* verify that the contoller is ready to process commands */
-	if (ctrlr->num_qpairs > 1) {
+	if (count > 1) {
 		SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Queue pairs already active!\n");
 		rsp->status.sc = SPDK_NVME_SC_COMMAND_SEQUENCE_ERROR;
 	} else {
@@ -1181,13 +1138,26 @@ spdk_nvmf_ctrlr_identify_ns(struct spdk_nvmf_subsystem *subsystem,
 {
 	struct spdk_nvmf_ns *ns;
 
-	ns = _spdk_nvmf_subsystem_get_ns(subsystem, cmd->nsid);
-	if (ns == NULL || ns->bdev == NULL) {
+	if (cmd->nsid == 0 || cmd->nsid > subsystem->max_nsid) {
 		SPDK_ERRLOG("Identify Namespace for invalid NSID %u\n", cmd->nsid);
+		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
 		rsp->status.sc = SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
 
+	ns = _spdk_nvmf_subsystem_get_ns(subsystem, cmd->nsid);
+	if (ns == NULL || ns->bdev == NULL) {
+		/*
+		 * Inactive namespaces should return a zero filled data structure.
+		 * The data buffer is already zeroed by spdk_nvmf_ctrlr_process_admin_cmd(),
+		 * so we can just return early here.
+		 */
+		SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Identify Namespace for inactive NSID %u\n", cmd->nsid);
+		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
+		rsp->status.sc = SPDK_NVME_SC_SUCCESS;
+		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
+	}
+
 	return spdk_nvmf_bdev_ctrlr_identify_ns(ns, nsdata);
 }
 
@@ -1241,6 +1211,7 @@ spdk_nvmf_ctrlr_identify_ctrlr(struct spdk_nvmf_ctrlr *ctrlr, struct spdk_nvme_c
 		cdata->cqes.max = 4;
 		cdata->nn = subsystem->max_nsid;
 		cdata->vwc.present = 1;
+		cdata->vwc.flush_broadcast = SPDK_NVME_FLUSH_BROADCAST_NOT_SUPPORTED;
 
 		cdata->nvmf_specific.ioccsz = sizeof(struct spdk_nvme_cmd) / 16;
 		cdata->nvmf_specific.iorcsz = sizeof(struct spdk_nvme_cpl) / 16;
@@ -1410,51 +1381,97 @@ invalid_cns:
 	return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 }
 
-static int
-spdk_nvmf_ctrlr_abort(struct spdk_nvmf_request *req)
+
+static struct spdk_nvmf_request *
+spdk_nvmf_qpair_abort(struct spdk_nvmf_qpair *qpair, uint16_t cid)
 {
-	struct spdk_nvmf_ctrlr *ctrlr = req->qpair->ctrlr;
+	struct spdk_nvmf_ctrlr *ctrlr = qpair->ctrlr;
+	struct spdk_nvmf_request *req;
+
+	if (spdk_nvmf_qpair_is_admin_queue(qpair)) {
+		if (ctrlr->aer_req && ctrlr->aer_req->cmd->nvme_cmd.cid == cid) {
+			SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Aborting AER request\n");
+			req = ctrlr->aer_req;
+			ctrlr->aer_req = NULL;
+			return req;
+		}
+	}
+
+	/* TODO: track list of outstanding requests in qpair? */
+	return NULL;
+}
+
+static void
+spdk_nvmf_ctrlr_abort_done(struct spdk_io_channel_iter *i, int status)
+{
+	struct spdk_nvmf_request *req = spdk_io_channel_iter_get_ctx(i);
+
+	spdk_nvmf_request_complete(req);
+}
+
+static void
+spdk_nvmf_ctrlr_abort_on_pg(struct spdk_io_channel_iter *i)
+{
+	struct spdk_nvmf_request *req = spdk_io_channel_iter_get_ctx(i);
+	struct spdk_io_channel *ch = spdk_io_channel_iter_get_channel(i);
+	struct spdk_nvmf_poll_group *group = spdk_io_channel_get_ctx(ch);
 	struct spdk_nvme_cpl *rsp = &req->rsp->nvme_cpl;
 	struct spdk_nvme_cmd *cmd = &req->cmd->nvme_cmd;
-	uint32_t cdw10 = cmd->cdw10;
-	uint16_t cid = cdw10 >> 16;
-	uint16_t sqid = cdw10 & 0xFFFFu;
+	uint16_t sqid = cmd->cdw10 & 0xFFFFu;
 	struct spdk_nvmf_qpair *qpair;
-	struct spdk_nvmf_request *req_to_abort;
 
-	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "abort sqid=%u cid=%u\n", sqid, cid);
+	TAILQ_FOREACH(qpair, &group->qpairs, link) {
+		if (qpair->ctrlr == req->qpair->ctrlr && qpair->qid == sqid) {
+			struct spdk_nvmf_request *req_to_abort;
+			uint16_t cid = cmd->cdw10 >> 16;
 
-	rsp->cdw0 = 1; /* Command not aborted */
+			/* Found the qpair */
 
-	qpair = spdk_nvmf_ctrlr_get_qpair(ctrlr, sqid);
-	if (qpair == NULL) {
-		SPDK_DEBUGLOG(SPDK_LOG_NVMF, "sqid %u not found\n", sqid);
-		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
-		rsp->status.sc = SPDK_NVME_SC_INVALID_FIELD;
-		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
-	}
+			req_to_abort = spdk_nvmf_qpair_abort(qpair, cid);
+			if (req_to_abort == NULL) {
+				SPDK_DEBUGLOG(SPDK_LOG_NVMF, "cid %u not found\n", cid);
+				rsp->status.sct = SPDK_NVME_SCT_GENERIC;
+				rsp->status.sc = SPDK_NVME_SC_INVALID_FIELD;
+				spdk_for_each_channel_continue(i, -EINVAL);
+				return;
+			}
 
-	/*
-	 * NOTE: This relies on the assumption that all connections for a ctrlr will be handled
-	 * on the same thread.  If this assumption becomes untrue, this will need to pass a message
-	 * to the thread handling qpair, and the abort will need to be asynchronous.
-	 */
-	req_to_abort = spdk_nvmf_qpair_get_request(qpair, cid);
-	if (req_to_abort == NULL) {
-		SPDK_DEBUGLOG(SPDK_LOG_NVMF, "cid %u not found\n", cid);
-		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
-		rsp->status.sc = SPDK_NVME_SC_INVALID_FIELD;
-		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
-	}
+			/* Complete the request with aborted status */
+			req_to_abort->rsp->nvme_cpl.status.sct = SPDK_NVME_SCT_GENERIC;
+			req_to_abort->rsp->nvme_cpl.status.sc = SPDK_NVME_SC_ABORTED_BY_REQUEST;
+			spdk_nvmf_request_complete(req_to_abort);
+
+			SPDK_DEBUGLOG(SPDK_LOG_NVMF, "abort ctrlr=%p req=%p sqid=%u cid=%u successful\n",
+				      qpair->ctrlr, req_to_abort, sqid, cid);
+			rsp->cdw0 = 0; /* Command successfully aborted */
+			rsp->status.sct = SPDK_NVME_SCT_GENERIC;
+			rsp->status.sc = SPDK_NVME_SC_SUCCESS;
+			/* Return -1 for the status so the iteration across threads stops. */
+			spdk_for_each_channel_continue(i, -1);
 
-	if (spdk_nvmf_request_abort(req_to_abort) == 0) {
-		SPDK_DEBUGLOG(SPDK_LOG_NVMF, "abort ctrlr=%p req=%p sqid=%u cid=%u successful\n",
-			      ctrlr, req_to_abort, sqid, cid);
-		rsp->cdw0 = 0; /* Command successfully aborted */
+		}
 	}
-	rsp->status.sct = SPDK_NVME_SCT_GENERIC;
-	rsp->status.sc = SPDK_NVME_SC_SUCCESS;
-	return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
+
+	spdk_for_each_channel_continue(i, 0);
+}
+
+static int
+spdk_nvmf_ctrlr_abort(struct spdk_nvmf_request *req)
+{
+	struct spdk_nvme_cpl *rsp = &req->rsp->nvme_cpl;
+
+	rsp->cdw0 = 1; /* Command not aborted */
+	rsp->status.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
+	rsp->status.sc = SPDK_NVME_SC_INVALID_QUEUE_IDENTIFIER;
+
+	/* Send a message to each poll group, searching for this ctrlr, sqid, and command. */
+	spdk_for_each_channel(req->qpair->ctrlr->subsys->tgt,
+			      spdk_nvmf_ctrlr_abort_on_pg,
+			      req,
+			      spdk_nvmf_ctrlr_abort_done
+			     );
+
+	return SPDK_NVMF_REQUEST_EXEC_STATUS_ASYNCHRONOUS;
 }
 
 static int
@@ -1710,3 +1727,14 @@ spdk_nvmf_ctrlr_async_event_ns_notice(struct spdk_nvmf_ctrlr *ctrlr)
 
 	return 0;
 }
+
+void
+spdk_nvmf_ctrlr_drain_aer_req(struct spdk_nvmf_ctrlr *ctrlr)
+{
+	if (!ctrlr->aer_req) {
+		return;
+	}
+
+	spdk_nvmf_request_complete(ctrlr->aer_req);
+	ctrlr->aer_req = NULL;
+}
diff --git a/lib/nvmf/ctrlr_bdev.c b/lib/nvmf/ctrlr_bdev.c
index 93c7423dc..a75eddd3d 100644
--- a/lib/nvmf/ctrlr_bdev.c
+++ b/lib/nvmf/ctrlr_bdev.c
@@ -37,7 +37,7 @@
 
 #include "spdk/bdev.h"
 #include "spdk/endian.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/likely.h"
 #include "spdk/nvme.h"
 #include "spdk/nvmf_spec.h"
@@ -179,9 +179,8 @@ nvmf_bdev_ctrlr_read_cmd(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
 
-	spdk_trace_record(TRACE_NVMF_LIB_READ_START, 0, 0, (uint64_t)req, 0);
-	if (spdk_unlikely(spdk_bdev_read_blocks(desc, ch, req->data, start_lba, num_blocks,
-						nvmf_bdev_ctrlr_complete_cmd, req))) {
+	if (spdk_unlikely(spdk_bdev_readv_blocks(desc, ch, req->iov, req->iovcnt, start_lba, num_blocks,
+			  nvmf_bdev_ctrlr_complete_cmd, req))) {
 		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
 		rsp->status.sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
@@ -218,8 +217,7 @@ nvmf_bdev_ctrlr_write_cmd(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
 
-	spdk_trace_record(TRACE_NVMF_LIB_WRITE_START, 0, 0, (uint64_t)req, 0);
-	if (spdk_unlikely(spdk_bdev_write_blocks(desc, ch, req->data, start_lba, num_blocks,
+	if (spdk_unlikely(spdk_bdev_writev_blocks(desc, ch, req->iov, req->iovcnt, start_lba, num_blocks,
 			  nvmf_bdev_ctrlr_complete_cmd, req))) {
 		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
 		rsp->status.sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
@@ -248,7 +246,6 @@ nvmf_bdev_ctrlr_write_zeroes_cmd(struct spdk_bdev *bdev, struct spdk_bdev_desc *
 		return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
 	}
 
-	spdk_trace_record(TRACE_NVMF_LIB_WRITE_START, 0, 0, (uint64_t)req, 0);
 	if (spdk_unlikely(spdk_bdev_write_zeroes_blocks(desc, ch, start_lba, num_blocks,
 			  nvmf_bdev_ctrlr_complete_cmd, req))) {
 		rsp->status.sct = SPDK_NVME_SCT_GENERIC;
diff --git a/lib/nvmf/ctrlr_discovery.c b/lib/nvmf/ctrlr_discovery.c
index 840da2f7b..19b29e063 100644
--- a/lib/nvmf/ctrlr_discovery.c
+++ b/lib/nvmf/ctrlr_discovery.c
@@ -45,7 +45,7 @@
 #include "spdk/trace.h"
 #include "spdk/nvmf_spec.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 
 static void
@@ -69,7 +69,7 @@ nvmf_update_discovery_log(struct spdk_nvmf_tgt *tgt)
 		return;
 	}
 
-	for (sid = 0; sid < tgt->max_sid; sid++) {
+	for (sid = 0; sid < tgt->opts.max_subsystems; sid++) {
 		subsystem = tgt->subsystems[sid];
 		if (subsystem == NULL) {
 			continue;
diff --git a/lib/nvmf/nvmf.c b/lib/nvmf/nvmf.c
index 554c7e6e3..ece31ddb7 100644
--- a/lib/nvmf/nvmf.c
+++ b/lib/nvmf/nvmf.c
@@ -34,10 +34,13 @@
 #include "spdk/stdinc.h"
 
 #include "spdk/bdev.h"
+#include "spdk/bit_array.h"
 #include "spdk/conf.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/nvmf.h"
 #include "spdk/trace.h"
+#include "spdk/endian.h"
+#include "spdk/string.h"
 
 #include "spdk_internal/log.h"
 
@@ -46,12 +49,19 @@
 
 SPDK_LOG_REGISTER_COMPONENT("nvmf", SPDK_LOG_NVMF)
 
-#define MAX_SUBSYSTEMS 4
-
 #define SPDK_NVMF_DEFAULT_MAX_QUEUE_DEPTH 128
 #define SPDK_NVMF_DEFAULT_MAX_QPAIRS_PER_CTRLR 64
 #define SPDK_NVMF_DEFAULT_IN_CAPSULE_DATA_SIZE 4096
 #define SPDK_NVMF_DEFAULT_MAX_IO_SIZE 131072
+#define SPDK_NVMF_DEFAULT_MAX_SUBSYSTEMS 1024
+#define SPDK_NVMF_DEFAULT_IO_UNIT_SIZE 131072
+
+struct nvmf_qpair_disconnect_ctx {
+	struct spdk_nvmf_qpair *qpair;
+	struct spdk_nvmf_ctrlr *ctrlr;
+	nvmf_qpair_disconnect_cb cb_fn;
+	void *ctx;
+};
 
 void
 spdk_nvmf_tgt_opts_init(struct spdk_nvmf_tgt_opts *opts)
@@ -60,6 +70,8 @@ spdk_nvmf_tgt_opts_init(struct spdk_nvmf_tgt_opts *opts)
 	opts->max_qpairs_per_ctrlr = SPDK_NVMF_DEFAULT_MAX_QPAIRS_PER_CTRLR;
 	opts->in_capsule_data_size = SPDK_NVMF_DEFAULT_IN_CAPSULE_DATA_SIZE;
 	opts->max_io_size = SPDK_NVMF_DEFAULT_MAX_IO_SIZE;
+	opts->max_subsystems = SPDK_NVMF_DEFAULT_MAX_SUBSYSTEMS;
+	opts->io_unit_size = SPDK_NVMF_DEFAULT_IO_UNIT_SIZE;
 }
 
 static int
@@ -90,18 +102,19 @@ spdk_nvmf_tgt_create_poll_group(void *io_device, void *ctx_buf)
 	uint32_t sid;
 
 	TAILQ_INIT(&group->tgroups);
+	TAILQ_INIT(&group->qpairs);
 
 	TAILQ_FOREACH(transport, &tgt->transports, link) {
 		spdk_nvmf_poll_group_add_transport(group, transport);
 	}
 
-	group->num_sgroups = tgt->max_sid;
-	group->sgroups = calloc(group->num_sgroups, sizeof(struct spdk_nvmf_subsystem_poll_group));
+	group->num_sgroups = tgt->opts.max_subsystems;
+	group->sgroups = calloc(tgt->opts.max_subsystems, sizeof(struct spdk_nvmf_subsystem_poll_group));
 	if (!group->sgroups) {
 		return -1;
 	}
 
-	for (sid = 0; sid < group->num_sgroups; sid++) {
+	for (sid = 0; sid < tgt->opts.max_subsystems; sid++) {
 		struct spdk_nvmf_subsystem *subsystem;
 
 		subsystem = tgt->subsystems[sid];
@@ -122,12 +135,17 @@ static void
 spdk_nvmf_tgt_destroy_poll_group(void *io_device, void *ctx_buf)
 {
 	struct spdk_nvmf_poll_group *group = ctx_buf;
+	struct spdk_nvmf_qpair *qpair, *qptmp;
 	struct spdk_nvmf_transport_poll_group *tgroup, *tmp;
 	struct spdk_nvmf_subsystem_poll_group *sgroup;
 	uint32_t sid, nsid;
 
 	spdk_poller_unregister(&group->poller);
 
+	TAILQ_FOREACH_SAFE(qpair, &group->qpairs, link, qptmp) {
+		spdk_nvmf_qpair_disconnect(qpair, NULL, NULL);
+	}
+
 	TAILQ_FOREACH_SAFE(tgroup, &group->tgroups, link, tmp) {
 		TAILQ_REMOVE(&group->tgroups, tgroup, link);
 		spdk_nvmf_transport_poll_group_destroy(tgroup);
@@ -165,13 +183,25 @@ spdk_nvmf_tgt_create(struct spdk_nvmf_tgt_opts *opts)
 		tgt->opts = *opts;
 	}
 
+	if ((tgt->opts.max_io_size % tgt->opts.io_unit_size != 0) ||
+	    (tgt->opts.max_io_size / tgt->opts.io_unit_size > SPDK_NVMF_MAX_SGL_ENTRIES)) {
+		SPDK_ERRLOG("Unsupported IO size, MaxIO:%d, UnitIO:%d\n", tgt->opts.max_io_size,
+			    tgt->opts.io_unit_size);
+		free(tgt);
+		return NULL;
+	}
+
 	tgt->discovery_genctr = 0;
 	tgt->discovery_log_page = NULL;
 	tgt->discovery_log_page_size = 0;
-	tgt->subsystems = NULL;
-	tgt->max_sid = 0;
 	TAILQ_INIT(&tgt->transports);
 
+	tgt->subsystems = calloc(tgt->opts.max_subsystems, sizeof(struct spdk_nvmf_subsystem *));
+	if (!tgt->subsystems) {
+		free(tgt);
+		return NULL;
+	}
+
 	spdk_io_device_register(tgt,
 				spdk_nvmf_tgt_create_poll_group,
 				spdk_nvmf_tgt_destroy_poll_group,
@@ -183,14 +213,18 @@ spdk_nvmf_tgt_create(struct spdk_nvmf_tgt_opts *opts)
 	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Max In Capsule Data: %d bytes\n",
 		      tgt->opts.in_capsule_data_size);
 	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "Max I/O Size: %d bytes\n", tgt->opts.max_io_size);
+	SPDK_DEBUGLOG(SPDK_LOG_NVMF, "I/O Unit Size: %d bytes\n", tgt->opts.io_unit_size);
 
 	return tgt;
 }
 
-void
-spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt)
+static void
+spdk_nvmf_tgt_destroy_cb(void *io_device)
 {
+	struct spdk_nvmf_tgt *tgt = io_device;
 	struct spdk_nvmf_transport *transport, *transport_tmp;
+	spdk_nvmf_tgt_destroy_done_fn		*destroy_cb_fn;
+	void					*destroy_cb_arg;
 	uint32_t i;
 
 	if (tgt->discovery_log_page) {
@@ -198,7 +232,7 @@ spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt)
 	}
 
 	if (tgt->subsystems) {
-		for (i = 0; i < tgt->max_sid; i++) {
+		for (i = 0; i < tgt->opts.max_subsystems; i++) {
 			if (tgt->subsystems[i]) {
 				spdk_nvmf_subsystem_destroy(tgt->subsystems[i]);
 			}
@@ -211,7 +245,25 @@ spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt)
 		spdk_nvmf_transport_destroy(transport);
 	}
 
+	destroy_cb_fn = tgt->destroy_cb_fn;
+	destroy_cb_arg = tgt->destroy_cb_arg;
+
 	free(tgt);
+
+	if (destroy_cb_fn) {
+		destroy_cb_fn(destroy_cb_arg, 0);
+	}
+}
+
+void
+spdk_nvmf_tgt_destroy(struct spdk_nvmf_tgt *tgt,
+		      spdk_nvmf_tgt_destroy_done_fn cb_fn,
+		      void *cb_arg)
+{
+	tgt->destroy_cb_fn = cb_fn;
+	tgt->destroy_cb_arg = cb_arg;
+
+	spdk_io_device_unregister(tgt, spdk_nvmf_tgt_destroy_cb);
 }
 
 struct spdk_nvmf_tgt_listen_ctx {
@@ -223,6 +275,139 @@ struct spdk_nvmf_tgt_listen_ctx {
 	void *cb_arg;
 };
 
+static void
+spdk_nvmf_write_subsystem_config_json(struct spdk_json_write_ctx *w,
+				      struct spdk_nvmf_subsystem *subsystem)
+{
+	struct spdk_nvmf_host *host;
+	struct spdk_nvmf_listener *listener;
+	const struct spdk_nvme_transport_id *trid;
+	struct spdk_nvmf_ns *ns;
+	struct spdk_nvmf_ns_opts ns_opts;
+	uint32_t max_namespaces;
+	char uuid_str[SPDK_UUID_STRING_LEN];
+	const char *trtype;
+	const char *adrfam;
+
+	if (spdk_nvmf_subsystem_get_type(subsystem) != SPDK_NVMF_SUBTYPE_NVME) {
+		return;
+	}
+
+	/* { */
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_string(w, "method", "construct_nvmf_subsystem");
+
+	/*     "params" : { */
+	spdk_json_write_named_object_begin(w, "params");
+	spdk_json_write_named_string(w, "nqn", spdk_nvmf_subsystem_get_nqn(subsystem));
+	spdk_json_write_named_bool(w, "allow_any_host", spdk_nvmf_subsystem_get_allow_any_host(subsystem));
+
+	/*         "listen_addresses" : [ */
+	spdk_json_write_named_array_begin(w, "listen_addresses");
+	for (listener = spdk_nvmf_subsystem_get_first_listener(subsystem); listener != NULL;
+	     listener = spdk_nvmf_subsystem_get_next_listener(subsystem, listener)) {
+		trid = spdk_nvmf_listener_get_trid(listener);
+
+		trtype = spdk_nvme_transport_id_trtype_str(trid->trtype);
+		adrfam = spdk_nvme_transport_id_adrfam_str(trid->adrfam);
+
+		/*        { */
+		spdk_json_write_object_begin(w);
+		spdk_json_write_named_string(w, "trtype", trtype);
+		if (adrfam) {
+			spdk_json_write_named_string(w, "adrfam", adrfam);
+		}
+
+		spdk_json_write_named_string(w, "traddr", trid->traddr);
+		spdk_json_write_named_string(w, "trsvcid", trid->trsvcid);
+		spdk_json_write_object_end(w);
+		/*        } */
+	}
+	spdk_json_write_array_end(w);
+	/*         ] "listen_addresses" */
+
+	/*         "hosts" : [ */
+	spdk_json_write_named_array_begin(w, "hosts");
+	for (host = spdk_nvmf_subsystem_get_first_host(subsystem); host != NULL;
+	     host = spdk_nvmf_subsystem_get_next_host(subsystem, host)) {
+		spdk_json_write_string(w, spdk_nvmf_host_get_nqn(host));
+	}
+	spdk_json_write_array_end(w);
+	/*         ] "hosts" */
+
+	spdk_json_write_named_string(w, "serial_number", spdk_nvmf_subsystem_get_sn(subsystem));
+
+	max_namespaces = spdk_nvmf_subsystem_get_max_namespaces(subsystem);
+	if (max_namespaces != 0) {
+		spdk_json_write_named_uint32(w, "max_namespaces", max_namespaces);
+	}
+
+	/*         "namespaces" : [ */
+	spdk_json_write_named_array_begin(w, "namespaces");
+	for (ns = spdk_nvmf_subsystem_get_first_ns(subsystem); ns != NULL;
+	     ns = spdk_nvmf_subsystem_get_next_ns(subsystem, ns)) {
+		spdk_nvmf_ns_get_opts(ns, &ns_opts, sizeof(ns_opts));
+
+		/*         { */
+		spdk_json_write_object_begin(w);
+		spdk_json_write_named_uint32(w, "nsid", spdk_nvmf_ns_get_id(ns));
+		spdk_json_write_named_string(w, "bdev_name", spdk_bdev_get_name(spdk_nvmf_ns_get_bdev(ns)));
+
+		if (!spdk_mem_all_zero(ns_opts.nguid, sizeof(ns_opts.nguid))) {
+			SPDK_STATIC_ASSERT(sizeof(ns_opts.nguid) == sizeof(uint64_t) * 2, "size mismatch");
+			spdk_json_write_named_string_fmt(w, "nguid", "%016"PRIX64"%016"PRIX64, from_be64(&ns_opts.nguid[0]),
+							 from_be64(&ns_opts.nguid[8]));
+		}
+
+		if (!spdk_mem_all_zero(ns_opts.eui64, sizeof(ns_opts.eui64))) {
+			SPDK_STATIC_ASSERT(sizeof(ns_opts.eui64) == sizeof(uint64_t), "size mismatch");
+			spdk_json_write_named_string_fmt(w, "eui64", "%016"PRIX64, from_be64(&ns_opts.eui64));
+		}
+
+		if (!spdk_mem_all_zero(&ns_opts.uuid, sizeof(ns_opts.uuid))) {
+			spdk_uuid_fmt_lower(uuid_str, sizeof(uuid_str), &ns_opts.uuid);
+			spdk_json_write_named_string(w, "uuid",  uuid_str);
+		}
+		/*         } */
+		spdk_json_write_object_end(w);
+	}
+
+	/*         ] "namespaces" */
+	spdk_json_write_array_end(w);
+
+	/*     } "params" */
+	spdk_json_write_object_end(w);
+
+	/* } */
+	spdk_json_write_object_end(w);
+}
+
+void
+spdk_nvmf_tgt_write_config_json(struct spdk_json_write_ctx *w, struct spdk_nvmf_tgt *tgt)
+{
+	struct spdk_nvmf_subsystem *subsystem;
+
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_string(w, "method", "set_nvmf_target_options");
+
+	spdk_json_write_named_object_begin(w, "params");
+	spdk_json_write_named_uint32(w, "max_queue_depth", tgt->opts.max_queue_depth);
+	spdk_json_write_named_uint32(w, "max_qpairs_per_ctrlr", tgt->opts.max_qpairs_per_ctrlr);
+	spdk_json_write_named_uint32(w, "in_capsule_data_size", tgt->opts.in_capsule_data_size);
+	spdk_json_write_named_uint32(w, "max_io_size", tgt->opts.max_io_size);
+	spdk_json_write_named_uint32(w, "max_subsystems", tgt->opts.max_subsystems);
+	spdk_json_write_named_uint32(w, "io_unit_size", tgt->opts.io_unit_size);
+	spdk_json_write_object_end(w);
+
+	spdk_json_write_object_end(w);
+
+	subsystem = spdk_nvmf_subsystem_get_first(tgt);
+	while (subsystem) {
+		spdk_nvmf_write_subsystem_config_json(w, subsystem);
+		subsystem = spdk_nvmf_subsystem_get_next(subsystem);
+	}
+}
+
 static void
 spdk_nvmf_tgt_listen_done(struct spdk_io_channel_iter *i, int status)
 {
@@ -311,7 +496,7 @@ spdk_nvmf_tgt_find_subsystem(struct spdk_nvmf_tgt *tgt, const char *subnqn)
 		return NULL;
 	}
 
-	for (sid = 0; sid < tgt->max_sid; sid++) {
+	for (sid = 0; sid < tgt->opts.max_subsystems; sid++) {
 		subsystem = tgt->subsystems[sid];
 		if (subsystem == NULL) {
 			continue;
@@ -379,7 +564,11 @@ spdk_nvmf_poll_group_add(struct spdk_nvmf_poll_group *group,
 	int rc = -1;
 	struct spdk_nvmf_transport_poll_group *tgroup;
 
+	TAILQ_INIT(&qpair->outstanding);
 	qpair->group = group;
+	qpair->state = SPDK_NVMF_QPAIR_ACTIVATING;
+
+	TAILQ_INSERT_TAIL(&group->qpairs, qpair, link);
 
 	TAILQ_FOREACH(tgroup, &group->tgroups, link) {
 		if (tgroup->transport == qpair->transport) {
@@ -388,6 +577,12 @@ spdk_nvmf_poll_group_add(struct spdk_nvmf_poll_group *group,
 		}
 	}
 
+	if (rc == 0) {
+		qpair->state = SPDK_NVMF_QPAIR_ACTIVE;
+	} else {
+		qpair->state = SPDK_NVMF_QPAIR_INACTIVE;
+	}
+
 	return rc;
 }
 
@@ -398,6 +593,8 @@ spdk_nvmf_poll_group_remove(struct spdk_nvmf_poll_group *group,
 	int rc = -1;
 	struct spdk_nvmf_transport_poll_group *tgroup;
 
+	TAILQ_REMOVE(&group->qpairs, qpair, link);
+
 	qpair->group = NULL;
 
 	TAILQ_FOREACH(tgroup, &group->tgroups, link) {
@@ -410,6 +607,116 @@ spdk_nvmf_poll_group_remove(struct spdk_nvmf_poll_group *group,
 	return rc;
 }
 
+static void
+_spdk_nvmf_ctrlr_free_from_qpair(void *ctx)
+{
+	struct nvmf_qpair_disconnect_ctx *qpair_ctx = ctx;
+	struct spdk_nvmf_ctrlr *ctrlr = qpair_ctx->ctrlr;
+
+	spdk_nvmf_ctrlr_destruct(ctrlr);
+
+	if (qpair_ctx->cb_fn) {
+		qpair_ctx->cb_fn(qpair_ctx->ctx);
+	}
+	free(qpair_ctx);
+}
+
+static void
+_spdk_nvmf_qpair_destroy(void *ctx, int status)
+{
+	struct nvmf_qpair_disconnect_ctx *qpair_ctx = ctx;
+	struct spdk_nvmf_qpair *qpair = qpair_ctx->qpair;
+	struct spdk_nvmf_ctrlr *ctrlr = qpair->ctrlr;
+	uint16_t qid = qpair->qid;
+	uint32_t count;
+
+	spdk_nvmf_poll_group_remove(qpair->group, qpair);
+
+	assert(qpair->state == SPDK_NVMF_QPAIR_DEACTIVATING);
+	qpair->state = SPDK_NVMF_QPAIR_INACTIVE;
+
+	spdk_nvmf_transport_qpair_fini(qpair);
+
+	if (!ctrlr) {
+		if (qpair_ctx->cb_fn) {
+			qpair_ctx->cb_fn(qpair_ctx->ctx);
+		}
+		free(qpair_ctx);
+		return;
+	}
+
+	pthread_mutex_lock(&ctrlr->mtx);
+	spdk_bit_array_clear(ctrlr->qpair_mask, qid);
+	count = spdk_bit_array_count_set(ctrlr->qpair_mask);
+	pthread_mutex_unlock(&ctrlr->mtx);
+
+	if (count == 0) {
+		/* If this was the last queue pair on the controller, also send a message
+		 * to the subsystem to remove the controller. */
+		qpair_ctx->ctrlr = ctrlr;
+		spdk_thread_send_msg(ctrlr->subsys->thread, _spdk_nvmf_ctrlr_free_from_qpair, qpair_ctx);
+	} else {
+		if (qpair_ctx->cb_fn) {
+			qpair_ctx->cb_fn(qpair_ctx->ctx);
+		}
+		free(qpair_ctx);
+	}
+}
+
+static void
+_spdk_nvmf_qpair_deactivate(void *ctx)
+{
+	struct nvmf_qpair_disconnect_ctx *qpair_ctx = ctx;
+	struct spdk_nvmf_qpair *qpair = qpair_ctx->qpair;
+
+	if (qpair->state == SPDK_NVMF_QPAIR_DEACTIVATING ||
+	    qpair->state == SPDK_NVMF_QPAIR_INACTIVE) {
+		/* This can occur if the connection is killed by the target,
+		 * which results in a notification that the connection
+		 * died. */
+		if (qpair_ctx->cb_fn) {
+			qpair_ctx->cb_fn(qpair_ctx->ctx);
+		}
+		free(qpair_ctx);
+		return;
+	}
+
+	assert(qpair->state == SPDK_NVMF_QPAIR_ACTIVE);
+	qpair->state = SPDK_NVMF_QPAIR_DEACTIVATING;
+
+	/* Check for outstanding I/O */
+	if (!TAILQ_EMPTY(&qpair->outstanding)) {
+		qpair->state_cb = _spdk_nvmf_qpair_destroy;
+		qpair->state_cb_arg = qpair_ctx;
+		return;
+	}
+
+	_spdk_nvmf_qpair_destroy(qpair_ctx, 0);
+}
+
+int
+spdk_nvmf_qpair_disconnect(struct spdk_nvmf_qpair *qpair, nvmf_qpair_disconnect_cb cb_fn, void *ctx)
+{
+	struct nvmf_qpair_disconnect_ctx *qpair_ctx = calloc(1, sizeof(struct nvmf_qpair_disconnect_ctx));
+
+	if (!qpair_ctx) {
+		SPDK_ERRLOG("Unable to allocate context for nvmf_qpair_disconnect\n");
+		return -ENOMEM;
+	}
+
+	qpair_ctx->qpair = qpair;
+	qpair_ctx->cb_fn = cb_fn;
+	qpair_ctx->ctx = ctx;
+
+	if (qpair->group->thread == spdk_get_thread()) {
+		_spdk_nvmf_qpair_deactivate(qpair_ctx);
+	} else {
+		/* Send a message to the thread that owns this qpair */
+		spdk_thread_send_msg(qpair->group->thread, _spdk_nvmf_qpair_deactivate, qpair_ctx);
+	}
+	return 0;
+}
+
 int
 spdk_nvmf_poll_group_add_transport(struct spdk_nvmf_poll_group *group,
 				   struct spdk_nvmf_transport *transport)
@@ -445,21 +752,7 @@ poll_group_update_subsystem(struct spdk_nvmf_poll_group *group,
 
 	/* Make sure our poll group has memory for this subsystem allocated */
 	if (subsystem->id >= group->num_sgroups) {
-		void *buf;
-
-		buf = realloc(group->sgroups, (subsystem->id + 1) * sizeof(*sgroup));
-		if (!buf) {
-			return -ENOMEM;
-		}
-
-		group->sgroups = buf;
-
-		/* Zero out the newly allocated memory */
-		memset(&group->sgroups[group->num_sgroups],
-		       0,
-		       (subsystem->id + 1 - group->num_sgroups) * sizeof(group->sgroups[0]));
-
-		group->num_sgroups = subsystem->id + 1;
+		return -ENOMEM;
 	}
 
 	sgroup = &group->sgroups[subsystem->id];
@@ -567,9 +860,21 @@ int
 spdk_nvmf_poll_group_remove_subsystem(struct spdk_nvmf_poll_group *group,
 				      struct spdk_nvmf_subsystem *subsystem)
 {
+	struct spdk_nvmf_qpair *qpair, *tmp;
 	struct spdk_nvmf_subsystem_poll_group *sgroup;
+	int rc = 0;
 	uint32_t nsid;
 
+	TAILQ_FOREACH_SAFE(qpair, &group->qpairs, link, tmp) {
+		if (qpair->ctrlr->subsys == subsystem) {
+			rc += spdk_nvmf_qpair_disconnect(qpair, NULL, NULL);
+		}
+	}
+
+	if (rc != 0) {
+		return -1;
+	}
+
 	sgroup = &group->sgroups[subsystem->id];
 	sgroup->state = SPDK_NVMF_SUBSYSTEM_INACTIVE;
 
@@ -630,10 +935,6 @@ spdk_nvmf_poll_group_resume_subsystem(struct spdk_nvmf_poll_group *group,
 		return rc;
 	}
 
-	/* poll_group_update_subsystem may realloc the sgroups array. We need
-	 * to do a new lookup to get the correct pointer. */
-	sgroup = &group->sgroups[subsystem->id];
-
 	sgroup->state = SPDK_NVMF_SUBSYSTEM_ACTIVE;
 
 	/* Release all queued requests */
@@ -644,26 +945,3 @@ spdk_nvmf_poll_group_resume_subsystem(struct spdk_nvmf_poll_group *group,
 
 	return 0;
 }
-
-SPDK_TRACE_REGISTER_FN(nvmf_trace)
-{
-	spdk_trace_register_object(OBJECT_NVMF_IO, 'r');
-	spdk_trace_register_description("NVMF_IO_START", "", TRACE_NVMF_IO_START,
-					OWNER_NONE, OBJECT_NVMF_IO, 1, 0, 0, "");
-	spdk_trace_register_description("NVMF_RDMA_READ_START", "", TRACE_RDMA_READ_START,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_RDMA_WRITE_START", "", TRACE_RDMA_WRITE_START,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_RDMA_READ_COMPLETE", "", TRACE_RDMA_READ_COMPLETE,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_RDMA_WRITE_COMPLETE", "", TRACE_RDMA_WRITE_COMPLETE,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_LIB_READ_START", "", TRACE_NVMF_LIB_READ_START,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_LIB_WRITE_START", "", TRACE_NVMF_LIB_WRITE_START,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_LIB_COMPLETE", "", TRACE_NVMF_LIB_COMPLETE,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-	spdk_trace_register_description("NVMF_IO_COMPLETION_DONE", "", TRACE_NVMF_IO_COMPLETE,
-					OWNER_NONE, OBJECT_NVMF_IO, 0, 0, 0, "");
-}
diff --git a/lib/nvmf/nvmf_fc.h b/lib/nvmf/nvmf_fc.h
new file mode 100644
index 000000000..b27904530
--- /dev/null
+++ b/lib/nvmf/nvmf_fc.h
@@ -0,0 +1,871 @@
+/*
+ *   BSD LICENSE
+ *
+ *   Copyright (c) 2018 Broadcom.  All Rights Reserved.
+ *   The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __NVMF_FC_H__
+#define __NVMF_FC_H__
+
+#include "spdk/nvmf.h"
+#include "spdk/assert.h"
+#include "spdk/nvme_spec.h"
+#include "spdk/nvmf_fc_spec.h"
+#include "spdk/event.h"
+#include "spdk/io_channel.h"
+#include "nvmf_internal.h"
+
+#define SPDK_NVMF_FC_TR_ADDR_LEN 64
+
+/*
+ * FC HW port states.
+ */
+enum spdk_fc_port_state {
+	SPDK_FC_PORT_OFFLINE = 0,
+	SPDK_FC_PORT_ONLINE = 1,
+	SPDK_FC_PORT_QUIESCED = 2,
+};
+
+enum spdk_fc_hwqp_state {
+	SPDK_FC_HWQP_OFFLINE = 0,
+	SPDK_FC_HWQP_ONLINE = 1,
+};
+
+/*
+ * NVMF BCM FC Object state
+ * Add all the generic states of the object here.
+ * Specific object states can be added separately
+ */
+enum spdk_nvmf_fc_object_state {
+	SPDK_NVMF_FC_OBJECT_CREATED = 0,
+	SPDK_NVMF_FC_OBJECT_TO_BE_DELETED = 1,
+	SPDK_NVMF_FC_OBJECT_ZOMBIE = 2,      /* Partial Create or Delete  */
+};
+
+/*
+ * FC request state
+ */
+enum spdk_nvmf_fc_request_state {
+	SPDK_NVMF_FC_REQ_INIT = 0,
+	SPDK_NVMF_FC_REQ_READ_BDEV,
+	SPDK_NVMF_FC_REQ_READ_XFER,
+	SPDK_NVMF_FC_REQ_READ_RSP,
+	SPDK_NVMF_FC_REQ_WRITE_BUFFS,
+	SPDK_NVMF_FC_REQ_WRITE_XFER,
+	SPDK_NVMF_FC_REQ_WRITE_BDEV,
+	SPDK_NVMF_FC_REQ_WRITE_RSP,
+	SPDK_NVMF_FC_REQ_NONE_BDEV,
+	SPDK_NVMF_FC_REQ_NONE_RSP,
+	SPDK_NVMF_FC_REQ_SUCCESS,
+	SPDK_NVMF_FC_REQ_FAILED,
+	SPDK_NVMF_FC_REQ_ABORTED,
+	SPDK_NVMF_FC_REQ_PENDING,
+	SPDK_NVMF_FC_REQ_MAX_STATE,
+};
+
+/*
+ * FC HWQP pointer
+ */
+typedef void *spdk_nvmf_fc_lld_hwqp_t;
+
+/*
+ * FC World Wide Name
+ */
+struct spdk_nvmf_fc_wwn {
+	union {
+		uint64_t wwn; /* World Wide Names consist of eight bytes */
+		uint8_t octets[sizeof(uint64_t)];
+	} u;
+};
+
+/*
+ * Generic DMA buffer descriptor
+ */
+struct spdk_nvmf_fc_buffer_desc {
+	void *virt;
+	uint64_t phys;
+	size_t len;
+
+	/* Internal */
+	uint32_t buf_index;
+};
+
+/*
+ * ABTS hadling context
+ */
+struct spdk_nvmf_fc_abts_ctx {
+	bool handled;
+	uint16_t hwqps_responded;
+	uint16_t rpi;
+	uint16_t oxid;
+	uint16_t rxid;
+	struct spdk_nvmf_fc_nport *nport;
+	uint16_t nport_hdl;
+	uint8_t port_hdl;
+	void *abts_poller_args;
+	void *sync_poller_args;
+	int num_hwqps;
+	bool queue_synced;
+	uint64_t u_id;
+	struct spdk_nvmf_fc_hwqp *ls_hwqp;
+	uint16_t fcp_rq_id;
+};
+
+/*
+ * NVME FC transport errors
+ */
+struct spdk_nvmf_fc_errors {
+	uint32_t no_xri;
+	uint32_t nport_invalid;
+	uint32_t unknown_frame;
+	uint32_t wqe_cmplt_err;
+	uint32_t wqe_write_err;
+	uint32_t rq_status_err;
+	uint32_t rq_buf_len_err;
+	uint32_t rq_id_err;
+	uint32_t rq_index_err;
+	uint32_t invalid_cq_type;
+	uint32_t invalid_cq_id;
+	uint32_t fc_req_buf_err;
+	uint32_t aq_buf_alloc_err;
+	uint32_t write_buf_alloc_err;
+	uint32_t read_buf_alloc_err;
+	uint32_t unexpected_err;
+	uint32_t nvme_cmd_iu_err;
+	uint32_t nvme_cmd_xfer_err;
+	uint32_t queue_entry_invalid;
+	uint32_t invalid_conn_err;
+	uint32_t fcp_rsp_failure;
+	uint32_t write_failed;
+	uint32_t read_failed;
+	uint32_t rport_invalid;
+	uint32_t num_aborted;
+	uint32_t num_abts_sent;
+};
+
+/*
+ *  Send Single Request/Response Sequence.
+ */
+struct spdk_nvmf_fc_send_srsr {
+	struct spdk_nvmf_fc_buffer_desc rqst;
+	struct spdk_nvmf_fc_buffer_desc rsp;
+	struct spdk_nvmf_fc_buffer_desc sgl; /* Note: Len = (2 * bcm_sge_t) */
+	uint16_t rpi;
+};
+
+/*
+ * Struct representing a nport
+ */
+struct spdk_nvmf_fc_nport {
+
+	uint16_t nport_hdl;
+	uint8_t port_hdl;
+	uint32_t d_id;
+	enum spdk_nvmf_fc_object_state nport_state;
+	struct spdk_nvmf_fc_wwn fc_nodename;
+	struct spdk_nvmf_fc_wwn fc_portname;
+
+	/* list of remote ports (i.e. initiators) connected to nport */
+	TAILQ_HEAD(, spdk_nvmf_fc_remote_port_info) rem_port_list;
+	uint32_t rport_count;
+
+	void *vendor_data;	/* available for vendor use */
+
+	/* list of associations to nport */
+	TAILQ_HEAD(, spdk_nvmf_fc_association) fc_associations;
+	uint32_t assoc_count;
+	struct spdk_nvmf_fc_port *fc_port;
+	TAILQ_ENTRY(spdk_nvmf_fc_nport) link; /* list of nports on a hw port. */
+};
+
+/*
+ * NVMF FC Connection
+ */
+struct spdk_nvmf_fc_conn {
+	struct spdk_nvmf_qpair qpair;
+
+	uint64_t conn_id;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	uint16_t esrp_ratio;
+	uint16_t rsp_count;
+	uint32_t rsn;
+
+	/* The maximum number of I/O outstanding on this connection at one time */
+	uint16_t max_queue_depth;
+	uint16_t max_rw_depth;
+	/* The current number of I/O outstanding on this connection. This number
+	 * includes all I/O from the time the capsule is first received until it is
+	 * completed.
+	 */
+	uint16_t cur_queue_depth;
+
+	/* number of read/write requests that are outstanding */
+	uint16_t cur_fc_rw_depth;
+
+	/* requests that are waiting to obtain xri/buffer */
+	TAILQ_HEAD(, spdk_nvmf_fc_request) pending_queue;
+
+	struct spdk_nvmf_fc_association *fc_assoc;
+
+	/* additional FC info here - TBD */
+	uint16_t rpi;
+
+	/* for association's connection list */
+	TAILQ_ENTRY(spdk_nvmf_fc_conn) assoc_link;
+
+	/* for assocations's available connection list */
+	TAILQ_ENTRY(spdk_nvmf_fc_conn) assoc_avail_link;
+
+	/* for hwqp's connection list */
+	TAILQ_ENTRY(spdk_nvmf_fc_conn) link;
+};
+
+/*
+ * Structure for maintaining the XRI's
+ */
+struct spdk_nvmf_fc_xri {
+	uint32_t xri;   /* The actual xri value */
+	/* Internal */
+	TAILQ_ENTRY(spdk_nvmf_fc_xri) link;
+	bool is_active;
+};
+
+struct spdk_nvmf_fc_poll_group;
+
+/*
+ *  HWQP poller structure passed from Master thread
+ */
+struct spdk_nvmf_fc_hwqp {
+	uint32_t lcore_id;   /* core hwqp is running on (for tracing purposes only) */
+	struct spdk_thread *thread;  /* thread hwqp is running on */
+	uint32_t hwqp_id;    /* A unique id (per physical port) for a hwqp */
+	uint32_t rq_size;    /* receive queue size */
+	spdk_nvmf_fc_lld_hwqp_t queues;          /* vendor HW queue set */
+	struct spdk_nvmf_fc_port *fc_port; /* HW port structure for these queues */
+	struct spdk_nvmf_fc_poll_group *poll_group;
+
+	void *context;			/* Vendor Context */
+
+	TAILQ_HEAD(, spdk_nvmf_fc_conn) connection_list;
+	uint32_t num_conns; /* number of connections to queue */
+	uint16_t cid_cnt;   /* used to generate unique conn. id for RQ */
+	uint32_t free_q_slots; /* free q slots available for connections  */
+	enum spdk_fc_hwqp_state state;  /* Poller state (e.g. online, offline) */
+
+	/* Internal */
+	struct spdk_mempool *fc_request_pool;
+	TAILQ_HEAD(, spdk_nvmf_fc_request) in_use_reqs;
+
+	TAILQ_HEAD(, spdk_nvmf_fc_xri) pending_xri_list;
+
+	struct spdk_nvmf_fc_errors counters;
+	uint32_t send_frame_xri;
+	uint8_t send_frame_seqid;
+
+	/* Pending LS request waiting for XRI. */
+	TAILQ_HEAD(, spdk_nvmf_fc_ls_rqst) ls_pending_queue;
+
+	/* Sync req list */
+	TAILQ_HEAD(, spdk_nvmf_fc_poller_api_queue_sync_args) sync_cbs;
+
+	TAILQ_ENTRY(spdk_nvmf_fc_hwqp) link;
+};
+
+struct spdk_nvmf_fc_ls_rsrc_pool {
+	void *assocs_mptr;
+	uint32_t assocs_count;
+	TAILQ_HEAD(, spdk_nvmf_fc_association) assoc_free_list;
+
+	void *conns_mptr;
+	uint32_t conns_count;
+	TAILQ_HEAD(, spdk_nvmf_fc_conn) fc_conn_free_list;
+};
+
+/*
+ * FC HW port.
+ */
+struct spdk_nvmf_fc_port {
+	uint8_t port_hdl;
+	enum spdk_fc_port_state hw_port_status;
+	uint32_t xri_base;
+	uint32_t xri_count;
+	uint16_t fcp_rq_id;
+	struct spdk_ring *xri_ring;
+	struct spdk_nvmf_fc_hwqp ls_queue;
+	uint32_t num_io_queues;
+	struct spdk_nvmf_fc_hwqp *io_queues;
+	/*
+	 * List of nports on this HW port.
+	 */
+	TAILQ_HEAD(, spdk_nvmf_fc_nport)nport_list;
+	int	num_nports;
+	TAILQ_ENTRY(spdk_nvmf_fc_port) link;
+
+	struct spdk_nvmf_fc_ls_rsrc_pool ls_rsrc_pool;
+	struct spdk_mempool *io_rsrc_pool; /* Pools to store bdev_io's for this port */
+	void *port_ctx;
+};
+
+/*
+ * NVMF FC Request
+ */
+struct spdk_nvmf_fc_request {
+	struct spdk_nvmf_request req;
+	struct spdk_nvmf_fc_ersp_iu ersp;
+	uint32_t poller_lcore; /* for tracing purposes only */
+	struct spdk_thread *poller_thread;
+	uint16_t buf_index;
+	struct spdk_nvmf_fc_xri *xri;
+	uint16_t oxid;
+	uint16_t rpi;
+	struct spdk_nvmf_fc_conn *fc_conn;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	int state;
+	uint32_t transfered_len;
+	bool is_aborted;
+	uint32_t magic;
+	uint32_t s_id;
+	uint32_t d_id;
+	TAILQ_ENTRY(spdk_nvmf_fc_request) link;
+	TAILQ_ENTRY(spdk_nvmf_fc_request) pending_link;
+	TAILQ_HEAD(, spdk_nvmf_fc_caller_ctx) abort_cbs;
+};
+
+SPDK_STATIC_ASSERT(!offsetof(struct spdk_nvmf_fc_request, req),
+		   "FC request and NVMF request address doesnt match.");
+
+/*
+ * NVMF FC Association
+ */
+struct spdk_nvmf_fc_association {
+	uint64_t assoc_id;
+	uint32_t s_id;
+	struct spdk_nvmf_fc_nport *tgtport;
+	struct spdk_nvmf_fc_remote_port_info *rport;
+	struct spdk_nvmf_subsystem *subsystem;
+	struct spdk_nvmf_host *host;
+	enum spdk_nvmf_fc_object_state assoc_state;
+
+	char host_id[FCNVME_ASSOC_HOSTID_LEN];
+	char host_nqn[FCNVME_ASSOC_HOSTNQN_LEN];
+	char sub_nqn[FCNVME_ASSOC_HOSTNQN_LEN];
+
+	struct spdk_nvmf_fc_conn *aq_conn; /* connection for admin queue */
+
+	uint16_t conn_count;
+	TAILQ_HEAD(, spdk_nvmf_fc_conn) fc_conns;
+
+	void *conns_buf;
+	TAILQ_HEAD(, spdk_nvmf_fc_conn) avail_fc_conns;
+
+	TAILQ_ENTRY(spdk_nvmf_fc_association) link;
+
+	/* for port's association free list */
+	TAILQ_ENTRY(spdk_nvmf_fc_association) port_free_assoc_list_link;
+
+	void *ls_del_op_ctx; /* delete assoc. callback list */
+
+	/* req/resp buffers used to send disconnect to initiator */
+	struct spdk_nvmf_fc_send_srsr snd_disconn_bufs;
+};
+
+/*
+ * FC Remote Port
+ */
+struct spdk_nvmf_fc_remote_port_info {
+	uint32_t s_id;
+	uint32_t rpi;
+	uint32_t assoc_count;
+	struct spdk_nvmf_fc_wwn fc_nodename;
+	struct spdk_nvmf_fc_wwn fc_portname;
+	enum spdk_nvmf_fc_object_state rport_state;
+	TAILQ_ENTRY(spdk_nvmf_fc_remote_port_info) link;
+};
+
+/*
+ * Poller API error codes
+ */
+enum spdk_nvmf_fc_poller_api_ret {
+	SPDK_NVMF_FC_POLLER_API_SUCCESS = 0,
+	SPDK_NVMF_FC_POLLER_API_ERROR,
+	SPDK_NVMF_FC_POLLER_API_INVALID_ARG,
+	SPDK_NVMF_FC_POLLER_API_NO_CONN_ID,
+	SPDK_NVMF_FC_POLLER_API_DUP_CONN_ID,
+	SPDK_NVMF_FC_POLLER_API_OXID_NOT_FOUND,
+};
+
+/*
+ * Poller API definitions
+ */
+enum spdk_nvmf_fc_poller_api {
+	SPDK_NVMF_FC_POLLER_API_ADD_CONNECTION,
+	SPDK_NVMF_FC_POLLER_API_DEL_CONNECTION,
+	SPDK_NVMF_FC_POLLER_API_QUIESCE_QUEUE,
+	SPDK_NVMF_FC_POLLER_API_ACTIVATE_QUEUE,
+	SPDK_NVMF_FC_POLLER_API_ABTS_RECEIVED,
+	SPDK_NVMF_FC_POLLER_API_ADAPTER_EVENT,
+	SPDK_NVMF_FC_POLLER_API_AEN,
+	SPDK_NVMF_FC_POLLER_API_QUEUE_SYNC,
+	SPDK_NVMF_FC_POLLER_API_QUEUE_SYNC_DONE,
+};
+
+/*
+ * Poller API callback function proto
+ */
+typedef void (*spdk_nvmf_fc_poller_api_cb)(void *cb_data, enum spdk_nvmf_fc_poller_api_ret ret);
+
+/*
+ * Poller API callback data
+ */
+struct spdk_nvmf_fc_poller_api_cb_info {
+	spdk_nvmf_fc_poller_api_cb cb_func;
+	void *cb_data;
+	enum spdk_nvmf_fc_poller_api_ret ret;
+};
+
+/*
+ * Poller API structures
+ */
+struct spdk_nvmf_fc_poller_api_add_connection_args {
+	struct spdk_nvmf_fc_conn *fc_conn;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+};
+
+struct spdk_nvmf_fc_poller_api_del_connection_args {
+	struct spdk_nvmf_fc_conn *fc_conn;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+	bool send_abts;
+	/* internal */
+	int fc_request_cnt;
+};
+
+struct spdk_nvmf_fc_poller_api_quiesce_queue_args {
+	void   *ctx;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+};
+
+struct spdk_nvmf_fc_poller_api_activate_queue_args {
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+};
+
+struct spdk_nvmf_fc_poller_api_abts_recvd_args {
+	struct spdk_nvmf_fc_abts_ctx *ctx;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+};
+
+struct spdk_nvmf_fc_poller_api_queue_sync_done_args {
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	uint64_t tag;
+};
+
+/*
+ * NVMF LS request structure
+ */
+struct spdk_nvmf_fc_ls_rqst {
+	struct spdk_nvmf_fc_buffer_desc rqstbuf;
+	struct spdk_nvmf_fc_buffer_desc rspbuf;
+	uint32_t rqst_len;
+	uint32_t rsp_len;
+	uint32_t rpi;
+	struct spdk_nvmf_fc_xri *xri;
+	uint16_t oxid;
+	void *private_data; /* for LLD only (LS does not touch) */
+	TAILQ_ENTRY(spdk_nvmf_fc_ls_rqst) ls_pending_link;
+	uint32_t s_id;
+	uint32_t d_id;
+	struct spdk_nvmf_fc_nport *nport;
+	struct spdk_nvmf_fc_remote_port_info *rport;
+	struct spdk_nvmf_tgt *nvmf_tgt;
+};
+
+/*
+ * RQ Buffer LS Overlay Structure
+ */
+#define FCNVME_LS_RSVD_SIZE (FCNVME_MAX_LS_BUFFER_SIZE - \
+	(sizeof(struct spdk_nvmf_fc_ls_rqst) + FCNVME_MAX_LS_REQ_SIZE + FCNVME_MAX_LS_RSP_SIZE))
+
+struct __attribute__((__packed__)) spdk_nvmf_fc_rq_buf_ls_request {
+	uint8_t rqst[FCNVME_MAX_LS_REQ_SIZE];
+	uint8_t resp[FCNVME_MAX_LS_RSP_SIZE];
+	struct spdk_nvmf_fc_ls_rqst ls_rqst;
+	uint8_t rsvd[FCNVME_LS_RSVD_SIZE];
+};
+
+SPDK_STATIC_ASSERT(sizeof(struct spdk_nvmf_fc_rq_buf_ls_request) ==
+		   FCNVME_MAX_LS_BUFFER_SIZE, "LS RQ Buffer overflow");
+
+
+struct spdk_nvmf_fc_poller_api_queue_sync_args {
+	uint64_t u_id;
+	struct spdk_nvmf_fc_hwqp *hwqp;
+	struct spdk_nvmf_fc_poller_api_cb_info cb_info;
+
+	/* Used internally by poller */
+	TAILQ_ENTRY(spdk_nvmf_fc_poller_api_queue_sync_args) link;
+};
+
+/*
+ * dump info
+ */
+struct spdk_nvmf_fc_queue_dump_info {
+	char *buffer;
+	int   offset;
+};
+#define SPDK_FC_HW_DUMP_BUF_SIZE (10 * 4096)
+
+static inline void
+spdk_nvmf_fc_dump_buf_print(struct spdk_nvmf_fc_queue_dump_info *dump_info, char *fmt, ...)
+{
+	uint64_t buffer_size = SPDK_FC_HW_DUMP_BUF_SIZE;
+	int32_t avail = (int32_t)(buffer_size - dump_info->offset);
+
+	if (avail > 0) {
+		va_list ap;
+		int32_t written;
+
+		va_start(ap, fmt);
+		written = vsnprintf(dump_info->buffer + dump_info->offset, avail, fmt, ap);
+		if (written >= avail) {
+			dump_info->offset += avail;
+		} else {
+			dump_info->offset += written;
+		}
+		va_end(ap);
+	}
+}
+
+/*
+ * NVMF FC caller callback definitions
+ */
+typedef void (*spdk_nvmf_fc_caller_cb)(void *hwqp, int32_t status, void *args);
+
+struct spdk_nvmf_fc_caller_ctx {
+	void *ctx;
+	spdk_nvmf_fc_caller_cb cb;
+	void *cb_args;
+	TAILQ_ENTRY(spdk_nvmf_fc_caller_ctx) link;
+};
+
+/*
+ * Low level FC driver function table (functions provided by vendor FC device driver)
+ */
+struct spdk_nvmf_fc_ll_drvr_ops {
+
+	/* initialize the low level driver */
+	int (*lld_init)(void);
+
+	/* low level driver finish */
+	void (*lld_fini)(void);
+
+	/* initialize hw queues */
+	int (*init_q)(struct spdk_nvmf_fc_hwqp *hwqp);
+
+	void (*reinit_q)(spdk_nvmf_fc_lld_hwqp_t queues_prev,
+			 spdk_nvmf_fc_lld_hwqp_t queues_curr);
+
+	/* initialize hw queue buffers */
+	int (*init_q_buffers)(struct spdk_nvmf_fc_hwqp *hwqp);
+
+	/* poll the hw queues for requests */
+	uint32_t (*poll_queue)(struct spdk_nvmf_fc_hwqp *hwqp);
+
+	/* receive data (for data-in requests) */
+	int (*recv_data)(struct spdk_nvmf_fc_request *fc_req);
+
+	/* send data (for data-out requests) */
+	int (*send_data)(struct spdk_nvmf_fc_request *fc_req);
+
+	/* release hw queust buffer */
+	void (*q_buffer_release)(struct spdk_nvmf_fc_hwqp *hwqp, uint16_t buff_idx);
+
+	/* transmist nvme response */
+	int (*xmt_rsp)(struct spdk_nvmf_fc_request *fc_req, uint8_t *ersp_buf, uint32_t ersp_len);
+
+	/* transmist LS response */
+	int (*xmt_ls_rsp)(struct spdk_nvmf_fc_nport *tgtport, struct spdk_nvmf_fc_ls_rqst *ls_rqst);
+
+	/* issue abts */
+	int (*issue_abort)(struct spdk_nvmf_fc_hwqp *hwqp, struct spdk_nvmf_fc_xri *xri,
+			   bool send_abts, spdk_nvmf_fc_caller_cb cb, void *cb_args);
+
+	/* transmit abts response */
+	int (*xmt_bls_rsp)(struct spdk_nvmf_fc_hwqp *hwqp, uint16_t ox_id, uint16_t rx_id, uint16_t rpi,
+			   bool rjt, uint8_t rjt_exp, spdk_nvmf_fc_caller_cb cb, void *cb_args);
+
+	/* transmit single request - single response */
+	int (*xmt_srsr_req)(struct spdk_nvmf_fc_hwqp *hwqp, struct spdk_nvmf_fc_send_srsr *srsr,
+			    spdk_nvmf_fc_caller_cb cb, void *cb_args);
+
+	/* issue queue marker (abts processing) */
+	int (*issue_q_marker)(struct spdk_nvmf_fc_hwqp *hwqp, uint64_t u_id, uint16_t skip_rq);
+
+	/* assign a new connection to a hwqp (return connection ID) */
+	struct spdk_nvmf_fc_hwqp *(*assign_conn_to_hwqp)(
+		struct spdk_nvmf_fc_hwqp *queues, uint32_t num_queues,
+		uint64_t *conn_id, uint32_t sq_size, bool for_aq);
+
+	/* get the hwqp from the given connection id */
+	struct spdk_nvmf_fc_hwqp *(*get_hwqp_from_conn_id)(struct spdk_nvmf_fc_hwqp *hwqp,
+			uint32_t num_queues, uint64_t conn_id);
+
+	/* release connection ID (done with using it) */
+	void (*release_conn)(struct spdk_nvmf_fc_hwqp *hwqp, uint64_t conn_id, uint32_t sq_size);
+
+	/* dump all queue info into dump_info */
+	void (*dump_all_queues)(struct spdk_nvmf_fc_hwqp *ls_queues,
+				struct spdk_nvmf_fc_hwqp *io_queues,
+				uint32_t num_queues,
+				struct spdk_nvmf_fc_queue_dump_info *dump_info);
+};
+
+extern struct spdk_nvmf_fc_ll_drvr_ops spdk_nvmf_fc_lld_ops;
+
+/*
+ * NVMF FC inline and function prototypes
+ */
+
+static inline struct spdk_nvmf_fc_request *
+spdk_nvmf_fc_get_fc_req(struct spdk_nvmf_request *req)
+{
+	return (struct spdk_nvmf_fc_request *)
+	       ((uintptr_t)req - offsetof(struct spdk_nvmf_fc_request, req));
+}
+
+static inline bool
+spdk_nvmf_fc_is_port_dead(struct spdk_nvmf_fc_hwqp *hwqp)
+{
+	switch (hwqp->fc_port->hw_port_status) {
+	case SPDK_FC_PORT_QUIESCED:
+		return true;
+	default:
+		return false;
+	}
+}
+
+static inline bool
+spdk_nvmf_fc_req_in_xfer(struct spdk_nvmf_fc_request *fc_req)
+{
+	switch (fc_req->state) {
+	case SPDK_NVMF_FC_REQ_READ_XFER:
+	case SPDK_NVMF_FC_REQ_READ_RSP:
+	case SPDK_NVMF_FC_REQ_WRITE_XFER:
+	case SPDK_NVMF_FC_REQ_WRITE_RSP:
+	case SPDK_NVMF_FC_REQ_NONE_RSP:
+		return true;
+	default:
+		return false;
+	}
+}
+
+typedef void (*spdk_nvmf_fc_del_assoc_cb)(void *arg, uint32_t err);
+int spdk_nvmf_fc_delete_association(struct spdk_nvmf_fc_nport *tgtport,
+				    uint64_t assoc_id, bool send_abts,
+				    spdk_nvmf_fc_del_assoc_cb del_assoc_cb,
+				    void *cb_data);
+
+void spdk_nvmf_fc_ls_init(struct spdk_nvmf_fc_port *fc_port);
+
+void spdk_nvmf_fc_ls_fini(struct spdk_nvmf_fc_port *fc_port);
+
+struct spdk_nvmf_fc_port *spdk_nvmf_fc_port_list_get(uint8_t port_hdl);
+
+int spdk_nvmf_fc_nport_set_state(struct spdk_nvmf_fc_nport *nport,
+				 enum spdk_nvmf_fc_object_state state);
+
+int spdk_nvmf_fc_assoc_set_state(struct spdk_nvmf_fc_association *assoc,
+				 enum spdk_nvmf_fc_object_state state);
+
+bool spdk_nvmf_fc_nport_add_rem_port(struct spdk_nvmf_fc_nport *nport,
+				     struct spdk_nvmf_fc_remote_port_info *rem_port);
+
+bool spdk_nvmf_fc_nport_remove_rem_port(struct spdk_nvmf_fc_nport *nport,
+					struct spdk_nvmf_fc_remote_port_info *rem_port);
+
+void spdk_nvmf_fc_init_poller_queues(struct spdk_nvmf_fc_hwqp *hwqp);
+
+void spdk_nvmf_fc_reinit_poller_queues(struct spdk_nvmf_fc_hwqp *hwqp,
+				       void *queues_curr);
+
+void spdk_nvmf_fc_init_poller(struct spdk_nvmf_fc_port *fc_port,
+			      struct spdk_nvmf_fc_hwqp *hwqp);
+
+void spdk_nvmf_fc_add_hwqp_to_poller(struct spdk_nvmf_fc_hwqp *hwqp, bool admin_q);
+
+void spdk_nvmf_fc_remove_hwqp_from_poller(struct spdk_nvmf_fc_hwqp *hwqp);
+
+bool spdk_nvmf_fc_port_is_offline(struct spdk_nvmf_fc_port *fc_port);
+
+int spdk_nvmf_fc_port_set_offline(struct spdk_nvmf_fc_port *fc_port);
+
+bool spdk_nvmf_fc_port_is_online(struct spdk_nvmf_fc_port *fc_port);
+
+int spdk_nvmf_fc_port_set_online(struct spdk_nvmf_fc_port *fc_port);
+
+int spdk_nvmf_fc_hwqp_port_set_online(struct spdk_nvmf_fc_hwqp *hwqp);
+
+int spdk_nvmf_fc_hwqp_port_set_offline(struct spdk_nvmf_fc_hwqp *hwqp);
+
+int spdk_nvmf_fc_rport_set_state(struct spdk_nvmf_fc_remote_port_info *rport,
+				 enum spdk_nvmf_fc_object_state state);
+
+void spdk_nvmf_fc_port_list_add(struct spdk_nvmf_fc_port *fc_port);
+
+struct spdk_nvmf_fc_nport *spdk_nvmf_fc_nport_get(uint8_t port_hdl, uint16_t nport_hdl);
+
+int spdk_nvmf_fc_port_add_nport(struct spdk_nvmf_fc_port *fc_port,
+				struct spdk_nvmf_fc_nport *nport);
+
+uint32_t spdk_nvmf_fc_nport_get_association_count(struct spdk_nvmf_fc_nport *nport);
+
+int spdk_nvmf_fc_port_remove_nport(struct spdk_nvmf_fc_port *fc_port,
+				   struct spdk_nvmf_fc_nport *nport);
+
+uint32_t spdk_nvmf_fc_get_prli_service_params(void);
+
+bool spdk_nvmf_fc_nport_is_rport_empty(struct spdk_nvmf_fc_nport *nport);
+
+void spdk_nvmf_fc_handle_abts_frame(struct spdk_nvmf_fc_nport *nport,
+				    uint16_t rpi, uint16_t oxid,
+				    uint16_t rxid);
+
+void spdk_nvmf_fc_dump_all_queues(struct spdk_nvmf_fc_port *fc_port,
+				  struct spdk_nvmf_fc_queue_dump_info *dump_info);
+
+void spdk_nvmf_fc_handle_ls_rqst(struct spdk_nvmf_fc_ls_rqst *ls_rqst);
+
+int spdk_nvmf_fc_xmt_ls_rsp(struct spdk_nvmf_fc_nport *tgtport,
+			    struct spdk_nvmf_fc_ls_rqst *ls_rqst);
+
+struct spdk_nvmf_fc_nport *spdk_nvmf_bcm_req_fc_nport_get(struct spdk_nvmf_request *req);
+
+struct spdk_nvmf_fc_association *spdk_nvmf_fc_get_ctrlr_assoc(struct spdk_nvmf_ctrlr *ctrlr);
+
+bool spdk_nvmf_fc_nport_is_association_empty(struct spdk_nvmf_fc_nport *nport);
+
+int spdk_nvmf_fc_xmt_srsr_req(struct spdk_nvmf_fc_hwqp *hwqp,
+			      struct spdk_nvmf_fc_send_srsr *srsr,
+			      spdk_nvmf_fc_caller_cb cb, void *cb_args);
+
+uint32_t spdk_nvmf_fc_get_num_nport_ctrlrs_in_subsystem(uint8_t port_hdl, uint16_t nport_hdl,
+		struct spdk_nvmf_subsystem *subsys);
+
+bool spdk_nvmf_fc_is_spdk_ctrlr_on_nport(uint8_t port_hdl, uint16_t nport_hdl,
+		struct spdk_nvmf_ctrlr *ctrlr);
+
+int spdk_nvmf_fc_get_ctrlr_init_traddr(char *traddr, struct spdk_nvmf_ctrlr *ctrlr);
+
+uint32_t spdk_nvmf_fc_get_hwqp_id(struct spdk_nvmf_request *req);
+
+void spdk_nvmf_fc_req_abort(struct spdk_nvmf_fc_request *fc_req,
+			    bool send_abts, spdk_nvmf_fc_caller_cb cb,
+			    void *cb_args);
+
+int spdk_nvmf_fc_add_port_listen(void *arg1, void *arg2);
+
+int spdk_nvmf_fc_remove_port_listen(void *arg1, void *arg2);
+
+void spdk_nvmf_fc_subsys_connect_cb(void *cb_ctx,
+				    struct spdk_nvmf_request *req);
+
+void spdk_nvmf_fc_subsys_disconnect_cb(void *cb_ctx,
+				       struct spdk_nvmf_qpair *qpair);
+
+uint32_t spdk_nvmf_fc_get_master_lcore(void);
+
+struct spdk_thread *spdk_nvmf_fc_get_master_thread(void);
+
+/*
+ * These functions are used by low level FC driver
+ */
+
+static inline struct spdk_nvmf_fc_conn *
+spdk_nvmf_fc_get_conn(struct spdk_nvmf_qpair *qpair)
+{
+	return (struct spdk_nvmf_fc_conn *)
+	       ((uintptr_t)qpair - offsetof(struct spdk_nvmf_fc_conn, qpair));
+}
+
+static inline uint16_t
+spdk_nvmf_fc_advance_conn_sqhead(struct spdk_nvmf_qpair *qpair)
+{
+	/* advance sq_head pointer - wrap if needed */
+	qpair->sq_head = (qpair->sq_head == qpair->sq_head_max) ?
+			 0 : (qpair->sq_head + 1);
+	return qpair->sq_head;
+}
+
+static inline bool
+spdk_nvmf_fc_use_send_frame(struct spdk_nvmf_request *req)
+{
+	/* For now use for only keepalives. */
+	if (req->qpair->qid == 0 &&
+	    (req->cmd->nvme_cmd.opc == SPDK_NVME_OPC_KEEP_ALIVE)) {
+		return true;
+	}
+	return false;
+}
+
+enum spdk_nvmf_fc_poller_api_ret spdk_nvmf_fc_poller_api_func(
+	struct spdk_nvmf_fc_hwqp *hwqp,
+	enum spdk_nvmf_fc_poller_api api,
+	void *api_args);
+
+int spdk_nvmf_fc_process_frame(struct spdk_nvmf_fc_hwqp *hwqp, uint32_t buff_idx,
+			       struct spdk_nvmf_fc_frame_hdr *frame,
+			       struct spdk_nvmf_fc_buffer_desc *buffer, uint32_t plen);
+
+void spdk_nvmf_fc_process_pending_req(struct spdk_nvmf_fc_hwqp *hwqp);
+
+void spdk_nvmf_fc_process_pending_ls_rqst(struct spdk_nvmf_fc_hwqp *hwqp);
+
+void spdk_nvmf_fc_req_set_state(struct spdk_nvmf_fc_request *fc_req,
+				enum spdk_nvmf_fc_request_state state);
+
+void spdk_nvmf_fc_free_req(struct spdk_nvmf_fc_request *fc_req);
+
+void spdk_nvmf_fc_req_abort_complete(void *arg1);
+
+bool spdk_nvmf_fc_send_ersp_required(struct spdk_nvmf_fc_request *fc_req,
+				     uint32_t rsp_cnt, uint32_t xfer_len);
+
+struct spdk_nvmf_fc_xri *spdk_nvmf_fc_get_xri(struct spdk_nvmf_fc_hwqp *hwqp);
+
+int spdk_nvmf_fc_put_xri(struct spdk_nvmf_fc_hwqp *hwqp,
+			 struct spdk_nvmf_fc_xri *xri);
+
+void spdk_nvmf_fc_release_xri(struct spdk_nvmf_fc_hwqp *hwqp,
+			      struct spdk_nvmf_fc_xri *xri, bool xb, bool abts);
+
+int spdk_nvmf_fc_handle_rsp(struct spdk_nvmf_fc_request *req);
+#endif
diff --git a/lib/nvmf/nvmf_internal.h b/lib/nvmf/nvmf_internal.h
index 2945e205a..4559cb462 100644
--- a/lib/nvmf/nvmf_internal.h
+++ b/lib/nvmf/nvmf_internal.h
@@ -43,7 +43,7 @@
 #include "spdk/queue.h"
 #include "spdk/util.h"
 
-#define SPDK_NVMF_DEFAULT_NUM_CTRLRS_PER_LCORE 1
+#define SPDK_NVMF_MAX_SGL_ENTRIES	16
 
 enum spdk_nvmf_subsystem_state {
 	SPDK_NVMF_SUBSYSTEM_INACTIVE = 0,
@@ -55,18 +55,30 @@ enum spdk_nvmf_subsystem_state {
 	SPDK_NVMF_SUBSYSTEM_DEACTIVATING,
 };
 
+enum spdk_nvmf_qpair_state {
+	SPDK_NVMF_QPAIR_INACTIVE = 0,
+	SPDK_NVMF_QPAIR_ACTIVATING,
+	SPDK_NVMF_QPAIR_ACTIVE,
+	SPDK_NVMF_QPAIR_DEACTIVATING,
+	SPDK_NVMF_QPAIR_ERROR,
+};
+
+typedef void (*spdk_nvmf_state_change_done)(void *cb_arg, int status);
+
 struct spdk_nvmf_tgt {
 	struct spdk_nvmf_tgt_opts		opts;
 
 	uint64_t				discovery_genctr;
 
-	/* Array of subsystem pointers of size max_sid indexed by sid */
+	/* Array of subsystem pointers of size max_subsystems indexed by sid */
 	struct spdk_nvmf_subsystem		**subsystems;
-	uint32_t				max_sid;
 
 	struct spdk_nvmf_discovery_log_page	*discovery_log_page;
 	size_t					discovery_log_page_size;
 	TAILQ_HEAD(, spdk_nvmf_transport)	transports;
+
+	spdk_nvmf_tgt_destroy_done_fn		*destroy_cb_fn;
+	void					*destroy_cb_arg;
 };
 
 struct spdk_nvmf_host {
@@ -104,6 +116,9 @@ struct spdk_nvmf_poll_group {
 	/* Array of poll groups indexed by subsystem id (sid) */
 	struct spdk_nvmf_subsystem_poll_group		*sgroups;
 	uint32_t					num_sgroups;
+
+	/* All of the queue pairs that belong to this poll group */
+	TAILQ_HEAD(, spdk_nvmf_qpair)			qpairs;
 };
 
 typedef enum _spdk_nvmf_request_exec_status {
@@ -134,6 +149,8 @@ struct spdk_nvmf_request {
 	void				*data;
 	union nvmf_h2c_msg		*cmd;
 	union nvmf_c2h_msg		*rsp;
+	struct iovec			iov[SPDK_NVMF_MAX_SGL_ENTRIES];
+	uint32_t			iovcnt;
 
 	TAILQ_ENTRY(spdk_nvmf_request)	link;
 };
@@ -146,6 +163,10 @@ struct spdk_nvmf_ns {
 };
 
 struct spdk_nvmf_qpair {
+	enum spdk_nvmf_qpair_state		state;
+	spdk_nvmf_state_change_done		state_cb;
+	void					*state_cb_arg;
+
 	struct spdk_nvmf_transport		*transport;
 	struct spdk_nvmf_ctrlr			*ctrlr;
 	struct spdk_nvmf_poll_group		*group;
@@ -154,6 +175,7 @@ struct spdk_nvmf_qpair {
 	uint16_t				sq_head;
 	uint16_t				sq_head_max;
 
+	TAILQ_HEAD(, spdk_nvmf_request)		outstanding;
 	TAILQ_ENTRY(spdk_nvmf_qpair)		link;
 };
 
@@ -186,9 +208,11 @@ struct spdk_nvmf_ctrlr {
 	struct spdk_nvmf_ctrlr_feat feat;
 
 	struct spdk_nvmf_qpair *admin_qpair;
-	TAILQ_HEAD(, spdk_nvmf_qpair) qpairs;
-	int num_qpairs;
-	int max_qpairs_allowed;
+
+	/* Mutex to protect the qpair mask */
+	pthread_mutex_t		mtx;
+	struct spdk_bit_array	*qpair_mask;
+
 	struct spdk_nvmf_request *aer_req;
 	union spdk_nvme_async_event_completion notice_event;
 	uint8_t hostid[16];
@@ -218,7 +242,6 @@ struct spdk_nvmf_subsystem {
 	uint32_t				max_nsid;
 	/* This is the maximum allowed nsid to a subsystem */
 	uint32_t				max_allowed_nsid;
-	uint32_t				num_allocated_nsid;
 
 	TAILQ_HEAD(, spdk_nvmf_ctrlr)		ctrlrs;
 
@@ -246,13 +269,11 @@ int spdk_nvmf_poll_group_resume_subsystem(struct spdk_nvmf_poll_group *group,
 		struct spdk_nvmf_subsystem *subsystem);
 void spdk_nvmf_request_exec(struct spdk_nvmf_request *req);
 int spdk_nvmf_request_complete(struct spdk_nvmf_request *req);
-int spdk_nvmf_request_abort(struct spdk_nvmf_request *req);
 
 void spdk_nvmf_get_discovery_log_page(struct spdk_nvmf_tgt *tgt,
 				      void *buffer, uint64_t offset,
 				      uint32_t length);
 
-struct spdk_nvmf_qpair *spdk_nvmf_ctrlr_get_qpair(struct spdk_nvmf_ctrlr *ctrlr, uint16_t qid);
 void spdk_nvmf_ctrlr_destruct(struct spdk_nvmf_ctrlr *ctrlr);
 int spdk_nvmf_ctrlr_process_fabrics_cmd(struct spdk_nvmf_request *req);
 int spdk_nvmf_ctrlr_process_admin_cmd(struct spdk_nvmf_request *req);
@@ -271,6 +292,8 @@ struct spdk_nvmf_ctrlr *spdk_nvmf_subsystem_get_ctrlr(struct spdk_nvmf_subsystem
 		uint16_t cntlid);
 int spdk_nvmf_ctrlr_async_event_ns_notice(struct spdk_nvmf_ctrlr *ctrlr);
 
+void spdk_nvmf_ctrlr_drain_aer_req(struct spdk_nvmf_ctrlr *ctrlr);
+
 static inline struct spdk_nvmf_ns *
 _spdk_nvmf_subsystem_get_ns(struct spdk_nvmf_subsystem *subsystem, uint32_t nsid)
 {
@@ -288,17 +311,4 @@ spdk_nvmf_qpair_is_admin_queue(struct spdk_nvmf_qpair *qpair)
 	return qpair->qid == 0;
 }
 
-#define OBJECT_NVMF_IO				0x30
-
-#define TRACE_GROUP_NVMF			0x3
-#define TRACE_NVMF_IO_START			SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x0)
-#define TRACE_RDMA_READ_START			SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x1)
-#define TRACE_RDMA_WRITE_START			SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x2)
-#define TRACE_RDMA_READ_COMPLETE		SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x3)
-#define TRACE_RDMA_WRITE_COMPLETE		SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x4)
-#define TRACE_NVMF_LIB_READ_START		SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x5)
-#define TRACE_NVMF_LIB_WRITE_START		SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x6)
-#define TRACE_NVMF_LIB_COMPLETE			SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x7)
-#define TRACE_NVMF_IO_COMPLETE			SPDK_TPOINT_ID(TRACE_GROUP_NVMF, 0x8)
-
 #endif /* __NVMF_INTERNAL_H__ */
diff --git a/lib/nvmf/rdma.c b/lib/nvmf/rdma.c
index 862c24cf1..cd45471b0 100644
--- a/lib/nvmf/rdma.c
+++ b/lib/nvmf/rdma.c
@@ -41,7 +41,7 @@
 #include "transport.h"
 
 #include "spdk/assert.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/nvmf.h"
 #include "spdk/nvmf_spec.h"
 #include "spdk/string.h"
@@ -55,6 +55,7 @@
  */
 #define NVMF_DEFAULT_TX_SGE		1
 #define NVMF_DEFAULT_RX_SGE		2
+#define NVMF_DEFAULT_DATA_SGE		16
 
 /* The RDMA completion queue size */
 #define NVMF_RDMA_CQ_SIZE	4096
@@ -77,9 +78,9 @@ enum spdk_nvmf_rdma_request_state {
 	RDMA_REQUEST_STATE_NEED_BUFFER,
 
 	/* The request is waiting on RDMA queue depth availability
-	 * to transfer data from the host to the controller.
+	 * to transfer data between the host and the controller.
 	 */
-	RDMA_REQUEST_STATE_TRANSFER_PENDING_HOST_TO_CONTROLLER,
+	RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING,
 
 	/* The request is currently transferring data from the host to the controller. */
 	RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER,
@@ -93,21 +94,77 @@ enum spdk_nvmf_rdma_request_state {
 	/* The request finished executing at the block device */
 	RDMA_REQUEST_STATE_EXECUTED,
 
-	/* The request is waiting on RDMA queue depth availability
-	 * to transfer data from the controller to the host.
-	 */
-	RDMA_REQUEST_STATE_TRANSFER_PENDING_CONTROLLER_TO_HOST,
-
 	/* The request is ready to send a completion */
 	RDMA_REQUEST_STATE_READY_TO_COMPLETE,
 
-	/* The request currently has a completion outstanding */
+	/* The request is currently transferring data from the controller to the host. */
+	RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST,
+
+	/* The request currently has an outstanding completion without an
+	 * associated data transfer.
+	 */
 	RDMA_REQUEST_STATE_COMPLETING,
 
 	/* The request completed and can be marked free. */
 	RDMA_REQUEST_STATE_COMPLETED,
+
+	/* Terminator */
+	RDMA_REQUEST_NUM_STATES,
 };
 
+#define OBJECT_NVMF_RDMA_IO				0x40
+
+#define									TRACE_GROUP_NVMF_RDMA 0x4
+#define TRACE_RDMA_REQUEST_STATE_NEW					SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x0)
+#define TRACE_RDMA_REQUEST_STATE_NEED_BUFFER				SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x1)
+#define TRACE_RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING			SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x2)
+#define TRACE_RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER	SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x3)
+#define TRACE_RDMA_REQUEST_STATE_READY_TO_EXECUTE			SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x4)
+#define TRACE_RDMA_REQUEST_STATE_EXECUTING				SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x5)
+#define TRACE_RDMA_REQUEST_STATE_EXECUTED				SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x6)
+#define TRACE_RDMA_REQUEST_STATE_READY_TO_COMPLETE			SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x7)
+#define TRACE_RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST	SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x8)
+#define TRACE_RDMA_REQUEST_STATE_COMPLETING				SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0x9)
+#define TRACE_RDMA_REQUEST_STATE_COMPLETED				SPDK_TPOINT_ID(TRACE_GROUP_NVMF_RDMA, 0xA)
+
+SPDK_TRACE_REGISTER_FN(nvmf_trace)
+{
+	spdk_trace_register_object(OBJECT_NVMF_RDMA_IO, 'r');
+	spdk_trace_register_description("RDMA_REQ_NEW", "",
+					TRACE_RDMA_REQUEST_STATE_NEW,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 1, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_NEED_BUFFER", "",
+					TRACE_RDMA_REQUEST_STATE_NEED_BUFFER,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_TX_PENDING_H_TO_C", "",
+					TRACE_RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_TX_H_TO_C", "",
+					TRACE_RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_RDY_TO_EXECUTE", "",
+					TRACE_RDMA_REQUEST_STATE_READY_TO_EXECUTE,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_EXECUTING", "",
+					TRACE_RDMA_REQUEST_STATE_EXECUTING,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_EXECUTED", "",
+					TRACE_RDMA_REQUEST_STATE_EXECUTED,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_RDY_TO_COMPLETE", "",
+					TRACE_RDMA_REQUEST_STATE_READY_TO_COMPLETE,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_COMPLETING_CONTROLLER_TO_HOST", "",
+					TRACE_RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_COMPLETING_INCAPSULE", "",
+					TRACE_RDMA_REQUEST_STATE_COMPLETING,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+	spdk_trace_register_description("RDMA_REQ_COMPLETED", "",
+					TRACE_RDMA_REQUEST_STATE_COMPLETED,
+					OWNER_NONE, OBJECT_NVMF_RDMA_IO, 0, 0, 0, "");
+}
+
 /* This structure holds commands as they are received off the wire.
  * It must be dynamically paired with a full request object
  * (spdk_nvmf_rdma_request) to service a request. It is separate
@@ -129,7 +186,7 @@ struct spdk_nvmf_rdma_recv {
 
 struct spdk_nvmf_rdma_request {
 	struct spdk_nvmf_request		req;
-	void					*data_from_pool;
+	bool					data_from_pool;
 
 	enum spdk_nvmf_rdma_request_state	state;
 
@@ -142,10 +199,12 @@ struct spdk_nvmf_rdma_request {
 
 	struct {
 		struct ibv_send_wr		wr;
-		struct ibv_sge			sgl[NVMF_DEFAULT_TX_SGE];
+		struct ibv_sge			sgl[SPDK_NVMF_MAX_SGL_ENTRIES];
+		void				*buffers[SPDK_NVMF_MAX_SGL_ENTRIES];
 	} data;
 
 	TAILQ_ENTRY(spdk_nvmf_rdma_request)	link;
+	TAILQ_ENTRY(spdk_nvmf_rdma_request)	state_link;
 };
 
 struct spdk_nvmf_rdma_qpair {
@@ -162,23 +221,14 @@ struct spdk_nvmf_rdma_qpair {
 	/* The maximum number of active RDMA READ and WRITE operations at one time */
 	uint16_t				max_rw_depth;
 
-	/* The current number of I/O outstanding on this connection. This number
-	 * includes all I/O from the time the capsule is first received until it is
-	 * completed.
-	 */
-	uint16_t				cur_queue_depth;
-
-	/* The number of RDMA READ and WRITE requests that are outstanding */
-	uint16_t				cur_rdma_rw_depth;
-
 	/* Receives that are waiting for a request object */
 	TAILQ_HEAD(, spdk_nvmf_rdma_recv)	incoming_queue;
 
-	/* Requests that are not in use */
-	TAILQ_HEAD(, spdk_nvmf_rdma_request)	free_queue;
+	/* Queues to track the requests in all states */
+	TAILQ_HEAD(, spdk_nvmf_rdma_request)	state_queue[RDMA_REQUEST_NUM_STATES];
 
-	/* Requests that are waiting to perform an RDMA READ or WRITE */
-	TAILQ_HEAD(, spdk_nvmf_rdma_request)	pending_rdma_rw_queue;
+	/* Number of requests in each state */
+	uint32_t				state_cntr[RDMA_REQUEST_NUM_STATES];
 
 	/* Array of size "max_queue_depth" containing RDMA requests. */
 	struct spdk_nvmf_rdma_request		*reqs;
@@ -205,11 +255,16 @@ struct spdk_nvmf_rdma_qpair {
 	struct ibv_mr				*bufs_mr;
 
 	TAILQ_ENTRY(spdk_nvmf_rdma_qpair)	link;
-	TAILQ_ENTRY(spdk_nvmf_rdma_qpair)	pending_link;
 
 	/* Mgmt channel */
 	struct spdk_io_channel			*mgmt_channel;
 	struct spdk_nvmf_rdma_mgmt_channel	*ch;
+
+	/* IBV queue pair attributes: they are used to manage
+	 * qp state and recover from errors.
+	 */
+	struct ibv_qp_init_attr			ibv_init_attr;
+	struct ibv_qp_attr			ibv_attr;
 };
 
 struct spdk_nvmf_rdma_poller {
@@ -259,8 +314,13 @@ struct spdk_nvmf_rdma_transport {
 
 	uint16_t			max_queue_depth;
 	uint32_t			max_io_size;
+	uint32_t			io_unit_size;
 	uint32_t			in_capsule_data_size;
 
+	/* fields used to poll RDMA/IB events */
+	nfds_t			npoll_fds;
+	struct pollfd		*poll_fds;
+
 	TAILQ_HEAD(, spdk_nvmf_rdma_device)	devices;
 	TAILQ_HEAD(, spdk_nvmf_rdma_port)	ports;
 };
@@ -270,6 +330,140 @@ struct spdk_nvmf_rdma_mgmt_channel {
 	TAILQ_HEAD(, spdk_nvmf_rdma_request)	pending_data_buf_queue;
 };
 
+/* API to IBV QueuePair */
+static const char *str_ibv_qp_state[] = {
+	"IBV_QPS_RESET",
+	"IBV_QPS_INIT",
+	"IBV_QPS_RTR",
+	"IBV_QPS_RTS",
+	"IBV_QPS_SQD",
+	"IBV_QPS_SQE",
+	"IBV_QPS_ERR"
+};
+
+static enum ibv_qp_state
+spdk_nvmf_rdma_get_ibv_state(struct spdk_nvmf_rdma_qpair *rqpair) {
+	return rqpair->ibv_attr.qp_state;
+}
+
+static int
+spdk_nvmf_rdma_update_ibv_qp(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	int rc;
+	/* All the attributes needed for recovery */
+	static int spdk_nvmf_ibv_attr_mask =
+		IBV_QP_STATE |
+		IBV_QP_PKEY_INDEX |
+		IBV_QP_PORT |
+		IBV_QP_ACCESS_FLAGS |
+		IBV_QP_AV |
+		IBV_QP_PATH_MTU |
+		IBV_QP_DEST_QPN |
+		IBV_QP_RQ_PSN |
+		IBV_QP_MAX_DEST_RD_ATOMIC |
+		IBV_QP_MIN_RNR_TIMER |
+		IBV_QP_SQ_PSN |
+		IBV_QP_TIMEOUT |
+		IBV_QP_RETRY_CNT |
+		IBV_QP_RNR_RETRY |
+		IBV_QP_MAX_QP_RD_ATOMIC;
+
+	rc = ibv_query_qp(rqpair->cm_id->qp, &rqpair->ibv_attr,
+			  spdk_nvmf_ibv_attr_mask, &rqpair->ibv_init_attr);
+	assert(!rc);
+	return rc;
+}
+
+static int
+spdk_nvmf_rdma_set_ibv_state(struct spdk_nvmf_rdma_qpair *rqpair,
+			     enum ibv_qp_state new_state)
+{
+	int rc;
+	enum ibv_qp_state state;
+	static int attr_mask_rc[] = {
+		[IBV_QPS_RESET] = IBV_QP_STATE,
+		[IBV_QPS_INIT] = (IBV_QP_STATE |
+				  IBV_QP_PKEY_INDEX |
+				  IBV_QP_PORT |
+				  IBV_QP_ACCESS_FLAGS),
+		[IBV_QPS_RTR] = (IBV_QP_STATE |
+				 IBV_QP_AV |
+				 IBV_QP_PATH_MTU |
+				 IBV_QP_DEST_QPN |
+				 IBV_QP_RQ_PSN |
+				 IBV_QP_MAX_DEST_RD_ATOMIC |
+				 IBV_QP_MIN_RNR_TIMER),
+		[IBV_QPS_RTS] = (IBV_QP_STATE |
+				 IBV_QP_SQ_PSN |
+				 IBV_QP_TIMEOUT |
+				 IBV_QP_RETRY_CNT |
+				 IBV_QP_RNR_RETRY |
+				 IBV_QP_MAX_QP_RD_ATOMIC),
+		[IBV_QPS_SQD] = IBV_QP_STATE,
+		[IBV_QPS_SQE] = IBV_QP_STATE,
+		[IBV_QPS_ERR] = IBV_QP_STATE,
+	};
+
+	switch (new_state) {
+	case IBV_QPS_RESET:
+	case IBV_QPS_INIT:
+	case IBV_QPS_RTR:
+	case IBV_QPS_RTS:
+	case IBV_QPS_SQD:
+	case IBV_QPS_SQE:
+	case IBV_QPS_ERR:
+		break;
+	default:
+		SPDK_ERRLOG("QP#%d: bad state requested: %u\n",
+			    rqpair->qpair.qid, new_state);
+		return -1;
+	}
+	rqpair->ibv_attr.cur_qp_state = rqpair->ibv_attr.qp_state;
+	rqpair->ibv_attr.qp_state = new_state;
+	rqpair->ibv_attr.ah_attr.port_num = rqpair->ibv_attr.port_num;
+
+	rc = ibv_modify_qp(rqpair->cm_id->qp, &rqpair->ibv_attr,
+			   attr_mask_rc[new_state]);
+
+	if (rc) {
+		SPDK_ERRLOG("QP#%d: failed to set state to: %s, %d (%s)\n",
+			    rqpair->qpair.qid, str_ibv_qp_state[new_state], errno, strerror(errno));
+		return rc;
+	}
+	rc = spdk_nvmf_rdma_update_ibv_qp(rqpair);
+
+	if (rc) {
+		SPDK_ERRLOG("QP#%d: failed to update attributes\n", rqpair->qpair.qid);
+		return rc;
+	}
+	state = spdk_nvmf_rdma_get_ibv_state(rqpair);
+
+	if (state != new_state) {
+		SPDK_ERRLOG("QP#%d: expected state: %s, actual state: %s\n",
+			    rqpair->qpair.qid, str_ibv_qp_state[new_state],
+			    str_ibv_qp_state[state]);
+		return -1;
+	}
+	SPDK_NOTICELOG("IBV QP#%u changed to: %s\n", rqpair->qpair.qid,
+		       str_ibv_qp_state[state]);
+	return 0;
+}
+
+static void spdk_nvmf_rdma_request_set_state(struct spdk_nvmf_rdma_request *rdma_req,
+		enum spdk_nvmf_rdma_request_state	state)
+{
+	struct spdk_nvmf_qpair		*qpair;
+	struct spdk_nvmf_rdma_qpair	*rqpair;
+
+	qpair = rdma_req->req.qpair;
+	rqpair = SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair);
+	TAILQ_REMOVE(&rqpair->state_queue[rdma_req->state], rdma_req, state_link);
+	rqpair->state_cntr[rdma_req->state]--;
+	rdma_req->state = state;
+	TAILQ_INSERT_TAIL(&rqpair->state_queue[rdma_req->state], rdma_req, state_link);
+	rqpair->state_cntr[rdma_req->state]++;
+}
+
 static int
 spdk_nvmf_rdma_mgmt_channel_create(void *io_device, void *ctx_buf)
 {
@@ -332,23 +526,24 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 	struct spdk_nvmf_rdma_transport *rtransport;
 	struct spdk_nvmf_rdma_qpair	*rqpair;
 	int				rc, i;
-	struct ibv_qp_init_attr		attr;
 	struct spdk_nvmf_rdma_recv	*rdma_recv;
 	struct spdk_nvmf_rdma_request	*rdma_req;
 
 	rqpair = SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair);
 	rtransport = SPDK_CONTAINEROF(qpair->transport, struct spdk_nvmf_rdma_transport, transport);
 
-	memset(&attr, 0, sizeof(struct ibv_qp_init_attr));
-	attr.qp_type		= IBV_QPT_RC;
-	attr.send_cq		= rqpair->poller->cq;
-	attr.recv_cq		= rqpair->poller->cq;
-	attr.cap.max_send_wr	= rqpair->max_queue_depth * 2; /* SEND, READ, and WRITE operations */
-	attr.cap.max_recv_wr	= rqpair->max_queue_depth; /* RECV operations */
-	attr.cap.max_send_sge	= NVMF_DEFAULT_TX_SGE;
-	attr.cap.max_recv_sge	= NVMF_DEFAULT_RX_SGE;
-
-	rc = rdma_create_qp(rqpair->cm_id, NULL, &attr);
+	memset(&rqpair->ibv_init_attr, 0, sizeof(struct ibv_qp_init_attr));
+	rqpair->ibv_init_attr.qp_context	= rqpair;
+	rqpair->ibv_init_attr.qp_type		= IBV_QPT_RC;
+	rqpair->ibv_init_attr.send_cq		= rqpair->poller->cq;
+	rqpair->ibv_init_attr.recv_cq		= rqpair->poller->cq;
+	rqpair->ibv_init_attr.cap.max_send_wr	= rqpair->max_queue_depth *
+			2; /* SEND, READ, and WRITE operations */
+	rqpair->ibv_init_attr.cap.max_recv_wr	= rqpair->max_queue_depth; /* RECV operations */
+	rqpair->ibv_init_attr.cap.max_send_sge	= SPDK_NVMF_MAX_SGL_ENTRIES;
+	rqpair->ibv_init_attr.cap.max_recv_sge	= NVMF_DEFAULT_RX_SGE;
+
+	rc = rdma_create_qp(rqpair->cm_id, NULL, &rqpair->ibv_init_attr);
 	if (rc) {
 		SPDK_ERRLOG("rdma_create_qp failed: errno %d: %s\n", errno, spdk_strerror(errno));
 		rdma_destroy_id(rqpair->cm_id);
@@ -365,10 +560,14 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 					0x1000, NULL);
 	rqpair->cpls = spdk_dma_zmalloc(rqpair->max_queue_depth * sizeof(*rqpair->cpls),
 					0x1000, NULL);
-	rqpair->bufs = spdk_dma_zmalloc(rqpair->max_queue_depth * rtransport->in_capsule_data_size,
-					0x1000, NULL);
+
+	if (rtransport->in_capsule_data_size) {
+		rqpair->bufs = spdk_dma_zmalloc(rqpair->max_queue_depth * rtransport->in_capsule_data_size,
+						0x1000, NULL);
+	}
+
 	if (!rqpair->reqs || !rqpair->recvs || !rqpair->cmds ||
-	    !rqpair->cpls || !rqpair->bufs) {
+	    !rqpair->cpls || (rtransport->in_capsule_data_size && !rqpair->bufs)) {
 		SPDK_ERRLOG("Unable to allocate sufficient memory for RDMA queue.\n");
 		spdk_nvmf_rdma_qpair_destroy(rqpair);
 		return -1;
@@ -380,11 +579,16 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 	rqpair->cpls_mr = ibv_reg_mr(rqpair->cm_id->pd, rqpair->cpls,
 				     rqpair->max_queue_depth * sizeof(*rqpair->cpls),
 				     0);
-	rqpair->bufs_mr = ibv_reg_mr(rqpair->cm_id->pd, rqpair->bufs,
-				     rqpair->max_queue_depth * rtransport->in_capsule_data_size,
-				     IBV_ACCESS_LOCAL_WRITE |
-				     IBV_ACCESS_REMOTE_WRITE);
-	if (!rqpair->cmds_mr || !rqpair->cpls_mr || !rqpair->bufs_mr) {
+
+	if (rtransport->in_capsule_data_size) {
+		rqpair->bufs_mr = ibv_reg_mr(rqpair->cm_id->pd, rqpair->bufs,
+					     rqpair->max_queue_depth * rtransport->in_capsule_data_size,
+					     IBV_ACCESS_LOCAL_WRITE |
+					     IBV_ACCESS_REMOTE_WRITE);
+	}
+
+	if (!rqpair->cmds_mr || !rqpair->cpls_mr || (rtransport->in_capsule_data_size &&
+			!rqpair->bufs_mr)) {
 		SPDK_ERRLOG("Unable to register required memory for RDMA queue.\n");
 		spdk_nvmf_rdma_qpair_destroy(rqpair);
 		return -1;
@@ -393,8 +597,16 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 		      rqpair->cmds, rqpair->max_queue_depth * sizeof(*rqpair->cmds), rqpair->cmds_mr->lkey);
 	SPDK_DEBUGLOG(SPDK_LOG_RDMA, "Completion Array: %p Length: %lx LKey: %x\n",
 		      rqpair->cpls, rqpair->max_queue_depth * sizeof(*rqpair->cpls), rqpair->cpls_mr->lkey);
-	SPDK_DEBUGLOG(SPDK_LOG_RDMA, "In Capsule Data Array: %p Length: %x LKey: %x\n",
-		      rqpair->bufs, rqpair->max_queue_depth * rtransport->in_capsule_data_size, rqpair->bufs_mr->lkey);
+	if (rqpair->bufs && rqpair->bufs_mr) {
+		SPDK_DEBUGLOG(SPDK_LOG_RDMA, "In Capsule Data Array: %p Length: %x LKey: %x\n",
+			      rqpair->bufs, rqpair->max_queue_depth * rtransport->in_capsule_data_size, rqpair->bufs_mr->lkey);
+	}
+
+	/* Initialise request state queues and counters of the queue pair */
+	for (i = RDMA_REQUEST_STATE_FREE; i < RDMA_REQUEST_NUM_STATES; i++) {
+		TAILQ_INIT(&rqpair->state_queue[i]);
+		rqpair->state_cntr[i] = 0;
+	}
 
 	for (i = 0; i < rqpair->max_queue_depth; i++) {
 		struct ibv_recv_wr *bad_wr = NULL;
@@ -403,19 +615,24 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 		rdma_recv->qpair = rqpair;
 
 		/* Set up memory to receive commands */
-		rdma_recv->buf = (void *)((uintptr_t)rqpair->bufs + (i * rtransport->in_capsule_data_size));
+		if (rqpair->bufs) {
+			rdma_recv->buf = (void *)((uintptr_t)rqpair->bufs + (i * rtransport->in_capsule_data_size));
+		}
 
 		rdma_recv->sgl[0].addr = (uintptr_t)&rqpair->cmds[i];
 		rdma_recv->sgl[0].length = sizeof(rqpair->cmds[i]);
 		rdma_recv->sgl[0].lkey = rqpair->cmds_mr->lkey;
+		rdma_recv->wr.num_sge = 1;
 
-		rdma_recv->sgl[1].addr = (uintptr_t)rdma_recv->buf;
-		rdma_recv->sgl[1].length = rtransport->in_capsule_data_size;
-		rdma_recv->sgl[1].lkey = rqpair->bufs_mr->lkey;
+		if (rdma_recv->buf && rqpair->bufs_mr) {
+			rdma_recv->sgl[1].addr = (uintptr_t)rdma_recv->buf;
+			rdma_recv->sgl[1].length = rtransport->in_capsule_data_size;
+			rdma_recv->sgl[1].lkey = rqpair->bufs_mr->lkey;
+			rdma_recv->wr.num_sge++;
+		}
 
 		rdma_recv->wr.wr_id = (uintptr_t)rdma_recv;
 		rdma_recv->wr.sg_list = rdma_recv->sgl;
-		rdma_recv->wr.num_sge = SPDK_COUNTOF(rdma_recv->sgl);
 
 		rc = ibv_post_recv(rqpair->cm_id->qp, &rdma_recv->wr, &bad_wr);
 		if (rc) {
@@ -452,8 +669,12 @@ spdk_nvmf_rdma_qpair_initialize(struct spdk_nvmf_qpair *qpair)
 		rdma_req->data.wr.sg_list = rdma_req->data.sgl;
 		rdma_req->data.wr.num_sge = SPDK_COUNTOF(rdma_req->data.sgl);
 
-		TAILQ_INSERT_TAIL(&rqpair->free_queue, rdma_req, link);
+		/* Initialize request state to FREE */
+		rdma_req->state = RDMA_REQUEST_STATE_FREE;
+		TAILQ_INSERT_TAIL(&rqpair->state_queue[rdma_req->state], rdma_req, state_link);
+		rqpair->state_cntr[rdma_req->state]++;
 	}
+	spdk_nvmf_rdma_update_ibv_qp(rqpair);
 
 	return 0;
 }
@@ -473,29 +694,20 @@ request_transfer_in(struct spdk_nvmf_request *req)
 
 	assert(req->xfer == SPDK_NVME_DATA_HOST_TO_CONTROLLER);
 
-	rqpair->cur_rdma_rw_depth++;
-
 	SPDK_DEBUGLOG(SPDK_LOG_RDMA, "RDMA READ POSTED. Request: %p Connection: %p\n", req, qpair);
-	spdk_trace_record(TRACE_RDMA_READ_START, 0, 0, (uintptr_t)req, 0);
 
 	rdma_req->data.wr.opcode = IBV_WR_RDMA_READ;
 	rdma_req->data.wr.next = NULL;
 	rc = ibv_post_send(rqpair->cm_id->qp, &rdma_req->data.wr, &bad_wr);
 	if (rc) {
 		SPDK_ERRLOG("Unable to transfer data from host to target\n");
-
-		/* Decrement r/w counter back since data transfer
-		 * has not started.
-		 */
-		rqpair->cur_rdma_rw_depth--;
 		return -1;
 	}
-
 	return 0;
 }
 
 static int
-request_transfer_out(struct spdk_nvmf_request *req)
+request_transfer_out(struct spdk_nvmf_request *req, int *data_posted)
 {
 	int				rc;
 	struct spdk_nvmf_rdma_request	*rdma_req;
@@ -505,6 +717,7 @@ request_transfer_out(struct spdk_nvmf_request *req)
 	struct ibv_recv_wr		*bad_recv_wr = NULL;
 	struct ibv_send_wr		*send_wr, *bad_send_wr = NULL;
 
+	*data_posted = 0;
 	qpair = req->qpair;
 	rsp = &req->rsp->nvme_cpl;
 	rdma_req = SPDK_CONTAINEROF(req, struct spdk_nvmf_rdma_request, req);
@@ -538,29 +751,20 @@ request_transfer_out(struct spdk_nvmf_request *req)
 	if (rsp->status.sc == SPDK_NVME_SC_SUCCESS &&
 	    req->xfer == SPDK_NVME_DATA_CONTROLLER_TO_HOST) {
 		SPDK_DEBUGLOG(SPDK_LOG_RDMA, "RDMA WRITE POSTED. Request: %p Connection: %p\n", req, qpair);
-		spdk_trace_record(TRACE_RDMA_WRITE_START, 0, 0, (uintptr_t)req, 0);
 
-		rqpair->cur_rdma_rw_depth++;
 		rdma_req->data.wr.opcode = IBV_WR_RDMA_WRITE;
 
 		rdma_req->data.wr.next = send_wr;
+		*data_posted = 1;
 		send_wr = &rdma_req->data.wr;
 	}
 
 	SPDK_DEBUGLOG(SPDK_LOG_RDMA, "RDMA SEND POSTED. Request: %p Connection: %p\n", req, qpair);
-	spdk_trace_record(TRACE_NVMF_IO_COMPLETE, 0, 0, (uintptr_t)req, 0);
 
 	/* Send the completion */
 	rc = ibv_post_send(rqpair->cm_id->qp, send_wr, &bad_send_wr);
 	if (rc) {
 		SPDK_ERRLOG("Unable to send response capsule\n");
-
-		if (rdma_req->data.wr.opcode == IBV_WR_RDMA_WRITE) {
-			/* Decrement r/w counter back since data transfer
-			 * has not started.
-			 */
-			rqpair->cur_rdma_rw_depth--;
-		}
 	}
 
 	return rc;
@@ -695,9 +899,6 @@ nvmf_rdma_connect(struct spdk_nvmf_transport *transport, struct rdma_cm_event *e
 	rqpair->cm_id = event->id;
 	rqpair->qpair.transport = transport;
 	TAILQ_INIT(&rqpair->incoming_queue);
-	TAILQ_INIT(&rqpair->free_queue);
-	TAILQ_INIT(&rqpair->pending_rdma_rw_queue);
-
 	event->id->context = &rqpair->qpair;
 
 	cb_fn(&rqpair->qpair);
@@ -705,32 +906,10 @@ nvmf_rdma_connect(struct spdk_nvmf_transport *transport, struct rdma_cm_event *e
 	return 0;
 }
 
-static void
-nvmf_rdma_handle_disconnect(void *ctx)
-{
-	struct spdk_nvmf_qpair		*qpair = ctx;
-	struct spdk_nvmf_ctrlr		*ctrlr;
-	struct spdk_nvmf_rdma_qpair	*rqpair;
-
-	rqpair = SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair);
-
-	ctrlr = qpair->ctrlr;
-	if (ctrlr == NULL) {
-		/* No ctrlr has been established yet, so destroy
-		 * the connection.
-		 */
-		spdk_nvmf_rdma_qpair_destroy(rqpair);
-		return;
-	}
-
-	spdk_nvmf_ctrlr_disconnect(qpair);
-}
-
 static int
 nvmf_rdma_disconnect(struct rdma_cm_event *evt)
 {
-	struct spdk_nvmf_qpair	*qpair;
-	struct spdk_io_channel	*ch;
+	struct spdk_nvmf_qpair		*qpair;
 
 	if (evt->id == NULL) {
 		SPDK_ERRLOG("disconnect request: missing cm_id\n");
@@ -745,8 +924,7 @@ nvmf_rdma_disconnect(struct rdma_cm_event *evt)
 	/* ack the disconnect event before rdma_destroy_id */
 	rdma_ack_cm_event(evt);
 
-	ch = spdk_io_channel_from_ctx(qpair->group);
-	spdk_thread_send_msg(spdk_io_channel_get_thread(ch), nvmf_rdma_handle_disconnect, qpair);
+	spdk_nvmf_qpair_disconnect(qpair, NULL, NULL);
 
 	return 0;
 }
@@ -795,7 +973,7 @@ spdk_nvmf_rdma_mem_notify(void *cb_ctx, struct spdk_mem_map *map,
 		}
 		break;
 	case SPDK_MEM_MAP_NOTIFY_UNREGISTER:
-		mr = (struct ibv_mr *)spdk_mem_map_translate(map, (uint64_t)vaddr);
+		mr = (struct ibv_mr *)spdk_mem_map_translate(map, (uint64_t)vaddr, size);
 		spdk_mem_map_clear_translation(map, (uint64_t)vaddr, size);
 		if (mr) {
 			ibv_dereg_mr(mr);
@@ -848,6 +1026,7 @@ spdk_nvmf_rdma_request_get_xfer(struct spdk_nvmf_rdma_request *rdma_req)
 	case SPDK_NVME_SGL_TYPE_BIT_BUCKET:
 	case SPDK_NVME_SGL_TYPE_SEGMENT:
 	case SPDK_NVME_SGL_TYPE_LAST_SEGMENT:
+	case SPDK_NVME_SGL_TYPE_TRANSPORT_DATA_BLOCK:
 		if (sgl->unkeyed.length == 0) {
 			xfer = SPDK_NVME_DATA_NONE;
 		}
@@ -862,6 +1041,55 @@ spdk_nvmf_rdma_request_get_xfer(struct spdk_nvmf_rdma_request *rdma_req)
 	return xfer;
 }
 
+static int
+spdk_nvmf_rdma_request_fill_iovs(struct spdk_nvmf_rdma_transport *rtransport,
+				 struct spdk_nvmf_rdma_device *device,
+				 struct spdk_nvmf_rdma_request *rdma_req)
+{
+	void		*buf = NULL;
+	uint32_t	length = rdma_req->req.length;
+	uint32_t	i = 0;
+
+	rdma_req->req.iovcnt = 0;
+	while (length) {
+		buf = spdk_mempool_get(rtransport->data_buf_pool);
+		if (!buf) {
+			goto nomem;
+		}
+
+		rdma_req->req.iov[i].iov_base = (void *)((uintptr_t)(buf + NVMF_DATA_BUFFER_MASK) &
+						~NVMF_DATA_BUFFER_MASK);
+		rdma_req->req.iov[i].iov_len  = spdk_min(length, rtransport->io_unit_size);
+		rdma_req->req.iovcnt++;
+		rdma_req->data.buffers[i] = buf;
+		rdma_req->data.wr.sg_list[i].addr = (uintptr_t)(rdma_req->req.iov[i].iov_base);
+		rdma_req->data.wr.sg_list[i].length = rdma_req->req.iov[i].iov_len;
+		rdma_req->data.wr.sg_list[i].lkey = ((struct ibv_mr *)spdk_mem_map_translate(device->map,
+						     (uint64_t)buf, rdma_req->req.iov[i].iov_len))->lkey;
+
+		length -= rdma_req->req.iov[i].iov_len;
+		i++;
+	}
+
+	rdma_req->data_from_pool = true;
+
+	return 0;
+
+nomem:
+	while (i) {
+		i--;
+		spdk_mempool_put(rtransport->data_buf_pool, rdma_req->req.iov[i].iov_base);
+		rdma_req->req.iov[i].iov_base = NULL;
+		rdma_req->req.iov[i].iov_len = 0;
+
+		rdma_req->data.wr.sg_list[i].addr = 0;
+		rdma_req->data.wr.sg_list[i].length = 0;
+		rdma_req->data.wr.sg_list[i].lkey = 0;
+	}
+	rdma_req->req.iovcnt = 0;
+	return -ENOMEM;
+}
+
 static int
 spdk_nvmf_rdma_request_parse_sgl(struct spdk_nvmf_rdma_transport *rtransport,
 				 struct spdk_nvmf_rdma_device *device,
@@ -885,26 +1113,25 @@ spdk_nvmf_rdma_request_parse_sgl(struct spdk_nvmf_rdma_transport *rtransport,
 			return -1;
 		}
 
+		/* fill request length and populate iovs */
 		rdma_req->req.length = sgl->keyed.length;
-		rdma_req->data_from_pool = spdk_mempool_get(rtransport->data_buf_pool);
-		if (!rdma_req->data_from_pool) {
+
+		if (spdk_nvmf_rdma_request_fill_iovs(rtransport, device, rdma_req) < 0) {
 			/* No available buffers. Queue this request up. */
 			SPDK_DEBUGLOG(SPDK_LOG_RDMA, "No available large data buffers. Queueing request %p\n", rdma_req);
 			return 0;
 		}
-		/* AIO backend requires block size aligned data buffers,
-		 * 4KiB aligned data buffer should work for most devices.
-		 */
-		rdma_req->req.data = (void *)((uintptr_t)(rdma_req->data_from_pool + NVMF_DATA_BUFFER_MASK)
-					      & ~NVMF_DATA_BUFFER_MASK);
-		rdma_req->data.sgl[0].addr = (uintptr_t)rdma_req->req.data;
-		rdma_req->data.sgl[0].length = sgl->keyed.length;
-		rdma_req->data.sgl[0].lkey = ((struct ibv_mr *)spdk_mem_map_translate(device->map,
-					      (uint64_t)rdma_req->req.data))->lkey;
+
+		/* backward compatible */
+		rdma_req->req.data = rdma_req->req.iov[0].iov_base;
+
+		/* rdma wr specifics */
+		rdma_req->data.wr.num_sge = rdma_req->req.iovcnt;
 		rdma_req->data.wr.wr.rdma.rkey = sgl->keyed.key;
 		rdma_req->data.wr.wr.rdma.remote_addr = sgl->address;
 
-		SPDK_DEBUGLOG(SPDK_LOG_RDMA, "Request %p took buffer from central pool\n", rdma_req);
+		SPDK_DEBUGLOG(SPDK_LOG_RDMA, "Request %p took %d buffer/s from central pool\n", rdma_req,
+			      rdma_req->req.iovcnt);
 
 		return 0;
 	} else if (sgl->generic.type == SPDK_NVME_SGL_TYPE_DATA_BLOCK &&
@@ -931,8 +1158,13 @@ spdk_nvmf_rdma_request_parse_sgl(struct spdk_nvmf_rdma_transport *rtransport,
 		}
 
 		rdma_req->req.data = rdma_req->recv->buf + offset;
-		rdma_req->data_from_pool = NULL;
+		rdma_req->data_from_pool = false;
 		rdma_req->req.length = sgl->unkeyed.length;
+
+		rdma_req->req.iov[0].iov_base = rdma_req->req.data;
+		rdma_req->req.iov[0].iov_len = rdma_req->req.length;
+		rdma_req->req.iovcnt = 1;
+
 		return 0;
 	}
 
@@ -942,6 +1174,20 @@ spdk_nvmf_rdma_request_parse_sgl(struct spdk_nvmf_rdma_transport *rtransport,
 	return -1;
 }
 
+static int
+spdk_nvmf_rdma_cur_rw_depth(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	return rqpair->state_cntr[RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER] +
+	       rqpair->state_cntr[RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST];
+}
+
+static int
+spdk_nvmf_rdma_cur_queue_depth(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	return rqpair->max_queue_depth -
+	       rqpair->state_cntr[RDMA_REQUEST_STATE_FREE];
+}
+
 static bool
 spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 			       struct spdk_nvmf_rdma_request *rdma_req)
@@ -953,6 +1199,8 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 	struct spdk_nvmf_rdma_recv	*rdma_recv;
 	enum spdk_nvmf_rdma_request_state prev_state;
 	bool				progress = false;
+	int				data_posted;
+	int				cur_rdma_rw_depth;
 
 	rqpair = SPDK_CONTAINEROF(rdma_req->req.qpair, struct spdk_nvmf_rdma_qpair, qpair);
 	device = rqpair->port->device;
@@ -971,7 +1219,7 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 			 * to escape this state. */
 			break;
 		case RDMA_REQUEST_STATE_NEW:
-			rqpair->cur_queue_depth++;
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_NEW, 0, 0, (uintptr_t)rdma_req, 0);
 			rdma_recv = rdma_req->recv;
 
 			/* The first element of the SGL is the NVMe command */
@@ -979,21 +1227,27 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 			memset(rdma_req->req.rsp, 0, sizeof(*rdma_req->req.rsp));
 
 			TAILQ_REMOVE(&rqpair->incoming_queue, rdma_recv, link);
-			TAILQ_REMOVE(&rqpair->free_queue, rdma_req, link);
 
+			if (rqpair->qpair.state == SPDK_NVMF_QPAIR_ERROR ||
+			    rqpair->qpair.state == SPDK_NVMF_QPAIR_DEACTIVATING) {
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_COMPLETED);
+				break;
+			}
 			/* The next state transition depends on the data transfer needs of this request. */
 			rdma_req->req.xfer = spdk_nvmf_rdma_request_get_xfer(rdma_req);
 
 			/* If no data to transfer, ready to execute. */
 			if (rdma_req->req.xfer == SPDK_NVME_DATA_NONE) {
-				rdma_req->state = RDMA_REQUEST_STATE_READY_TO_EXECUTE;
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_READY_TO_EXECUTE);
 				break;
 			}
 
-			rdma_req->state = RDMA_REQUEST_STATE_NEED_BUFFER;
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_NEED_BUFFER);
 			TAILQ_INSERT_TAIL(&rqpair->ch->pending_data_buf_queue, rdma_req, link);
 			break;
 		case RDMA_REQUEST_STATE_NEED_BUFFER:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_NEED_BUFFER, 0, 0, (uintptr_t)rdma_req, 0);
+
 			assert(rdma_req->req.xfer != SPDK_NVME_DATA_NONE);
 
 			if (rdma_req != TAILQ_FIRST(&rqpair->ch->pending_data_buf_queue)) {
@@ -1006,7 +1260,7 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 			if (rc < 0) {
 				TAILQ_REMOVE(&rqpair->ch->pending_data_buf_queue, rdma_req, link);
 				rsp->status.sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
-				rdma_req->state = RDMA_REQUEST_STATE_READY_TO_COMPLETE;
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_READY_TO_COMPLETE);
 				break;
 			}
 
@@ -1020,84 +1274,115 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 			/* If data is transferring from host to controller and the data didn't
 			 * arrive using in capsule data, we need to do a transfer from the host.
 			 */
-			if (rdma_req->req.xfer == SPDK_NVME_DATA_HOST_TO_CONTROLLER && rdma_req->data_from_pool != NULL) {
-				rdma_req->state = RDMA_REQUEST_STATE_TRANSFER_PENDING_HOST_TO_CONTROLLER;
-				TAILQ_INSERT_TAIL(&rqpair->pending_rdma_rw_queue, rdma_req, link);
+			if (rdma_req->req.xfer == SPDK_NVME_DATA_HOST_TO_CONTROLLER && rdma_req->data_from_pool) {
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING);
 				break;
 			}
 
-			rdma_req->state = RDMA_REQUEST_STATE_READY_TO_EXECUTE;
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_READY_TO_EXECUTE);
 			break;
-		case RDMA_REQUEST_STATE_TRANSFER_PENDING_HOST_TO_CONTROLLER:
-			if (rdma_req != TAILQ_FIRST(&rqpair->pending_rdma_rw_queue)) {
+		case RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING, 0, 0,
+					  (uintptr_t)rdma_req, 0);
+
+			if (rdma_req != TAILQ_FIRST(&rqpair->state_queue[RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING])) {
 				/* This request needs to wait in line to perform RDMA */
 				break;
 			}
+			cur_rdma_rw_depth = spdk_nvmf_rdma_cur_rw_depth(rqpair);
+
+			if (cur_rdma_rw_depth >= rqpair->max_rw_depth) {
+				/* R/W queue is full, need to wait */
+				break;
+			}
 
-			if (rqpair->cur_rdma_rw_depth < rqpair->max_rw_depth) {
-				TAILQ_REMOVE(&rqpair->pending_rdma_rw_queue, rdma_req, link);
-				rdma_req->state = RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER;
+			if (rdma_req->req.xfer == SPDK_NVME_DATA_HOST_TO_CONTROLLER) {
 				rc = request_transfer_in(&rdma_req->req);
-				if (rc) {
+				if (!rc) {
+					spdk_nvmf_rdma_request_set_state(rdma_req,
+									 RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER);
+				} else {
 					rsp->status.sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
-					rdma_req->state = RDMA_REQUEST_STATE_READY_TO_COMPLETE;
+					spdk_nvmf_rdma_request_set_state(rdma_req,
+									 RDMA_REQUEST_STATE_READY_TO_COMPLETE);
 				}
+			} else if (rdma_req->req.xfer == SPDK_NVME_DATA_CONTROLLER_TO_HOST) {
+				/* The data transfer will be kicked off from
+				 * RDMA_REQUEST_STATE_READY_TO_COMPLETE state.
+				 */
+				spdk_nvmf_rdma_request_set_state(rdma_req,
+								 RDMA_REQUEST_STATE_READY_TO_COMPLETE);
+			} else {
+				SPDK_ERRLOG("Cannot perform data transfer, unknown state: %u\n",
+					    rdma_req->req.xfer);
+				assert(0);
 			}
 			break;
 		case RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER, 0, 0,
+					  (uintptr_t)rdma_req, 0);
 			/* Some external code must kick a request into RDMA_REQUEST_STATE_READY_TO_EXECUTE
 			 * to escape this state. */
 			break;
 		case RDMA_REQUEST_STATE_READY_TO_EXECUTE:
-			rdma_req->state = RDMA_REQUEST_STATE_EXECUTING;
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_READY_TO_EXECUTE, 0, 0, (uintptr_t)rdma_req, 0);
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_EXECUTING);
 			spdk_nvmf_request_exec(&rdma_req->req);
 			break;
 		case RDMA_REQUEST_STATE_EXECUTING:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_EXECUTING, 0, 0, (uintptr_t)rdma_req, 0);
 			/* Some external code must kick a request into RDMA_REQUEST_STATE_EXECUTED
 			 * to escape this state. */
 			break;
 		case RDMA_REQUEST_STATE_EXECUTED:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_EXECUTED, 0, 0, (uintptr_t)rdma_req, 0);
 			if (rdma_req->req.xfer == SPDK_NVME_DATA_CONTROLLER_TO_HOST) {
-				rdma_req->state = RDMA_REQUEST_STATE_TRANSFER_PENDING_CONTROLLER_TO_HOST;
-				TAILQ_INSERT_TAIL(&rqpair->pending_rdma_rw_queue, rdma_req, link);
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING);
 			} else {
-				rdma_req->state = RDMA_REQUEST_STATE_READY_TO_COMPLETE;
-			}
-			break;
-		case RDMA_REQUEST_STATE_TRANSFER_PENDING_CONTROLLER_TO_HOST:
-			if (rdma_req != TAILQ_FIRST(&rqpair->pending_rdma_rw_queue)) {
-				/* This request needs to wait in line to perform RDMA */
-				break;
-			}
-
-			if (rqpair->cur_rdma_rw_depth < rqpair->max_rw_depth) {
-				rdma_req->state = RDMA_REQUEST_STATE_READY_TO_COMPLETE;
-				TAILQ_REMOVE(&rqpair->pending_rdma_rw_queue, rdma_req, link);
+				spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_READY_TO_COMPLETE);
 			}
 			break;
 		case RDMA_REQUEST_STATE_READY_TO_COMPLETE:
-			rdma_req->state = RDMA_REQUEST_STATE_COMPLETING;
-
-			rc = request_transfer_out(&rdma_req->req);
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_READY_TO_COMPLETE, 0, 0, (uintptr_t)rdma_req, 0);
+			rc = request_transfer_out(&rdma_req->req, &data_posted);
 			assert(rc == 0); /* No good way to handle this currently */
+			spdk_nvmf_rdma_request_set_state(rdma_req,
+							 data_posted ?
+							 RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST :
+							 RDMA_REQUEST_STATE_COMPLETING);
+			break;
+		case RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST, 0, 0,
+					  (uintptr_t)rdma_req,
+					  0);
+			/* Some external code must kick a request into RDMA_REQUEST_STATE_COMPLETED
+			 * to escape this state. */
 			break;
 		case RDMA_REQUEST_STATE_COMPLETING:
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_COMPLETING, 0, 0, (uintptr_t)rdma_req, 0);
 			/* Some external code must kick a request into RDMA_REQUEST_STATE_COMPLETED
 			 * to escape this state. */
 			break;
 		case RDMA_REQUEST_STATE_COMPLETED:
-			assert(rqpair->cur_queue_depth > 0);
-			rqpair->cur_queue_depth--;
+			spdk_trace_record(TRACE_RDMA_REQUEST_STATE_COMPLETED, 0, 0, (uintptr_t)rdma_req, 0);
 
 			if (rdma_req->data_from_pool) {
-				/* Put the buffer back in the pool */
-				spdk_mempool_put(rtransport->data_buf_pool, rdma_req->data_from_pool);
-				rdma_req->data_from_pool = NULL;
+				/* Put the buffer/s back in the pool */
+				for (uint32_t i = 0; i < rdma_req->req.iovcnt; i++) {
+					spdk_mempool_put(rtransport->data_buf_pool, rdma_req->data.buffers[i]);
+					rdma_req->req.iov[i].iov_base = NULL;
+					rdma_req->data.buffers[i] = NULL;
+				}
+				rdma_req->data_from_pool = false;
 			}
 			rdma_req->req.length = 0;
+			rdma_req->req.iovcnt = 0;
 			rdma_req->req.data = NULL;
-			rdma_req->state = RDMA_REQUEST_STATE_FREE;
-			TAILQ_INSERT_TAIL(&rqpair->free_queue, rdma_req, link);
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_FREE);
+			break;
+		case RDMA_REQUEST_NUM_STATES:
+		default:
+			assert(0);
 			break;
 		}
 
@@ -1111,6 +1396,8 @@ spdk_nvmf_rdma_request_process(struct spdk_nvmf_rdma_transport *rtransport,
 
 /* Public API callbacks begin here */
 
+static int spdk_nvmf_rdma_destroy(struct spdk_nvmf_transport *transport);
+
 static struct spdk_nvmf_transport *
 spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 {
@@ -1120,13 +1407,23 @@ spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 	struct ibv_context		**contexts;
 	uint32_t			i;
 	int				flag;
+	uint32_t			sge_count;
 
 	rtransport = calloc(1, sizeof(*rtransport));
 	if (!rtransport) {
 		return NULL;
 	}
 
-	pthread_mutex_init(&rtransport->lock, NULL);
+	if (pthread_mutex_init(&rtransport->lock, NULL)) {
+		SPDK_ERRLOG("pthread_mutex_init() failed\n");
+		free(rtransport);
+		return NULL;
+	}
+
+	spdk_io_device_register(rtransport, spdk_nvmf_rdma_mgmt_channel_create,
+				spdk_nvmf_rdma_mgmt_channel_destroy,
+				sizeof(struct spdk_nvmf_rdma_mgmt_channel));
+
 	TAILQ_INIT(&rtransport->devices);
 	TAILQ_INIT(&rtransport->ports);
 
@@ -1137,12 +1434,25 @@ spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 
 	rtransport->max_queue_depth = tgt->opts.max_queue_depth;
 	rtransport->max_io_size = tgt->opts.max_io_size;
+	rtransport->io_unit_size = tgt->opts.io_unit_size;
 	rtransport->in_capsule_data_size = tgt->opts.in_capsule_data_size;
 
+	/* I/O unit size cannot be larger than max I/O size */
+	if (rtransport->io_unit_size > rtransport->max_io_size) {
+		rtransport->io_unit_size = rtransport->max_io_size;
+	}
+
+	sge_count = rtransport->max_io_size / rtransport->io_unit_size;
+	if (sge_count > SPDK_NVMF_MAX_SGL_ENTRIES) {
+		SPDK_ERRLOG("Unsupported IO Unit size specified, %d bytes\n", rtransport->io_unit_size);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
+		return NULL;
+	}
+
 	rtransport->event_channel = rdma_create_event_channel();
 	if (rtransport->event_channel == NULL) {
 		SPDK_ERRLOG("rdma_create_event_channel() failed, %s\n", spdk_strerror(errno));
-		free(rtransport);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
 		return NULL;
 	}
 
@@ -1150,26 +1460,28 @@ spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 	if (fcntl(rtransport->event_channel->fd, F_SETFL, flag | O_NONBLOCK) < 0) {
 		SPDK_ERRLOG("fcntl can't set nonblocking mode for socket, fd: %d (%s)\n",
 			    rtransport->event_channel->fd, spdk_strerror(errno));
-		free(rtransport);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
 		return NULL;
 	}
 
 	rtransport->data_buf_pool = spdk_mempool_create("spdk_nvmf_rdma",
 				    rtransport->max_queue_depth * 4, /* The 4 is arbitrarily chosen. Needs to be configurable. */
-				    rtransport->max_io_size + NVMF_DATA_BUFFER_ALIGNMENT,
+				    rtransport->io_unit_size + NVMF_DATA_BUFFER_ALIGNMENT,
 				    SPDK_MEMPOOL_DEFAULT_CACHE_SIZE,
 				    SPDK_ENV_SOCKET_ID_ANY);
 	if (!rtransport->data_buf_pool) {
 		SPDK_ERRLOG("Unable to allocate buffer pool for poll group\n");
-		free(rtransport);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
 		return NULL;
 	}
 
-	spdk_io_device_register(rtransport, spdk_nvmf_rdma_mgmt_channel_create,
-				spdk_nvmf_rdma_mgmt_channel_destroy,
-				sizeof(struct spdk_nvmf_rdma_mgmt_channel));
-
 	contexts = rdma_get_devices(NULL);
+	if (contexts == NULL) {
+		SPDK_ERRLOG("rdma_get_devices() failed: %s (%d)\n", spdk_strerror(errno), errno);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
+		return NULL;
+	}
+
 	i = 0;
 	rc = 0;
 	while (contexts[i] != NULL) {
@@ -1187,6 +1499,14 @@ spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 			break;
 
 		}
+		/* set up device context async ev fd as NON_BLOCKING */
+		flag = fcntl(device->context->async_fd, F_GETFL);
+		rc = fcntl(device->context->async_fd, F_SETFL, flag | O_NONBLOCK);
+		if (rc < 0) {
+			SPDK_ERRLOG("Failed to set context async fd to NONBLOCK.\n");
+			free(device);
+			break;
+		}
 
 		device->pd = NULL;
 		device->map = NULL;
@@ -1194,20 +1514,32 @@ spdk_nvmf_rdma_create(struct spdk_nvmf_tgt *tgt)
 		TAILQ_INSERT_TAIL(&rtransport->devices, device, link);
 		i++;
 	}
+	rdma_free_devices(contexts);
 
 	if (rc < 0) {
-		TAILQ_FOREACH_SAFE(device, &rtransport->devices, link, tmp) {
-			TAILQ_REMOVE(&rtransport->devices, device, link);
-			free(device);
-		}
-		spdk_mempool_free(rtransport->data_buf_pool);
-		rdma_destroy_event_channel(rtransport->event_channel);
-		free(rtransport);
-		rdma_free_devices(contexts);
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
 		return NULL;
 	}
 
-	rdma_free_devices(contexts);
+	/* Set up poll descriptor array to monitor events from RDMA and IB
+	 * in a single poll syscall
+	 */
+	rtransport->npoll_fds = i + 1;
+	i = 0;
+	rtransport->poll_fds = calloc(rtransport->npoll_fds, sizeof(struct pollfd));
+	if (rtransport->poll_fds == NULL) {
+		SPDK_ERRLOG("poll_fds allocation failed\n");
+		spdk_nvmf_rdma_destroy(&rtransport->transport);
+		return NULL;
+	}
+
+	rtransport->poll_fds[i].fd = rtransport->event_channel->fd;
+	rtransport->poll_fds[i++].events = POLLIN;
+
+	TAILQ_FOREACH_SAFE(device, &rtransport->devices, link, tmp) {
+		rtransport->poll_fds[i].fd = device->context->async_fd;
+		rtransport->poll_fds[i++].events = POLLIN;
+	}
 
 	return &rtransport->transport;
 }
@@ -1227,6 +1559,10 @@ spdk_nvmf_rdma_destroy(struct spdk_nvmf_transport *transport)
 		free(port);
 	}
 
+	if (rtransport->poll_fds != NULL) {
+		free(rtransport->poll_fds);
+	}
+
 	if (rtransport->event_channel != NULL) {
 		rdma_destroy_event_channel(rtransport->event_channel);
 	}
@@ -1247,6 +1583,7 @@ spdk_nvmf_rdma_destroy(struct spdk_nvmf_transport *transport)
 
 	spdk_mempool_free(rtransport->data_buf_pool);
 	spdk_io_device_unregister(rtransport, NULL);
+	pthread_mutex_destroy(&rtransport->lock);
 	free(rtransport);
 
 	return 0;
@@ -1337,6 +1674,14 @@ spdk_nvmf_rdma_listen(struct spdk_nvmf_transport *transport,
 		return rc;
 	}
 
+	if (!port->id->verbs) {
+		SPDK_ERRLOG("ibv_context is null\n");
+		rdma_destroy_id(port->id);
+		free(port);
+		pthread_mutex_unlock(&rtransport->lock);
+		return -1;
+	}
+
 	rc = rdma_listen(port->id, 10); /* 10 = backlog */
 	if (rc < 0) {
 		SPDK_ERRLOG("rdma_listen() failed\n");
@@ -1420,7 +1765,7 @@ spdk_nvmf_rdma_stop_listen(struct spdk_nvmf_transport *transport,
 }
 
 static void
-spdk_nvmf_rdma_accept(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
+spdk_nvmf_process_cm_event(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
 {
 	struct spdk_nvmf_rdma_transport *rtransport;
 	struct rdma_cm_event		*event;
@@ -1438,6 +1783,12 @@ spdk_nvmf_rdma_accept(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
 			SPDK_DEBUGLOG(SPDK_LOG_RDMA, "Acceptor Event: %s\n", CM_EVENT_STR[event->event]);
 
 			switch (event->event) {
+			case RDMA_CM_EVENT_ADDR_RESOLVED:
+			case RDMA_CM_EVENT_ADDR_ERROR:
+			case RDMA_CM_EVENT_ROUTE_RESOLVED:
+			case RDMA_CM_EVENT_ROUTE_ERROR:
+				/* No action required. The target never attempts to resolve routes. */
+				break;
 			case RDMA_CM_EVENT_CONNECT_REQUEST:
 				rc = nvmf_rdma_connect(transport, event, cb_fn);
 				if (rc < 0) {
@@ -1445,18 +1796,37 @@ spdk_nvmf_rdma_accept(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
 					break;
 				}
 				break;
+			case RDMA_CM_EVENT_CONNECT_RESPONSE:
+				/* The target never initiates a new connection. So this will not occur. */
+				break;
+			case RDMA_CM_EVENT_CONNECT_ERROR:
+				/* Can this happen? The docs say it can, but not sure what causes it. */
+				break;
+			case RDMA_CM_EVENT_UNREACHABLE:
+			case RDMA_CM_EVENT_REJECTED:
+				/* These only occur on the client side. */
+				break;
 			case RDMA_CM_EVENT_ESTABLISHED:
+				/* TODO: Should we be waiting for this event anywhere? */
 				break;
-			case RDMA_CM_EVENT_ADDR_CHANGE:
 			case RDMA_CM_EVENT_DISCONNECTED:
 			case RDMA_CM_EVENT_DEVICE_REMOVAL:
-			case RDMA_CM_EVENT_TIMEWAIT_EXIT:
 				rc = nvmf_rdma_disconnect(event);
 				if (rc < 0) {
 					SPDK_ERRLOG("Unable to process disconnect event. rc: %d\n", rc);
 					break;
 				}
 				continue;
+			case RDMA_CM_EVENT_MULTICAST_JOIN:
+			case RDMA_CM_EVENT_MULTICAST_ERROR:
+				/* Multicast is not used */
+				break;
+			case RDMA_CM_EVENT_ADDR_CHANGE:
+				/* Not utilizing this event */
+				break;
+			case RDMA_CM_EVENT_TIMEWAIT_EXIT:
+				/* For now, do nothing. The target never re-uses queue pairs. */
+				break;
 			default:
 				SPDK_ERRLOG("Unexpected Acceptor Event [%d]\n", event->event);
 				break;
@@ -1472,6 +1842,349 @@ spdk_nvmf_rdma_accept(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
 	}
 }
 
+static bool
+spdk_nvmf_rdma_qpair_is_idle(struct spdk_nvmf_qpair *qpair)
+{
+	int cur_queue_depth, cur_rdma_rw_depth;
+	struct spdk_nvmf_rdma_qpair *rqpair;
+
+	rqpair = SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair);
+	cur_queue_depth = spdk_nvmf_rdma_cur_queue_depth(rqpair);
+	cur_rdma_rw_depth = spdk_nvmf_rdma_cur_rw_depth(rqpair);
+
+	if (cur_queue_depth == 0 && cur_rdma_rw_depth == 0) {
+		return true;
+	}
+	return false;
+}
+
+static void
+spdk_nvmf_rdma_qpair_process_pending(struct spdk_nvmf_rdma_transport *rtransport,
+				     struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	struct spdk_nvmf_rdma_recv	*rdma_recv, *recv_tmp;
+	struct spdk_nvmf_rdma_request	*rdma_req, *req_tmp;
+
+	/* We process I/O in the data transfer pending queue at the highest priority. */
+	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->state_queue[RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING],
+			   state_link, req_tmp) {
+		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
+			break;
+		}
+	}
+
+	/* The second highest priority is I/O waiting on memory buffers. */
+	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->ch->pending_data_buf_queue, link,
+			   req_tmp) {
+		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
+			break;
+		}
+	}
+
+	/* Do not process newly received commands if qp is in ERROR state,
+	 * wait till the recovery is complete.
+	 */
+	if (rqpair->qpair.state == SPDK_NVMF_QPAIR_ERROR) {
+		return;
+	}
+
+	/* The lowest priority is processing newly received commands */
+	TAILQ_FOREACH_SAFE(rdma_recv, &rqpair->incoming_queue, link, recv_tmp) {
+		if (TAILQ_EMPTY(&rqpair->state_queue[RDMA_REQUEST_STATE_FREE])) {
+			break;
+		}
+
+		rdma_req = TAILQ_FIRST(&rqpair->state_queue[RDMA_REQUEST_STATE_FREE]);
+		rdma_req->recv = rdma_recv;
+		spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_NEW);
+		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
+			break;
+		}
+	}
+}
+
+/* The recovery completion event handler to be executed in the rqpair
+ * poll group thread. It kicks off processing of the requests that are
+ * waiting for the rqpair is back online.
+ */
+static void
+_spdk_nvmf_rdma_qpair_process_pending(void *arg)
+{
+	struct spdk_nvmf_rdma_qpair *rqpair;
+	struct spdk_nvmf_rdma_transport *rtransport;
+
+	rqpair = arg;
+	rtransport = SPDK_CONTAINEROF(rqpair->qpair.transport,
+				      struct spdk_nvmf_rdma_transport, transport);
+	spdk_nvmf_rdma_qpair_process_pending(rtransport, rqpair);
+}
+
+static int
+spdk_nvmf_rdma_recover(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	int recovered;
+	enum ibv_qp_state state, next_state;
+
+	state = spdk_nvmf_rdma_get_ibv_state(rqpair);
+	next_state = state;
+
+	SPDK_NOTICELOG("IBV QP#%u is in state: %s\n",
+		       rqpair->qpair.qid,
+		       str_ibv_qp_state[state]);
+
+	if (!(state == IBV_QPS_ERR || state == IBV_QPS_RESET)) {
+		SPDK_ERRLOG("Can't recover IBV qp#%u from the state: %s\n",
+			    rqpair->qpair.qid,
+			    str_ibv_qp_state[state]);
+		return -1;
+	}
+
+	rqpair->qpair.state = SPDK_NVMF_QPAIR_INACTIVE;
+	recovered = 0;
+
+	while (!recovered) {
+		state = spdk_nvmf_rdma_get_ibv_state(rqpair);
+		switch (state) {
+		case IBV_QPS_ERR:
+			next_state = IBV_QPS_RESET;
+			break;
+		case IBV_QPS_RESET:
+			next_state = IBV_QPS_INIT;
+			break;
+		case IBV_QPS_INIT:
+			next_state = IBV_QPS_RTR;
+			break;
+		case IBV_QPS_RTR:
+			next_state = IBV_QPS_RTS;
+			break;
+		case IBV_QPS_RTS:
+			recovered = 1;
+			break;
+		default:
+			SPDK_ERRLOG("IBV qp#%u unexpected state for recovery: %u\n",
+				    rqpair->qpair.qid, state);
+			goto error;
+		}
+		/* Do not transition into same state */
+		if (next_state == state) {
+			break;
+		}
+
+		if (spdk_nvmf_rdma_set_ibv_state(rqpair, next_state)) {
+			goto error;
+		}
+	}
+	rqpair->qpair.state = SPDK_NVMF_QPAIR_ACTIVE;
+	spdk_thread_send_msg(rqpair->qpair.group->thread, _spdk_nvmf_rdma_qpair_process_pending, rqpair);
+
+	return 0;
+error:
+	SPDK_ERRLOG("IBV qp#%u recovery failed\n", rqpair->qpair.qid);
+	/* Put NVMf qpair back into error state so recovery
+	   will trigger disconnect */
+	rqpair->qpair.state = SPDK_NVMF_QPAIR_ERROR;
+	return -1;
+}
+
+static void
+spdk_nvmf_rdma_drain_state_queue(struct spdk_nvmf_rdma_qpair *rqpair,
+				 enum spdk_nvmf_rdma_request_state state)
+{
+	struct spdk_nvmf_rdma_request *rdma_req, *req_tmp;
+	struct spdk_nvmf_rdma_transport *rtransport;
+
+	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->state_queue[state], state_link, req_tmp) {
+		rtransport = SPDK_CONTAINEROF(rdma_req->req.qpair->transport,
+					      struct spdk_nvmf_rdma_transport, transport);
+		spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_COMPLETED);
+		spdk_nvmf_rdma_request_process(rtransport, rdma_req);
+	}
+}
+
+static void spdk_nvmf_rdma_drain_rw_reqs(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	spdk_nvmf_rdma_drain_state_queue(rqpair, RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER);
+	spdk_nvmf_rdma_drain_state_queue(rqpair, RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST);
+	spdk_nvmf_rdma_drain_state_queue(rqpair, RDMA_REQUEST_STATE_COMPLETING);
+}
+
+static void spdk_nvmf_rdma_drain_pending_reqs(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	struct spdk_nvmf_rdma_request *rdma_req, *req_tmp;
+
+	spdk_nvmf_rdma_drain_state_queue(rqpair, RDMA_REQUEST_STATE_DATA_TRANSFER_PENDING);
+	/* First wipe the requests waiting for buffer from the global list */
+	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->state_queue[RDMA_REQUEST_STATE_NEED_BUFFER], link, req_tmp) {
+		TAILQ_REMOVE(&rqpair->ch->pending_data_buf_queue, rdma_req, link);
+	}
+	/* Then drain the requests through the rdma queue */
+	spdk_nvmf_rdma_drain_state_queue(rqpair, RDMA_REQUEST_STATE_NEED_BUFFER);
+}
+
+static void
+spdk_nvmf_rdma_qp_drained(struct spdk_nvmf_rdma_qpair *rqpair)
+{
+	SPDK_NOTICELOG("IBV QP#%u drained\n", rqpair->qpair.qid);
+
+	if (spdk_nvmf_qpair_is_admin_queue(&rqpair->qpair)) {
+		spdk_nvmf_ctrlr_drain_aer_req(rqpair->qpair.ctrlr);
+	}
+
+	spdk_nvmf_rdma_drain_pending_reqs(rqpair);
+	spdk_nvmf_rdma_drain_rw_reqs(rqpair);
+
+	if (!spdk_nvmf_rdma_qpair_is_idle(&rqpair->qpair)) {
+		/* There must be outstanding requests down to media.
+		 * If so, wait till they're complete.
+		 */
+		assert(!TAILQ_EMPTY(&rqpair->qpair.outstanding));
+		SPDK_DEBUGLOG(SPDK_LOG_RDMA,
+			      "QP#%u (%p): wait for outstanding requests...\n",
+			      rqpair->qpair.qid, &rqpair->qpair);
+		return;
+	}
+
+	if (rqpair->qpair.state != SPDK_NVMF_QPAIR_ERROR) {
+		/* Do not start recovery if qp is not in error state. */
+		return;
+	}
+
+	if (spdk_nvmf_rdma_recover(rqpair) != 0) {
+		SPDK_NOTICELOG("QP#%u (%p): recovery failed, disconnecting...\n",
+			       rqpair->qpair.qid, &rqpair->qpair);
+		spdk_nvmf_qpair_disconnect(&rqpair->qpair, NULL, NULL);
+	}
+}
+
+static void
+_spdk_nvmf_rdma_sq_drained(void *cb_arg)
+{
+	spdk_nvmf_rdma_qp_drained(cb_arg);
+}
+
+static void
+_spdk_nvmf_rdma_qp_last_wqe(void *cb_arg)
+{
+	struct spdk_nvmf_rdma_qpair *rqpair = cb_arg;
+
+	if (rqpair->qpair.state != SPDK_NVMF_QPAIR_ERROR) {
+		SPDK_ERRLOG("QP#%u is not in ERROR state, dropping LAST_WQE event...\n",
+			    rqpair->qpair.qid);
+		return;
+	}
+	spdk_nvmf_rdma_qp_drained(rqpair);
+}
+
+static void
+_spdk_nvmf_rdma_qp_error(void *arg)
+{
+	struct spdk_nvmf_rdma_qpair *rqpair = arg;
+
+	rqpair->qpair.state = SPDK_NVMF_QPAIR_ERROR;
+
+	if (spdk_nvmf_rdma_qpair_is_idle(&rqpair->qpair)) {
+		/* There are no outstanding requests */
+		spdk_nvmf_rdma_qp_drained(rqpair);
+	}
+}
+
+static struct spdk_nvmf_rdma_qpair *
+spdk_nvmf_rqpair_from_qp(struct ibv_qp *qp)
+{
+	return qp->qp_context;
+}
+
+static void
+spdk_nvmf_process_ib_event(struct spdk_nvmf_rdma_device *device)
+{
+	int rc;
+	struct spdk_nvmf_rdma_qpair	*rqpair;
+	struct ibv_async_event event;
+
+	rc = ibv_get_async_event(device->context, &event);
+
+	if (rc) {
+		SPDK_ERRLOG("Failed to get async_event (%d): %s\n",
+			    errno, spdk_strerror(errno));
+		return;
+	}
+
+	SPDK_NOTICELOG("Async event: %s\n",
+		       ibv_event_type_str(event.event_type));
+
+	switch (event.event_type) {
+	case IBV_EVENT_QP_FATAL:
+		rqpair = spdk_nvmf_rqpair_from_qp(event.element.qp);
+		spdk_nvmf_rdma_update_ibv_qp(rqpair);
+		spdk_thread_send_msg(rqpair->qpair.group->thread, _spdk_nvmf_rdma_qp_error, rqpair);
+		break;
+	case IBV_EVENT_SQ_DRAINED:
+		rqpair = spdk_nvmf_rqpair_from_qp(event.element.qp);
+		spdk_nvmf_rdma_update_ibv_qp(rqpair);
+		spdk_thread_send_msg(rqpair->qpair.group->thread, _spdk_nvmf_rdma_sq_drained, rqpair);
+		break;
+	case IBV_EVENT_QP_LAST_WQE_REACHED:
+		rqpair = spdk_nvmf_rqpair_from_qp(event.element.qp);
+		spdk_nvmf_rdma_update_ibv_qp(rqpair);
+		spdk_thread_send_msg(rqpair->qpair.group->thread, _spdk_nvmf_rdma_qp_last_wqe, rqpair);
+		break;
+	case IBV_EVENT_CQ_ERR:
+	case IBV_EVENT_QP_REQ_ERR:
+	case IBV_EVENT_QP_ACCESS_ERR:
+	case IBV_EVENT_COMM_EST:
+	case IBV_EVENT_PATH_MIG:
+	case IBV_EVENT_PATH_MIG_ERR:
+	case IBV_EVENT_DEVICE_FATAL:
+	case IBV_EVENT_PORT_ACTIVE:
+	case IBV_EVENT_PORT_ERR:
+	case IBV_EVENT_LID_CHANGE:
+	case IBV_EVENT_PKEY_CHANGE:
+	case IBV_EVENT_SM_CHANGE:
+	case IBV_EVENT_SRQ_ERR:
+	case IBV_EVENT_SRQ_LIMIT_REACHED:
+	case IBV_EVENT_CLIENT_REREGISTER:
+	case IBV_EVENT_GID_CHANGE:
+	default:
+		break;
+	}
+	ibv_ack_async_event(&event);
+}
+
+static void
+spdk_nvmf_rdma_accept(struct spdk_nvmf_transport *transport, new_qpair_fn cb_fn)
+{
+	int	nfds, i = 0;
+	struct spdk_nvmf_rdma_transport *rtransport;
+	struct spdk_nvmf_rdma_device *device, *tmp;
+
+	rtransport = SPDK_CONTAINEROF(transport, struct spdk_nvmf_rdma_transport, transport);
+	nfds = poll(rtransport->poll_fds, rtransport->npoll_fds, 0);
+
+	if (nfds <= 0) {
+		return;
+	}
+
+	/* The first poll descriptor is RDMA CM event */
+	if (rtransport->poll_fds[i++].revents & POLLIN) {
+		spdk_nvmf_process_cm_event(transport, cb_fn);
+		nfds--;
+	}
+
+	if (nfds == 0) {
+		return;
+	}
+
+	/* Second and subsequent poll descriptors are IB async events */
+	TAILQ_FOREACH_SAFE(device, &rtransport->devices, link, tmp) {
+		if (rtransport->poll_fds[i++].revents & POLLIN) {
+			spdk_nvmf_process_ib_event(device);
+			nfds--;
+		}
+	}
+	/* check all flagged fd's have been served */
+	assert(nfds == 0);
+}
+
 static void
 spdk_nvmf_rdma_discover(struct spdk_nvmf_transport *transport,
 			struct spdk_nvme_transport_id *trid,
@@ -1664,6 +2377,7 @@ spdk_nvmf_rdma_poll_group_remove(struct spdk_nvmf_transport_poll_group *group,
 	TAILQ_FOREACH_SAFE(rq, &poller->qpairs, link, trq) {
 		if (rq == rqpair) {
 			TAILQ_REMOVE(&poller->qpairs, rqpair, link);
+			rqpair->poller = NULL;
 			break;
 		}
 	}
@@ -1681,11 +2395,35 @@ spdk_nvmf_rdma_request_complete(struct spdk_nvmf_request *req)
 {
 	struct spdk_nvmf_rdma_transport	*rtransport = SPDK_CONTAINEROF(req->qpair->transport,
 			struct spdk_nvmf_rdma_transport, transport);
-	struct spdk_nvmf_rdma_request	*rdma_req = SPDK_CONTAINEROF(req, struct spdk_nvmf_rdma_request, req);
-
-	rdma_req->state = RDMA_REQUEST_STATE_EXECUTED;
-	spdk_nvmf_rdma_request_process(rtransport, rdma_req);
+	struct spdk_nvmf_rdma_request	*rdma_req = SPDK_CONTAINEROF(req,
+			struct spdk_nvmf_rdma_request, req);
+	struct spdk_nvmf_rdma_qpair     *rqpair = SPDK_CONTAINEROF(rdma_req->req.qpair,
+			struct spdk_nvmf_rdma_qpair, qpair);
+
+	switch (rqpair->qpair.state) {
+	case SPDK_NVMF_QPAIR_ERROR:
+		/* Mark request as COMPLETED for ERROR state
+		 * so RDMA transfer is not kicked off
+		 */
+		spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_COMPLETED);
+		spdk_nvmf_rdma_request_process(rtransport, rdma_req);
 
+		/* QP in ERROR state is awaiting for all requests to be
+		 * completed by bdev layer
+		 */
+		if (spdk_nvmf_rdma_qpair_is_idle(&rqpair->qpair)) {
+			spdk_nvmf_rdma_qp_drained(rqpair);
+		}
+		break;
+	case SPDK_NVMF_QPAIR_INACTIVE:
+	case SPDK_NVMF_QPAIR_ACTIVATING:
+	case SPDK_NVMF_QPAIR_ACTIVE:
+	case SPDK_NVMF_QPAIR_DEACTIVATING:
+	default:
+		spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_EXECUTED);
+		spdk_nvmf_rdma_request_process(rtransport, rdma_req);
+		break;
+	}
 	return 0;
 }
 
@@ -1695,43 +2433,6 @@ spdk_nvmf_rdma_close_qpair(struct spdk_nvmf_qpair *qpair)
 	spdk_nvmf_rdma_qpair_destroy(SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair));
 }
 
-static void
-spdk_nvmf_rdma_qpair_process_pending(struct spdk_nvmf_rdma_transport *rtransport,
-				     struct spdk_nvmf_rdma_qpair *rqpair)
-{
-	struct spdk_nvmf_rdma_recv	*rdma_recv, *recv_tmp;
-	struct spdk_nvmf_rdma_request	*rdma_req, *req_tmp;
-
-	/* We process I/O in the pending_rdma_rw queue at the highest priority. */
-	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->pending_rdma_rw_queue, link, req_tmp) {
-		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
-			break;
-		}
-	}
-
-	/* The second highest priority is I/O waiting on memory buffers. */
-	TAILQ_FOREACH_SAFE(rdma_req, &rqpair->ch->pending_data_buf_queue, link, req_tmp) {
-		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
-			break;
-		}
-	}
-
-	/* The lowest priority is processing newly received commands */
-	TAILQ_FOREACH_SAFE(rdma_recv, &rqpair->incoming_queue, link, recv_tmp) {
-		rdma_req = TAILQ_FIRST(&rqpair->free_queue);
-		if (rdma_req == NULL) {
-			/* Need to wait for more SEND completions */
-			break;
-		}
-
-		rdma_req->recv = rdma_recv;
-		rdma_req->state = RDMA_REQUEST_STATE_NEW;
-		if (spdk_nvmf_rdma_request_process(rtransport, rdma_req) == false) {
-			break;
-		}
-	}
-}
-
 static struct spdk_nvmf_rdma_request *
 get_rdma_req_from_wc(struct ibv_wc *wc)
 {
@@ -1771,6 +2472,15 @@ get_rdma_recv_from_wc(struct ibv_wc *wc)
 	return rdma_recv;
 }
 
+#ifdef DEBUG
+static int
+spdk_nvmf_rdma_req_is_completing(struct spdk_nvmf_rdma_request *rdma_req)
+{
+	return rdma_req->state == RDMA_REQUEST_STATE_TRANSFERRING_CONTROLLER_TO_HOST ||
+	       rdma_req->state == RDMA_REQUEST_STATE_COMPLETING;
+}
+#endif
+
 static int
 spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 			   struct spdk_nvmf_rdma_poller *rpoller)
@@ -1793,8 +2503,8 @@ spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 
 	for (i = 0; i < reaped; i++) {
 		if (wc[i].status) {
-			SPDK_ERRLOG("CQ error on CQ %p, Request 0x%lu (%d): %s\n",
-				    rpoller->cq, wc[i].wr_id, wc[i].status, ibv_wc_status_str(wc[i].status));
+			SPDK_DEBUGLOG(SPDK_LOG_RDMA, "CQ error on CQ %p, Request 0x%lu (%d): %s\n",
+				      rpoller->cq, wc[i].wr_id, wc[i].status, ibv_wc_status_str(wc[i].status));
 			error = true;
 			continue;
 		}
@@ -1804,9 +2514,8 @@ spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 			rdma_req = get_rdma_req_from_wc(&wc[i]);
 			rqpair = SPDK_CONTAINEROF(rdma_req->req.qpair, struct spdk_nvmf_rdma_qpair, qpair);
 
-			assert(rdma_req->state == RDMA_REQUEST_STATE_COMPLETING);
-			rdma_req->state = RDMA_REQUEST_STATE_COMPLETED;
-
+			assert(spdk_nvmf_rdma_req_is_completing(rdma_req));
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_COMPLETED);
 			spdk_nvmf_rdma_request_process(rtransport, rdma_req);
 
 			count++;
@@ -1819,8 +2528,6 @@ spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 			rdma_req = get_rdma_req_from_wc(&wc[i]);
 			rqpair = SPDK_CONTAINEROF(rdma_req->req.qpair, struct spdk_nvmf_rdma_qpair, qpair);
 
-			rqpair->cur_rdma_rw_depth--;
-
 			/* Try to process other queued requests */
 			spdk_nvmf_rdma_qpair_process_pending(rtransport, rqpair);
 			break;
@@ -1830,9 +2537,7 @@ spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 			rqpair = SPDK_CONTAINEROF(rdma_req->req.qpair, struct spdk_nvmf_rdma_qpair, qpair);
 
 			assert(rdma_req->state == RDMA_REQUEST_STATE_TRANSFERRING_HOST_TO_CONTROLLER);
-			rqpair->cur_rdma_rw_depth--;
-			rdma_req->state = RDMA_REQUEST_STATE_READY_TO_EXECUTE;
-
+			spdk_nvmf_rdma_request_set_state(rdma_req, RDMA_REQUEST_STATE_READY_TO_EXECUTE);
 			spdk_nvmf_rdma_request_process(rtransport, rdma_req);
 
 			/* Try to process other queued requests */
@@ -1844,7 +2549,6 @@ spdk_nvmf_rdma_poller_poll(struct spdk_nvmf_rdma_transport *rtransport,
 			rqpair = rdma_recv->qpair;
 
 			TAILQ_INSERT_TAIL(&rqpair->incoming_queue, rdma_recv, link);
-
 			/* Try to process other queued requests */
 			spdk_nvmf_rdma_qpair_process_pending(rtransport, rqpair);
 			break;
@@ -1885,19 +2589,6 @@ spdk_nvmf_rdma_poll_group_poll(struct spdk_nvmf_transport_poll_group *group)
 	return count;
 }
 
-static bool
-spdk_nvmf_rdma_qpair_is_idle(struct spdk_nvmf_qpair *qpair)
-{
-	struct spdk_nvmf_rdma_qpair *rqpair;
-
-	rqpair = SPDK_CONTAINEROF(qpair, struct spdk_nvmf_rdma_qpair, qpair);
-
-	if (rqpair->cur_queue_depth == 0 && rqpair->cur_rdma_rw_depth == 0) {
-		return true;
-	}
-	return false;
-}
-
 const struct spdk_nvmf_transport_ops spdk_nvmf_transport_rdma = {
 	.type = SPDK_NVME_TRANSPORT_RDMA,
 	.create = spdk_nvmf_rdma_create,
diff --git a/lib/nvmf/request.c b/lib/nvmf/request.c
index 1b02e01b3..734339424 100644
--- a/lib/nvmf/request.c
+++ b/lib/nvmf/request.c
@@ -36,7 +36,7 @@
 #include "nvmf_internal.h"
 #include "transport.h"
 
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/likely.h"
 #include "spdk/nvme.h"
 #include "spdk/nvmf_spec.h"
@@ -49,20 +49,35 @@ int
 spdk_nvmf_request_complete(struct spdk_nvmf_request *req)
 {
 	struct spdk_nvme_cpl *rsp = &req->rsp->nvme_cpl;
+	struct spdk_nvmf_qpair *qpair;
 
 	rsp->sqid = 0;
 	rsp->status.p = 0;
 	rsp->cid = req->cmd->nvme_cmd.cid;
 
+	qpair = req->qpair;
+
 	SPDK_DEBUGLOG(SPDK_LOG_NVMF,
 		      "cpl: cid=%u cdw0=0x%08x rsvd1=%u status=0x%04x\n",
 		      rsp->cid, rsp->cdw0, rsp->rsvd1,
 		      *(uint16_t *)&rsp->status);
 
+	TAILQ_REMOVE(&qpair->outstanding, req, link);
 	if (spdk_nvmf_transport_req_complete(req)) {
 		SPDK_ERRLOG("Transport request completion error!\n");
 	}
 
+	if (qpair->state == SPDK_NVMF_QPAIR_DEACTIVATING) {
+		assert(qpair->state_cb != NULL);
+
+		if (TAILQ_EMPTY(&qpair->outstanding)) {
+
+			qpair->state_cb(qpair->state_cb_arg, 0);
+		}
+	} else {
+		assert(qpair->state == SPDK_NVMF_QPAIR_ACTIVE);
+	}
+
 	return 0;
 }
 
@@ -118,6 +133,15 @@ spdk_nvmf_request_exec(struct spdk_nvmf_request *req)
 
 	nvmf_trace_command(req->cmd, spdk_nvmf_qpair_is_admin_queue(qpair));
 
+	if (qpair->state != SPDK_NVMF_QPAIR_ACTIVE) {
+		req->rsp->nvme_cpl.status.sct = SPDK_NVME_SCT_GENERIC;
+		req->rsp->nvme_cpl.status.sc = SPDK_NVME_SC_COMMAND_SEQUENCE_ERROR;
+		/* Place the request on the outstanding list so we can keep track of it */
+		TAILQ_INSERT_TAIL(&qpair->outstanding, req, link);
+		spdk_nvmf_request_complete(req);
+		return;
+	}
+
 	/* Check if the subsystem is paused (if there is a subsystem) */
 	if (qpair->ctrlr) {
 		struct spdk_nvmf_subsystem_poll_group *sgroup = &qpair->group->sgroups[qpair->ctrlr->subsys->id];
@@ -126,8 +150,12 @@ spdk_nvmf_request_exec(struct spdk_nvmf_request *req)
 			TAILQ_INSERT_TAIL(&sgroup->queued, req, link);
 			return;
 		}
+
 	}
 
+	/* Place the request on the outstanding list so we can keep track of it */
+	TAILQ_INSERT_TAIL(&qpair->outstanding, req, link);
+
 	if (spdk_unlikely(req->cmd->nvmf_cmd.opcode == SPDK_NVME_OPC_FABRIC)) {
 		status = spdk_nvmf_ctrlr_process_fabrics_cmd(req);
 	} else if (spdk_unlikely(spdk_nvmf_qpair_is_admin_queue(qpair))) {
@@ -140,10 +168,3 @@ spdk_nvmf_request_exec(struct spdk_nvmf_request *req)
 		spdk_nvmf_request_complete(req);
 	}
 }
-
-int
-spdk_nvmf_request_abort(struct spdk_nvmf_request *req)
-{
-	/* TODO: implement abort, at least for commands that are still queued in software */
-	return -1;
-}
diff --git a/lib/nvmf/subsystem.c b/lib/nvmf/subsystem.c
index 3b70720a6..408bad96b 100644
--- a/lib/nvmf/subsystem.c
+++ b/lib/nvmf/subsystem.c
@@ -43,7 +43,7 @@
 #include "spdk/nvmf_spec.h"
 #include "spdk/uuid.h"
 
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 #include "spdk_internal/log.h"
 #include "spdk_internal/utf.h"
 
@@ -253,21 +253,13 @@ spdk_nvmf_subsystem_create(struct spdk_nvmf_tgt *tgt,
 	}
 
 	/* Find a free subsystem id (sid) */
-	for (sid = 0; sid < tgt->max_sid; sid++) {
+	for (sid = 0; sid < tgt->opts.max_subsystems; sid++) {
 		if (tgt->subsystems[sid] == NULL) {
 			break;
 		}
 	}
-	if (sid == tgt->max_sid) {
-		struct spdk_nvmf_subsystem **subsys_array;
-		/* No free slots. Add more. */
-		tgt->max_sid++;
-		subsys_array = realloc(tgt->subsystems, tgt->max_sid * sizeof(struct spdk_nvmf_subsystem *));
-		if (!subsys_array) {
-			tgt->max_sid--;
-			return NULL;
-		}
-		tgt->subsystems = subsys_array;
+	if (sid >= tgt->opts.max_subsystems) {
+		return NULL;
 	}
 
 	subsystem = calloc(1, sizeof(struct spdk_nvmf_subsystem));
@@ -281,12 +273,7 @@ spdk_nvmf_subsystem_create(struct spdk_nvmf_tgt *tgt,
 	subsystem->id = sid;
 	subsystem->subtype = type;
 	subsystem->max_nsid = num_ns;
-	/*
-	 *  Initially max_nsid and max_allowed_nsid will be same. If max_allowed_nsid is zero nsid range can grow dynamically
-	 *  but if it is more than 1 nsid range cannot be extended beyond max_allowed_nsid
-	 */
 	subsystem->max_allowed_nsid = num_ns;
-	subsystem->num_allocated_nsid = 0;
 	subsystem->next_cntlid = 0;
 	snprintf(subsystem->subnqn, sizeof(subsystem->subnqn), "%s", nqn);
 	TAILQ_INIT(&subsystem->listeners);
@@ -560,7 +547,7 @@ spdk_nvmf_subsystem_get_first(struct spdk_nvmf_tgt *tgt)
 	struct spdk_nvmf_subsystem	*subsystem;
 	uint32_t sid;
 
-	for (sid = 0; sid < tgt->max_sid; sid++) {
+	for (sid = 0; sid < tgt->opts.max_subsystems; sid++) {
 		subsystem = tgt->subsystems[sid];
 		if (subsystem) {
 			return subsystem;
@@ -582,7 +569,7 @@ spdk_nvmf_subsystem_get_next(struct spdk_nvmf_subsystem *subsystem)
 
 	tgt = subsystem->tgt;
 
-	for (sid = subsystem->id + 1; sid < tgt->max_sid; sid++) {
+	for (sid = subsystem->id + 1; sid < tgt->opts.max_subsystems; sid++) {
 		subsystem = tgt->subsystems[sid];
 		if (subsystem) {
 			return subsystem;
@@ -909,7 +896,6 @@ _spdk_nvmf_subsystem_remove_ns(struct spdk_nvmf_subsystem *subsystem, uint32_t n
 
 	spdk_bdev_close(ns->desc);
 	free(ns);
-	subsystem->num_allocated_nsid--;
 
 	spdk_nvmf_subsystem_ns_changed(subsystem, nsid);
 
@@ -987,7 +973,6 @@ spdk_nvmf_subsystem_add_ns(struct spdk_nvmf_subsystem *subsystem, struct spdk_bd
 {
 	struct spdk_nvmf_ns_opts opts;
 	struct spdk_nvmf_ns *ns;
-	uint32_t i;
 	int rc;
 
 	if (!(subsystem->state == SPDK_NVMF_SUBSYSTEM_INACTIVE ||
@@ -1009,52 +994,50 @@ spdk_nvmf_subsystem_add_ns(struct spdk_nvmf_subsystem *subsystem, struct spdk_bd
 		return 0;
 	}
 
-	if ((subsystem->max_allowed_nsid > 0) && (opts.nsid > subsystem->max_allowed_nsid)) {
-		SPDK_ERRLOG("Can't extend NSID range above MaxNamespaces\n");
+	if (opts.nsid == 0) {
+		/*
+		 * NSID not specified - find a free index.
+		 *
+		 * If no free slots are found, opts.nsid will be subsystem->max_nsid + 1, which will
+		 * expand max_nsid if possible.
+		 */
+		for (opts.nsid = 1; opts.nsid <= subsystem->max_nsid; opts.nsid++) {
+			if (_spdk_nvmf_subsystem_get_ns(subsystem, opts.nsid) == NULL) {
+				break;
+			}
+		}
+	}
+
+	if (_spdk_nvmf_subsystem_get_ns(subsystem, opts.nsid)) {
+		SPDK_ERRLOG("Requested NSID %" PRIu32 " already in use\n", opts.nsid);
 		return 0;
 	}
 
-	if (opts.nsid > subsystem->max_nsid ||
-	    (opts.nsid == 0 && subsystem->num_allocated_nsid == subsystem->max_nsid)) {
+	if (opts.nsid > subsystem->max_nsid) {
 		struct spdk_nvmf_ns **new_ns_array;
-		uint32_t new_max_nsid;
 
-		if (opts.nsid > subsystem->max_nsid) {
-			new_max_nsid = opts.nsid;
-		} else {
-			new_max_nsid = subsystem->max_nsid + 1;
+		/* If MaxNamespaces was specified, we can't extend max_nsid beyond it. */
+		if (subsystem->max_allowed_nsid > 0 && opts.nsid > subsystem->max_allowed_nsid) {
+			SPDK_ERRLOG("Can't extend NSID range above MaxNamespaces\n");
+			return 0;
+		}
+
+		/* If a controller is connected, we can't change NN. */
+		if (!TAILQ_EMPTY(&subsystem->ctrlrs)) {
+			SPDK_ERRLOG("Can't extend NSID range while controllers are connected\n");
+			return 0;
 		}
 
-		new_ns_array = realloc(subsystem->ns, sizeof(struct spdk_nvmf_ns *) * new_max_nsid);
+		new_ns_array = realloc(subsystem->ns, sizeof(struct spdk_nvmf_ns *) * opts.nsid);
 		if (new_ns_array == NULL) {
 			SPDK_ERRLOG("Memory allocation error while resizing namespace array.\n");
 			return 0;
 		}
 
 		memset(new_ns_array + subsystem->max_nsid, 0,
-		       sizeof(struct spdk_nvmf_ns *) * (new_max_nsid - subsystem->max_nsid));
+		       sizeof(struct spdk_nvmf_ns *) * (opts.nsid - subsystem->max_nsid));
 		subsystem->ns = new_ns_array;
-		subsystem->max_nsid = new_max_nsid;
-	}
-
-	if (opts.nsid == 0) {
-		/* NSID not specified - find a free index */
-		for (i = 0; i < subsystem->max_nsid; i++) {
-			if (_spdk_nvmf_subsystem_get_ns(subsystem, i + 1) == NULL) {
-				opts.nsid = i + 1;
-				break;
-			}
-		}
-		if (opts.nsid == 0) {
-			SPDK_ERRLOG("All available NSIDs in use\n");
-			return 0;
-		}
-	} else {
-		/* Specific NSID requested */
-		if (_spdk_nvmf_subsystem_get_ns(subsystem, opts.nsid)) {
-			SPDK_ERRLOG("Requested NSID %" PRIu32 " already in use\n", opts.nsid);
-			return 0;
-		}
+		subsystem->max_nsid = opts.nsid;
 	}
 
 	ns = calloc(1, sizeof(*ns));
@@ -1080,9 +1063,6 @@ spdk_nvmf_subsystem_add_ns(struct spdk_nvmf_subsystem *subsystem, struct spdk_bd
 		      spdk_bdev_get_name(bdev),
 		      opts.nsid);
 
-	subsystem->max_nsid = spdk_max(subsystem->max_nsid, opts.nsid);
-	subsystem->num_allocated_nsid++;
-
 	spdk_nvmf_subsystem_ns_changed(subsystem, opts.nsid);
 
 	return opts.nsid;
@@ -1260,3 +1240,9 @@ spdk_nvmf_subsystem_get_ctrlr(struct spdk_nvmf_subsystem *subsystem, uint16_t cn
 
 	return NULL;
 }
+
+uint32_t
+spdk_nvmf_subsystem_get_max_namespaces(const struct spdk_nvmf_subsystem *subsystem)
+{
+	return subsystem->max_allowed_nsid;
+}
diff --git a/lib/nvmf/transport.c b/lib/nvmf/transport.c
index d9e31f2fa..9e24f9fb7 100644
--- a/lib/nvmf/transport.c
+++ b/lib/nvmf/transport.c
@@ -77,9 +77,6 @@ spdk_nvmf_transport_create(struct spdk_nvmf_tgt *tgt,
 		return NULL;
 	}
 
-	transport->ops = ops;
-	transport->tgt = tgt;
-
 	return transport;
 }
 
diff --git a/lib/rocksdb/env_spdk.cc b/lib/rocksdb/env_spdk.cc
index 06a46edca..0fe3a3639 100644
--- a/lib/rocksdb/env_spdk.cc
+++ b/lib/rocksdb/env_spdk.cc
@@ -43,7 +43,7 @@ extern "C" {
 #include "spdk/blobfs.h"
 #include "spdk/blob_bdev.h"
 #include "spdk/log.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/bdev.h"
 }
 
diff --git a/lib/rocksdb/spdk.rocksdb.mk b/lib/rocksdb/spdk.rocksdb.mk
index d133ddb4a..2f7a4a86a 100644
--- a/lib/rocksdb/spdk.rocksdb.mk
+++ b/lib/rocksdb/spdk.rocksdb.mk
@@ -55,11 +55,11 @@ endif
 
 SPDK_LIB_LIST = event_bdev event_copy
 SPDK_LIB_LIST += blobfs bdev copy event util conf trace \
-		log jsonrpc json rpc
+		log jsonrpc json rpc thread
 
 AM_LINK += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS)
 AM_LINK += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
-AM_LINK += -luuid
+AM_LINK += $(SYS_LIBS)
 
 ifeq ($(CONFIG_UBSAN),y)
 AM_LINK += -fsanitize=undefined
diff --git a/lib/rpc/rpc.c b/lib/rpc/rpc.c
index 50e0fb08e..4890b66ad 100644
--- a/lib/rpc/rpc.c
+++ b/lib/rpc/rpc.c
@@ -40,6 +40,7 @@
 #include "spdk/env.h"
 #include "spdk/log.h"
 #include "spdk/string.h"
+#include "spdk/util.h"
 
 #define RPC_DEFAULT_PORT	"5260"
 
@@ -48,15 +49,23 @@ static char g_rpc_lock_path[sizeof(g_rpc_listen_addr_unix.sun_path) + sizeof(".l
 static int g_rpc_lock_fd = -1;
 
 static struct spdk_jsonrpc_server *g_jsonrpc_server = NULL;
+static uint32_t g_rpc_state;
 
 struct spdk_rpc_method {
 	const char *name;
 	spdk_rpc_method_handler func;
 	SLIST_ENTRY(spdk_rpc_method) slist;
+	uint32_t state_mask;
 };
 
 static SLIST_HEAD(, spdk_rpc_method) g_rpc_methods = SLIST_HEAD_INITIALIZER(g_rpc_methods);
 
+void
+spdk_rpc_set_state(uint32_t state)
+{
+	g_rpc_state = state;
+}
+
 static void
 spdk_jsonrpc_handler(struct spdk_jsonrpc_request *request,
 		     const struct spdk_json_val *method,
@@ -68,7 +77,14 @@ spdk_jsonrpc_handler(struct spdk_jsonrpc_request *request,
 
 	SLIST_FOREACH(m, &g_rpc_methods, slist) {
 		if (spdk_json_strequal(method, m->name)) {
-			m->func(request, params);
+			if ((m->state_mask & g_rpc_state) == g_rpc_state) {
+				m->func(request, params);
+			} else {
+				spdk_jsonrpc_send_error_response_fmt(request, SPDK_JSONRPC_ERROR_INVALID_STATE,
+								     "Method is allowed in any state in the mask (%"PRIx32"),"
+								     " but current state is (%"PRIx32")",
+								     m->state_mask, g_rpc_state);
+			}
 			return;
 		}
 	}
@@ -184,7 +200,7 @@ spdk_rpc_accept(void)
 }
 
 void
-spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func)
+spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func, uint32_t state_mask)
 {
 	struct spdk_rpc_method *m;
 
@@ -195,6 +211,7 @@ spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func)
 	assert(m->name != NULL);
 
 	m->func = func;
+	m->state_mask = state_mask;
 
 	/* TODO: use a hash table or sorted list */
 	SLIST_INSERT_HEAD(&g_rpc_methods, m, slist);
@@ -224,18 +241,30 @@ spdk_rpc_close(void)
 	}
 }
 
+struct rpc_get_rpc_methods {
+	bool current;
+};
+
+static const struct spdk_json_object_decoder rpc_get_rpc_methods_decoders[] = {
+	{"current", offsetof(struct rpc_get_rpc_methods, current), spdk_json_decode_bool, true},
+};
 
 static void
 spdk_rpc_get_rpc_methods(struct spdk_jsonrpc_request *request,
 			 const struct spdk_json_val *params)
 {
+	struct rpc_get_rpc_methods req = {};
 	struct spdk_json_write_ctx *w;
 	struct spdk_rpc_method *m;
 
 	if (params != NULL) {
-		spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
-						 "get_rpc_methods requires no parameters");
-		return;
+		if (spdk_json_decode_object(params, rpc_get_rpc_methods_decoders,
+					    SPDK_COUNTOF(rpc_get_rpc_methods_decoders), &req)) {
+			SPDK_ERRLOG("spdk_json_decode_object failed\n");
+			spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
+							 "Invalid parameters");
+			return;
+		}
 	}
 
 	w = spdk_jsonrpc_begin_result(request);
@@ -245,9 +274,12 @@ spdk_rpc_get_rpc_methods(struct spdk_jsonrpc_request *request,
 
 	spdk_json_write_array_begin(w);
 	SLIST_FOREACH(m, &g_rpc_methods, slist) {
+		if (req.current && ((m->state_mask & g_rpc_state) != g_rpc_state)) {
+			continue;
+		}
 		spdk_json_write_string(w, m->name);
 	}
 	spdk_json_write_array_end(w);
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_rpc_methods", spdk_rpc_get_rpc_methods)
+SPDK_RPC_REGISTER("get_rpc_methods", spdk_rpc_get_rpc_methods, SPDK_RPC_STARTUP | SPDK_RPC_RUNTIME)
diff --git a/lib/scsi/dev.c b/lib/scsi/dev.c
index c86eaee8a..335ffacba 100644
--- a/lib/scsi/dev.c
+++ b/lib/scsi/dev.c
@@ -355,7 +355,7 @@ spdk_scsi_dev_free_io_channels(struct spdk_scsi_dev *dev)
 		if (dev->lun[i] == NULL) {
 			continue;
 		}
-		spdk_scsi_lun_free_io_channel(dev->lun[i]);
+		_spdk_scsi_lun_free_io_channel(dev->lun[i]);
 	}
 }
 
@@ -368,7 +368,7 @@ spdk_scsi_dev_allocate_io_channels(struct spdk_scsi_dev *dev)
 		if (dev->lun[i] == NULL) {
 			continue;
 		}
-		rc = spdk_scsi_lun_allocate_io_channel(dev->lun[i]);
+		rc = _spdk_scsi_lun_allocate_io_channel(dev->lun[i]);
 		if (rc < 0) {
 			spdk_scsi_dev_free_io_channels(dev);
 			return -1;
diff --git a/lib/scsi/lun.c b/lib/scsi/lun.c
index 679959141..ea44d86e3 100644
--- a/lib/scsi/lun.c
+++ b/lib/scsi/lun.c
@@ -35,7 +35,7 @@
 #include "scsi_internal.h"
 #include "spdk/endian.h"
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/event.h"
 #include "spdk/util.h"
 
@@ -181,37 +181,78 @@ spdk_scsi_lun_execute_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task *tas
 	}
 }
 
-static int
-spdk_scsi_lun_hotplug(void *arg)
+static void
+spdk_scsi_lun_remove(struct spdk_scsi_lun *lun)
 {
-	struct spdk_scsi_lun *lun = (struct spdk_scsi_lun *)arg;
+	spdk_bdev_close(lun->bdev_desc);
 
-	if (!spdk_scsi_lun_has_pending_tasks(lun)) {
-		spdk_scsi_lun_free_io_channel(lun);
+	spdk_scsi_dev_delete_lun(lun->dev, lun);
+	free(lun);
+}
 
-		spdk_bdev_close(lun->bdev_desc);
-		spdk_poller_unregister(&lun->hotplug_poller);
+static int
+spdk_scsi_lun_check_io_channel(void *arg)
+{
+	struct spdk_scsi_lun *lun = (struct spdk_scsi_lun *)arg;
 
-		spdk_scsi_dev_delete_lun(lun->dev, lun);
-		free(lun);
+	if (lun->io_channel) {
+		return -1;
 	}
+	spdk_poller_unregister(&lun->hotremove_poller);
 
+	spdk_scsi_lun_remove(lun);
 	return -1;
 }
 
 static void
-_spdk_scsi_lun_hot_remove(void *arg1)
+spdk_scsi_lun_notify_hot_remove(struct spdk_scsi_lun *lun)
 {
-	struct spdk_scsi_lun *lun = arg1;
+	struct spdk_scsi_desc *desc, *tmp;
 
 	if (lun->hotremove_cb) {
 		lun->hotremove_cb(lun, lun->hotremove_ctx);
 	}
 
+	TAILQ_FOREACH_SAFE(desc, &lun->open_descs, link, tmp) {
+		if (desc->hotremove_cb) {
+			desc->hotremove_cb(lun, desc->hotremove_ctx);
+		} else {
+			spdk_scsi_lun_close(desc);
+		}
+	}
+
+	if (lun->io_channel) {
+		lun->hotremove_poller = spdk_poller_register(spdk_scsi_lun_check_io_channel,
+					lun, 10);
+	} else {
+		spdk_scsi_lun_remove(lun);
+	}
+}
+
+static int
+spdk_scsi_lun_check_pending_tasks(void *arg)
+{
+	struct spdk_scsi_lun *lun = (struct spdk_scsi_lun *)arg;
+
+	if (spdk_scsi_lun_has_pending_tasks(lun)) {
+		return -1;
+	}
+	spdk_poller_unregister(&lun->hotremove_poller);
+
+	spdk_scsi_lun_notify_hot_remove(lun);
+	return -1;
+}
+
+static void
+_spdk_scsi_lun_hot_remove(void *arg1)
+{
+	struct spdk_scsi_lun *lun = arg1;
+
 	if (spdk_scsi_lun_has_pending_tasks(lun)) {
-		lun->hotplug_poller = spdk_poller_register(spdk_scsi_lun_hotplug, lun, 10);
+		lun->hotremove_poller = spdk_poller_register(spdk_scsi_lun_check_pending_tasks,
+					lun, 10);
 	} else {
-		spdk_scsi_lun_hotplug(lun);
+		spdk_scsi_lun_notify_hot_remove(lun);
 	}
 }
 
@@ -280,6 +321,7 @@ spdk_scsi_lun_construct(struct spdk_bdev *bdev,
 	lun->io_channel = NULL;
 	lun->hotremove_cb = hotremove_cb;
 	lun->hotremove_ctx = hotremove_ctx;
+	TAILQ_INIT(&lun->open_descs);
 
 	return lun;
 }
@@ -290,10 +332,44 @@ spdk_scsi_lun_destruct(struct spdk_scsi_lun *lun)
 	spdk_scsi_lun_hot_remove(lun);
 }
 
-int spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun)
+int
+spdk_scsi_lun_open(struct spdk_scsi_lun *lun, spdk_scsi_remove_cb_t hotremove_cb,
+		   void *hotremove_ctx, struct spdk_scsi_desc **_desc)
+{
+	struct spdk_scsi_desc *desc;
+
+	desc = calloc(1, sizeof(*desc));
+	if (desc == NULL) {
+		SPDK_ERRLOG("calloc() failed for LUN descriptor.\n");
+		return -ENOMEM;
+	}
+
+	TAILQ_INSERT_TAIL(&lun->open_descs, desc, link);
+
+	desc->lun = lun;
+	desc->hotremove_cb = hotremove_cb;
+	desc->hotremove_ctx = hotremove_ctx;
+	*_desc = desc;
+
+	return 0;
+}
+
+void
+spdk_scsi_lun_close(struct spdk_scsi_desc *desc)
+{
+	struct spdk_scsi_lun *lun = desc->lun;
+
+	TAILQ_REMOVE(&lun->open_descs, desc, link);
+	free(desc);
+
+	assert(!TAILQ_EMPTY(&lun->open_descs) || lun->io_channel == NULL);
+}
+
+int
+_spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun)
 {
 	if (lun->io_channel != NULL) {
-		if (pthread_self() == lun->thread_id) {
+		if (spdk_get_thread() == spdk_io_channel_get_thread(lun->io_channel)) {
 			lun->ref++;
 			return 0;
 		}
@@ -306,20 +382,43 @@ int spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun)
 	if (lun->io_channel == NULL) {
 		return -1;
 	}
-	lun->thread_id = pthread_self();
 	lun->ref = 1;
 	return 0;
 }
 
-void spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun)
+void
+_spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun)
 {
-	if (lun->io_channel != NULL) {
-		lun->ref--;
-		if (lun->ref == 0) {
-			spdk_put_io_channel(lun->io_channel);
-			lun->io_channel = NULL;
-		}
+	if (lun->io_channel == NULL) {
+		return;
 	}
+
+	if (spdk_get_thread() != spdk_io_channel_get_thread(lun->io_channel)) {
+		SPDK_ERRLOG("io_channel was freed by different thread\n");
+		return;
+	}
+
+	lun->ref--;
+	if (lun->ref == 0) {
+		spdk_put_io_channel(lun->io_channel);
+		lun->io_channel = NULL;
+	}
+}
+
+int
+spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_desc *desc)
+{
+	struct spdk_scsi_lun *lun = desc->lun;
+
+	return _spdk_scsi_lun_allocate_io_channel(lun);
+}
+
+void
+spdk_scsi_lun_free_io_channel(struct spdk_scsi_desc *desc)
+{
+	struct spdk_scsi_lun *lun = desc->lun;
+
+	_spdk_scsi_lun_free_io_channel(lun);
 }
 
 int
@@ -345,3 +444,9 @@ spdk_scsi_lun_has_pending_tasks(const struct spdk_scsi_lun *lun)
 {
 	return !TAILQ_EMPTY(&lun->tasks);
 }
+
+bool
+spdk_scsi_lun_is_removing(const struct spdk_scsi_lun *lun)
+{
+	return lun->removed;
+}
diff --git a/lib/scsi/scsi_bdev.c b/lib/scsi/scsi_bdev.c
index adefbbe8b..289d86268 100644
--- a/lib/scsi/scsi_bdev.c
+++ b/lib/scsi/scsi_bdev.c
@@ -38,7 +38,7 @@
  * TODO: move bdev SCSI error code translation tests to bdev unit test
  * and remove this include.
  */
-#include "spdk_internal/bdev.h"
+#include "spdk/bdev_module.h"
 
 #include "spdk/env.h"
 #include "spdk/bdev.h"
@@ -60,6 +60,8 @@
 #define INQUIRY_OFFSET(field)		offsetof(struct spdk_scsi_cdb_inquiry_data, field) + \
 					sizeof(((struct spdk_scsi_cdb_inquiry_data *)0x0)->field)
 
+static void spdk_bdev_scsi_process_block_resubmit(void *arg);
+
 static int
 spdk_hex2bin(char ch)
 {
@@ -1294,6 +1296,24 @@ spdk_bdev_scsi_task_complete_mgmt(struct spdk_bdev_io *bdev_io, bool success,
 	spdk_scsi_lun_complete_mgmt_task(task->lun, task);
 }
 
+static void
+spdk_bdev_scsi_queue_io(struct spdk_scsi_task *task, spdk_bdev_io_wait_cb cb_fn, void *cb_arg)
+{
+	struct spdk_scsi_lun *lun = task->lun;
+	struct spdk_bdev *bdev = lun->bdev;
+	struct spdk_io_channel *ch = lun->io_channel;
+	int rc;
+
+	task->bdev_io_wait.bdev = bdev;
+	task->bdev_io_wait.cb_fn = cb_fn;
+	task->bdev_io_wait.cb_arg = cb_arg;
+
+	rc = spdk_bdev_queue_io_wait(bdev, ch, &task->bdev_io_wait);
+	if (rc != 0) {
+		assert(false);
+	}
+}
+
 static int
 spdk_bdev_scsi_read(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 		    struct spdk_io_channel *bdev_ch, struct spdk_scsi_task *task,
@@ -1317,7 +1337,12 @@ spdk_bdev_scsi_read(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 	rc = spdk_bdev_readv(bdev_desc, bdev_ch, task->iovs,
 			     task->iovcnt, offset, nbytes,
 			     spdk_bdev_scsi_task_complete_cmd, task);
+
 	if (rc) {
+		if (rc == -ENOMEM) {
+			spdk_bdev_scsi_queue_io(task, spdk_bdev_scsi_process_block_resubmit, task);
+			return SPDK_SCSI_TASK_PENDING;
+		}
 		SPDK_ERRLOG("spdk_bdev_readv() failed\n");
 		spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
 					  SPDK_SCSI_SENSE_NO_SENSE,
@@ -1327,8 +1352,6 @@ spdk_bdev_scsi_read(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 	}
 
 	task->data_transferred = nbytes;
-	task->status = SPDK_SCSI_STATUS_GOOD;
-
 	return SPDK_SCSI_TASK_PENDING;
 }
 
@@ -1367,6 +1390,10 @@ spdk_bdev_scsi_write(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 			      task);
 
 	if (rc) {
+		if (rc == -ENOMEM) {
+			spdk_bdev_scsi_queue_io(task, spdk_bdev_scsi_process_block_resubmit, task);
+			return SPDK_SCSI_TASK_PENDING;
+		}
 		SPDK_ERRLOG("spdk_bdev_writev failed\n");
 		spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
 					  SPDK_SCSI_SENSE_NO_SENSE,
@@ -1379,7 +1406,6 @@ spdk_bdev_scsi_write(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 		      (uint64_t)task->length, nbytes);
 
 	task->data_transferred = task->length;
-	task->status = SPDK_SCSI_STATUS_GOOD;
 	return SPDK_SCSI_TASK_PENDING;
 }
 
@@ -1411,6 +1437,10 @@ spdk_bdev_scsi_sync(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 				    spdk_bdev_scsi_task_complete_cmd, task);
 
 	if (rc) {
+		if (rc == -ENOMEM) {
+			spdk_bdev_scsi_queue_io(task, spdk_bdev_scsi_process_block_resubmit, task);
+			return SPDK_SCSI_TASK_PENDING;
+		}
 		SPDK_ERRLOG("spdk_bdev_flush_blocks() failed\n");
 		spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
 					  SPDK_SCSI_SENSE_NO_SENSE,
@@ -1419,7 +1449,6 @@ spdk_bdev_scsi_sync(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 		return SPDK_SCSI_TASK_COMPLETE;
 	}
 	task->data_transferred = 0;
-	task->status = SPDK_SCSI_STATUS_GOOD;
 	return SPDK_SCSI_TASK_PENDING;
 }
 
@@ -1486,6 +1515,9 @@ struct spdk_bdev_scsi_unmap_ctx {
 	uint32_t			count;
 };
 
+static int spdk_bdev_scsi_unmap(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
+				struct spdk_io_channel *bdev_ch, struct spdk_scsi_task *task, struct spdk_bdev_scsi_unmap_ctx *ctx);
+
 static void
 spdk_bdev_scsi_task_complete_unmap_cmd(struct spdk_bdev_io *bdev_io, bool success,
 				       void *cb_arg)
@@ -1543,27 +1575,41 @@ __copy_desc(struct spdk_bdev_scsi_unmap_ctx *ctx, uint8_t *data, size_t data_len
 	return desc_count;
 }
 
+static void
+spdk_bdev_scsi_unmap_resubmit(void *arg)
+{
+	struct spdk_bdev_scsi_unmap_ctx	*ctx = arg;
+	struct spdk_scsi_task *task = ctx->task;
+	struct spdk_scsi_lun *lun = task->lun;
+
+	spdk_bdev_scsi_unmap(lun->bdev, lun->bdev_desc, lun->io_channel, task, ctx);
+}
+
 static int
 spdk_bdev_scsi_unmap(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
-		     struct spdk_io_channel *bdev_ch, struct spdk_scsi_task *task)
+		     struct spdk_io_channel *bdev_ch, struct spdk_scsi_task *task, struct spdk_bdev_scsi_unmap_ctx *ctx)
 {
 	uint8_t				*data;
-	struct spdk_bdev_scsi_unmap_ctx	*ctx;
 	int				desc_count, i;
 	int				data_len;
 	int				rc;
 
-	ctx = calloc(1, sizeof(*ctx));
-	if (!ctx) {
-		spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
-					  SPDK_SCSI_SENSE_NO_SENSE,
-					  SPDK_SCSI_ASC_NO_ADDITIONAL_SENSE,
-					  SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
-		return SPDK_SCSI_TASK_COMPLETE;
+	assert(task->status == SPDK_SCSI_STATUS_GOOD);
+
+	if (ctx == NULL) {
+		ctx = calloc(1, sizeof(*ctx));
+		if (!ctx) {
+			spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
+						  SPDK_SCSI_SENSE_NO_SENSE,
+						  SPDK_SCSI_ASC_NO_ADDITIONAL_SENSE,
+						  SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
+			return SPDK_SCSI_TASK_COMPLETE;
+		}
+
+		ctx->task = task;
+		ctx->count = 0;
 	}
 
-	ctx->task = task;
-	ctx->count = 0;
 
 	if (task->iovcnt == 1) {
 		data = (uint8_t *)task->iovs[0].iov_base;
@@ -1586,13 +1632,7 @@ spdk_bdev_scsi_unmap(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 		return SPDK_SCSI_TASK_COMPLETE;
 	}
 
-	/* Before we submit commands, set the status to success */
-	spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_GOOD,
-				  SPDK_SCSI_SENSE_NO_SENSE,
-				  SPDK_SCSI_ASC_NO_ADDITIONAL_SENSE,
-				  SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
-
-	for (i = 0; i < desc_count; i++) {
+	for (i = ctx->count; i < desc_count; i++) {
 		struct spdk_scsi_unmap_bdesc	*desc;
 		uint64_t offset_blocks;
 		uint64_t num_blocks;
@@ -1611,6 +1651,12 @@ spdk_bdev_scsi_unmap(struct spdk_bdev *bdev, struct spdk_bdev_desc *bdev_desc,
 					    spdk_bdev_scsi_task_complete_unmap_cmd, ctx);
 
 		if (rc) {
+			if (rc == -ENOMEM) {
+				spdk_bdev_scsi_queue_io(task, spdk_bdev_scsi_unmap_resubmit, ctx);
+				/* Unmap was not yet submitted to bdev */
+				ctx->count--;
+				return SPDK_SCSI_TASK_PENDING;
+			}
 			SPDK_ERRLOG("SCSI Unmapping failed\n");
 			spdk_scsi_task_set_status(task, SPDK_SCSI_STATUS_CHECK_CONDITION,
 						  SPDK_SCSI_SENSE_NO_SENSE,
@@ -1745,7 +1791,7 @@ spdk_bdev_scsi_process_block(struct spdk_scsi_task *task)
 		break;
 
 	case SPDK_SBC_UNMAP:
-		return spdk_bdev_scsi_unmap(bdev, lun->bdev_desc, lun->io_channel, task);
+		return spdk_bdev_scsi_unmap(bdev, lun->bdev_desc, lun->io_channel, task, NULL);
 
 	default:
 		return SPDK_SCSI_TASK_UNKNOWN;
@@ -1754,6 +1800,14 @@ spdk_bdev_scsi_process_block(struct spdk_scsi_task *task)
 	return SPDK_SCSI_TASK_COMPLETE;
 }
 
+static void
+spdk_bdev_scsi_process_block_resubmit(void *arg)
+{
+	struct spdk_scsi_task *task = arg;
+
+	spdk_bdev_scsi_process_block(task);
+}
+
 static int
 spdk_bdev_scsi_check_len(struct spdk_scsi_task *task, int len, int min_len)
 {
@@ -2041,11 +2095,22 @@ spdk_bdev_scsi_execute(struct spdk_scsi_task *task)
 	return rc;
 }
 
-int
+static void
+spdk_bdev_scsi_reset_resubmit(void *arg)
+{
+	struct spdk_scsi_task *task = arg;
+
+	spdk_bdev_scsi_reset(task);
+}
+
+void
 spdk_bdev_scsi_reset(struct spdk_scsi_task *task)
 {
 	struct spdk_scsi_lun *lun = task->lun;
+	int rc;
 
-	return spdk_bdev_reset(lun->bdev_desc, lun->io_channel,
-			       spdk_bdev_scsi_task_complete_mgmt, task);
+	rc = spdk_bdev_reset(lun->bdev_desc, lun->io_channel, spdk_bdev_scsi_task_complete_mgmt, task);
+	if (rc == -ENOMEM) {
+		spdk_bdev_scsi_queue_io(task, spdk_bdev_scsi_reset_resubmit, task);
+	}
 }
diff --git a/lib/scsi/scsi_internal.h b/lib/scsi/scsi_internal.h
index 465d2695b..85caf7621 100644
--- a/lib/scsi/scsi_internal.h
+++ b/lib/scsi/scsi_internal.h
@@ -72,6 +72,13 @@ struct spdk_scsi_dev {
 	uint8_t			protocol_id;
 };
 
+struct spdk_scsi_desc {
+	struct spdk_scsi_lun		*lun;
+	spdk_scsi_remove_cb_t		hotremove_cb;
+	void				*hotremove_ctx;
+	TAILQ_ENTRY(spdk_scsi_desc)	link;
+};
+
 struct spdk_scsi_lun {
 	/** LUN id for this logical unit. */
 	int id;
@@ -88,19 +95,14 @@ struct spdk_scsi_lun {
 	/** I/O channel for the bdev associated with this LUN. */
 	struct spdk_io_channel *io_channel;
 
-	/** Thread ID for the thread that allocated the I/O channel for this
-	 *   LUN.  All I/O to this LUN must be performed from this thread.
-	 */
-	pthread_t thread_id;
-
 	/**  The reference number for this LUN, thus we can correctly free the io_channel */
 	uint32_t ref;
 
 	/** Poller to release the resource of the lun when it is hot removed */
-	struct spdk_poller *hotplug_poller;
+	struct spdk_poller *hotremove_poller;
 
 	/** The LUN is removed */
-	bool				removed;
+	bool removed;
 
 	/** Callback to be fired when LUN removal is first triggered. */
 	void (*hotremove_cb)(const struct spdk_scsi_lun *lun, void *arg);
@@ -108,7 +110,11 @@ struct spdk_scsi_lun {
 	/** Argument for hotremove_cb */
 	void *hotremove_ctx;
 
-	TAILQ_HEAD(tasks, spdk_scsi_task) tasks;			/* pending tasks */
+	/** List of open descriptors for this LUN. */
+	TAILQ_HEAD(, spdk_scsi_desc) open_descs;
+
+	/** pending tasks */
+	TAILQ_HEAD(tasks, spdk_scsi_task) tasks;
 };
 
 struct spdk_lun_db_entry {
@@ -132,9 +138,9 @@ void spdk_scsi_lun_execute_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task
 int spdk_scsi_lun_task_mgmt_execute(struct spdk_scsi_task *task, enum spdk_scsi_task_func func);
 void spdk_scsi_lun_complete_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task *task);
 void spdk_scsi_lun_complete_mgmt_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task *task);
-int spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun);
-void spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun);
 bool spdk_scsi_lun_has_pending_tasks(const struct spdk_scsi_lun *lun);
+int _spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun);
+void _spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun);
 
 struct spdk_scsi_dev *spdk_scsi_dev_get_list(void);
 
@@ -143,7 +149,7 @@ int spdk_scsi_port_construct(struct spdk_scsi_port *port, uint64_t id,
 void spdk_scsi_port_destruct(struct spdk_scsi_port *port);
 
 int spdk_bdev_scsi_execute(struct spdk_scsi_task *task);
-int spdk_bdev_scsi_reset(struct spdk_scsi_task *task);
+void spdk_bdev_scsi_reset(struct spdk_scsi_task *task);
 
 struct spdk_scsi_globals {
 	pthread_mutex_t mutex;
diff --git a/lib/scsi/scsi_rpc.c b/lib/scsi/scsi_rpc.c
index 9b75afc21..150069a99 100644
--- a/lib/scsi/scsi_rpc.c
+++ b/lib/scsi/scsi_rpc.c
@@ -79,4 +79,4 @@ spdk_rpc_get_scsi_devices(struct spdk_jsonrpc_request *request,
 
 	spdk_jsonrpc_end_result(request, w);
 }
-SPDK_RPC_REGISTER("get_scsi_devices", spdk_rpc_get_scsi_devices)
+SPDK_RPC_REGISTER("get_scsi_devices", spdk_rpc_get_scsi_devices, SPDK_RPC_RUNTIME)
diff --git a/lib/scsi/task.c b/lib/scsi/task.c
index 72546c2ec..6ddc00858 100644
--- a/lib/scsi/task.c
+++ b/lib/scsi/task.c
@@ -37,6 +37,9 @@
 #include "spdk/env.h"
 #include "spdk/util.h"
 
+static void
+spdk_scsi_task_free_data(struct spdk_scsi_task *task);
+
 void
 spdk_scsi_task_put(struct spdk_scsi_task *task)
 {
@@ -81,7 +84,7 @@ spdk_scsi_task_construct(struct spdk_scsi_task *task,
 	task->iovcnt = 1;
 }
 
-void
+static void
 spdk_scsi_task_free_data(struct spdk_scsi_task *task)
 {
 	if (task->alloc_len != 0) {
@@ -93,7 +96,7 @@ spdk_scsi_task_free_data(struct spdk_scsi_task *task)
 	task->iov.iov_len = 0;
 }
 
-void *
+static void *
 spdk_scsi_task_alloc_data(struct spdk_scsi_task *task, uint32_t alloc_len)
 {
 	assert(task->alloc_len == 0);
@@ -242,3 +245,12 @@ spdk_scsi_task_set_status(struct spdk_scsi_task *task, int sc, int sk,
 	}
 	task->status = sc;
 }
+
+void
+spdk_scsi_task_copy_status(struct spdk_scsi_task *dst,
+			   struct spdk_scsi_task *src)
+{
+	memcpy(dst->sense_data, src->sense_data, src->sense_data_len);
+	dst->sense_data_len = src->sense_data_len;
+	dst->status = src->status;
+}
diff --git a/lib/sock/Makefile b/lib/sock/Makefile
new file mode 100644
index 000000000..8860556d1
--- /dev/null
+++ b/lib/sock/Makefile
@@ -0,0 +1,44 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+
+C_SRCS = sock.c net_framework.c
+
+LIBNAME = sock
+
+DIRS-y += posix
+DIRS-$(CONFIG_VPP) += vpp
+
+include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/net/net_framework.c b/lib/sock/net_framework.c
similarity index 100%
rename from lib/net/net_framework.c
rename to lib/sock/net_framework.c
diff --git a/lib/net/posix/Makefile b/lib/sock/posix/Makefile
similarity index 98%
rename from lib/net/posix/Makefile
rename to lib/sock/posix/Makefile
index 7da760f58..540694c45 100644
--- a/lib/net/posix/Makefile
+++ b/lib/sock/posix/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-LIBNAME = net_posix
+LIBNAME = sock_posix
 C_SRCS = posix.c
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/net/posix/posix.c b/lib/sock/posix/posix.c
similarity index 100%
rename from lib/net/posix/posix.c
rename to lib/sock/posix/posix.c
diff --git a/lib/net/sock.c b/lib/sock/sock.c
similarity index 100%
rename from lib/net/sock.c
rename to lib/sock/sock.c
diff --git a/lib/net/vpp/Makefile b/lib/sock/vpp/Makefile
similarity index 98%
rename from lib/net/vpp/Makefile
rename to lib/sock/vpp/Makefile
index b513abf2b..614fd2e30 100644
--- a/lib/net/vpp/Makefile
+++ b/lib/sock/vpp/Makefile
@@ -36,6 +36,6 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
 C_SRCS += vpp.c
 
-LIBNAME = net_vpp
+LIBNAME = sock_vpp
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/net/vpp/vpp.c b/lib/sock/vpp/vpp.c
similarity index 100%
rename from lib/net/vpp/vpp.c
rename to lib/sock/vpp/vpp.c
diff --git a/lib/cunit/Makefile b/lib/thread/Makefile
similarity index 96%
rename from lib/cunit/Makefile
rename to lib/thread/Makefile
index 659d784d7..467e32ff9 100644
--- a/lib/cunit/Makefile
+++ b/lib/thread/Makefile
@@ -34,8 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-CFLAGS += -I$(SPDK_ROOT_DIR)/test
-C_SRCS = spdk_cunit.c
-LIBNAME = cunit
+C_SRCS = thread.c
+LIBNAME = thread
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/util/io_channel.c b/lib/thread/thread.c
similarity index 93%
rename from lib/util/io_channel.c
rename to lib/thread/thread.c
index 97681c560..5c1167465 100644
--- a/lib/util/io_channel.c
+++ b/lib/thread/thread.c
@@ -33,7 +33,7 @@
 
 #include "spdk/stdinc.h"
 
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/log.h"
 
 #ifdef __linux__
@@ -75,6 +75,7 @@ struct spdk_thread {
 };
 
 static TAILQ_HEAD(, spdk_thread) g_threads = TAILQ_HEAD_INITIALIZER(g_threads);
+static uint32_t g_thread_count = 0;
 
 static struct spdk_thread *
 _get_thread(void)
@@ -137,6 +138,7 @@ spdk_allocate_thread(spdk_thread_pass_msg msg_fn,
 	thread->thread_ctx = thread_ctx;
 	TAILQ_INIT(&thread->io_channels);
 	TAILQ_INSERT_TAIL(&g_threads, thread, tailq);
+	g_thread_count++;
 	if (name) {
 		_set_thread_name(name);
 		thread->name = strdup(name);
@@ -161,6 +163,8 @@ spdk_free_thread(void)
 		return;
 	}
 
+	assert(g_thread_count > 0);
+	g_thread_count--;
 	TAILQ_REMOVE(&g_threads, thread, tailq);
 	free(thread->name);
 	free(thread);
@@ -168,6 +172,17 @@ spdk_free_thread(void)
 	pthread_mutex_unlock(&g_devlist_mutex);
 }
 
+uint32_t
+spdk_thread_get_count(void)
+{
+	/*
+	 * Return cached value of the current thread count.  We could acquire the
+	 *  lock and iterate through the TAILQ of threads to count them, but that
+	 *  count could still be invalidated after we release the lock.
+	 */
+	return g_thread_count;
+}
+
 struct spdk_thread *
 spdk_get_thread(void)
 {
@@ -208,18 +223,21 @@ spdk_poller_register(spdk_poller_fn fn,
 
 	thread = spdk_get_thread();
 	if (!thread) {
-		abort();
+		assert(false);
+		return NULL;
 	}
 
 	if (!thread->start_poller_fn || !thread->stop_poller_fn) {
 		SPDK_ERRLOG("No related functions to start requested poller\n");
-		abort();
+		assert(false);
+		return NULL;
 	}
 
 	poller = thread->start_poller_fn(thread->thread_ctx, fn, arg, period_microseconds);
 	if (!poller) {
 		SPDK_ERRLOG("Unable to start requested poller\n");
-		abort();
+		assert(false);
+		return NULL;
 	}
 
 	return poller;
@@ -373,6 +391,7 @@ spdk_io_device_unregister(void *io_device, spdk_io_device_unregister_cb unregist
 
 	if (!dev) {
 		SPDK_ERRLOG("io_device %p not found\n", io_device);
+		assert(false);
 		pthread_mutex_unlock(&g_devlist_mutex);
 		return;
 	}
@@ -474,8 +493,21 @@ _spdk_put_io_channel(void *arg)
 	bool do_remove_dev = true;
 
 	assert(ch->thread == spdk_get_thread());
-	assert(ch->ref == 0);
 
+	if (ch->ref > 0) {
+		/*
+		 * Another reference to the associated io_device was requested
+		 *  after this message was sent but before it had a chance to
+		 *  execute.
+		 */
+		return;
+	}
+
+	pthread_mutex_lock(&g_devlist_mutex);
+	TAILQ_REMOVE(&ch->thread->io_channels, ch, tailq);
+	pthread_mutex_unlock(&g_devlist_mutex);
+
+	/* Don't hold the devlist mutex while the destroy_cb is called. */
 	ch->destroy_cb(ch->dev->io_device, spdk_io_channel_get_ctx(ch));
 
 	pthread_mutex_lock(&g_devlist_mutex);
@@ -503,11 +535,6 @@ spdk_put_io_channel(struct spdk_io_channel *ch)
 	ch->ref--;
 
 	if (ch->ref == 0) {
-		/* If this was the last reference, remove the channel from the list */
-		pthread_mutex_lock(&g_devlist_mutex);
-		TAILQ_REMOVE(&ch->thread->io_channels, ch, tailq);
-		pthread_mutex_unlock(&g_devlist_mutex);
-
 		spdk_thread_send_msg(ch->thread, _spdk_put_io_channel, ch);
 	}
 }
@@ -631,9 +658,7 @@ spdk_for_each_channel(void *io_device, spdk_channel_msg fn, void *ctx,
 
 	pthread_mutex_unlock(&g_devlist_mutex);
 
-	cpl(i, 0);
-
-	free(i);
+	spdk_thread_send_msg(i->orig_thread, _call_completion, i);
 }
 
 void
diff --git a/lib/util/Makefile b/lib/util/Makefile
index 4e2773a4f..1dd0f395c 100644
--- a/lib/util/Makefile
+++ b/lib/util/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-C_SRCS = bit_array.c cpuset.c crc16.c crc32.c crc32c.c crc32_ieee.c fd.c io_channel.c strerror_tls.c string.c uuid.c
+C_SRCS = base64.c bit_array.c cpuset.c crc16.c crc32.c crc32c.c crc32_ieee.c fd.c strerror_tls.c string.c uuid.c
 LIBNAME = util
 
 include $(SPDK_ROOT_DIR)/mk/spdk.lib.mk
diff --git a/lib/util/base64.c b/lib/util/base64.c
new file mode 100644
index 000000000..81361263b
--- /dev/null
+++ b/lib/util/base64.c
@@ -0,0 +1,228 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright(c) Intel Corporation. All rights reserved.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/stdinc.h"
+#include "spdk/endian.h"
+#include "spdk/base64.h"
+
+#define BASE64_ENC_BITMASK 0x3FUL
+#define BASE64_PADDING_CHAR '='
+
+static const char base64_enc_table[] =
+	"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+	"abcdefghijklmnopqrstuvwxyz"
+	"0123456789+/";
+
+static const char base64_urfsafe_enc_table[] =
+	"ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+	"abcdefghijklmnopqrstuvwxyz"
+	"0123456789-_";
+
+static const uint8_t
+base64_dec_table[] = {
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  62, 255, 255, 255,  63,
+	52,  53,  54,  55,  56,  57,  58,  59,  60,  61, 255, 255, 255, 255, 255, 255,
+	255,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,
+	15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25, 255, 255, 255, 255, 255,
+	255,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,
+	41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+};
+
+static const uint8_t
+base64_urlsafe_dec_table[] = {
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,  62, 255, 255,
+	52,  53,  54,  55,  56,  57,  58,  59,  60,  61, 255, 255, 255, 255, 255, 255,
+	255,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,
+	15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25, 255, 255, 255, 255,  63,
+	255,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,
+	41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+	255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
+};
+
+static int
+_spdk_base64_encode(char *dst, const char *enc_table, const void *src, size_t src_len)
+{
+	uint32_t raw_u32;
+
+	if (!dst || !src || src_len <= 0) {
+		return -EINVAL;
+	}
+
+	while (src_len >= 4) {
+		raw_u32 = from_be32(src);
+
+		*dst++ = enc_table[(raw_u32 >> 26) & BASE64_ENC_BITMASK];
+		*dst++ = enc_table[(raw_u32 >> 20) & BASE64_ENC_BITMASK];
+		*dst++ = enc_table[(raw_u32 >> 14) & BASE64_ENC_BITMASK];
+		*dst++ = enc_table[(raw_u32 >> 8) & BASE64_ENC_BITMASK];
+
+		src_len -= 3;
+		src += 3;
+	}
+
+	if (src_len == 0) {
+		goto out;
+	}
+
+	raw_u32 = 0;
+	memcpy(&raw_u32, src, src_len);
+	raw_u32 = from_be32(&raw_u32);
+
+	*dst++ = enc_table[(raw_u32 >> 26) & BASE64_ENC_BITMASK];
+	*dst++ = enc_table[(raw_u32 >> 20) & BASE64_ENC_BITMASK];
+	*dst++ = (src_len >= 2) ? enc_table[(raw_u32 >> 14) & BASE64_ENC_BITMASK] : BASE64_PADDING_CHAR;
+	*dst++ = (src_len == 3) ? enc_table[(raw_u32 >> 8) & BASE64_ENC_BITMASK] : BASE64_PADDING_CHAR;
+
+out:
+	*dst = '\0';
+
+	return 0;
+}
+
+int
+spdk_base64_encode(char *dst, const void *src, size_t src_len)
+{
+	return _spdk_base64_encode(dst, base64_enc_table, src, src_len);
+}
+
+int
+spdk_base64_urlsafe_encode(char *dst, const void *src, size_t src_len)
+{
+	return _spdk_base64_encode(dst, base64_urfsafe_enc_table, src, src_len);
+}
+
+static int
+_spdk_base64_decode(void *dst, size_t *_dst_len, const uint8_t *dec_table, const char *src)
+{
+	size_t src_strlen, dst_len;
+	size_t tail_len = 0;
+	const uint8_t *src_in;
+	uint32_t tmp[4];
+	int i;
+
+	if (!dst || !src) {
+		return -EINVAL;
+	}
+
+	src_strlen = strlen(src);
+
+	/* strlen of src should be 4n */
+	if (src_strlen == 0 || src_strlen % 4 != 0) {
+		return -EINVAL;
+	}
+
+	/* Consider Base64 padding, it at most has 2 padding characters. */
+	for (i = 0; i < 2; i++) {
+		if (src[src_strlen - 1] != BASE64_PADDING_CHAR) {
+			break;
+		}
+		src_strlen--;
+	}
+
+	/* strlen of src without padding shouldn't be 4n+1 */
+	if (src_strlen == 0 || src_strlen % 4 == 1) {
+		return -EINVAL;
+	}
+
+	dst_len = spdk_base64_get_decoded_len(src_strlen);
+	src_in = (const uint8_t *) src;
+
+	/* space of dst can be used by to_be32 */
+	while (src_strlen > 4) {
+		tmp[0] = dec_table[*src_in++];
+		tmp[1] = dec_table[*src_in++];
+		tmp[2] = dec_table[*src_in++];
+		tmp[3] = dec_table[*src_in++];
+
+		if (tmp[0] == 255 || tmp[1] == 255 || tmp[2] == 255 || tmp[3] == 255) {
+			return -EINVAL;
+		}
+
+		to_be32(dst, tmp[3] << 8 | tmp[2] << 14 | tmp[1] << 20 | tmp[0] << 26);
+
+		dst += 3;
+		src_strlen -= 4;
+	}
+
+	/* space of dst is not enough to be used by to_be32 */
+	tmp[0] = dec_table[src_in[0]];
+	tmp[1] = dec_table[src_in[1]];
+	tmp[2] = (src_strlen >= 3) ? dec_table[src_in[2]] : 0;
+	tmp[3] = (src_strlen == 4) ? dec_table[src_in[3]] : 0;
+	tail_len = src_strlen - 1;
+
+	if (tmp[0] == 255 || tmp[1] == 255 || tmp[2] == 255 || tmp[3] == 255) {
+		return -EINVAL;
+	}
+
+	to_be32(&tmp[3], tmp[3] << 8 | tmp[2] << 14 | tmp[1] << 20 | tmp[0] << 26);
+	memcpy(dst, (uint8_t *)&tmp[3], tail_len);
+
+	/* Assign pointers */
+	if (_dst_len) {
+		*_dst_len = dst_len;
+	}
+
+	return 0;
+}
+
+int
+spdk_base64_decode(void *dst, size_t *dst_len, const char *src)
+{
+	return _spdk_base64_decode(dst, dst_len, base64_dec_table, src);
+}
+
+int
+spdk_base64_urlsafe_decode(void *dst, size_t *dst_len, const char *src)
+{
+	return _spdk_base64_decode(dst, dst_len, base64_urlsafe_dec_table, src);
+}
diff --git a/lib/util/bit_array.c b/lib/util/bit_array.c
index cf5753bbc..394b84bbb 100644
--- a/lib/util/bit_array.c
+++ b/lib/util/bit_array.c
@@ -41,6 +41,7 @@
 
 typedef uint64_t spdk_bit_array_word;
 #define SPDK_BIT_ARRAY_WORD_TZCNT(x)	(__builtin_ctzll(x))
+#define SPDK_BIT_ARRAY_WORD_POPCNT(x)	(__builtin_popcountll(x))
 #define SPDK_BIT_ARRAY_WORD_C(x)	((spdk_bit_array_word)(x))
 #define SPDK_BIT_ARRAY_WORD_BYTES	sizeof(spdk_bit_array_word)
 #define SPDK_BIT_ARRAY_WORD_BITS	(SPDK_BIT_ARRAY_WORD_BYTES * 8)
@@ -270,3 +271,27 @@ spdk_bit_array_find_first_clear(const struct spdk_bit_array *ba, uint32_t start_
 {
 	return _spdk_bit_array_find_first(ba, start_bit_index, SPDK_BIT_ARRAY_WORD_C(-1));
 }
+
+uint32_t
+spdk_bit_array_count_set(const struct spdk_bit_array *ba)
+{
+	const spdk_bit_array_word *cur_word = ba->words;
+	uint32_t word_count = spdk_bit_array_word_count(ba->bit_count);
+	uint32_t set_count = 0;
+
+	while (word_count--) {
+		/*
+		 * No special treatment is needed for the last (potentially partial) word, since
+		 * spdk_bit_array_resize() makes sure the bits past bit_count are cleared.
+		 */
+		set_count += SPDK_BIT_ARRAY_WORD_POPCNT(*cur_word++);
+	}
+
+	return set_count;
+}
+
+uint32_t
+spdk_bit_array_count_clear(const struct spdk_bit_array *ba)
+{
+	return ba->bit_count - spdk_bit_array_count_set(ba);
+}
diff --git a/lib/vhost/rte_vhost/vhost_user.c b/lib/vhost/rte_vhost/vhost_user.c
index 80a6e4f0e..2acf08849 100644
--- a/lib/vhost/rte_vhost/vhost_user.c
+++ b/lib/vhost/rte_vhost/vhost_user.c
@@ -1193,10 +1193,6 @@ vhost_user_msg_handler(int vid, int fd)
 		if (cmd[0] == 0x06) {
 			memcpy(msg.payload.nvme.buf, &buf, 4096);
 			msg.size += 4096;
-		} else if (cmd[0] == 0x09 || cmd[0] == 0x0a) {
-			memcpy(&msg.payload.nvme.buf, &buf, 4);
-			msg.size += 4096;
-
 		}
 		send_vhost_message(fd, &msg);
 		break;
diff --git a/lib/vhost/vhost.c b/lib/vhost/vhost.c
index 002799b91..b0b531da3 100644
--- a/lib/vhost/vhost.c
+++ b/lib/vhost/vhost.c
@@ -338,7 +338,7 @@ spdk_vhost_set_coalescing(struct spdk_vhost_dev *vdev, uint32_t delay_base_us,
 			  uint32_t iops_threshold)
 {
 	uint64_t delay_time_base = delay_base_us * spdk_get_ticks_hz() / 1000000ULL;
-	uint32_t io_rate = iops_threshold * SPDK_VHOST_DEV_STATS_CHECK_INTERVAL_MS / 1000;
+	uint32_t io_rate = iops_threshold * SPDK_VHOST_DEV_STATS_CHECK_INTERVAL_MS / 1000U;
 
 	if (delay_time_base >= UINT32_MAX) {
 		SPDK_ERRLOG("Delay time of %"PRIu32" is to big\n", delay_base_us);
@@ -351,9 +351,25 @@ spdk_vhost_set_coalescing(struct spdk_vhost_dev *vdev, uint32_t delay_base_us,
 
 	vdev->coalescing_delay_time_base = delay_time_base;
 	vdev->coalescing_io_rate_threshold = io_rate;
+
+	vdev->coalescing_delay_us = delay_base_us;
+	vdev->coalescing_iops_threshold = iops_threshold;
 	return 0;
 }
 
+void
+spdk_vhost_get_coalescing(struct spdk_vhost_dev *vdev, uint32_t *delay_base_us,
+			  uint32_t *iops_threshold)
+{
+	if (delay_base_us) {
+		*delay_base_us = vdev->coalescing_delay_us;
+	}
+
+	if (iops_threshold) {
+		*iops_threshold = vdev->coalescing_iops_threshold;
+	}
+}
+
 /*
  * Enqueue id and len to used ring.
  */
@@ -1301,8 +1317,22 @@ int
 spdk_vhost_init(void)
 {
 	uint32_t last_core;
+	size_t len;
 	int ret;
 
+	if (dev_dirname[0] == '\0') {
+		if (getcwd(dev_dirname, sizeof(dev_dirname) - 1) == NULL) {
+			SPDK_ERRLOG("getcwd failed (%d): %s\n", errno, spdk_strerror(errno));
+			return -1;
+		}
+
+		len = strlen(dev_dirname);
+		if (dev_dirname[len - 1] != '/') {
+			dev_dirname[len] = '/';
+			dev_dirname[len + 1] = '\0';
+		}
+	}
+
 	last_core = spdk_env_get_last_core();
 	g_num_ctrlrs = calloc(last_core + 1, sizeof(uint32_t));
 	if (!g_num_ctrlrs) {
@@ -1386,6 +1416,8 @@ static int
 spdk_vhost_config_json_cb(struct spdk_vhost_dev *vdev, void *arg)
 {
 	struct spdk_vhost_write_config_json_ctx *ctx = arg;
+	uint32_t delay_base_us;
+	uint32_t iops_threshold;
 
 	if (vdev == NULL) {
 		spdk_json_write_array_end(ctx->w);
@@ -1395,6 +1427,21 @@ spdk_vhost_config_json_cb(struct spdk_vhost_dev *vdev, void *arg)
 	}
 
 	vdev->backend->write_config_json(vdev, ctx->w);
+
+	spdk_vhost_get_coalescing(vdev, &delay_base_us, &iops_threshold);
+	if (delay_base_us) {
+		spdk_json_write_object_begin(ctx->w);
+		spdk_json_write_named_string(ctx->w, "method", "set_vhost_controller_coalescing");
+
+		spdk_json_write_named_object_begin(ctx->w, "params");
+		spdk_json_write_named_string(ctx->w, "ctrlr", vdev->name);
+		spdk_json_write_named_uint32(ctx->w, "delay_base_us", delay_base_us);
+		spdk_json_write_named_uint32(ctx->w, "iops_threshold", iops_threshold);
+		spdk_json_write_object_end(ctx->w);
+
+		spdk_json_write_object_end(ctx->w);
+	}
+
 	return 0;
 }
 
diff --git a/lib/vhost/vhost_blk.c b/lib/vhost/vhost_blk.c
index 9e986d499..a105b503f 100644
--- a/lib/vhost/vhost_blk.c
+++ b/lib/vhost/vhost_blk.c
@@ -36,7 +36,7 @@
 #include "spdk/env.h"
 #include "spdk/bdev.h"
 #include "spdk/conf.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/likely.h"
 #include "spdk/string.h"
 #include "spdk/util.h"
diff --git a/lib/vhost/vhost_internal.h b/lib/vhost/vhost_internal.h
index 33b8e7a7f..dfc0bf623 100644
--- a/lib/vhost/vhost_internal.h
+++ b/lib/vhost/vhost_internal.h
@@ -150,6 +150,12 @@ struct spdk_vhost_dev {
 
 	const struct spdk_vhost_dev_backend *backend;
 
+	/* Saved orginal values used to setup coalescing to avoid integer
+	 * rounding issues during save/load config.
+	 */
+	uint32_t coalescing_delay_us;
+	uint32_t coalescing_iops_threshold;
+
 	uint32_t coalescing_delay_time_base;
 
 	/* Threshold when event coalescing for virtqueue will be turned on. */
diff --git a/lib/vhost/vhost_nvme.c b/lib/vhost/vhost_nvme.c
index 75065f005..94bb80c3b 100644
--- a/lib/vhost/vhost_nvme.c
+++ b/lib/vhost/vhost_nvme.c
@@ -38,7 +38,7 @@
 #include "spdk/conf.h"
 #include "spdk/util.h"
 #include "spdk/string.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/barrier.h"
 #include "spdk/vhost.h"
 #include "spdk/bdev.h"
@@ -71,7 +71,9 @@ struct spdk_vhost_nvme_cq {
 	bool valid;
 	volatile struct spdk_nvme_cpl *cq_cqe;
 	uint16_t cq_head;
-	uint16_t last_signaled_cq_head;
+	uint16_t guest_signaled_cq_head;
+	uint32_t need_signaled_cnt;
+	STAILQ_HEAD(, spdk_vhost_nvme_task) cq_full_waited_tasks;
 	bool irq_enabled;
 	int virq;
 };
@@ -107,7 +109,9 @@ struct spdk_vhost_nvme_task {
 
 	/* parent pointer. */
 	struct spdk_vhost_nvme_task *parent;
-	bool success;
+	uint8_t dnr;
+	uint8_t sct;
+	uint8_t sc;
 	uint32_t num_children;
 	STAILQ_ENTRY(spdk_vhost_nvme_task) stailq;
 };
@@ -178,6 +182,12 @@ nvme_inc_cq_head(struct spdk_vhost_nvme_cq *cq)
 	}
 }
 
+static bool
+nvme_cq_is_full(struct spdk_vhost_nvme_cq *cq)
+{
+	return ((cq->cq_head + 1) % cq->size == cq->guest_signaled_cq_head);
+}
+
 static void
 nvme_inc_sq_head(struct spdk_vhost_nvme_sq *sq)
 {
@@ -276,62 +286,91 @@ spdk_nvme_map_prps(struct spdk_vhost_nvme_dev *nvme, struct spdk_nvme_cmd *cmd,
 }
 
 static void
-blk_request_complete_cb(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+spdk_nvme_cq_signal_fd(struct spdk_vhost_nvme_dev *nvme)
+{
+	struct spdk_vhost_nvme_cq *cq;
+	uint32_t qid, cq_head;
+
+	assert(nvme != NULL);
+
+	for (qid = 1; qid <= MAX_IO_QUEUES; qid++) {
+		cq = spdk_vhost_nvme_get_cq_from_qid(nvme, qid);
+		if (!cq || !cq->valid) {
+			continue;
+		}
+
+		cq_head = nvme->dbbuf_dbs[cq_offset(qid, 1)];
+		if (cq->irq_enabled && cq->need_signaled_cnt && (cq->cq_head != cq_head)) {
+			eventfd_write(cq->virq, (eventfd_t)1);
+			cq->need_signaled_cnt = 0;
+		}
+	}
+}
+
+static void
+spdk_vhost_nvme_task_complete(struct spdk_vhost_nvme_task *task)
 {
-	struct spdk_vhost_nvme_task *task = cb_arg;
 	struct spdk_vhost_nvme_dev *nvme = task->nvme;
-	uint16_t cqid;
 	struct spdk_nvme_cpl cqe = {0};
 	struct spdk_vhost_nvme_cq *cq;
 	struct spdk_vhost_nvme_sq *sq;
 	struct spdk_nvme_cmd *cmd = &task->cmd;
-	uint32_t cq_head;
-	int sc, sct;
-
-	if (spdk_likely(bdev_io)) {
-		spdk_bdev_free_io(bdev_io);
-	}
+	uint16_t cqid = task->cqid;
+	uint16_t sqid = task->sqid;
 
-	cqid = task->cqid;
 	cq = spdk_vhost_nvme_get_cq_from_qid(nvme, cqid);
-	sq = spdk_vhost_nvme_get_sq_from_qid(nvme, task->sqid);
+	sq = spdk_vhost_nvme_get_sq_from_qid(nvme, sqid);
 	if (spdk_unlikely(!cq || !sq)) {
-		spdk_bdev_free_io(bdev_io);
 		return;
 	}
 
-	cqe.sqid = task->sqid;
+	cq->guest_signaled_cq_head = nvme->dbbuf_dbs[cq_offset(cqid, 1)];
+	if (spdk_unlikely(nvme_cq_is_full(cq))) {
+		STAILQ_INSERT_TAIL(&cq->cq_full_waited_tasks, task, stailq);
+		return;
+	}
+
+	cqe.sqid = sqid;
 	cqe.sqhd = sq->sq_head;
 	cqe.cid = cmd->cid;
-	cqe.status.sct = 0;
-	cqe.status.sc = 0;
-	if (spdk_unlikely(!success)) {
-		spdk_bdev_io_get_nvme_status(bdev_io, &sct, &sc);
-		cqe.status.sct = sct;
-		cqe.status.sc = sc;
-		cqe.status.dnr = 1;
-		SPDK_ERRLOG("I/O error, sector %u\n", cmd->cdw10);
-	}
+	cqe.status.dnr = task->dnr;
+	cqe.status.sct = task->sct;
+	cqe.status.sc = task->sc;
 	cqe.status.p = !cq->phase;
 	cq->cq_cqe[cq->cq_head] = cqe;
 	spdk_smp_wmb();
 	cq->cq_cqe[cq->cq_head].status.p = cq->phase;
 
 	nvme_inc_cq_head(cq);
+	cq->need_signaled_cnt++;
 
-	/* completion */
-	cq_head = nvme->dbbuf_dbs[cq_offset(cqid, 1)];
-	if (cq_head != cq->last_signaled_cq_head) {
-		cq->last_signaled_cq_head = (uint16_t)cq_head;
-		/* MMIO Controll */
-		nvme->dbbuf_eis[cq_offset(cqid, 1)] = (uint32_t)(cq_head - 1);
-	}
+	/* MMIO Controll */
+	nvme->dbbuf_eis[cq_offset(cqid, 1)] = (uint32_t)(cq->guest_signaled_cq_head - 1);
+
+	STAILQ_INSERT_TAIL(&nvme->free_tasks, task, stailq);
+}
+
+static void
+blk_request_complete_cb(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+{
+	struct spdk_vhost_nvme_task *task = cb_arg;
+	struct spdk_nvme_cmd *cmd = &task->cmd;
+	int sc, sct;
+
+	assert(bdev_io != NULL);
+
+	spdk_bdev_io_get_nvme_status(bdev_io, &sct, &sc);
+	spdk_bdev_free_io(bdev_io);
+
+	task->dnr = !success;
+	task->sct = sct;
+	task->sc = sc;
 
-	if (cq->irq_enabled && (cq->cq_head != cq_head)) {
-		eventfd_write(cq->virq, (eventfd_t)1);
+	if (spdk_unlikely(!success)) {
+		SPDK_ERRLOG("I/O error, sector %u\n", cmd->cdw10);
 	}
 
-	STAILQ_INSERT_TAIL(&nvme->free_tasks, task, stailq);
+	spdk_vhost_nvme_task_complete(task);
 }
 
 static void
@@ -340,17 +379,22 @@ blk_unmap_complete_cb(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
 	struct spdk_vhost_nvme_task *child = cb_arg;
 	struct spdk_vhost_nvme_task *task = child->parent;
 	struct spdk_vhost_nvme_dev *nvme = task->nvme;
+	int sct, sc;
 
-	if (bdev_io) {
-		spdk_bdev_free_io(bdev_io);
-	}
+	assert(bdev_io != NULL);
 
 	task->num_children--;
 	if (!success) {
-		task->success = false;
+		task->dnr = 1;
+		spdk_bdev_io_get_nvme_status(bdev_io, &sct, &sc);
+		task->sct = sct;
+		task->sc = sc;
 	}
+
+	spdk_bdev_free_io(bdev_io);
+
 	if (!task->num_children) {
-		blk_request_complete_cb(NULL, task->success, task);
+		spdk_vhost_nvme_task_complete(task);
 	}
 
 	STAILQ_INSERT_TAIL(&nvme->free_tasks, child, stailq);
@@ -380,21 +424,29 @@ spdk_nvme_process_sq(struct spdk_vhost_nvme_dev *nvme, struct spdk_vhost_nvme_sq
 	uint16_t i, num_ranges = 0;
 
 	task->nvme = nvme;
+	task->dnr = 0;
+	task->sct = 0;
+	task->sc = 0;
 
 	ns = spdk_vhost_nvme_get_ns_from_nsid(nvme, cmd->nsid);
 	if (spdk_unlikely(!ns)) {
-		blk_request_complete_cb(NULL, false, task);
+		task->dnr = 1;
+		task->sct = SPDK_NVME_SCT_GENERIC;
+		task->sc = SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT;
+		spdk_vhost_nvme_task_complete(task);
 		return -1;
 	}
 
 	block_size = ns->block_size;
-	task->success = true;
 	task->num_children = 0;
 	task->cqid = sq->cqid;
 	task->sqid = sq->sqid;
 
 	if (spdk_unlikely(!ns->active_ns)) {
-		blk_request_complete_cb(NULL, false, task);
+		task->dnr = 1;
+		task->sct = SPDK_NVME_SCT_GENERIC;
+		task->sc = SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT;
+		spdk_vhost_nvme_task_complete(task);
 		return -1;
 	}
 
@@ -408,7 +460,10 @@ spdk_nvme_process_sq(struct spdk_vhost_nvme_dev *nvme, struct spdk_vhost_nvme_sq
 		if (cmd->psdt != SPDK_NVME_PSDT_PRP) {
 			SPDK_DEBUGLOG(SPDK_LOG_VHOST_NVME, "Invalid PSDT %u%ub in command\n",
 				      cmd->psdt >> 1, cmd->psdt & 1u);
-			blk_request_complete_cb(NULL, false, task);
+			task->dnr = 1;
+			task->sct = SPDK_NVME_SCT_GENERIC;
+			task->sc = SPDK_NVME_SC_INVALID_FIELD;
+			spdk_vhost_nvme_task_complete(task);
 			return -1;
 		}
 
@@ -422,7 +477,10 @@ spdk_nvme_process_sq(struct spdk_vhost_nvme_dev *nvme, struct spdk_vhost_nvme_sq
 		ret = spdk_nvme_map_prps(nvme, cmd, task, len);
 		if (spdk_unlikely(ret != 0)) {
 			SPDK_ERRLOG("nvme command map prps failed\n");
-			blk_request_complete_cb(NULL, false, task);
+			task->dnr = 1;
+			task->sct = SPDK_NVME_SCT_GENERIC;
+			task->sc = SPDK_NVME_SC_INVALID_FIELD;
+			spdk_vhost_nvme_task_complete(task);
 			return -1;
 		}
 	}
@@ -474,7 +532,10 @@ spdk_nvme_process_sq(struct spdk_vhost_nvme_dev *nvme, struct spdk_vhost_nvme_sq
 	if (spdk_unlikely(ret)) {
 		/* post error status to cqe */
 		SPDK_ERRLOG("Error Submission For Command %u, ret %d\n", cmd->opc, ret);
-		blk_request_complete_cb(NULL, false, task);
+		task->dnr = 1;
+		task->sct = SPDK_NVME_SCT_GENERIC;
+		task->sc = SPDK_NVME_SC_INTERNAL_DEVICE_ERROR;
+		spdk_vhost_nvme_task_complete(task);
 	}
 
 	return ret;
@@ -485,6 +546,7 @@ nvme_worker(void *arg)
 {
 	struct spdk_vhost_nvme_dev *nvme = (struct spdk_vhost_nvme_dev *)arg;
 	struct spdk_vhost_nvme_sq *sq;
+	struct spdk_vhost_nvme_cq *cq;
 	struct spdk_vhost_nvme_task *task;
 	uint32_t qid, dbbuf_sq;
 	int ret;
@@ -501,13 +563,23 @@ nvme_worker(void *arg)
 		return -1;
 	}
 
-	/* Submission Queue */
 	for (qid = 1; qid <= MAX_IO_QUEUES; qid++) {
 
 		sq = spdk_vhost_nvme_get_sq_from_qid(nvme, qid);
 		if (!sq->valid) {
 			continue;
 		}
+		cq = spdk_vhost_nvme_get_cq_from_qid(nvme, sq->cqid);
+		if (spdk_unlikely(!cq)) {
+			return -1;
+		}
+		cq->guest_signaled_cq_head = nvme->dbbuf_dbs[cq_offset(sq->cqid, 1)];
+		if (spdk_unlikely(!STAILQ_EMPTY(&cq->cq_full_waited_tasks) &&
+				  !nvme_cq_is_full(cq))) {
+			task = STAILQ_FIRST(&cq->cq_full_waited_tasks);
+			STAILQ_REMOVE_HEAD(&cq->cq_full_waited_tasks, stailq);
+			spdk_vhost_nvme_task_complete(task);
+		}
 
 		dbbuf_sq = nvme->dbbuf_dbs[sq_offset(qid, 1)];
 		sq->sq_tail = (uint16_t)dbbuf_sq;
@@ -544,6 +616,9 @@ nvme_worker(void *arg)
 		}
 	}
 
+	/* Completion Queue */
+	spdk_nvme_cq_signal_fd(nvme);
+
 	return count;
 }
 
@@ -689,7 +764,8 @@ vhost_nvme_create_io_cq(struct spdk_vhost_nvme_dev *nvme,
 	/* Setup virq through vhost messages */
 	cq->virq = -1;
 	cq->cq_head = 0;
-	cq->last_signaled_cq_head = 0;
+	cq->guest_signaled_cq_head = 0;
+	cq->need_signaled_cnt = 0;
 	requested_len = sizeof(struct spdk_nvme_cpl) * cq->size;
 	cq->cq_cqe = spdk_vhost_gpa_to_vva(&nvme->vdev, dma_addr, requested_len);
 	if (!cq->cq_cqe) {
@@ -697,6 +773,7 @@ vhost_nvme_create_io_cq(struct spdk_vhost_nvme_dev *nvme,
 	}
 	nvme->num_cqs++;
 	cq->valid = true;
+	STAILQ_INIT(&cq->cq_full_waited_tasks);
 
 	cpl->status.sc = 0;
 	cpl->status.sct = 0;
@@ -763,7 +840,6 @@ spdk_vhost_nvme_admin_passthrough(int vid, void *cmd, void *cqe, void *buf)
 	int ret = 0;
 	struct spdk_vhost_nvme_dev *nvme;
 	uint32_t cq_head, sq_tail;
-	uint32_t dw0;
 
 	nvme = spdk_vhost_nvme_get_by_name(vid);
 	if (!nvme) {
@@ -806,8 +882,7 @@ spdk_vhost_nvme_admin_passthrough(int vid, void *cmd, void *cqe, void *buf)
 		if (req->cdw10 == SPDK_NVME_FEAT_NUMBER_OF_QUEUES) {
 			cpl->status.sc = 0;
 			cpl->status.sct = 0;
-			dw0 = (nvme->num_io_queues - 1) | ((nvme->num_io_queues - 1) << 16);
-			memcpy(buf, &dw0, 4);
+			cpl->cdw0 = (nvme->num_io_queues - 1) | ((nvme->num_io_queues - 1) << 16);
 		} else {
 			cpl->status.sc = SPDK_NVME_SC_INVALID_FIELD;
 			cpl->status.sct = SPDK_NVME_SCT_GENERIC;
@@ -1029,41 +1104,74 @@ spdk_vhost_nvme_dump_info_json(struct spdk_vhost_dev *vdev, struct spdk_json_wri
 {
 	struct spdk_vhost_nvme_dev *nvme = to_nvme_dev(vdev);
 	struct spdk_vhost_nvme_ns *ns_dev;
-	struct spdk_bdev *bdev;
 	uint32_t i;
 
 	if (nvme == NULL) {
 		return;
 	}
 
-	spdk_json_write_name(w, "namespaces");
-	spdk_json_write_object_begin(w);
+	spdk_json_write_named_array_begin(w, "namespaces");
 
 	for (i = 0; i < nvme->num_ns; i++) {
 		ns_dev = &nvme->ns[i];
 		if (!ns_dev->active_ns) {
 			continue;
 		}
-		bdev = ns_dev->bdev;
 
-		spdk_json_write_name(w, "nsid");
-		spdk_json_write_uint32(w, ns_dev->nsid);
+		spdk_json_write_object_begin(w);
+		spdk_json_write_named_uint32(w, "nsid", ns_dev->nsid);
+		spdk_json_write_named_string(w, "bdev",  spdk_bdev_get_name(ns_dev->bdev));
+		spdk_json_write_object_end(w);
+	}
 
-		spdk_json_write_name(w, "bdev");
-		if (bdev) {
-			spdk_json_write_string(w, spdk_bdev_get_name(bdev));
-		} else {
-			spdk_json_write_null(w);
-		}
+	spdk_json_write_array_end(w);
+}
+
+static void
+spdk_vhost_nvme_write_config_json(struct spdk_vhost_dev *vdev, struct spdk_json_write_ctx *w)
+{
+	struct spdk_vhost_nvme_dev *nvme = to_nvme_dev(vdev);
+	struct spdk_vhost_nvme_ns *ns_dev;
+	uint32_t i;
+
+	if (nvme == NULL) {
+		return;
 	}
 
+	spdk_json_write_object_begin(w);
+	spdk_json_write_named_string(w, "method", "construct_vhost_nvme_controller");
+
+	spdk_json_write_named_object_begin(w, "params");
+	spdk_json_write_named_string(w, "ctrlr", nvme->vdev.name);
+	spdk_json_write_named_uint32(w, "io_queues", nvme->num_io_queues);
+	spdk_json_write_named_string(w, "cpumask", spdk_cpuset_fmt(nvme->vdev.cpumask));
 	spdk_json_write_object_end(w);
+
+	spdk_json_write_object_end(w);
+
+	for (i = 0; i < nvme->num_ns; i++) {
+		ns_dev = &nvme->ns[i];
+		if (!ns_dev->active_ns) {
+			continue;
+		}
+
+		spdk_json_write_object_begin(w);
+		spdk_json_write_named_string(w, "method", "add_vhost_nvme_ns");
+
+		spdk_json_write_named_object_begin(w, "params");
+		spdk_json_write_named_string(w, "ctrlr", nvme->vdev.name);
+		spdk_json_write_named_string(w, "bdev_name", spdk_bdev_get_name(ns_dev->bdev));
+		spdk_json_write_object_end(w);
+
+		spdk_json_write_object_end(w);
+	}
 }
 
 static const struct spdk_vhost_dev_backend spdk_vhost_nvme_device_backend = {
 	.start_device = spdk_vhost_nvme_start_device,
 	.stop_device = spdk_vhost_nvme_stop_device,
 	.dump_info_json = spdk_vhost_nvme_dump_info_json,
+	.write_config_json = spdk_vhost_nvme_write_config_json,
 	.remove_device = spdk_vhost_nvme_dev_remove,
 };
 
@@ -1108,7 +1216,7 @@ spdk_vhost_nvme_ctrlr_identify_update(struct spdk_vhost_nvme_dev *dev)
 	dev->cap.bits.cqr = 1;
 	dev->cap.bits.to = 1;
 	dev->cap.bits.dstrd = 0;
-	dev->cap.bits.css_nvm = 1;
+	dev->cap.bits.css = SPDK_NVME_CAP_CSS_NVM;
 	dev->cap.bits.mpsmin = 0;
 	dev->cap.bits.mpsmax = 0;
 	/* MQES is 0 based value */
@@ -1159,6 +1267,7 @@ spdk_vhost_nvme_dev_construct(const char *name, const char *cpumask, uint32_t nu
 	}
 
 	if (num_io_queues < 1 || num_io_queues > MAX_IO_QUEUES) {
+		spdk_dma_free(dev);
 		return -EINVAL;
 	}
 
diff --git a/lib/vhost/vhost_rpc.c b/lib/vhost/vhost_rpc.c
index 0493f0ee3..49ac7562d 100644
--- a/lib/vhost/vhost_rpc.c
+++ b/lib/vhost/vhost_rpc.c
@@ -98,7 +98,8 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
 }
-SPDK_RPC_REGISTER("construct_vhost_scsi_controller", spdk_rpc_construct_vhost_scsi_controller)
+SPDK_RPC_REGISTER("construct_vhost_scsi_controller", spdk_rpc_construct_vhost_scsi_controller,
+		  SPDK_RPC_RUNTIME)
 
 struct rpc_add_vhost_scsi_ctrlr_lun {
 	char *ctrlr;
@@ -197,7 +198,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
 }
-SPDK_RPC_REGISTER("add_vhost_scsi_lun", spdk_rpc_add_vhost_scsi_lun)
+SPDK_RPC_REGISTER("add_vhost_scsi_lun", spdk_rpc_add_vhost_scsi_lun, SPDK_RPC_RUNTIME)
 
 struct rpc_remove_vhost_scsi_ctrlr_target {
 	char *ctrlr;
@@ -297,7 +298,7 @@ invalid:
 					 spdk_strerror(-rc));
 }
 
-SPDK_RPC_REGISTER("remove_vhost_scsi_target", spdk_rpc_remove_vhost_scsi_target)
+SPDK_RPC_REGISTER("remove_vhost_scsi_target", spdk_rpc_remove_vhost_scsi_target, SPDK_RPC_RUNTIME)
 
 struct rpc_vhost_blk_ctrlr {
 	char *ctrlr;
@@ -359,7 +360,8 @@ invalid:
 					 spdk_strerror(-rc));
 
 }
-SPDK_RPC_REGISTER("construct_vhost_blk_controller", spdk_rpc_construct_vhost_blk_controller)
+SPDK_RPC_REGISTER("construct_vhost_blk_controller", spdk_rpc_construct_vhost_blk_controller,
+		  SPDK_RPC_RUNTIME)
 
 struct rpc_remove_vhost_ctrlr {
 	char *ctrlr;
@@ -446,7 +448,7 @@ invalid:
 					 spdk_strerror(-rc));
 
 }
-SPDK_RPC_REGISTER("remove_vhost_controller", spdk_rpc_remove_vhost_controller)
+SPDK_RPC_REGISTER("remove_vhost_controller", spdk_rpc_remove_vhost_controller, SPDK_RPC_RUNTIME)
 
 struct rpc_get_vhost_ctrlrs {
 	struct spdk_json_write_ctx *w;
@@ -457,6 +459,8 @@ static int
 spdk_rpc_get_vhost_controllers_cb(struct spdk_vhost_dev *vdev, void *arg)
 {
 	struct rpc_get_vhost_ctrlrs *ctx = arg;
+	uint32_t delay_base_us, iops_threshold;
+
 
 	if (vdev == NULL) {
 		spdk_json_write_array_end(ctx->w);
@@ -465,22 +469,21 @@ spdk_rpc_get_vhost_controllers_cb(struct spdk_vhost_dev *vdev, void *arg)
 		return 0;
 	}
 
-	spdk_json_write_object_begin(ctx->w);
-
-	spdk_json_write_name(ctx->w, "ctrlr");
-	spdk_json_write_string(ctx->w, spdk_vhost_dev_get_name(vdev));
+	spdk_vhost_get_coalescing(vdev, &delay_base_us, &iops_threshold);
 
-	spdk_json_write_name(ctx->w, "cpumask");
-	spdk_json_write_string_fmt(ctx->w, "0x%s", spdk_cpuset_fmt(vdev->cpumask));
+	spdk_json_write_object_begin(ctx->w);
 
-	spdk_json_write_name(ctx->w, "backend_specific");
+	spdk_json_write_named_string(ctx->w, "ctrlr", spdk_vhost_dev_get_name(vdev));
+	spdk_json_write_named_string_fmt(ctx->w, "cpumask", "0x%s", spdk_cpuset_fmt(vdev->cpumask));
+	spdk_json_write_named_uint32(ctx->w, "delay_base_us", delay_base_us);
+	spdk_json_write_named_uint32(ctx->w, "iops_threshold", iops_threshold);
+	spdk_json_write_named_string(ctx->w, "socket", vdev->path);
 
-	spdk_json_write_object_begin(ctx->w);
+	spdk_json_write_named_object_begin(ctx->w, "backend_specific");
 	spdk_vhost_dump_info_json(vdev, ctx->w);
 	spdk_json_write_object_end(ctx->w);
 
-	spdk_json_write_object_end(ctx->w); // ctrl
-
+	spdk_json_write_object_end(ctx->w);
 	return 0;
 }
 
@@ -516,7 +519,7 @@ spdk_rpc_get_vhost_controllers(struct spdk_jsonrpc_request *request,
 	ctx->request = request;
 	spdk_vhost_call_external_event_foreach(spdk_rpc_get_vhost_controllers_cb, ctx);
 }
-SPDK_RPC_REGISTER("get_vhost_controllers", spdk_rpc_get_vhost_controllers)
+SPDK_RPC_REGISTER("get_vhost_controllers", spdk_rpc_get_vhost_controllers, SPDK_RPC_RUNTIME)
 
 
 struct rpc_vhost_ctrlr_coalescing {
@@ -605,7 +608,8 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
 }
-SPDK_RPC_REGISTER("set_vhost_controller_coalescing", spdk_rpc_set_vhost_controller_coalescing)
+SPDK_RPC_REGISTER("set_vhost_controller_coalescing", spdk_rpc_set_vhost_controller_coalescing,
+		  SPDK_RPC_RUNTIME)
 
 struct rpc_vhost_nvme_ctrlr {
 	char *ctrlr;
@@ -663,7 +667,8 @@ invalid:
 					 spdk_strerror(-rc));
 
 }
-SPDK_RPC_REGISTER("construct_vhost_nvme_controller", spdk_rpc_construct_vhost_nvme_controller)
+SPDK_RPC_REGISTER("construct_vhost_nvme_controller", spdk_rpc_construct_vhost_nvme_controller,
+		  SPDK_RPC_RUNTIME)
 
 struct rpc_add_vhost_nvme_ctrlr_ns {
 	char *ctrlr;
@@ -751,7 +756,7 @@ invalid:
 	spdk_jsonrpc_send_error_response(request, SPDK_JSONRPC_ERROR_INVALID_PARAMS,
 					 spdk_strerror(-rc));
 }
-SPDK_RPC_REGISTER("add_vhost_nvme_ns", spdk_rpc_add_vhost_nvme_ns)
+SPDK_RPC_REGISTER("add_vhost_nvme_ns", spdk_rpc_add_vhost_nvme_ns, SPDK_RPC_RUNTIME)
 
 
 SPDK_LOG_REGISTER_COMPONENT("vhost_rpc", SPDK_LOG_VHOST_RPC)
diff --git a/lib/vhost/vhost_scsi.c b/lib/vhost/vhost_scsi.c
index dcb5f98d1..7c2ba7fd4 100644
--- a/lib/vhost/vhost_scsi.c
+++ b/lib/vhost/vhost_scsi.c
@@ -36,7 +36,7 @@
 #include <linux/virtio_scsi.h>
 
 #include "spdk/env.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/scsi.h"
 #include "spdk/scsi_spec.h"
 #include "spdk/conf.h"
@@ -823,11 +823,6 @@ spdk_vhost_scsi_dev_add_tgt(struct spdk_vhost_dev *vdev, unsigned scsi_tgt_num,
 		return -EINVAL;
 	}
 
-	if (vdev->lcore != -1 && !spdk_vhost_dev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
-		SPDK_ERRLOG("Controller %s is in use and hotplug is not supported\n", vdev->name);
-		return -ENOTSUP;
-	}
-
 	if (svdev->scsi_dev[scsi_tgt_num] != NULL) {
 		SPDK_ERRLOG("Controller %s target %u already occupied\n", vdev->name, scsi_tgt_num);
 		return -EEXIST;
@@ -852,13 +847,25 @@ spdk_vhost_scsi_dev_add_tgt(struct spdk_vhost_dev *vdev, unsigned scsi_tgt_num,
 	}
 	spdk_scsi_dev_add_port(svdev->scsi_dev[scsi_tgt_num], 0, "vhost");
 
-	if (vdev->lcore != -1) {
-		spdk_scsi_dev_allocate_io_channels(svdev->scsi_dev[scsi_tgt_num]);
-		eventq_enqueue(svdev, scsi_tgt_num, VIRTIO_SCSI_T_TRANSPORT_RESET, VIRTIO_SCSI_EVT_RESET_RESCAN);
-	}
-
 	SPDK_INFOLOG(SPDK_LOG_VHOST, "Controller %s: defined target '%s' using bdev '%s'\n",
 		     vdev->name, target_name, bdev_name);
+
+	if (vdev->lcore == -1) {
+		/* All done. */
+		return 0;
+	}
+
+	spdk_scsi_dev_allocate_io_channels(svdev->scsi_dev[scsi_tgt_num]);
+
+	if (spdk_vhost_dev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
+		eventq_enqueue(svdev, scsi_tgt_num, VIRTIO_SCSI_T_TRANSPORT_RESET,
+			       VIRTIO_SCSI_EVT_RESET_RESCAN);
+	} else {
+		SPDK_NOTICELOG("Device %s does not support hotplug. "
+			       "Please restart the driver or perform a rescan.\n",
+			       vdev->name);
+	}
+
 	return 0;
 }
 
@@ -931,8 +938,7 @@ spdk_vhost_scsi_controller_construct(void)
 	char *bdev_name, *tgt_num_str;
 	char *cpumask;
 	char *name;
-	char *keyword;
-	char *dev = NULL, *tgt = NULL;
+	char *tgt = NULL;
 
 	while (sp != NULL) {
 		if (!spdk_conf_section_match_prefix(sp, "VhostScsi")) {
@@ -956,40 +962,25 @@ spdk_vhost_scsi_controller_construct(void)
 		vdev = spdk_vhost_dev_find(name);
 		assert(vdev);
 
-		dev = spdk_conf_section_get_nval(sp, "Dev", 0);
-		tgt = spdk_conf_section_get_nval(sp, "Target", 0);
-
-		if (dev && tgt) {
-			SPDK_ERRLOG("Used both 'Dev' and 'Target' keywords in section [VhostScsi%u]\n"
-				    "Please use one.\n", ctrlr_num);
-			return -1;
-		} else if (dev) {
-			SPDK_NOTICELOG("'Dev' mnemonic is deprecated, and will be removed shortly.\n"
-				       "Please, use 'Target' instead\n");
-			keyword = "Dev";
-		} else {
-			keyword = "Target";
-		}
-
 		for (i = 0; ; i++) {
 
-			tgt = spdk_conf_section_get_nval(sp, keyword, i);
+			tgt = spdk_conf_section_get_nval(sp, "Target", i);
 			if (tgt == NULL) {
 				break;
 			}
 
-			tgt_num_str = spdk_conf_section_get_nmval(sp, keyword, i, 0);
+			tgt_num_str = spdk_conf_section_get_nmval(sp, "Target", i, 0);
 			if (tgt_num_str == NULL) {
 				SPDK_ERRLOG("%s: Invalid or missing target number\n", name);
 				return -1;
 			}
 
 			dev_num = (int)strtol(tgt_num_str, NULL, 10);
-			bdev_name = spdk_conf_section_get_nmval(sp, keyword, i, 1);
+			bdev_name = spdk_conf_section_get_nmval(sp, "Target", i, 1);
 			if (bdev_name == NULL) {
 				SPDK_ERRLOG("%s: Invalid or missing bdev name for target %d\n", name, dev_num);
 				return -1;
-			} else if (spdk_conf_section_get_nmval(sp, keyword, i, 2)) {
+			} else if (spdk_conf_section_get_nmval(sp, "Target", i, 2)) {
 				SPDK_ERRLOG("%s: Only one LUN per vhost SCSI device supported\n", name);
 				return -1;
 			}
diff --git a/lib/virtio/virtio.c b/lib/virtio/virtio.c
index c0f557873..1e2991a1a 100644
--- a/lib/virtio/virtio.c
+++ b/lib/virtio/virtio.c
@@ -96,22 +96,28 @@ virtio_init_vring(struct virtqueue *vq)
 	vq->vq_free_cnt = vq->vq_nentries;
 	vq->req_start = VQ_RING_DESC_CHAIN_END;
 	vq->req_end = VQ_RING_DESC_CHAIN_END;
+	vq->reqs_finished = 0;
 	memset(vq->vq_descx, 0, sizeof(struct vq_desc_extra) * vq->vq_nentries);
 
 	vring_desc_init(vr->desc, size);
 
-	/* Tell the backend not to interrupt us. */
-	vq->vq_ring.avail->flags |= VRING_AVAIL_F_NO_INTERRUPT;
+	/* Tell the backend not to interrupt us.
+	 * If F_EVENT_IDX is negotiated, we will always set incredibly high
+	 * used event idx, so that we will practically never receive an
+	 * interrupt. See virtqueue_req_flush()
+	 */
+	if (vq->vdev->negotiated_features & (1ULL << VIRTIO_RING_F_EVENT_IDX)) {
+		vring_used_event(&vq->vq_ring) = UINT16_MAX;
+	} else {
+		vq->vq_ring.avail->flags |= VRING_AVAIL_F_NO_INTERRUPT;
+	}
 }
 
 static int
 virtio_init_queue(struct virtio_dev *dev, uint16_t vtpci_queue_idx)
 {
-	void *queue_mem;
 	unsigned int vq_size, size;
-	uint64_t queue_mem_phys_addr;
 	struct virtqueue *vq;
-	int ret;
 
 	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "setting up queue: %"PRIu16"\n", vtpci_queue_idx);
 
@@ -155,34 +161,22 @@ virtio_init_queue(struct virtio_dev *dev, uint16_t vtpci_queue_idx)
 	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "vring_size: %u, rounded_vring_size: %u\n",
 		      size, vq->vq_ring_size);
 
-	queue_mem = spdk_dma_zmalloc(vq->vq_ring_size, VIRTIO_PCI_VRING_ALIGN, &queue_mem_phys_addr);
-	if (queue_mem == NULL) {
-		ret = -ENOMEM;
-		goto fail_q_alloc;
+	vq->owner_thread = NULL;
+
+	if (virtio_dev_backend_ops(dev)->setup_queue(dev, vq) < 0) {
+		SPDK_ERRLOG("setup_queue failed\n");
+		spdk_dma_free(vq);
+		dev->vqs[vtpci_queue_idx] = NULL;
+		return -EINVAL;
 	}
 
-	vq->vq_ring_mem = queue_mem_phys_addr;
-	vq->vq_ring_virt_mem = queue_mem;
 	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "vq->vq_ring_mem:      0x%" PRIx64 "\n",
 		      vq->vq_ring_mem);
 	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "vq->vq_ring_virt_mem: 0x%" PRIx64 "\n",
 		      (uint64_t)(uintptr_t)vq->vq_ring_virt_mem);
 
 	virtio_init_vring(vq);
-
-	vq->owner_thread = NULL;
-
-	if (virtio_dev_backend_ops(dev)->setup_queue(dev, vq) < 0) {
-		SPDK_ERRLOG("setup_queue failed\n");
-		return -EINVAL;
-	}
-
 	return 0;
-
-fail_q_alloc:
-	rte_free(vq);
-
-	return ret;
 }
 
 static void
@@ -202,7 +196,7 @@ virtio_free_queues(struct virtio_dev *dev)
 			continue;
 		}
 
-		spdk_dma_free(vq->vq_ring_virt_mem);
+		virtio_dev_backend_ops(dev)->del_queue(dev, vq);
 
 		rte_free(vq);
 		dev->vqs[i] = NULL;
@@ -415,19 +409,42 @@ virtqueue_dequeue_burst_rx(struct virtqueue *vq, void **rx_pkts,
 	return i;
 }
 
+static void
+finish_req(struct virtqueue *vq)
+{
+	struct vring_desc *desc;
+	uint16_t avail_idx;
+
+	desc = &vq->vq_ring.desc[vq->req_end];
+	desc->flags &= ~VRING_DESC_F_NEXT;
+
+	/*
+	 * Place the head of the descriptor chain into the next slot and make
+	 * it usable to the host. The chain is made available now rather than
+	 * deferring to virtqueue_req_flush() in the hopes that if the host is
+	 * currently running on another CPU, we can keep it processing the new
+	 * descriptor.
+	 */
+	avail_idx = (uint16_t)(vq->vq_avail_idx & (vq->vq_nentries - 1));
+	vq->vq_ring.avail->ring[avail_idx] = vq->req_start;
+	vq->vq_avail_idx++;
+	vq->req_end = VQ_RING_DESC_CHAIN_END;
+	virtio_wmb();
+	vq->vq_ring.avail->idx = vq->vq_avail_idx;
+	vq->reqs_finished++;
+}
+
 int
 virtqueue_req_start(struct virtqueue *vq, void *cookie, int iovcnt)
 {
-	struct vring_desc *desc;
 	struct vq_desc_extra *dxp;
 
 	if (iovcnt > vq->vq_free_cnt) {
 		return iovcnt > vq->vq_nentries ? -EINVAL : -ENOMEM;
 	}
 
-	if (vq->req_start != VQ_RING_DESC_CHAIN_END) {
-		desc = &vq->vq_ring.desc[vq->req_end];
-		desc->flags &= ~VRING_DESC_F_NEXT;
+	if (vq->req_end != VQ_RING_DESC_CHAIN_END) {
+		finish_req(vq);
 	}
 
 	vq->req_start = vq->vq_desc_head_idx;
@@ -441,40 +458,36 @@ virtqueue_req_start(struct virtqueue *vq, void *cookie, int iovcnt)
 void
 virtqueue_req_flush(struct virtqueue *vq)
 {
-	struct vring_desc *desc;
-	uint16_t avail_idx;
+	uint16_t reqs_finished;
 
-	if (vq->req_start == VQ_RING_DESC_CHAIN_END) {
-		/* no requests have been started */
+	if (vq->req_end == VQ_RING_DESC_CHAIN_END) {
+		/* no non-empty requests have been started */
 		return;
 	}
 
-	desc = &vq->vq_ring.desc[vq->req_end];
-	desc->flags &= ~VRING_DESC_F_NEXT;
-
-	/*
-	 * Place the head of the descriptor chain into the next slot and make
-	 * it usable to the host. The chain is made available now rather than
-	 * deferring to virtqueue_notify() in the hopes that if the host is
-	 * currently running on another CPU, we can keep it processing the new
-	 * descriptor.
-	 */
-	avail_idx = (uint16_t)(vq->vq_avail_idx & (vq->vq_nentries - 1));
-	if (spdk_unlikely(vq->vq_ring.avail->ring[avail_idx] != vq->req_start)) {
-		vq->vq_ring.avail->ring[avail_idx] = vq->req_start;
-	}
+	finish_req(vq);
+	virtio_mb();
 
-	vq->vq_avail_idx++;
-	vq->req_start = VQ_RING_DESC_CHAIN_END;
+	reqs_finished = vq->reqs_finished;
+	vq->reqs_finished = 0;
 
-	virtio_wmb();
-	vq->vq_ring.avail->idx = vq->vq_avail_idx;
+	if (vq->vdev->negotiated_features & (1ULL << VIRTIO_RING_F_EVENT_IDX)) {
+		/* Set used event idx to a value the device will never reach.
+		 * This effectively disables interrupts.
+		 */
+		vring_used_event(&vq->vq_ring) = vq->vq_used_cons_idx - vq->vq_nentries - 1;
 
-	virtio_mb();
-	if (spdk_unlikely(!(vq->vq_ring.used->flags & VRING_USED_F_NO_NOTIFY))) {
-		virtio_dev_backend_ops(vq->vdev)->notify_queue(vq->vdev, vq);
-		SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "Notified backend after xmit\n");
+		if (!vring_need_event(vring_avail_event(&vq->vq_ring),
+				      vq->vq_avail_idx,
+				      vq->vq_avail_idx - reqs_finished)) {
+			return;
+		}
+	} else if (vq->vq_ring.used->flags & VRING_USED_F_NO_NOTIFY) {
+		return;
 	}
+
+	virtio_dev_backend_ops(vq->vdev)->notify_queue(vq->vdev, vq);
+	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "Notified backend after xmit\n");
 }
 
 void
@@ -556,10 +569,7 @@ virtio_recv_pkts(struct virtqueue *vq, void **io, uint32_t *len, uint16_t nb_pkt
 		num = num - ((vq->vq_used_cons_idx + num) % DESC_PER_CACHELINE);
 	}
 
-	num = virtqueue_dequeue_burst_rx(vq, io, len, num);
-	SPDK_DEBUGLOG(SPDK_LOG_VIRTIO_DEV, "used:%"PRIu16" dequeue:%"PRIu16"\n", nb_used, num);
-
-	return num;
+	return virtqueue_dequeue_burst_rx(vq, io, len, num);
 }
 
 int
@@ -658,18 +668,18 @@ virtio_dev_release_queue(struct virtio_dev *vdev, uint16_t index)
 	pthread_mutex_unlock(&vdev->mutex);
 }
 
-void
+int
 virtio_dev_read_dev_config(struct virtio_dev *dev, size_t offset,
 			   void *dst, int length)
 {
-	virtio_dev_backend_ops(dev)->read_dev_cfg(dev, offset, dst, length);
+	return virtio_dev_backend_ops(dev)->read_dev_cfg(dev, offset, dst, length);
 }
 
-void
+int
 virtio_dev_write_dev_config(struct virtio_dev *dev, size_t offset,
 			    const void *src, int length)
 {
-	virtio_dev_backend_ops(dev)->write_dev_cfg(dev, offset, src, length);
+	return virtio_dev_backend_ops(dev)->write_dev_cfg(dev, offset, src, length);
 }
 
 void
diff --git a/lib/virtio/virtio_pci.c b/lib/virtio/virtio_pci.c
index 1246bfec4..2dc1e6f6b 100644
--- a/lib/virtio/virtio_pci.c
+++ b/lib/virtio/virtio_pci.c
@@ -146,7 +146,7 @@ io_write64_twopart(uint64_t val, uint32_t *lo, uint32_t *hi)
 	spdk_mmio_write_4(hi, val >> 32);
 }
 
-static void
+static int
 modern_read_dev_config(struct virtio_dev *dev, size_t offset,
 		       void *dst, int length)
 {
@@ -165,9 +165,11 @@ modern_read_dev_config(struct virtio_dev *dev, size_t offset,
 
 		new_gen = spdk_mmio_read_1(&hw->common_cfg->config_generation);
 	} while (old_gen != new_gen);
+
+	return 0;
 }
 
-static void
+static int
 modern_write_dev_config(struct virtio_dev *dev, size_t offset,
 			const void *src, int length)
 {
@@ -178,6 +180,8 @@ modern_write_dev_config(struct virtio_dev *dev, size_t offset,
 	for (i = 0;  i < length; i++) {
 		spdk_mmio_write_1(((uint8_t *)hw->dev_cfg) + offset + i, *p++);
 	}
+
+	return 0;
 }
 
 static uint64_t
@@ -257,8 +261,27 @@ modern_setup_queue(struct virtio_dev *dev, struct virtqueue *vq)
 	struct virtio_hw *hw = dev->ctx;
 	uint64_t desc_addr, avail_addr, used_addr;
 	uint16_t notify_off;
+	void *queue_mem;
+	uint64_t queue_mem_phys_addr;
+
+	/* To ensure physical address contiguity we make the queue occupy
+	 * only a single hugepage (2MB). As of Virtio 1.0, the queue size
+	 * always falls within this limit.
+	 */
+	if (vq->vq_ring_size > 0x200000) {
+		return -ENOMEM;
+	}
+
+	queue_mem = spdk_dma_zmalloc(vq->vq_ring_size, 0x200000, &queue_mem_phys_addr);
+	if (queue_mem == NULL) {
+		return -ENOMEM;
+	}
+
+	vq->vq_ring_mem = queue_mem_phys_addr;
+	vq->vq_ring_virt_mem = queue_mem;
 
 	if (!check_vq_phys_addr_ok(vq)) {
+		spdk_dma_free(queue_mem);
 		return -1;
 	}
 
@@ -307,6 +330,8 @@ modern_del_queue(struct virtio_dev *dev, struct virtqueue *vq)
 			   &hw->common_cfg->queue_used_hi);
 
 	spdk_mmio_write_2(&hw->common_cfg->queue_enable, 0);
+
+	spdk_dma_free(vq->vq_ring_virt_mem);
 }
 
 static void
diff --git a/lib/virtio/virtio_user.c b/lib/virtio/virtio_user.c
index ab9cce2ba..a40b9f791 100644
--- a/lib/virtio/virtio_user.c
+++ b/lib/virtio/virtio_user.c
@@ -46,6 +46,10 @@
 
 #include "spdk_internal/virtio.h"
 
+#define VIRTIO_USER_SUPPORTED_PROTOCOL_FEATURES \
+	((1ULL << VHOST_USER_PROTOCOL_F_MQ) | \
+	(1ULL << VHOST_USER_PROTOCOL_F_CONFIG))
+
 static int
 virtio_user_create_queue(struct virtio_dev *vdev, uint32_t queue_sel)
 {
@@ -142,6 +146,15 @@ virtio_user_start_device(struct virtio_dev *vdev)
 	uint64_t host_max_queues;
 	int ret;
 
+	if ((dev->protocol_features & (1ULL << VHOST_USER_PROTOCOL_F_MQ)) == 0 &&
+	    vdev->max_queues > 1 + vdev->fixed_queues_num) {
+		SPDK_WARNLOG("%s: requested %"PRIu16" request queues, but the "
+			     "host doesn't support VHOST_USER_PROTOCOL_F_MQ. "
+			     "Only one request queue will be used.\n",
+			     vdev->name, vdev->max_queues - vdev->fixed_queues_num);
+		vdev->max_queues = 1 + vdev->fixed_queues_num;
+	}
+
 	/* negotiate the number of I/O queues. */
 	ret = dev->ops->send_request(dev, VHOST_USER_GET_QUEUE_NUM, &host_max_queues);
 	if (ret < 0) {
@@ -202,39 +215,50 @@ virtio_user_dev_setup(struct virtio_dev *vdev)
 	return 0;
 }
 
-static void
+static int
 virtio_user_read_dev_config(struct virtio_dev *vdev, size_t offset,
 			    void *dst, int length)
 {
 	struct virtio_user_dev *dev = vdev->ctx;
 	struct vhost_user_config cfg = {0};
 
+	if ((dev->protocol_features & (1ULL << VHOST_USER_PROTOCOL_F_CONFIG)) == 0) {
+		return -ENOTSUP;
+	}
+
 	cfg.offset = 0;
 	cfg.size = VHOST_USER_MAX_CONFIG_SIZE;
 
 	if (dev->ops->send_request(dev, VHOST_USER_GET_CONFIG, &cfg) < 0) {
 		SPDK_ERRLOG("get_config failed: %s\n", spdk_strerror(errno));
-		return;
+		return -errno;
 	}
 
 	memcpy(dst, cfg.region + offset, length);
+	return 0;
 }
 
-static void
+static int
 virtio_user_write_dev_config(struct virtio_dev *vdev, size_t offset,
 			     const void *src, int length)
 {
 	struct virtio_user_dev *dev = vdev->ctx;
 	struct vhost_user_config cfg = {0};
 
+	if ((dev->protocol_features & (1ULL << VHOST_USER_PROTOCOL_F_CONFIG)) == 0) {
+		return -ENOTSUP;
+	}
+
 	cfg.offset = offset;
 	cfg.size = length;
 	memcpy(cfg.region, src, length);
 
 	if (dev->ops->send_request(dev, VHOST_USER_SET_CONFIG, &cfg) < 0) {
 		SPDK_ERRLOG("set_config failed: %s\n", spdk_strerror(errno));
-		return;
+		return -errno;
 	}
+
+	return 0;
 }
 
 static void
@@ -286,6 +310,7 @@ static int
 virtio_user_set_features(struct virtio_dev *vdev, uint64_t features)
 {
 	struct virtio_user_dev *dev = vdev->ctx;
+	uint64_t protocol_features;
 	int ret;
 
 	ret = dev->ops->send_request(dev, VHOST_USER_SET_FEATURES, &features);
@@ -296,6 +321,23 @@ virtio_user_set_features(struct virtio_dev *vdev, uint64_t features)
 	vdev->negotiated_features = features;
 	vdev->modern = virtio_dev_has_feature(vdev, VIRTIO_F_VERSION_1);
 
+	if (!virtio_dev_has_feature(vdev, VHOST_USER_F_PROTOCOL_FEATURES)) {
+		/* nothing else to do */
+		return 0;
+	}
+
+	ret = dev->ops->send_request(dev, VHOST_USER_GET_PROTOCOL_FEATURES, &protocol_features);
+	if (ret < 0) {
+		return -1;
+	}
+
+	protocol_features &= VIRTIO_USER_SUPPORTED_PROTOCOL_FEATURES;
+	ret = dev->ops->send_request(dev, VHOST_USER_SET_PROTOCOL_FEATURES, &protocol_features);
+	if (ret < 0) {
+		return -1;
+	}
+
+	dev->protocol_features = protocol_features;
 	return 0;
 }
 
@@ -312,7 +354,9 @@ static int
 virtio_user_setup_queue(struct virtio_dev *vdev, struct virtqueue *vq)
 {
 	struct virtio_user_dev *dev = vdev->ctx;
+	struct vhost_vring_state state;
 	uint16_t queue_idx = vq->vq_queue_index;
+	void *queue_mem;
 	uint64_t desc_addr, avail_addr, used_addr;
 	int callfd;
 	int kickfd;
@@ -339,6 +383,27 @@ virtio_user_setup_queue(struct virtio_dev *vdev, struct virtqueue *vq)
 		return -1;
 	}
 
+	queue_mem = spdk_dma_zmalloc(vq->vq_ring_size, VIRTIO_PCI_VRING_ALIGN, NULL);
+	if (queue_mem == NULL) {
+		close(kickfd);
+		close(callfd);
+		return -ENOMEM;
+	}
+
+	vq->vq_ring_mem = SPDK_VTOPHYS_ERROR;
+	vq->vq_ring_virt_mem = queue_mem;
+
+	state.index = vq->vq_queue_index;
+	state.num = 0;
+
+	if (virtio_dev_has_feature(vdev, VHOST_USER_F_PROTOCOL_FEATURES) &&
+	    dev->ops->send_request(dev, VHOST_USER_SET_VRING_ENABLE, &state) < 0) {
+		SPDK_ERRLOG("failed to send VHOST_USER_SET_VRING_ENABLE: %s\n",
+			    spdk_strerror(errno));
+		spdk_dma_free(queue_mem);
+		return -1;
+	}
+
 	dev->callfds[queue_idx] = callfd;
 	dev->kickfds[queue_idx] = kickfd;
 
@@ -365,8 +430,8 @@ virtio_user_del_queue(struct virtio_dev *vdev, struct virtqueue *vq)
 	 * For modern devices, set queue desc, avail, used in PCI bar to 0,
 	 * not see any more behavior in QEMU.
 	 *
-	 * Here we just care about what information to deliver to vhost-user
-	 * or vhost-kernel. So we just close ioeventfd for now.
+	 * Here we just care about what information to deliver to vhost-user.
+	 * So we just close ioeventfd for now.
 	 */
 	struct virtio_user_dev *dev = vdev->ctx;
 
@@ -374,6 +439,8 @@ virtio_user_del_queue(struct virtio_dev *vdev, struct virtqueue *vq)
 	close(dev->kickfds[vq->vq_queue_index]);
 	dev->callfds[vq->vq_queue_index] = -1;
 	dev->kickfds[vq->vq_queue_index] = -1;
+
+	spdk_dma_free(vq->vq_ring_virt_mem);
 }
 
 static void
diff --git a/lib/virtio/virtio_user/vhost.h b/lib/virtio/virtio_user/vhost.h
index 35a1af349..2503e00f4 100644
--- a/lib/virtio/virtio_user/vhost.h
+++ b/lib/virtio/virtio_user/vhost.h
@@ -43,6 +43,14 @@
 
 #define VHOST_USER_MAX_CONFIG_SIZE 256
 
+#ifndef VHOST_USER_PROTOCOL_F_MQ
+#define VHOST_USER_PROTOCOL_F_MQ	0
+#endif
+
+#ifndef VHOST_USER_PROTOCOL_F_CONFIG
+#define VHOST_USER_PROTOCOL_F_CONFIG	9
+#endif
+
 enum vhost_user_request {
 	VHOST_USER_NONE = 0,
 	VHOST_USER_GET_FEATURES = 1,
@@ -71,16 +79,15 @@ enum vhost_user_request {
 struct virtio_user_backend_ops;
 
 struct virtio_user_dev {
-	/* for vhost_user backend */
 	int		vhostfd;
 
-	/* for both vhost_user and vhost_kernel */
 	int		callfds[SPDK_VIRTIO_MAX_VIRTQUEUES];
 	int		kickfds[SPDK_VIRTIO_MAX_VIRTQUEUES];
 	uint32_t	queue_size;
 
 	uint8_t		status;
 	char		path[PATH_MAX];
+	uint64_t	protocol_features;
 	struct vring	vrings[SPDK_VIRTIO_MAX_VIRTQUEUES];
 	struct virtio_user_backend_ops *ops;
 };
@@ -101,6 +108,5 @@ struct vhost_user_config {
 };
 
 extern struct virtio_user_backend_ops ops_user;
-extern struct virtio_user_backend_ops ops_kernel;
 
 #endif
diff --git a/lib/virtio/virtio_user/vhost_user.c b/lib/virtio/virtio_user/vhost_user.c
index 7911a2464..bd7714d98 100644
--- a/lib/virtio/virtio_user/vhost_user.c
+++ b/lib/virtio/virtio_user/vhost_user.c
@@ -226,6 +226,14 @@ get_hugepage_file_info(struct hugepage_file_info huges[], int max)
 			SPDK_ERRLOG("Exceed maximum of %d\n", max);
 			goto error;
 		}
+
+		if (idx > 0 &&
+		    strncmp(tmp, huges[idx - 1].path, PATH_MAX) == 0 &&
+		    v_start == huges[idx - 1].addr + huges[idx - 1].size) {
+			huges[idx - 1].size += (v_end - v_start);
+			continue;
+		}
+
 		huges[idx].addr = v_start;
 		huges[idx].size = v_end - v_start;
 		snprintf(huges[idx].path, PATH_MAX, "%s", tmp);
@@ -306,12 +314,14 @@ vhost_user_sock(struct virtio_user_dev *dev,
 
 	switch (req) {
 	case VHOST_USER_GET_FEATURES:
+	case VHOST_USER_GET_PROTOCOL_FEATURES:
 	case VHOST_USER_GET_QUEUE_NUM:
 		need_reply = 1;
 		break;
 
 	case VHOST_USER_SET_FEATURES:
 	case VHOST_USER_SET_LOG_BASE:
+	case VHOST_USER_SET_PROTOCOL_FEATURES:
 		msg.payload.u64 = *((__u64 *)arg);
 		msg.size = sizeof(msg.payload.u64);
 		break;
@@ -406,6 +416,7 @@ vhost_user_sock(struct virtio_user_dev *dev,
 
 		switch (req) {
 		case VHOST_USER_GET_FEATURES:
+		case VHOST_USER_GET_PROTOCOL_FEATURES:
 		case VHOST_USER_GET_QUEUE_NUM:
 			if (msg.size != sizeof(msg.payload.u64)) {
 				SPDK_WARNLOG("Received bad msg size\n");
diff --git a/mk/nvme.libtest.mk b/mk/nvme.libtest.mk
index 38eec850b..acaa13401 100644
--- a/mk/nvme.libtest.mk
+++ b/mk/nvme.libtest.mk
@@ -35,11 +35,13 @@ NVME_DIR := $(SPDK_ROOT_DIR)/lib/nvme
 
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.modules.mk
 
 C_SRCS = $(APP:%=%.c)
 
-SPDK_LIB_LIST = nvme util log
+SPDK_LIB_LIST = nvme thread util log
 
+LIBS += $(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 ifeq ($(CONFIG_RDMA),y)
@@ -49,7 +51,7 @@ endif
 all: $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SOCK_MODULES_FILES) $(SPDK_LIB_FILES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean:
diff --git a/mk/spdk.common.mk b/mk/spdk.common.mk
index 7326e7869..98a8c32ab 100644
--- a/mk/spdk.common.mk
+++ b/mk/spdk.common.mk
@@ -125,6 +125,32 @@ LIBS += -L$(CONFIG_VPP_DIR)/lib64
 COMMON_CFLAGS += -I$(CONFIG_VPP_DIR)/include
 endif
 
+#Attach only if FreeBSD and RDMA is specified with configure
+ifeq ($(OS),FreeBSD)
+ifeq ($(CONFIG_RDMA),y)
+# RDMA Userspace Verbs Library
+ifneq ("$(wildcard /usr/lib/libibverbs.*)","")
+LIBS += -libverbs
+endif
+# RDMA Connection Manager Library
+ifneq ("$(wildcard /usr/lib/librdmacm.*)","")
+LIBS += -lrdmacm
+endif
+# Mellanox - MLX4 HBA Userspace Library
+ifneq ("$(wildcard /usr/lib/libmlx4.*)","")
+LIBS += -lmlx4
+endif
+# Mellanox - MLX5 HBA Userspace Library
+ifneq ("$(wildcard /usr/lib/libmlx5.*)","")
+LIBS += -lmlx5
+endif
+# Chelsio HBA Userspace Library
+ifneq ("$(wildcard /usr/lib/libcxgb4.*)","")
+LIBS += -lcxgb4
+endif
+endif
+endif
+
 ifeq ($(CONFIG_DEBUG), y)
 COMMON_CFLAGS += -DDEBUG -O0 -fno-omit-frame-pointer
 else
@@ -166,6 +192,7 @@ CXXFLAGS += $(COMMON_CFLAGS) -std=c++0x
 
 SYS_LIBS += -lrt
 SYS_LIBS += -luuid
+SYS_LIBS += -lcrypto
 
 MAKEFLAGS += --no-print-directory
 
@@ -212,6 +239,12 @@ INSTALL_LIB=\
 	install -d -m 755 "$(DESTDIR)$(libdir)"; \
 	install -m 644 "$(LIB)" "$(DESTDIR)$(libdir)/"
 
+# Install a shared library
+INSTALL_SHARED_LIB=\
+	$(Q)echo "  INSTALL $(DESTDIR)$(libdir)/$(notdir $(SHARED_LIB))"; \
+	install -d -m 755 "$(DESTDIR)$(libdir)"; \
+	install -m 644 "$(SHARED_LIB)" "$(DESTDIR)$(libdir)/"
+
 # Install an app binary
 INSTALL_APP=\
 	$(Q)echo "  INSTALL $(DESTDIR)$(bindir)/$(APP)"; \
diff --git a/mk/spdk.modules.mk b/mk/spdk.modules.mk
index de2da9652..ef9e8c515 100644
--- a/mk/spdk.modules.mk
+++ b/mk/spdk.modules.mk
@@ -57,22 +57,26 @@ BLOCKDEV_MODULES_LIST += bdev_rbd
 BLOCKDEV_MODULES_DEPS += -lrados -lrbd
 endif
 
+ifeq ($(CONFIG_RAID),y)
+BLOCKDEV_MODULES_LIST += vbdev_raid
+endif
+
 ifeq ($(CONFIG_PMDK),y)
 BLOCKDEV_MODULES_LIST += bdev_pmem
 BLOCKDEV_MODULES_DEPS += -lpmemblk
 endif
 
-NET_MODULES_LIST = net
-NET_MODULES_LIST += net_posix
+SOCK_MODULES_LIST = sock
+SOCK_MODULES_LIST += sock_posix
 
 ifeq ($(CONFIG_VPP),y)
 ifneq ($(CONFIG_VPP_DIR),)
-NET_MODULES_DEPS = -l:libvppinfra.a -l:libsvm.a -l:libvapiclient.a
-NET_MODULES_DEPS += -l:libvppcom.a -l:libvlibmemoryclient.a
+SOCK_MODULES_DEPS = -l:libvppinfra.a -l:libsvm.a -l:libvapiclient.a
+SOCK_MODULES_DEPS += -l:libvppcom.a -l:libvlibmemoryclient.a
 else
-NET_MODULES_DEPS = -lvppcom
+SOCK_MODULES_DEPS = -lvppcom
 endif
-NET_MODULES_LIST += net_vpp
+SOCK_MODULES_LIST += sock_vpp
 endif
 
 COPY_MODULES_LIST = copy_ioat ioat
@@ -99,9 +103,9 @@ COPY_MODULES_LINKER_ARGS = -Wl,--whole-archive \
 
 COPY_MODULES_FILES = $(call spdk_lib_list_to_files,$(COPY_MODULES_LIST))
 
-NET_MODULES_LINKER_ARGS = -Wl,--whole-archive \
-			   $(NET_MODULES_LIST:%=-lspdk_%) \
-			   $(NET_MODULES_DEPS) \
+SOCK_MODULES_LINKER_ARGS = -Wl,--whole-archive \
+			   $(SOCK_MODULES_LIST:%=-lspdk_%) \
+			   $(SOCK_MODULES_DEPS) \
 			   -Wl,--no-whole-archive
 
-NET_MODULES_FILES = $(call spdk_lib_list_to_files,$(NET_MODULES_LIST))
+SOCK_MODULES_FILES = $(call spdk_lib_list_to_files,$(SOCK_MODULES_LIST))
diff --git a/mk/spdk.unittest.mk b/mk/spdk.unittest.mk
index 84e4ef111..d30a90edb 100644
--- a/mk/spdk.unittest.mk
+++ b/mk/spdk.unittest.mk
@@ -40,7 +40,7 @@ C_SRCS = $(TEST_FILE)
 CFLAGS += -I$(SPDK_ROOT_DIR)/lib
 CFLAGS += -I$(SPDK_ROOT_DIR)/test
 
-SPDK_LIB_LIST += util log spdk_mock
+SPDK_LIB_LIST += thread util log spdk_mock sock
 
 LIBS += -lcunit $(SPDK_LIB_LINKER_ARGS)
 
diff --git a/scripts/build_kmod.sh b/scripts/build_kmod.sh
deleted file mode 100755
index 41f40b42a..000000000
--- a/scripts/build_kmod.sh
+++ /dev/null
@@ -1,33 +0,0 @@
-#!/usr/bin/env bash
-
-readonly BASEDIR=$(readlink -f $(dirname $0))/..
-
-set -e
-
-function build_ioat_kmod() {
-	if [ -d $BASEDIR/examples/ioat/kperf/kmod ]; then
-		echo "Build Linux Ioat Test Module ..."
-		cd $BASEDIR/examples/ioat/kperf/kmod
-		make
-	fi
-}
-
-function clean_ioat_kmod() {
-	# remove dmaperf test module
-	grep -q "^dmaperf" /proc/modules && rmmod dmaperf
-	# cleanup build
-	if [ -d $BASEDIR/examples/ioat/kperf/kmod ]; then
-		echo "Cleanup Linux Ioat Test Module ..."
-		cd $BASEDIR/examples/ioat/kperf/kmod
-		make clean
-	fi
-}
-
-if [ `uname` = Linux ]; then
-	if [ "$1" = "build" ]; then
-		build_ioat_kmod
-	fi
-	if [ "$1" = "clean" ]; then
-		clean_ioat_kmod
-	fi
-fi
diff --git a/scripts/check_format.sh b/scripts/check_format.sh
index 5d1e8070c..4d20e8064 100755
--- a/scripts/check_format.sh
+++ b/scripts/check_format.sh
@@ -77,7 +77,7 @@ rm -f whitespace.log
 
 echo -n "Checking for use of forbidden library functions..."
 
-git grep --line-number -w '\(strncpy\|strcpy\|sprintf\|vsprintf\)' -- './*.c' ':!lib/vhost/rte_vhost*/**' > badfunc.log || true
+git grep --line-number -w '\(strncpy\|strcpy\|strcat\|sprintf\|vsprintf\)' -- './*.c' ':!lib/vhost/rte_vhost*/**' > badfunc.log || true
 if [ -s badfunc.log ]; then
 	echo " Forbidden library functions detected"
 	cat badfunc.log
@@ -87,6 +87,18 @@ else
 fi
 rm -f badfunc.log
 
+echo -n "Checking for use of forbidden CUnit macros..."
+
+git grep --line-number -w 'CU_ASSERT_FATAL' -- 'test/*' ':!test/spdk_cunit.h' > badcunit.log || true
+if [ -s badcunit.log ]; then
+	echo " Forbidden CU_ASSERT_FATAL usage detected - use SPDK_CU_ASSERT_FATAL instead"
+	cat badcunit.log
+	rc=1
+else
+	echo " OK"
+fi
+rm -f badcunit.log
+
 echo -n "Checking blank lines at end of file..."
 
 if ! git grep -I -l -e . -z | \
@@ -110,13 +122,19 @@ else
 fi
 rm -f scripts/posix.log
 
-if hash pep8; then
+if hash pycodestyle 2>/dev/null; then
+	PEP8=pycodestyle
+elif hash pep8 2>/dev/null; then
+	PEP8=pep8
+fi
+
+if [ ! -z ${PEP8} ]; then
 	echo -n "Checking Python style..."
 
 	PEP8_ARGS+=" --max-line-length=140"
 
 	error=0
-	git ls-files '*.py' | xargs -n1 pep8 $PEP8_ARGS > pep8.log || error=1
+	git ls-files '*.py' | xargs -n1 $PEP8 $PEP8_ARGS > pep8.log || error=1
 	if [ $error -ne 0 ]; then
 		echo " Python formatting errors detected"
 		cat pep8.log
@@ -125,6 +143,8 @@ if hash pep8; then
 		echo " OK"
 	fi
 	rm -f pep8.log
+else
+	echo "You do not have pycodestyle or pep8 installed so your Python style is not being checked!"
 fi
 
 # Check if any of the public interfaces were modified by this patch.
diff --git a/scripts/fio.py b/scripts/fio.py
index 4316f7e67..8e2316d2b 100755
--- a/scripts/fio.py
+++ b/scripts/fio.py
@@ -16,7 +16,7 @@ ioengine=libaio
 direct=1
 bs=%(blocksize)d
 iodepth=%(iodepth)d
-norandommap=1
+norandommap=%(norandommap)d
 %(verify)s
 verify_dump=1
 
@@ -37,7 +37,7 @@ filename=%(device)s
 
 def interrupt_handler(signum, frame):
     fio.terminate()
-    print "FIO terminated"
+    print("FIO terminated")
     sys.exit(0)
 
 
@@ -45,11 +45,11 @@ def main():
 
     global fio
     if (len(sys.argv) < 5):
-        print "usage:"
-        print "  " + sys.argv[0] + " <io_size> <queue_depth> <test_type> <runtime>"
-        print "advanced usage:"
-        print "If you want to run fio with verify, please add verify string after runtime."
-        print "Currently fio.py only support write rw randwrite randrw with verify enabled."
+        print("usage:")
+        print("  " + sys.argv[0] + " <io_size> <queue_depth> <test_type> <runtime>")
+        print("advanced usage:")
+        print("If you want to run fio with verify, please add verify string after runtime.")
+        print("Currently fio.py only support write rw randwrite randrw with verify enabled.")
         sys.exit(1)
 
     io_size = int(sys.argv[1])
@@ -62,7 +62,7 @@ def main():
         verify = False
 
     devices = get_target_devices()
-    print "Found devices: ", devices
+    print("Found devices: ", devices)
 
     configure_devices(devices)
     fio_executable = '/usr/bin/fio'
@@ -72,37 +72,48 @@ def main():
     signal.signal(signal.SIGTERM, interrupt_handler)
     signal.signal(signal.SIGINT, interrupt_handler)
     fio = Popen([fio_executable, '-'], stdin=PIPE)
-    fio.communicate(create_fio_config(io_size, queue_depth, device_paths, test_type, runtime, verify))
+    fio.communicate(create_fio_config(io_size, queue_depth, device_paths, test_type, runtime, verify).encode())
     fio.stdin.close()
     rc = fio.wait()
-    print "FIO completed with code %d\n" % rc
+    print("FIO completed with code %d\n" % rc)
     sys.stdout.flush()
     sys.exit(rc)
 
 
 def get_target_devices():
     output = check_output('iscsiadm -m session -P 3', shell=True)
-    return re.findall("Attached scsi disk (sd[a-z]+)", output)
+    return re.findall("Attached scsi disk (sd[a-z]+)", output.decode("ascii"))
 
 
 def create_fio_config(size, q_depth, devices, test, run_time, verify):
+    norandommap = 0
     if not verify:
         verifyfio = ""
+        norandommap = 1
     else:
         verifyfio = verify_template
     fiofile = fio_template % {"blocksize": size, "iodepth": q_depth,
-                              "testtype": test, "runtime": run_time, "verify": verifyfio}
+                              "testtype": test, "runtime": run_time,
+                              "norandommap": norandommap, "verify": verifyfio}
     for (i, dev) in enumerate(devices):
         fiofile += fio_job_template % {"jobnumber": i, "device": dev}
     return fiofile
 
 
 def set_device_parameter(devices, filename_template, value):
+    valid_value = True
+
     for dev in devices:
         filename = filename_template % dev
         f = open(filename, 'r+b')
-        f.write(value)
-        f.close()
+        try:
+            f.write(value.encode())
+            f.close()
+        except OSError:
+            valid_value = False
+            continue
+
+    return valid_value
 
 
 def configure_devices(devices):
@@ -117,10 +128,11 @@ def configure_devices(devices):
         except IOError:
             qd = qd - 1
     if qd == 0:
-        print "Could not set block device queue depths."
+        print("Could not set block device queue depths.")
     else:
-        print "Requested queue_depth {} but only {} is supported.".format(str(requested_qd), str(qd))
-    set_device_parameter(devices, "/sys/block/%s/queue/scheduler", "noop")
+        print("Requested queue_depth {} but only {} is supported.".format(str(requested_qd), str(qd)))
+    if not set_device_parameter(devices, "/sys/block/%s/queue/scheduler", "noop"):
+        set_device_parameter(devices, "/sys/block/%s/queue/scheduler", "none")
 
 
 if __name__ == "__main__":
diff --git a/scripts/gen_nvme.sh b/scripts/gen_nvme.sh
index ed450f68d..fa8a9242e 100755
--- a/scripts/gen_nvme.sh
+++ b/scripts/gen_nvme.sh
@@ -5,11 +5,42 @@ set -e
 rootdir=$(readlink -f $(dirname $0))/..
 source "$rootdir/scripts/common.sh"
 
-bdfs=$(iter_pci_class_code 01 08 02)
-
-echo "[Nvme]"
-i=0
-for bdf in $bdfs; do
-        echo "  TransportID \"trtype:PCIe traddr:$bdf\" Nvme$i"
-        let i=i+1
-done
+bdfs=($(iter_pci_class_code 01 08 02))
+function create_classic_config()
+{
+	echo "[Nvme]"
+	for (( i=0; i < ${#bdfs[@]}; i++))
+	do
+		echo "  TransportID \"trtype:PCIe traddr:${bdfs[i]}\" Nvme$i"
+	done
+}
+
+function create_json_config()
+{
+	echo "{"
+	echo '"subsystem": "bdev",'
+	echo '"config": ['
+	for (( i=0; i < ${#bdfs[@]}; i++))
+	do
+		echo '{'
+		echo '"params": {'
+		echo '"trtype": "PCIe",'
+		echo "\"name\": \"Nvme$i\","
+		echo "\"traddr\": \"${bdfs[i]}\""
+		echo '},'
+		echo '"method": "construct_nvme_bdev"'
+		if [ -z ${bdfs[i+1]} ]; then
+			echo '}'
+		else
+			echo '},'
+		fi
+	done
+	echo ']'
+	echo '}'
+}
+
+if [ "$1" = "--json" ]; then
+	create_json_config
+else
+	create_classic_config
+fi
diff --git a/scripts/perf/vhost/fio_test.conf b/scripts/perf/vhost/fio_test.conf
new file mode 100644
index 000000000..e1054e079
--- /dev/null
+++ b/scripts/perf/vhost/fio_test.conf
@@ -0,0 +1,21 @@
+[global]
+ioengine=libaio
+thread=1
+group_reporting=1
+direct=1
+verify=0
+norandommap=1
+cpumask=1
+percentile_list=50:90:99:99.5:99.9:99.99:99.999
+
+[perf_test]
+stonewall
+description="Run NVMe driver performance test for a given workload"
+bs={blksize}
+rw={rw}
+rwmixread={rwmixread}
+iodepth={iodepth}
+time_based=1
+ramp_time={ramptime}
+runtime={runtime}
+filename=
diff --git a/scripts/perf/vhost/run_vhost_test.py b/scripts/perf/vhost/run_vhost_test.py
new file mode 100644
index 000000000..61ab7e818
--- /dev/null
+++ b/scripts/perf/vhost/run_vhost_test.py
@@ -0,0 +1,208 @@
+import os
+import sys
+import argparse
+import multiprocessing
+import subprocess
+from subprocess import check_call, call, check_output, Popen, PIPE
+
+
+def range_incl(a, b):
+    return range(a, b + 1)
+
+
+def list_spdk_used_cpus(cpus):
+    cpu_list = []
+    for chunk in cpus.split(","):
+        if "-" in chunk:
+            _ = chunk.split("-")
+            _ = list(map(int, _))
+            cpu_list.extend(list(range_incl(*_)))
+        else:
+            cpu_list.append(int(chunk))
+    return cpu_list
+
+
+def gen_cpu_mask_config(output_dir, spdk_cpu_list, vm_count, vm_cpu_num):
+    spdk = gen_spdk_cpu_mask_config(spdk_cpu_list)
+    qemu = gen_qemu_cpu_mask_config(spdk_cpu_list, vm_count, vm_cpu_num)
+    file_path = os.path.join(output_dir, "mask_config")
+    with open(file_path, "w") as fh:
+        fh.write("".join([spdk, qemu]))
+    return file_path
+
+
+def gen_spdk_cpu_mask_config(spdk_cpu_list):
+    cpus = "vhost_0_reactor_mask=[%s]" % (spdk_cpu_list)
+
+    # Go through assigned CPUs and use the lowest CPU index as
+    # default primary core
+    cpu_indexes = list_spdk_used_cpus(spdk_cpu_list)
+    cpu_indexes.sort()
+    print(cpu_indexes)
+
+    pr_core = "vhost_0_master_core=%s" % (cpu_indexes[0])
+    return "\n".join([cpus, pr_core, "\n"])
+
+
+def get_host_cpus():
+    cpu_num = multiprocessing.cpu_count()
+    cpu_list = list(range(0, cpu_num))
+    output = check_output("lscpu | grep 'per core'", shell=True)
+
+    # Assuming 2-socket server
+    if "2" in str(output):
+        ht_enabled = True
+        cpu_chunk = int(cpu_num/4)
+        numa0_cpus = cpu_list[0:cpu_chunk]
+        numa0_cpus.extend(cpu_list[2*cpu_chunk:3*cpu_chunk])
+        numa1_cpus = cpu_list[cpu_chunk:2*cpu_chunk]
+        numa1_cpus.extend(cpu_list[3*cpu_chunk:4*cpu_chunk])
+    else:
+        ht_enabled = False
+        cpu_chunk = int(cpu_num/2)
+        numa0_cpus = cpu_list[:cpu_chunk]
+        numa1_cpus = cpu_list[cpu_chunk:]
+    return [numa0_cpus, numa1_cpus]
+
+
+def gen_qemu_cpu_mask_config(spdk_cpu_list, vm_count, vm_cpu_num):
+    print("Creating masks for QEMU")
+    ret = ""
+
+    # Exclude SPDK cores from available CPU list
+    numa0_cpus, numa1_cpus = get_host_cpus()
+    spdk_cpus = list_spdk_used_cpus(spdk_cpu_list)
+    spdk_cpus.sort()
+
+    numa0_cpus = sorted(list(set(numa0_cpus) - set(spdk_cpus)))
+    numa1_cpus = sorted(list(set(numa1_cpus) - set(spdk_cpus)))
+
+    # Generate qemu cpu mask and numa param for VMs out of
+    # remaining free CPU cores.
+    # All CPUs assigned to a VM will come from the same NUMA node.
+    # Assuming 2 socket server.
+    used_numa = 0
+    available = numa0_cpus
+    for i in range(0, vm_count):
+        cpus = [str(x) for x in available[0:vm_cpu_num]]
+
+        # If there is not enough cores on first numa node for a VM
+        # then switch to next numa node
+        if len(cpus) < vm_cpu_num and used_numa == 0:
+            available = numa1_cpus
+            used_numa = 1
+            cpus = [str(x) for x in available[0:vm_cpu_num]]
+
+        # If not enough cores on second numa node - break and exit
+        if len(cpus) < vm_cpu_num and used_numa == 1:
+            print("There is not enough CPU Cores available on \
+            Numa node1 to create VM %s" % i)
+            break
+
+        cpus = ",".join(cpus)
+        cpus = "VM_%s_qemu_mask=%s" % (i, cpus)
+        numa = "VM_%s_qemu_numa_node=%s\n" % (i, used_numa)
+
+        # Remove used CPU cores from available list
+        available = available[vm_cpu_num:]
+        ret = "\n".join([ret, cpus, numa])
+
+    return ret
+
+
+def create_fio_cfg(template_dir, output_dir, **kwargs):
+    fio_tempalte = os.path.join(template_dir, "fio_test.conf")
+    with open("scripts/perf/vhost/fio_test.conf", "r") as fh:
+        cfg = fh.read()
+    cfg = cfg.format(**kwargs)
+
+    file_path = os.path.join(output_dir, "fio_job.cfg")
+    with open(file_path, "w") as fh:
+        fh.write(cfg)
+    return file_path
+
+
+script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
+parser = argparse.ArgumentParser()
+
+parser.add_argument('blksize', default="4k", type=str,
+                    help="Block size param for FIO. Default: 4k")
+parser.add_argument('iodepth', default="128", type=str,
+                    help="Iodepth param for FIO. Default: 128")
+parser.add_argument('rw', default="randread", type=str,
+                    help="RW param for FIO. Default: randread")
+parser.add_argument('-m', '--rwmixread', default="70", type=str,
+                    help="Percentage of reads in read-write mode. Default: 70")
+parser.add_argument('-r', '--runtime', default="10", type=str,
+                    help="Run time param for FIO (in seconds). Default: 10")
+parser.add_argument('-R', '--ramptime', default="10", type=str,
+                    help="Ramp time param for FIO (in seconds). Default: 10")
+parser.add_argument('-c', '--ctrl-type', default="spdk_vhost_scsi", type=str,
+                    help="Type of vhost controller to use in test.\
+                    Possible options: spdk_vhost_scsi, spdk_vhost_blk.\
+                    Default: spdk_vhost_scsi")
+parser.add_argument('-s', '--split', default=False, type=bool,
+                    help="Use split vbdevs instead of logical volumes. Default: false")
+parser.add_argument('-d', '--max-disks', default=0, type=int,
+                    help="How many physical disks to use in test. Default: all disks.\
+                    Depending on the number of --vm-count disks may be split into\
+                    smaller logical bdevs (splits or logical volumes) so that\
+                    each virtual machine gets it's own bdev to work on.")
+parser.add_argument('-v', '--vm-count', default=1, type=int,
+                    help="How many VMs to run in test. Default: 1")
+parser.add_argument('-i', '--vm-image', default="/home/sys_sgsw/vhost_vm_image.qcow2",
+                    type=str, help="VM image to use for running VMs.")
+
+subparsers = parser.add_subparsers()
+cpu_cfg_create = subparsers.add_parser('create_cpu_cfg',
+                                       help="Generate a CPU config file for test.\
+                                       This option will attempt to automatically\
+                                       generate config file with SPDK/QEMU cpu lists.\
+                                       CPU cores on NUMA Node 0 will be used first\
+                                       (including logical cores when HT is enabled)\
+                                       and NUMA Node 1 will be used last.")
+cpu_cfg_create.add_argument('spdk_cpu_list', default=None,
+                            help="List of CPU cores to be used by SPDK vhost app.\
+                            Accepted format examples:\
+                            single cpus: 0,2,4\
+                            ranges (inclusive!): 0-2\
+                            mixed: 0,2-5,9")
+cpu_cfg_create.add_argument('vm_cpu_num', default=None, type=int)
+
+cpu_cfg_load = subparsers.add_parser('load_cpu_cfg',
+                                     help="Load and use a CPU config file for test\
+                                     Example configuration files can be found in:\
+                                     test/vhost/common/autotest.config")
+cpu_cfg_load.add_argument('custom_mask_file', default=None,
+                          help="Path to file with custom values for vhost's\
+                          reactor mask and master core, and each VM's qemu mask\
+                          and qemu numa node")
+
+args = parser.parse_args()
+fio_cfg_path = create_fio_cfg(script_dir, script_dir, **vars(args))
+
+cpu_cfg_arg = ""
+disk_arg = ""
+split_arg = ""
+if "spdk_cpu_list" in args:
+    cfg_path = gen_cpu_mask_config(script_dir, args.spdk_cpu_list, args.vm_count, args.vm_cpu_num)
+    cpu_cfg_arg = "--custom-cpu-cfg=%s" % cfg_path
+if "custom_mask_file" in args:
+    cpu_cfg_arg = "--custom-cpu-cfg=%s" % args.custom_mask_file
+if args.split is True:
+    split_arg = "--use-split"
+if args.max_disks > 0:
+    disk_arg = "--max-disks=%s" % args.max_disks
+
+
+command = " ".join(["test/vhost/perf_bench/vhost_perf.sh",
+                    "--vm-image=%s" % args.vm_image,
+                    "--vm-count=%s" % args.vm_count,
+                    "--ctrl-type=%s" % args.ctrl_type,
+                    "%s" % split_arg,
+                    "%s" % disk_arg,
+                    "--fio-job=%s" % fio_cfg_path,
+                    "%s" % cpu_cfg_arg])
+print("INFO: Running perf test with command:")
+print(command)
+pr = check_output(command, shell=True)
diff --git a/scripts/pkgdep.sh b/scripts/pkgdep.sh
index db77b8a7e..da5f77d77 100755
--- a/scripts/pkgdep.sh
+++ b/scripts/pkgdep.sh
@@ -9,19 +9,20 @@ if [ -s /etc/redhat-release ]; then
 		# Add EPEL repository for CUnit-devel
 		yum --enablerepo=extras install -y epel-release
 	fi
-	yum install -y gcc gcc-c++ make CUnit-devel libaio-devel openssl-devel \
-		git astyle-devel python-pep8 lcov python clang-analyzer libuuid-devel \
+	yum install -y gcc gcc-c++ make CUnit-devel libaio-devel \
+		git astyle python-pep8 lcov python clang-analyzer libuuid-devel \
 		sg3_utils libiscsi-devel
+	yum install -y --allowerasing openssl-devel
 	# Additional dependencies for NVMe over Fabrics
 	yum install -y libibverbs-devel librdmacm-devel
 	# Additional dependencies for DPDK
-	yum install -y numactl-devel
+	yum install -y numactl-devel nasm
 	# Additional dependencies for building docs
 	yum install -y doxygen mscgen graphviz
 	# Additional dependencies for building pmem based backends
 	yum install -y libpmemblk-devel || true
 	# Additional dependencies for SPDK CLI
-	yum install -y python-configshell
+	yum install -y python-configshell python-pexpect python3-configshell python3-pexpect
 elif [ -f /etc/debian_version ]; then
 	# Includes Ubuntu, Debian
 	apt-get install -y gcc g++ make libcunit1-dev libaio-dev libssl-dev \
@@ -29,27 +30,29 @@ elif [ -f /etc/debian_version ]; then
 	# Additional dependencies for NVMe over Fabrics
 	apt-get install -y libibverbs-dev librdmacm-dev
 	# Additional dependencies for DPDK
-	apt-get install -y libnuma-dev
+	apt-get install -y libnuma-dev nasm
 	# Additional dependencies for building docs
 	apt-get install -y doxygen mscgen graphviz
 	# Additional dependencies for SPDK CLI
-	apt-get install -y "python-configshell*"
+	apt-get install -y python-pip python3-pip
+	pip install configshell_fb pexpect
+	pip3 install configshell_fb pexpect
 elif [ -f /etc/SuSE-release ]; then
 	zypper install -y gcc gcc-c++ make cunit-devel libaio-devel libopenssl-devel \
 		git-core lcov python-base python-pep8 libuuid-devel sg3_utils
 	# Additional dependencies for NVMe over Fabrics
 	zypper install -y rdma-core-devel
 	# Additional dependencies for DPDK
-	zypper install -y libnuma-devel
-	# Additional dependencies for building nvml based backends
+	zypper install -y libnuma-devel nasm
+	# Additional dependencies for building pmem based backends
 	zypper install -y libpmemblk-devel
 	# Additional dependencies for building docs
 	zypper install -y doxygen mscgen graphviz
 elif [ $SYSTEM = "FreeBSD" ] ; then
-	pkg install gmake cunit openssl git devel/astyle bash devel/pep8 \
-		python misc/e2fsprogs-libuuid sysutils/sg3_utils
+	pkg install -y gmake cunit openssl git devel/astyle bash py27-pycodestyle \
+		python misc/e2fsprogs-libuuid sysutils/sg3_utils nasm
 	# Additional dependencies for building docs
-	pkg install doxygen mscgen graphviz
+	pkg install -y doxygen mscgen graphviz
 else
 	echo "pkgdep: unknown system type."
 	exit 1
diff --git a/scripts/rpc.py b/scripts/rpc.py
index 9f7e4927e..2f1bb617b 100755
--- a/scripts/rpc.py
+++ b/scripts/rpc.py
@@ -40,11 +40,19 @@ if __name__ == "__main__":
                         help='Verbose mode', action='store_true')
     subparsers = parser.add_subparsers(help='RPC methods')
 
+    @call_cmd
+    def start_subsystem_init(args):
+        rpc.start_subsystem_init(args.client)
+
+    p = subparsers.add_parser('start_subsystem_init', help='Start initialization of subsystems')
+    p.set_defaults(func=start_subsystem_init)
+
     @call_cmd
     def get_rpc_methods(args):
-        print_dict(rpc.get_rpc_methods(args.client))
+        print_dict(rpc.get_rpc_methods(args.client, args))
 
     p = subparsers.add_parser('get_rpc_methods', help='Get list of supported RPC methods')
+    p.add_argument('-c', '--current', help='Get list of RPC methods only callable in the current state.', action='store_true')
     p.set_defaults(func=get_rpc_methods)
 
     @call_cmd
@@ -64,13 +72,35 @@ if __name__ == "__main__":
 
     p = subparsers.add_parser('load_config', help="""Configure SPDK subsystems and tagets using JSON RPC. If no file is
     provided or file is '-' read configuration from stdin.""")
-    p.add_argument('--filename', help="""JSON Configuration file.""")
+    p.add_argument('-f', '--filename', help="""JSON Configuration file.""")
     p.set_defaults(func=load_config)
 
+    @call_cmd
+    def save_subsystem_config(args):
+        rpc.save_subsystem_config(args.client, args)
+
+    p = subparsers.add_parser('save_subsystem_config', help="""Write current (live) configuration of SPDK subsystem.
+    If no filename is given write configuration to stdout.""")
+    p.add_argument('-f', '--filename', help='File where to save JSON configuration to.')
+    p.add_argument('-i', '--indent', help="""Indent level. Value less than 0 mean compact mode. If filename is not given default
+    indent level is 2. If writing to file of filename is '-' then default is compact mode.""", type=int, default=2)
+    p.add_argument('-n', '--name', help='Name of subsystem', required=True)
+    p.set_defaults(func=save_subsystem_config)
+
+    @call_cmd
+    def load_subsystem_config(args):
+        rpc.load_subsystem_config(args.client, args)
+
+    p = subparsers.add_parser('load_subsystem_config', help="""Configure SPDK subsystem using JSON RPC. If no file is
+    provided or file is '-' read configuration from stdin.""")
+    p.add_argument('-f', '--filename', help="""JSON Configuration file.""")
+    p.set_defaults(func=load_subsystem_config)
+
     # app
     @call_cmd
     def kill_instance(args):
-        rpc.app.kill_instance(args.client, args)
+        rpc.app.kill_instance(args.client,
+                              sig_name=args.sig_name)
 
     p = subparsers.add_parser('kill_instance', help='Send signal to instance')
     p.add_argument('sig_name', help='signal will be sent to server.')
@@ -78,7 +108,13 @@ if __name__ == "__main__":
 
     @call_cmd
     def context_switch_monitor(args):
-        print_dict(rpc.app.context_switch_monitor(args.client, args))
+        enabled = None
+        if args.enable:
+            enabled = True
+        if args.disable:
+            enabled = False
+        print_dict(rpc.app.context_switch_monitor(args.client,
+                                                  enabled=enabled))
 
     p = subparsers.add_parser('context_switch_monitor', help='Control whether the context switch monitor is enabled')
     p.add_argument('-e', '--enable', action='store_true', help='Enable context switch monitoring')
@@ -86,9 +122,25 @@ if __name__ == "__main__":
     p.set_defaults(func=context_switch_monitor)
 
     # bdev
+    @call_cmd
+    def set_bdev_options(args):
+        rpc.bdev.set_bdev_options(args.client,
+                                  bdev_io_pool_size=args.bdev_io_pool_size,
+                                  bdev_io_cache_size=args.bdev_io_cache_size)
+
+    p = subparsers.add_parser('set_bdev_options', help="""Set options of bdev subsystem""")
+    p.add_argument('-p', '--bdev-io-pool-size', help='Number of bdev_io structures in shared buffer pool', type=int)
+    p.add_argument('-c', '--bdev-io-cache-size', help='Maximum number of bdev_io structures cached per thread', type=int)
+    p.set_defaults(func=set_bdev_options)
+
     @call_cmd
     def construct_malloc_bdev(args):
-        print_array(rpc.bdev.construct_malloc_bdev(args.client, args))
+        num_blocks = (args.total_size * 1024 * 1024) // args.block_size
+        print(rpc.bdev.construct_malloc_bdev(args.client,
+                                             num_blocks=num_blocks,
+                                             block_size=args.block_size,
+                                             name=args.name,
+                                             uuid=args.uuid))
 
     p = subparsers.add_parser('construct_malloc_bdev',
                               help='Add a bdev with malloc backend')
@@ -99,9 +151,23 @@ if __name__ == "__main__":
     p.add_argument('block_size', help='Block size for this bdev', type=int)
     p.set_defaults(func=construct_malloc_bdev)
 
+    @call_cmd
+    def delete_malloc_bdev(args):
+        rpc.bdev.delete_malloc_bdev(args.client,
+                                    name=args.name)
+
+    p = subparsers.add_parser('delete_malloc_bdev', help='Delete a malloc disk')
+    p.add_argument('name', help='malloc bdev name')
+    p.set_defaults(func=delete_malloc_bdev)
+
     @call_cmd
     def construct_null_bdev(args):
-        print_array(rpc.bdev.construct_null_bdev(args.client, args))
+        num_blocks = (args.total_size * 1024 * 1024) // args.block_size
+        print(rpc.bdev.construct_null_bdev(args.client,
+                                           num_blocks=num_blocks,
+                                           block_size=args.block_size,
+                                           name=args.name,
+                                           uuid=args.uuid))
 
     p = subparsers.add_parser('construct_null_bdev',
                               help='Add a bdev with null backend')
@@ -112,20 +178,47 @@ if __name__ == "__main__":
     p.add_argument('block_size', help='Block size for this bdev', type=int)
     p.set_defaults(func=construct_null_bdev)
 
+    @call_cmd
+    def delete_null_bdev(args):
+        rpc.bdev.delete_null_bdev(args.client,
+                                  name=args.name)
+
+    p = subparsers.add_parser('delete_null_bdev', help='Delete a null bdev')
+    p.add_argument('name', help='null bdev name')
+    p.set_defaults(func=delete_null_bdev)
+
     @call_cmd
     def construct_aio_bdev(args):
-        print_array(rpc.bdev.construct_aio_bdev(args.client, args))
+        print(rpc.bdev.construct_aio_bdev(args.client,
+                                          filename=args.filename,
+                                          name=args.name,
+                                          block_size=args.block_size))
 
     p = subparsers.add_parser('construct_aio_bdev',
                               help='Add a bdev with aio backend')
     p.add_argument('filename', help='Path to device or file (ex: /dev/sda)')
     p.add_argument('name', help='Block device name')
-    p.add_argument('block_size', help='Block size for this bdev', type=int, default=argparse.SUPPRESS)
+    p.add_argument('block_size', help='Block size for this bdev', type=int, nargs='?', default=0)
     p.set_defaults(func=construct_aio_bdev)
 
+    @call_cmd
+    def delete_aio_bdev(args):
+        rpc.bdev.delete_aio_bdev(args.client,
+                                 name=args.name)
+
+    p = subparsers.add_parser('delete_aio_bdev', help='Delete an aio disk')
+    p.add_argument('name', help='aio bdev name')
+    p.set_defaults(func=delete_aio_bdev)
+
     @call_cmd
     def construct_nvme_bdev(args):
-        print_array(rpc.bdev.construct_nvme_bdev(args.client, args))
+        print_array(rpc.bdev.construct_nvme_bdev(args.client,
+                                                 name=args.name,
+                                                 trtype=args.trtype,
+                                                 traddr=args.traddr,
+                                                 adrfam=args.adrfam,
+                                                 trsvcid=args.trsvcid,
+                                                 subnqn=args.subnqn))
 
     p = subparsers.add_parser('construct_nvme_bdev',
                               help='Add bdev with nvme backend')
@@ -143,7 +236,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_rbd_bdev(args):
-        print_array(rpc.bdev.construct_rbd_bdev(args.client, args))
+        print(rpc.bdev.construct_rbd_bdev(args.client,
+                                          name=args.name,
+                                          pool_name=args.pool_name,
+                                          rbd_name=args.rbd_name,
+                                          block_size=args.block_size))
 
     p = subparsers.add_parser('construct_rbd_bdev',
                               help='Add a bdev with ceph rbd backend')
@@ -153,37 +250,102 @@ if __name__ == "__main__":
     p.add_argument('block_size', help='rbd block size', type=int)
     p.set_defaults(func=construct_rbd_bdev)
 
+    @call_cmd
+    def delete_rbd_bdev(args):
+        rpc.bdev.delete_rbd_bdev(args.client,
+                                 name=args.name)
+
+    p = subparsers.add_parser('delete_rbd_bdev', help='Delete a rbd bdev')
+    p.add_argument('name', help='rbd bdev name')
+    p.set_defaults(func=delete_rbd_bdev)
+
     @call_cmd
     def construct_error_bdev(args):
-        rpc.bdev.construct_error_bdev(args.client, args)
+        print(rpc.bdev.construct_error_bdev(args.client,
+                                            base_name=args.base_name))
 
     p = subparsers.add_parser('construct_error_bdev',
                               help='Add bdev with error injection backend')
     p.add_argument('base_name', help='base bdev name')
     p.set_defaults(func=construct_error_bdev)
 
+    @call_cmd
+    def delete_error_bdev(args):
+        rpc.bdev.delete_error_bdev(args.client,
+                                   name=args.name)
+
+    p = subparsers.add_parser('delete_error_bdev', help='Delete an error bdev')
+    p.add_argument('name', help='error bdev name')
+    p.set_defaults(func=delete_error_bdev)
+
+    @call_cmd
+    def construct_iscsi_bdev(args):
+        print(rpc.bdev.construct_iscsi_bdev(args.client,
+                                            name=args.name,
+                                            url=args.url,
+                                            initiator_iqn=args.initiator_iqn))
+
+    p = subparsers.add_parser('construct_iscsi_bdev',
+                              help='Add bdev with iSCSI initiator backend')
+    p.add_argument('-b', '--name', help="Name of the bdev", required=True)
+    p.add_argument('-i', '--initiator-iqn', help="Initiator IQN", required=True)
+    p.add_argument('--url', help="iSCSI Lun URL", required=True)
+    p.set_defaults(func=construct_iscsi_bdev)
+
+    @call_cmd
+    def delete_iscsi_bdev(args):
+        rpc.bdev.delete_iscsi_bdev(args.client,
+                                   name=args.name)
+
+    p = subparsers.add_parser('delete_iscsi_bdev', help='Delete an iSCSI bdev')
+    p.add_argument('name', help='iSCSI bdev name')
+    p.set_defaults(func=delete_iscsi_bdev)
+
     @call_cmd
     def construct_pmem_bdev(args):
-        print_array(rpc.bdev.construct_pmem_bdev(args.client, args))
+        print(rpc.bdev.construct_pmem_bdev(args.client,
+                                           pmem_file=args.pmem_file,
+                                           name=args.name))
 
     p = subparsers.add_parser('construct_pmem_bdev', help='Add a bdev with pmem backend')
     p.add_argument('pmem_file', help='Path to pmemblk pool file')
     p.add_argument('-n', '--name', help='Block device name', required=True)
     p.set_defaults(func=construct_pmem_bdev)
 
+    @call_cmd
+    def delete_pmem_bdev(args):
+        rpc.bdev.delete_pmem_bdev(args.client,
+                                  name=args.name)
+
+    p = subparsers.add_parser('delete_pmem_bdev', help='Delete a pmem bdev')
+    p.add_argument('name', help='pmem bdev name')
+    p.set_defaults(func=delete_pmem_bdev)
+
     @call_cmd
     def construct_passthru_bdev(args):
-        print_array(rpc.bdev.construct_passthru_bdev(args.client, args))
+        print(rpc.bdev.construct_passthru_bdev(args.client,
+                                               base_bdev_name=args.base_bdev_name,
+                                               passthru_bdev_name=args.passthru_bdev_name))
 
     p = subparsers.add_parser('construct_passthru_bdev',
                               help='Add a pass through bdev on existing bdev')
     p.add_argument('-b', '--base-bdev-name', help="Name of the existing bdev", required=True)
-    p.add_argument('-p', '--passthru-bdev-name', help="Name of the passthru bdev", required=True)
+    p.add_argument('-p', '--passthru-bdev-name', help="Name of the pass through bdev", required=True)
     p.set_defaults(func=construct_passthru_bdev)
 
+    @call_cmd
+    def delete_passthru_bdev(args):
+        rpc.bdev.delete_passthru_bdev(args.client,
+                                      name=args.name)
+
+    p = subparsers.add_parser('delete_passthru_bdev', help='Delete a pass through bdev')
+    p.add_argument('name', help='pass through bdev name')
+    p.set_defaults(func=delete_passthru_bdev)
+
     @call_cmd
     def get_bdevs(args):
-        print_dict(rpc.bdev.get_bdevs(args.client, args))
+        print_dict(rpc.bdev.get_bdevs(args.client,
+                                      name=args.name))
 
     p = subparsers.add_parser(
         'get_bdevs', help='Display current blockdev list or required blockdev')
@@ -192,25 +354,52 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_bdevs_config(args):
-        print_dict(rpc.bdev.get_bdevs_config(args.client, args))
+        print_dict(rpc.bdev.get_bdevs_config(args.client,
+                                             name=args.name))
 
     p = subparsers.add_parser(
         'get_bdevs_config', help='Display current (live) blockdev configuration list or required blockdev')
     p.add_argument('-b', '--name', help="Name of the Blockdev. Example: Nvme0n1", required=False)
     p.set_defaults(func=get_bdevs_config)
 
+    @call_cmd
+    def get_bdevs_iostat(args):
+        print_dict(rpc.bdev.get_bdevs_iostat(args.client,
+                                             name=args.name))
+
+    p = subparsers.add_parser(
+        'get_bdevs_iostat', help='Display current I/O statistics of all the blockdevs or required blockdev.')
+    p.add_argument('-b', '--name', help="Name of the Blockdev. Example: Nvme0n1", required=False)
+    p.set_defaults(func=get_bdevs_iostat)
+
     @call_cmd
     def delete_bdev(args):
-        rpc.bdev.delete_bdev(args.client, args)
+        rpc.bdev.delete_bdev(args.client,
+                             bdev_name=args.bdev_name)
 
     p = subparsers.add_parser('delete_bdev', help='Delete a blockdev')
     p.add_argument(
         'bdev_name', help='Blockdev name to be deleted. Example: Malloc0.')
     p.set_defaults(func=delete_bdev)
 
+    @call_cmd
+    def set_bdev_qd_sampling_period(args):
+        rpc.bdev.set_bdev_qd_sampling_period(args.client,
+                                             name=args.name,
+                                             period=args.period)
+
+    p = subparsers.add_parser('set_bdev_qd_sampling_period', help="Enable or disable tracking of a bdev's queue depth.")
+    p.add_argument('name', help='Blockdev name. Example: Malloc0')
+    p.add_argument('period', help='Period with which to poll the block device queue depth in microseconds.'
+                   ' If set to 0, polling will be disabled.',
+                   type=int)
+    p.set_defaults(func=set_bdev_qd_sampling_period)
+
     @call_cmd
     def set_bdev_qos_limit_iops(args):
-        rpc.bdev.set_bdev_qos_limit_iops(args.client, args)
+        rpc.bdev.set_bdev_qos_limit_iops(args.client,
+                                         name=args.name,
+                                         ios_per_sec=args.ios_per_sec)
 
     p = subparsers.add_parser('set_bdev_qos_limit_iops', help='Set QoS IOPS limit on a blockdev')
     p.add_argument('name', help='Blockdev name to set QoS. Example: Malloc0')
@@ -220,7 +409,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def bdev_inject_error(args):
-        rpc.bdev.bdev_inject_error(args.client, args)
+        rpc.bdev.bdev_inject_error(args.client,
+                                   name=args.name,
+                                   io_type=args.io_type,
+                                   error_type=args.error_type,
+                                   num=args.num)
 
     p = subparsers.add_parser('bdev_inject_error', help='bdev inject error')
     p.add_argument('name', help="""the name of the error injection bdev""")
@@ -232,7 +425,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def apply_firmware(args):
-        print_dict(rpc.bdev.apply_firmware(args.client, args))
+        print_dict(rpc.bdev.apply_firmware(args.client,
+                                           bdev_name=args.bdev_name,
+                                           filename=args.filename))
 
     p = subparsers.add_parser('apply_firmware', help='Download and commit firmware to NVMe device')
     p.add_argument('filename', help='filename of the firmware to download')
@@ -240,9 +435,51 @@ if __name__ == "__main__":
     p.set_defaults(func=apply_firmware)
 
     # iSCSI
+    def set_iscsi_options(args):
+        rpc.iscsi.set_iscsi_options(
+            args.client,
+            auth_file=args.auth_file,
+            node_base=args.node_base,
+            nop_timeout=args.nop_timeout,
+            nop_in_interval=args.nop_in_interval,
+            no_discovery_auth=args.no_discovery_auth,
+            req_discovery_auth=args.req_discovery_auth,
+            req_discovery_auth_mutual=args.req_discovery_auth_mutual,
+            discovery_auth_group=args.discovery_auth_group,
+            max_sessions=args.max_sessions,
+            max_connections_per_session=args.max_connections_per_session,
+            default_time2wait=args.default_time2wait,
+            default_time2retain=args.default_time2retain,
+            immediate_data=args.immediate_data,
+            error_recovery_level=args.error_recovery_level,
+            allow_duplicated_isid=args.allow_duplicated_isid,
+            min_connections_per_session=args.min_connections_per_session)
+
+    p = subparsers.add_parser('set_iscsi_options', help="""Set options of iSCSI subsystem""")
+    p.add_argument('-f', '--auth-file', help='Path to CHAP shared secret file for discovery session')
+    p.add_argument('-b', '--node-base', help='Prefix of the name of iSCSI target node')
+    p.add_argument('-o', '--nop-timeout', help='Timeout in seconds to nop-in request to the initiator', type=int)
+    p.add_argument('-n', '--nop-in-interval', help='Time interval in secs between nop-in requests by the target', type=int)
+    p.add_argument('-d', '--no-discovery-auth', help="""CHAP for discovery session should be disabled.
+    *** Mutually exclusive with --req-discovery-auth""", action='store_true')
+    p.add_argument('-r', '--req-discovery-auth', help="""CHAP for discovery session should be required.
+    *** Mutually exclusive with --no-discovery-auth""", action='store_true')
+    p.add_argument('-m', '--req-discovery-auth-mutual', help='CHAP for discovery session should be mutual', action='store_true')
+    p.add_argument('-g', '--discovery-auth-group', help="""Authentication group ID for discovery session.
+    *** Authentication group must be precreated ***""", type=int)
+    p.add_argument('-a', '--max-sessions', help='Maximum number of sessions in the host.', type=int)
+    p.add_argument('-c', '--max-connections-per-session', help='Negotiated parameter, MaxConnections.', type=int)
+    p.add_argument('-w', '--default-time2wait', help='Negotiated parameter, DefaultTime2Wait.', type=int)
+    p.add_argument('-v', '--default-time2retain', help='Negotiated parameter, DefaultTime2Retain.', type=int)
+    p.add_argument('-i', '--immediate-data', help='Negotiated parameter, ImmediateData.', action='store_true')
+    p.add_argument('-l', '--error-recovery-level', help='Negotiated parameter, ErrorRecoveryLevel', type=int)
+    p.add_argument('-p', '--allow-duplicated-isid', help='Allow duplicated initiator session ID.', action='store_true')
+    p.add_argument('-u', '--min-connections-per-session', help='Allocation unit of connections per core', type=int)
+    p.set_defaults(func=set_iscsi_options)
+
     @call_cmd
     def get_portal_groups(args):
-        print_dict(rpc.iscsi.get_portal_groups(args.client, args))
+        print_dict(rpc.iscsi.get_portal_groups(args.client))
 
     p = subparsers.add_parser(
         'get_portal_groups', help='Display current portal group configuration')
@@ -250,7 +487,7 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_initiator_groups(args):
-        print_dict(rpc.iscsi.get_initiator_groups(args.client, args))
+        print_dict(rpc.iscsi.get_initiator_groups(args.client))
 
     p = subparsers.add_parser('get_initiator_groups',
                               help='Display current initiator group configuration')
@@ -258,14 +495,36 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_target_nodes(args):
-        print_dict(rpc.iscsi.get_target_nodes(args.client, args))
+        print_dict(rpc.iscsi.get_target_nodes(args.client))
 
     p = subparsers.add_parser('get_target_nodes', help='Display target nodes')
     p.set_defaults(func=get_target_nodes)
 
     @call_cmd
     def construct_target_node(args):
-        rpc.iscsi.construct_target_node(args.client, args)
+        luns = []
+        for u in args.bdev_name_id_pairs.strip().split(" "):
+            bdev_name, lun_id = u.split(":")
+            luns.append({"bdev_name": bdev_name, "lun_id": int(lun_id)})
+
+        pg_ig_maps = []
+        for u in args.pg_ig_mappings.strip().split(" "):
+            pg, ig = u.split(":")
+            pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
+
+        rpc.iscsi.construct_target_node(
+            args.client,
+            luns=luns,
+            pg_ig_maps=pg_ig_maps,
+            name=args.name,
+            alias_name=args.alias_name,
+            queue_depth=args.queue_depth,
+            chap_group=args.chap_group,
+            disable_chap=args.disable_chap,
+            require_chap=args.require_chap,
+            mutual_chap=args.mutual_chap,
+            header_digest=args.header_digest,
+            data_digest=args.data_digest)
 
     p = subparsers.add_parser('construct_target_node',
                               help='Add a target node')
@@ -299,7 +558,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def target_node_add_lun(args):
-        rpc.iscsi.target_node_add_lun(args.client, args)
+        rpc.iscsi.target_node_add_lun(
+            args.client,
+            name=args.name,
+            bdev_name=args.bdev_name,
+            lun_id=args.lun_id)
 
     p = subparsers.add_parser('target_node_add_lun', help='Add LUN to the target node')
     p.add_argument('name', help='Target node name (ASCII)')
@@ -311,7 +574,14 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_pg_ig_maps(args):
-        rpc.iscsi.add_pg_ig_maps(args.client, args)
+        pg_ig_maps = []
+        for u in args.pg_ig_mappings.strip().split(" "):
+            pg, ig = u.split(":")
+            pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
+        rpc.iscsi.add_pg_ig_maps(
+            args.client,
+            pg_ig_maps=pg_ig_maps,
+            name=args.name)
 
     p = subparsers.add_parser('add_pg_ig_maps', help='Add PG-IG maps to the target node')
     p.add_argument('name', help='Target node name (ASCII)')
@@ -324,7 +594,12 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_pg_ig_maps(args):
-        rpc.iscsi.delete_pg_ig_maps(args.client, args)
+        pg_ig_maps = []
+        for u in args.pg_ig_mappings.strip().split(" "):
+            pg, ig = u.split(":")
+            pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
+        rpc.iscsi.delete_pg_ig_maps(
+            args.client, pg_ig_maps=pg_ig_maps, name=args.name)
 
     p = subparsers.add_parser('delete_pg_ig_maps', help='Delete PG-IG maps from the target node')
     p.add_argument('name', help='Target node name (ASCII)')
@@ -337,7 +612,21 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_portal_group(args):
-        rpc.iscsi.add_portal_group(args.client, args)
+        portals = []
+        for p in args.portal_list:
+            ip, separator, port_cpumask = p.rpartition(':')
+            split_port_cpumask = port_cpumask.split('@')
+            if len(split_port_cpumask) == 1:
+                port = port_cpumask
+                portals.append({'host': ip, 'port': port})
+            else:
+                port = split_port_cpumask[0]
+                cpumask = split_port_cpumask[1]
+                portals.append({'host': ip, 'port': port, 'cpumask': cpumask})
+        rpc.iscsi.add_portal_group(
+            args.client,
+            portals=portals,
+            tag=args.tag)
 
     p = subparsers.add_parser('add_portal_group', help='Add a portal group')
     p.add_argument(
@@ -349,7 +638,17 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_initiator_group(args):
-        rpc.iscsi.add_initiator_group(args.client, args)
+        initiators = []
+        netmasks = []
+        for i in args.initiator_list.strip().split(' '):
+            initiators.append(i)
+        for n in args.netmask_list.strip().split(' '):
+            netmasks.append(n)
+        rpc.iscsi.add_initiator_group(
+            args.client,
+            tag=args.tag,
+            initiators=initiators,
+            netmasks=netmasks)
 
     p = subparsers.add_parser('add_initiator_group',
                               help='Add an initiator group')
@@ -363,7 +662,21 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_initiators_to_initiator_group(args):
-        rpc.iscsi.add_initiators_to_initiator_group(args.client, args)
+        initiators = None
+        netmasks = None
+        if args.initiator_list:
+            initiators = []
+            for i in args.initiator_list.strip().split(' '):
+                initiators.append(i)
+        if args.netmask_list:
+            netmasks = []
+            for n in args.netmask_list.strip().split(' '):
+                netmasks.append(n)
+        rpc.iscsi.add_initiators_to_initiator_group(
+            args.client,
+            tag=args.tag,
+            initiators=initiators,
+            netmasks=netmasks)
 
     p = subparsers.add_parser('add_initiators_to_initiator_group',
                               help='Add initiators to an existing initiator group')
@@ -377,7 +690,21 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_initiators_from_initiator_group(args):
-        rpc.iscsi.delete_initiators_from_initiator_group(args.client, args)
+        initiators = None
+        netmasks = None
+        if args.initiator_list:
+            initiators = []
+            for i in args.initiator_list.strip().split(' '):
+                initiators.append(i)
+        if args.netmask_list:
+            netmasks = []
+            for n in args.netmask_list.strip().split(' '):
+                netmasks.append(n)
+        rpc.iscsi.delete_initiators_from_initiator_group(
+            args.client,
+            tag=args.tag,
+            initiators=initiators,
+            netmasks=netmasks)
 
     p = subparsers.add_parser('delete_initiators_from_initiator_group',
                               help='Delete initiators from an existing initiator group')
@@ -391,7 +718,8 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_target_node(args):
-        rpc.iscsi.delete_target_node(args.client, args)
+        rpc.iscsi.delete_target_node(
+            args.client, target_node_name=args.target_node_name)
 
     p = subparsers.add_parser('delete_target_node',
                               help='Delete a target node')
@@ -401,7 +729,7 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_portal_group(args):
-        rpc.iscsi.delete_portal_group(args.client, args)
+        rpc.iscsi.delete_portal_group(args.client, tag=args.tag)
 
     p = subparsers.add_parser('delete_portal_group',
                               help='Delete a portal group')
@@ -411,7 +739,7 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_initiator_group(args):
-        rpc.iscsi.delete_initiator_group(args.client, args)
+        rpc.iscsi.delete_initiator_group(args.client, tag=args.tag)
 
     p = subparsers.add_parser('delete_initiator_group',
                               help='Delete an initiator group')
@@ -421,7 +749,7 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_iscsi_connections(args):
-        print_dict(rpc.iscsi.get_iscsi_connections(args.client, args))
+        print_dict(rpc.iscsi.get_iscsi_connections(args.client))
 
     p = subparsers.add_parser('get_iscsi_connections',
                               help='Display iSCSI connections')
@@ -429,14 +757,14 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_iscsi_global_params(args):
-        print_dict(rpc.iscsi.get_iscsi_global_params(args.client, args))
+        print_dict(rpc.iscsi.get_iscsi_global_params(args.client))
 
     p = subparsers.add_parser('get_iscsi_global_params', help='Display iSCSI global parameters')
     p.set_defaults(func=get_iscsi_global_params)
 
     @call_cmd
     def get_scsi_devices(args):
-        print_dict(rpc.iscsi.get_scsi_devices(args.client, args))
+        print_dict(rpc.iscsi.get_scsi_devices(args.client))
 
     p = subparsers.add_parser('get_scsi_devices', help='Display SCSI devices')
     p.set_defaults(func=get_scsi_devices)
@@ -500,10 +828,10 @@ if __name__ == "__main__":
     # lvol
     @call_cmd
     def construct_lvol_store(args):
-        print_array(rpc.lvol.construct_lvol_store(args.client,
-                                                  bdev_name=args.bdev_name,
-                                                  lvs_name=args.lvs_name,
-                                                  cluster_sz=args.cluster_sz))
+        print(rpc.lvol.construct_lvol_store(args.client,
+                                            bdev_name=args.bdev_name,
+                                            lvs_name=args.lvs_name,
+                                            cluster_sz=args.cluster_sz))
 
     p = subparsers.add_parser('construct_lvol_store', help='Add logical volume store on base bdev')
     p.add_argument('bdev_name', help='base bdev name')
@@ -524,12 +852,12 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_lvol_bdev(args):
-        print_array(rpc.lvol.construct_lvol_bdev(args.client,
-                                                 lvol_name=args.lvol_name,
-                                                 size=args.size * 1024 * 1024,
-                                                 thin_provision=args.thin_provision,
-                                                 uuid=args.uuid,
-                                                 lvs_name=args.lvs_name))
+        print(rpc.lvol.construct_lvol_bdev(args.client,
+                                           lvol_name=args.lvol_name,
+                                           size=args.size * 1024 * 1024,
+                                           thin_provision=args.thin_provision,
+                                           uuid=args.uuid,
+                                           lvs_name=args.lvs_name))
 
     p = subparsers.add_parser('construct_lvol_bdev', help='Add a bdev with an logical volume backend')
     p.add_argument('-u', '--uuid', help='lvol store UUID', required=False)
@@ -541,9 +869,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def snapshot_lvol_bdev(args):
-        rpc.lvol.snapshot_lvol_bdev(args.client,
-                                    lvol_name=args.lvol_name,
-                                    snapshot_name=args.snapshot_name)
+        print(rpc.lvol.snapshot_lvol_bdev(args.client,
+                                          lvol_name=args.lvol_name,
+                                          snapshot_name=args.snapshot_name))
 
     p = subparsers.add_parser('snapshot_lvol_bdev', help='Create a snapshot of an lvol bdev')
     p.add_argument('lvol_name', help='lvol bdev name')
@@ -552,9 +880,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def clone_lvol_bdev(args):
-        rpc.lvol.clone_lvol_bdev(args.client,
-                                 snapshot_name=args.snapshot_name,
-                                 clone_name=args.clone_name)
+        print(rpc.lvol.clone_lvol_bdev(args.client,
+                                       snapshot_name=args.snapshot_name,
+                                       clone_name=args.clone_name))
 
     p = subparsers.add_parser('clone_lvol_bdev', help='Create a clone of an lvol snapshot')
     p.add_argument('snapshot_name', help='lvol snapshot name')
@@ -572,6 +900,24 @@ if __name__ == "__main__":
     p.add_argument('new_name', help='new lvol name')
     p.set_defaults(func=rename_lvol_bdev)
 
+    @call_cmd
+    def inflate_lvol_bdev(args):
+        rpc.lvol.inflate_lvol_bdev(args.client,
+                                   name=args.name)
+
+    p = subparsers.add_parser('inflate_lvol_bdev', help='Make thin provisioned lvol a thick provisioned lvol')
+    p.add_argument('name', help='lvol bdev name')
+    p.set_defaults(func=inflate_lvol_bdev)
+
+    @call_cmd
+    def decouple_parent_lvol_bdev(args):
+        rpc.lvol.decouple_parent_lvol_bdev(args.client,
+                                           name=args.name)
+
+    p = subparsers.add_parser('decouple_parent_lvol_bdev', help='Decouple parent of lvol')
+    p.add_argument('name', help='lvol bdev name')
+    p.set_defaults(func=decouple_parent_lvol_bdev)
+
     @call_cmd
     def resize_lvol_bdev(args):
         rpc.lvol.resize_lvol_bdev(args.client,
@@ -614,9 +960,52 @@ if __name__ == "__main__":
     p.add_argument('-l', '--lvs-name', help='lvol store name', required=False)
     p.set_defaults(func=get_lvol_stores)
 
+    @call_cmd
+    def get_raid_bdevs(args):
+        print_array(rpc.bdev.get_raid_bdevs(args.client,
+                                            category=args.category))
+
+    p = subparsers.add_parser('get_raid_bdevs', help="""This is used to list all the raid bdev names based on the input category
+    requested. Category should be one of 'all', 'online', 'configuring' or 'offline'. 'all' means all the raid bdevs whether
+    they are online or configuring or offline. 'online' is the raid bdev which is registered with bdev layer. 'configuring'
+    is the raid bdev which does not have full configuration discovered yet. 'offline' is the raid bdev which is not registered
+    with bdev as of now and it has encountered any error or user has requested to offline the raid bdev""")
+    p.add_argument('category', help='all or online or configuring or offline')
+    p.set_defaults(func=get_raid_bdevs)
+
+    @call_cmd
+    def construct_raid_bdev(args):
+        base_bdevs = []
+        for u in args.base_bdevs.strip().split(" "):
+            base_bdevs.append(u)
+
+        rpc.bdev.construct_raid_bdev(args.client,
+                                     name=args.name,
+                                     strip_size=args.strip_size,
+                                     raid_level=args.raid_level,
+                                     base_bdevs=base_bdevs)
+    p = subparsers.add_parser('construct_raid_bdev', help='Construct new raid bdev')
+    p.add_argument('-n', '--name', help='raid bdev name', required=True)
+    p.add_argument('-s', '--strip-size', help='strip size in KB', type=int, required=True)
+    p.add_argument('-r', '--raid-level', help='raid level, only raid level 0 is supported', type=int, required=True)
+    p.add_argument('-b', '--base-bdevs', help='base bdevs name, whitespace separated list in quotes', required=True)
+    p.set_defaults(func=construct_raid_bdev)
+
+    @call_cmd
+    def destroy_raid_bdev(args):
+        rpc.bdev.destroy_raid_bdev(args.client,
+                                   name=args.name)
+    p = subparsers.add_parser('destroy_raid_bdev', help='Destroy existing raid bdev')
+    p.add_argument('name', help='raid bdev name')
+    p.set_defaults(func=destroy_raid_bdev)
+
     # split
+    @call_cmd
     def construct_split_vbdev(args):
-        print_dict(rpc.bdev.construct_split_vbdev(args.client, args))
+        print_array(rpc.bdev.construct_split_vbdev(args.client,
+                                                   base_bdev=args.base_bdev,
+                                                   split_count=args.split_count,
+                                                   split_size_mb=args.split_size_mb))
 
     p = subparsers.add_parser('construct_split_vbdev', help="""Add given disk name to split config. If bdev with base_name
     name exist the split bdevs will be created right away, if not split bdevs will be created when base bdev became
@@ -627,8 +1016,10 @@ if __name__ == "__main__":
     exceed the base bdev size.""", type=int)
     p.set_defaults(func=construct_split_vbdev)
 
+    @call_cmd
     def destruct_split_vbdev(args):
-        rpc.destruct_split_vbdev(args.client, args)
+        rpc.bdev.destruct_split_vbdev(args.client,
+                                      base_bdev=args.base_bdev)
 
     p = subparsers.add_parser('destruct_split_vbdev', help="""Delete split config with all created splits.""")
     p.add_argument('base_bdev', help='base bdev name')
@@ -637,9 +1028,9 @@ if __name__ == "__main__":
     # nbd
     @call_cmd
     def start_nbd_disk(args):
-        rpc.nbd.start_nbd_disk(args.client,
-                               bdev_name=args.bdev_name,
-                               nbd_device=args.nbd_device)
+        print(rpc.nbd.start_nbd_disk(args.client,
+                                     bdev_name=args.bdev_name,
+                                     nbd_device=args.nbd_device))
 
     p = subparsers.add_parser('start_nbd_disk', help='Export a bdev as a nbd disk')
     p.add_argument('bdev_name', help='Blockdev name to be exported. Example: Malloc0.')
@@ -692,9 +1083,37 @@ if __name__ == "__main__":
     p.set_defaults(func=get_interfaces)
 
     # NVMe-oF
+    @call_cmd
+    def set_nvmf_target_options(args):
+        rpc.nvmf.set_nvmf_target_options(args.client,
+                                         max_queue_depth=args.max_queue_depth,
+                                         max_qpairs_per_ctrlr=args.max_qpairs_per_ctrlr,
+                                         in_capsule_data_size=args.in_capsule_data_size,
+                                         max_io_size=args.max_io_size,
+                                         max_subsystems=args.max_subsystems,
+                                         io_unit_size=args.io_unit_size)
+
+    p = subparsers.add_parser('set_nvmf_target_options', help='Set NVMf target options')
+    p.add_argument('-q', '--max-queue-depth', help='Max number of outstanding I/O per queue', type=int)
+    p.add_argument('-p', '--max-qpairs-per-ctrlr', help='Max number of SQ and CQ per controller', type=int)
+    p.add_argument('-c', '--in-capsule-data-size', help='Max number of in-capsule data size', type=int)
+    p.add_argument('-i', '--max-io-size', help='Max I/O size (bytes)', type=int)
+    p.add_argument('-x', '--max-subsystems', help='Max number of NVMf subsystems', type=int)
+    p.add_argument('-u', '--io-unit-size', help='I/O unit size (bytes)', type=int)
+    p.set_defaults(func=set_nvmf_target_options)
+
+    @call_cmd
+    def set_nvmf_target_config(args):
+        rpc.nvmf.set_nvmf_target_config(args.client,
+                                        acceptor_poll_rate=args.acceptor_poll_rate)
+
+    p = subparsers.add_parser('set_nvmf_target_config', help='Set NVMf target config')
+    p.add_argument('-r', '--acceptor-poll-rate', help='Polling interval of the acceptor for incoming connections (usec)', type=int)
+    p.set_defaults(func=set_nvmf_target_config)
+
     @call_cmd
     def get_nvmf_subsystems(args):
-        print_dict(rpc.nvmf.get_nvmf_subsystems(args.client, args))
+        print_dict(rpc.nvmf.get_nvmf_subsystems(args.client))
 
     p = subparsers.add_parser('get_nvmf_subsystems',
                               help='Display nvmf subsystems')
@@ -702,7 +1121,45 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_nvmf_subsystem(args):
-        rpc.nvmf.construct_nvmf_subsystem(args.client, args)
+        listen_addresses = None
+        hosts = None
+        namespaces = None
+        if args.listen:
+            listen_addresses = [
+                dict(
+                    u.split(
+                        ":",
+                        1) for u in a.split(" ")) for a in args.listen.split(",")]
+
+        if args.hosts:
+            hosts = []
+            for u in args.hosts.strip().split(" "):
+                hosts.append(u)
+
+        if args.namespaces:
+            namespaces = []
+            for u in args.namespaces.strip().split(" "):
+                bdev_name = u
+                nsid = 0
+                if ':' in u:
+                    (bdev_name, nsid) = u.split(":")
+
+                ns_params = {'bdev_name': bdev_name}
+
+                nsid = int(nsid)
+                if nsid != 0:
+                    ns_params['nsid'] = nsid
+
+                namespaces.append(ns_params)
+
+        rpc.nvmf.construct_nvmf_subsystem(args.client,
+                                          nqn=args.nqn,
+                                          listen_addresses=listen_addresses,
+                                          hosts=hosts,
+                                          allow_any_host=args.allow_any_host,
+                                          serial_number=args.serial_number,
+                                          namespaces=namespaces,
+                                          max_namespaces=args.max_namespaces)
 
     p = subparsers.add_parser('construct_nvmf_subsystem', help='Add a nvmf subsystem')
     p.add_argument('nqn', help='Target nqn(ASCII)')
@@ -726,7 +1183,8 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_nvmf_subsystem(args):
-        rpc.nvmf.delete_nvmf_subsystem(args.client, args)
+        rpc.nvmf.delete_nvmf_subsystem(args.client,
+                                       nqn=args.subsystem_nqn)
 
     p = subparsers.add_parser('delete_nvmf_subsystem',
                               help='Delete a nvmf subsystem')
@@ -736,7 +1194,12 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_add_listener(args):
-        rpc.nvmf.nvmf_subsystem_add_listener(args.client, args)
+        rpc.nvmf.nvmf_subsystem_add_listener(args.client,
+                                             nqn=args.nqn,
+                                             trtype=args.trtype,
+                                             traddr=args.traddr,
+                                             adrfam=args.adrfam,
+                                             trsvcid=args.trsvcid)
 
     p = subparsers.add_parser('nvmf_subsystem_add_listener', help='Add a listener to an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -748,7 +1211,12 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_remove_listener(args):
-        rpc.nvmf.nvmf_subsystem_remove_listener(args.client, args)
+        rpc.nvmf.nvmf_subsystem_remove_listener(args.client,
+                                                nqn=args.nqn,
+                                                trtype=args.trtype,
+                                                traddr=args.traddr,
+                                                adrfam=args.adrfam,
+                                                trsvcid=args.trsvcid)
 
     p = subparsers.add_parser('nvmf_subsystem_remove_listener', help='Remove a listener from an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -760,7 +1228,13 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_add_ns(args):
-        rpc.nvmf.nvmf_subsystem_add_ns(args.client, args)
+        rpc.nvmf.nvmf_subsystem_add_ns(args.client,
+                                       nqn=args.nqn,
+                                       bdev_name=args.bdev_name,
+                                       nsid=args.nsid,
+                                       nguid=args.nguid,
+                                       eui64=args.eui64,
+                                       uuid=args.uuid)
 
     p = subparsers.add_parser('nvmf_subsystem_add_ns', help='Add a namespace to an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -768,11 +1242,14 @@ if __name__ == "__main__":
     p.add_argument('-n', '--nsid', help='The requested NSID (optional)', type=int)
     p.add_argument('-g', '--nguid', help='Namespace globally unique identifier (optional)')
     p.add_argument('-e', '--eui64', help='Namespace EUI-64 identifier (optional)')
+    p.add_argument('-u', '--uuid', help='Namespace UUID (optional)')
     p.set_defaults(func=nvmf_subsystem_add_ns)
 
     @call_cmd
     def nvmf_subsystem_remove_ns(args):
-        rpc.nvmf.nvmf_subsystem_remove_ns(args.client, args)
+        rpc.nvmf.nvmf_subsystem_remove_ns(args.client,
+                                          nqn=args.nqn,
+                                          nsid=args.nsid)
 
     p = subparsers.add_parser('nvmf_subsystem_remove_ns', help='Remove a namespace to an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -781,7 +1258,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_add_host(args):
-        rpc.nvmf.nvmf_subsystem_add_host(args.client, args)
+        rpc.nvmf.nvmf_subsystem_add_host(args.client,
+                                         nqn=args.nqn,
+                                         host=args.host)
 
     p = subparsers.add_parser('nvmf_subsystem_add_host', help='Add a host to an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -790,7 +1269,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_remove_host(args):
-        rpc.nvmf.nvmf_subsystem_remove_host(args.client, args)
+        rpc.nvmf.nvmf_subsystem_remove_host(args.client,
+                                            nqn=args.nqn,
+                                            host=args.host)
 
     p = subparsers.add_parser('nvmf_subsystem_remove_host', help='Remove a host from an NVMe-oF subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -799,7 +1280,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def nvmf_subsystem_allow_any_host(args):
-        rpc.nvmf.nvmf_subsystem_allow_any_host(args.client, args)
+        rpc.nvmf.nvmf_subsystem_allow_any_host(args.client,
+                                               nqn=args.nqn,
+                                               disable=args.disable)
 
     p = subparsers.add_parser('nvmf_subsystem_allow_any_host', help='Allow any host to connect to the subsystem')
     p.add_argument('nqn', help='NVMe-oF subsystem NQN')
@@ -810,7 +1293,11 @@ if __name__ == "__main__":
     # pmem
     @call_cmd
     def create_pmem_pool(args):
-        rpc.pmem.create_pmem_pool(args.client, args)
+        num_blocks = int((args.total_size * 1024 * 1024) / args.block_size)
+        rpc.pmem.create_pmem_pool(args.client,
+                                  pmem_file=args.pmem_file,
+                                  num_blocks=num_blocks,
+                                  block_size=args.block_size)
 
     p = subparsers.add_parser('create_pmem_pool', help='Create pmem pool')
     p.add_argument('pmem_file', help='Path to pmemblk pool file')
@@ -820,7 +1307,8 @@ if __name__ == "__main__":
 
     @call_cmd
     def pmem_pool_info(args):
-        print_dict(rpc.pmem.pmem_pool_info(args.client, args))
+        print_dict(rpc.pmem.pmem_pool_info(args.client,
+                                           pmem_file=args.pmem_file))
 
     p = subparsers.add_parser('pmem_pool_info', help='Display pmem pool info and check consistency')
     p.add_argument('pmem_file', help='Path to pmemblk pool file')
@@ -828,7 +1316,8 @@ if __name__ == "__main__":
 
     @call_cmd
     def delete_pmem_pool(args):
-        rpc.pmem.delete_pmem_pool(args.client, args)
+        rpc.pmem.delete_pmem_pool(args.client,
+                                  pmem_file=args.pmem_file)
 
     p = subparsers.add_parser('delete_pmem_pool', help='Delete pmem pool')
     p.add_argument('pmem_file', help='Path to pmemblk pool file')
@@ -854,7 +1343,10 @@ if __name__ == "__main__":
     # vhost
     @call_cmd
     def set_vhost_controller_coalescing(args):
-        rpc.vhost.set_vhost_controller_coalescing(args.client, args)
+        rpc.vhost.set_vhost_controller_coalescing(args.client,
+                                                  ctrlr=args.ctrlr,
+                                                  delay_base_us=args.delay_base_us,
+                                                  iops_threshold=args.iops_threshold)
 
     p = subparsers.add_parser('set_vhost_controller_coalescing', help='Set vhost controller coalescing')
     p.add_argument('ctrlr', help='controller name')
@@ -864,7 +1356,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_vhost_scsi_controller(args):
-        rpc.vhost.construct_vhost_scsi_controller(args.client, args)
+        rpc.vhost.construct_vhost_scsi_controller(args.client,
+                                                  ctrlr=args.ctrlr,
+                                                  cpumask=args.cpumask)
 
     p = subparsers.add_parser(
         'construct_vhost_scsi_controller', help='Add new vhost controller')
@@ -874,7 +1368,10 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_vhost_scsi_lun(args):
-        rpc.vhost.add_vhost_scsi_lun(args.client, args)
+        rpc.vhost.add_vhost_scsi_lun(args.client,
+                                     ctrlr=args.ctrlr,
+                                     scsi_target_num=args.scsi_target_num,
+                                     bdev_name=args.bdev_name)
 
     p = subparsers.add_parser('add_vhost_scsi_lun',
                               help='Add lun to vhost controller')
@@ -885,7 +1382,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def remove_vhost_scsi_target(args):
-        rpc.vhost.remove_vhost_scsi_target(args.client, args)
+        rpc.vhost.remove_vhost_scsi_target(args.client,
+                                           ctrlr=args.ctrlr,
+                                           scsi_target_num=args.scsi_target_num)
 
     p = subparsers.add_parser('remove_vhost_scsi_target', help='Remove target from vhost controller')
     p.add_argument('ctrlr', help='controller name to remove target from')
@@ -894,7 +1393,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_vhost_blk_controller(args):
-        rpc.vhost.construct_vhost_blk_controller(args.client, args)
+        rpc.vhost.construct_vhost_blk_controller(args.client,
+                                                 ctrlr=args.ctrlr,
+                                                 dev_name=args.dev_name,
+                                                 cpumask=args.cpumask,
+                                                 readonly=args.readonly)
 
     p = subparsers.add_parser('construct_vhost_blk_controller', help='Add a new vhost block controller')
     p.add_argument('ctrlr', help='controller name')
@@ -905,7 +1408,10 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_vhost_nvme_controller(args):
-        rpc.vhost.construct_vhost_nvme_controller(args.client, args)
+        rpc.vhost.construct_vhost_nvme_controller(args.client,
+                                                  ctrlr=args.ctrlr,
+                                                  io_queues=args.io_queues,
+                                                  cpumask=args.cpumask)
 
     p = subparsers.add_parser('construct_vhost_nvme_controller', help='Add new vhost controller')
     p.add_argument('ctrlr', help='controller name')
@@ -915,7 +1421,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def add_vhost_nvme_ns(args):
-        rpc.vhost.add_vhost_nvme_ns(args.client, args)
+        rpc.vhost.add_vhost_nvme_ns(args.client,
+                                    ctrlr=args.ctrlr,
+                                    bdev_name=args.bdev_name)
 
     p = subparsers.add_parser('add_vhost_nvme_ns', help='Add a Namespace to vhost controller')
     p.add_argument('ctrlr', help='conntroller name where add a Namespace')
@@ -924,14 +1432,15 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_vhost_controllers(args):
-        print_dict(rpc.vhost.get_vhost_controllers(args.client, args))
+        print_dict(rpc.vhost.get_vhost_controllers(args.client))
 
     p = subparsers.add_parser('get_vhost_controllers', help='List vhost controllers')
     p.set_defaults(func=get_vhost_controllers)
 
     @call_cmd
     def remove_vhost_controller(args):
-        rpc.vhost.remove_vhost_controller(args.client, args)
+        rpc.vhost.remove_vhost_controller(args.client,
+                                          ctrlr=args.ctrlr)
 
     p = subparsers.add_parser('remove_vhost_controller', help='Remove a vhost controller')
     p.add_argument('ctrlr', help='controller name')
@@ -939,7 +1448,13 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_virtio_dev(args):
-        print_dict(rpc.vhost.construct_virtio_dev(args.client, args))
+        print_array(rpc.vhost.construct_virtio_dev(args.client,
+                                                   name=args.name,
+                                                   trtype=args.trtype,
+                                                   traddr=args.traddr,
+                                                   dev_type=args.dev_type,
+                                                   vq_count=args.vq_count,
+                                                   vq_size=args.vq_size))
 
     p = subparsers.add_parser('construct_virtio_dev', help="""Construct new virtio device using provided
     transport type and device type. In case of SCSI device type this implies scan and add bdevs offered by
@@ -957,7 +1472,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_virtio_user_scsi_bdev(args):
-        print_dict(rpc.vhost.construct_virtio_user_scsi_bdev(args.client, args))
+        print_array(rpc.vhost.construct_virtio_user_scsi_bdev(args.client,
+                                                              path=args.path,
+                                                              name=args.name,
+                                                              vq_count=args.vq_count,
+                                                              vq_size=args.vq_size))
 
     p = subparsers.add_parser('construct_virtio_user_scsi_bdev', help="""Connect to virtio user scsi device.
     This imply scan and add bdevs offered by remote side.
@@ -971,7 +1490,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_virtio_pci_scsi_bdev(args):
-        print_dict(rpc.vhost.construct_virtio_pci_scsi_bdev(args.client, args))
+        print_array(rpc.vhost.construct_virtio_pci_scsi_bdev(args.client,
+                                                             pci_address=args.pci_address,
+                                                             name=args.name))
 
     p = subparsers.add_parser('construct_virtio_pci_scsi_bdev', help="""Create a Virtio
     SCSI device from a virtio-pci device.""")
@@ -983,14 +1504,15 @@ if __name__ == "__main__":
 
     @call_cmd
     def get_virtio_scsi_devs(args):
-        print_dict(rpc.vhost.get_virtio_scsi_devs(args.client, args))
+        print_dict(rpc.vhost.get_virtio_scsi_devs(args.client))
 
     p = subparsers.add_parser('get_virtio_scsi_devs', help='List all Virtio-SCSI devices.')
     p.set_defaults(func=get_virtio_scsi_devs)
 
     @call_cmd
     def remove_virtio_scsi_bdev(args):
-        rpc.vhost.remove_virtio_scsi_bdev(args.client, args)
+        rpc.vhost.remove_virtio_scsi_bdev(args.client,
+                                          name=args.name)
 
     p = subparsers.add_parser('remove_virtio_scsi_bdev', help="""Remove a Virtio-SCSI device
     This will delete all bdevs exposed by this device""")
@@ -999,7 +1521,11 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_virtio_user_blk_bdev(args):
-        print_dict(rpc.vhost.construct_virtio_user_blk_bdev(args.client, args))
+        print(rpc.vhost.construct_virtio_user_blk_bdev(args.client,
+                                                       path=args.path,
+                                                       name=args.name,
+                                                       vq_count=args.vq_count,
+                                                       vq_size=args.vq_size))
 
     p = subparsers.add_parser('construct_virtio_user_blk_bdev', help='Connect to a virtio user blk device.')
     p.add_argument('path', help='Path to Virtio BLK socket')
@@ -1010,7 +1536,9 @@ if __name__ == "__main__":
 
     @call_cmd
     def construct_virtio_pci_blk_bdev(args):
-        print_dict(rpc.vhost.construct_virtio_pci_blk_bdev(args.client, args))
+        print(rpc.vhost.construct_virtio_pci_blk_bdev(args.client,
+                                                      pci_address=args.pci_address,
+                                                      name=args.name))
 
     p = subparsers.add_parser('construct_virtio_pci_blk_bdev', help='Create a Virtio Blk device from a virtio-pci device.')
     p.add_argument('pci_address', help="""PCI address in domain:bus:device.function format or
@@ -1018,6 +1546,20 @@ if __name__ == "__main__":
     p.add_argument('name', help='Name for the bdev')
     p.set_defaults(func=construct_virtio_pci_blk_bdev)
 
+    # ioat
+    @call_cmd
+    def scan_ioat_copy_engine(args):
+        pci_whitelist = []
+        if args.pci_whitelist:
+            for w in args.pci_whitelist.strip().split(" "):
+                pci_whitelist.append(w)
+        rpc.ioat.scan_ioat_copy_engine(args.client, pci_whitelist)
+
+    p = subparsers.add_parser('scan_ioat_copy_engine', help='Set scan and enable IOAT copy engine offload.')
+    p.add_argument('-w', '--pci-whitelist', help="""Whitespace-separated list of PCI addresses in
+    domain:bus:device.function format or domain.bus.device.function format""")
+    p.set_defaults(func=scan_ioat_copy_engine)
+
     args = parser.parse_args()
 
     try:
diff --git a/scripts/rpc/__init__.py b/scripts/rpc/__init__.py
index 75f371117..4f004aa01 100755
--- a/scripts/rpc/__init__.py
+++ b/scripts/rpc/__init__.py
@@ -3,6 +3,7 @@ import sys
 
 from . import app
 from . import bdev
+from . import ioat
 from . import iscsi
 from . import log
 from . import lvol
@@ -12,26 +13,24 @@ from . import nvmf
 from . import pmem
 from . import subsystem
 from . import vhost
+from . import client as rpc_client
 
 
-def get_rpc_methods(client):
-    return client.call('get_rpc_methods')
+def start_subsystem_init(client):
+    return client.call('start_subsystem_init')
 
 
-def save_config(client, args):
-    config = {
-        'subsystems': []
-    }
+def get_rpc_methods(client, args):
+    params = {}
 
-    for elem in client.call('get_subsystems'):
-        cfg = {
-            'subsystem': elem['subsystem'],
-            'config': client.call('get_subsystem_config', {"name": elem['subsystem']})
-        }
-        config['subsystems'].append(cfg)
+    if args.current:
+        params['current'] = args.current
 
-    indent = args.indent
-    if args.filename is None:
+    return client.call('get_rpc_methods', params)
+
+
+def _json_dump(config, filename, indent):
+    if filename is None:
         if indent is None:
             indent = 2
         elif indent < 0:
@@ -41,24 +40,108 @@ def save_config(client, args):
     else:
         if indent is None or indent < 0:
             indent = None
-        with open(args.filename, 'w') as file:
+        with open(filename, 'w') as file:
             json.dump(config, file, indent=indent)
             file.write('\n')
 
 
-def load_config(client, args):
-    if not args.filename or args.filename == '-':
-        config = json.load(sys.stdin)
+def _json_load(filename):
+    if not filename or filename == '-':
+        return json.load(sys.stdin)
+
     else:
-        with open(args.filename, 'r') as file:
-            config = json.load(file)
+        with open(filename, 'r') as file:
+            return json.load(file)
+
+
+def save_config(client, args):
+    config = {
+        'subsystems': []
+    }
+
+    for elem in client.call('get_subsystems'):
+        cfg = {
+            'subsystem': elem['subsystem'],
+            'config': client.call('get_subsystem_config', {"name": elem['subsystem']})
+        }
+        config['subsystems'].append(cfg)
+
+    _json_dump(config, args.filename, args.indent)
+
+
+def load_config(client, args):
+    json_config = _json_load(args.filename)
+
+    # remove subsystems with no config
+    subsystems = json_config['subsystems']
+    for subsystem in list(subsystems):
+        if not subsystem['config']:
+            subsystems.remove(subsystem)
 
-    for subsystem in config['subsystems']:
-        name = subsystem['subsystem']
+    # check if methods in the config file are known
+    allowed_methods = client.call('get_rpc_methods')
+    for subsystem in list(subsystems):
         config = subsystem['config']
-        if not config:
+        for elem in list(config):
+            if 'method' not in elem or elem['method'] not in allowed_methods:
+                raise rpc_client.JSONRPCException("Unknown method was included in the config file")
+
+    while subsystems:
+        allowed_methods = client.call('get_rpc_methods', {'current': True})
+        allowed_found = False
+
+        for subsystem in list(subsystems):
+            config = subsystem['config']
+            for elem in list(config):
+                if 'method' not in elem or elem['method'] not in allowed_methods:
+                    continue
+
+                client.call(elem['method'], elem['params'])
+                config.remove(elem)
+                allowed_found = True
+
+            if not config:
+                subsystems.remove(subsystem)
+
+        if 'start_subsystem_init' in allowed_methods:
+            client.call('start_subsystem_init')
+            allowed_found = True
+
+        if not allowed_found:
+            break
+
+    if subsystems:
+        print("Some configs were skipped because the RPC state that can call them passed over.")
+
+
+def save_subsystem_config(client, args):
+    cfg = {
+        'subsystem': args.name,
+        'config': client.call('get_subsystem_config', {"name": args.name})
+    }
+
+    _json_dump(cfg, args.filename, args.indent)
+
+
+def load_subsystem_config(client, args):
+    subsystem = _json_load(args.filename)
+
+    if not subsystem['config']:
+        return
+
+    allowed_methods = client.call('get_rpc_methods')
+    config = subsystem['config']
+    for elem in list(config):
+        if 'method' not in elem or elem['method'] not in allowed_methods:
+            raise rpc_client.JSONRPCException("Unknown method was included in the config file")
+
+    allowed_methods = client.call('get_rpc_methods', {'current': True})
+    for elem in list(config):
+        if 'method' not in elem or elem['method'] not in allowed_methods:
             continue
-        for elem in subsystem['config']:
-            if not elem or 'method' not in elem:
-                continue
-            client.call(elem['method'], elem['params'])
+
+        client.call(elem['method'], elem['params'])
+        config.remove(elem)
+
+    if config:
+        print("Some configs were skipped because they cannot be called in the current RPC state.")
diff --git a/scripts/rpc/app.py b/scripts/rpc/app.py
index bc510db10..c9b088f83 100755
--- a/scripts/rpc/app.py
+++ b/scripts/rpc/app.py
@@ -1,12 +1,23 @@
-def kill_instance(client, args):
-    params = {'sig_name': args.sig_name}
+def kill_instance(client, sig_name):
+    """Send a signal to the SPDK process.
+
+    Args:
+        sig_name: signal to send ("SIGINT", "SIGTERM", "SIGQUIT", "SIGHUP", or "SIGKILL")
+    """
+    params = {'sig_name': sig_name}
     return client.call('kill_instance', params)
 
 
-def context_switch_monitor(client, args):
+def context_switch_monitor(client, enabled=None):
+    """Query or set state of context switch monitoring.
+
+    Args:
+        enabled: True to enable monitoring; False to disable monitoring; None to query (optional)
+
+    Returns:
+        Current context switch monitoring state (after applying enabled flag).
+    """
     params = {}
-    if args.enable:
-        params['enabled'] = True
-    if args.disable:
-        params['enabled'] = False
+    if enabled is not None:
+        params['enabled'] = enabled
     return client.call('context_switch_monitor', params)
diff --git a/scripts/rpc/bdev.py b/scripts/rpc/bdev.py
index 345fc1193..93487c7c9 100755
--- a/scripts/rpc/bdev.py
+++ b/scripts/rpc/bdev.py
@@ -1,142 +1,463 @@
-def construct_malloc_bdev(client, args):
-    num_blocks = (args.total_size * 1024 * 1024) // args.block_size
-    params = {'num_blocks': num_blocks, 'block_size': args.block_size}
-    if args.name:
-        params['name'] = args.name
-    if args.uuid:
-        params['uuid'] = args.uuid
+def set_bdev_options(client, bdev_io_pool_size=None, bdev_io_cache_size=None):
+    """Set parameters for the bdev subsystem.
+
+    Args:
+        bdev_io_pool_size: number of bdev_io structures in shared buffer pool (optional)
+        bdev_io_cache_size: maximum number of bdev_io structures cached per thread (optional)
+    """
+    params = {}
+
+    if bdev_io_pool_size:
+        params['bdev_io_pool_size'] = bdev_io_pool_size
+    if bdev_io_cache_size:
+        params['bdev_io_cache_size'] = bdev_io_cache_size
+
+    return client.call('set_bdev_options', params)
+
+
+def construct_malloc_bdev(client, num_blocks, block_size, name=None, uuid=None):
+    """Construct a malloc block device.
+
+    Args:
+        num_blocks: size of block device in blocks
+        block_size: block size of device; must be a power of 2 and at least 512
+        name: name of block device (optional)
+        uuid: UUID of block device (optional)
+
+    Returns:
+        Name of created block device.
+    """
+    params = {'num_blocks': num_blocks, 'block_size': block_size}
+    if name:
+        params['name'] = name
+    if uuid:
+        params['uuid'] = uuid
     return client.call('construct_malloc_bdev', params)
 
 
-def construct_null_bdev(client, args):
-    num_blocks = (args.total_size * 1024 * 1024) // args.block_size
-    params = {'name': args.name, 'num_blocks': num_blocks,
-              'block_size': args.block_size}
-    if args.uuid:
-        params['uuid'] = args.uuid
+def delete_malloc_bdev(client, name):
+    """Delete malloc block device.
+
+    Args:
+        bdev_name: name of malloc bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_malloc_bdev', params)
+
+
+def construct_null_bdev(client, num_blocks, block_size, name, uuid=None):
+    """Construct a null block device.
+
+    Args:
+        num_blocks: size of block device in blocks
+        block_size: block size of device; must be a power of 2 and at least 512
+        name: name of block device
+        uuid: UUID of block device (optional)
+
+    Returns:
+        Name of created block device.
+    """
+    params = {'name': name, 'num_blocks': num_blocks,
+              'block_size': block_size}
+    if uuid:
+        params['uuid'] = uuid
     return client.call('construct_null_bdev', params)
 
 
-def construct_aio_bdev(client, args):
-    params = {'name': args.name,
-              'filename': args.filename}
+def delete_null_bdev(client, name):
+    """Remove null bdev from the system.
+
+    Args:
+        name: name of null bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_null_bdev', params)
+
+
+def get_raid_bdevs(client, category):
+    """Get list of raid bdevs based on category
+
+    Args:
+        category: any one of all or online or configuring or offline
+
+    Returns:
+        List of raid bdev names
+    """
+    params = {'category': category}
+    return client.call('get_raid_bdevs', params)
+
+
+def construct_raid_bdev(client, name, strip_size, raid_level, base_bdevs):
+    """Construct pooled device
+
+    Args:
+        name: user defined raid bdev name
+        strip_size: strip size of raid bdev in KB, supported values like 8, 16, 32, 64, 128, 256, 512, 1024 etc
+        raid_level: raid level of raid bdev, supported values 0
+        base_bdevs: Space separated names of Nvme bdevs in double quotes, like "Nvme0n1 Nvme1n1 Nvme2n1"
+
+    Returns:
+        None
+    """
+    params = {'name': name, 'strip_size': strip_size, 'raid_level': raid_level, 'base_bdevs': base_bdevs}
 
-    if args.block_size:
-        params['block_size'] = args.block_size
+    return client.call('construct_raid_bdev', params)
+
+
+def destroy_raid_bdev(client, name):
+    """Destroy pooled device
+
+    Args:
+        name: raid bdev name
+
+    Returns:
+        None
+    """
+    params = {'name': name}
+    return client.call('destroy_raid_bdev', params)
+
+
+def construct_aio_bdev(client, filename, name, block_size=None):
+    """Construct a Linux AIO block device.
+
+    Args:
+        filename: path to device or file (ex: /dev/sda)
+        name: name of block device
+        block_size: block size of device (optional; autodetected if omitted)
+
+    Returns:
+        Name of created block device.
+    """
+    params = {'name': name,
+              'filename': filename}
+
+    if block_size:
+        params['block_size'] = block_size
 
     return client.call('construct_aio_bdev', params)
 
 
-def construct_nvme_bdev(client, args):
-    params = {'name': args.name,
-              'trtype': args.trtype,
-              'traddr': args.traddr}
+def delete_aio_bdev(client, name):
+    """Remove aio bdev from the system.
+
+    Args:
+        bdev_name: name of aio bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_aio_bdev', params)
+
 
-    if args.adrfam:
-        params['adrfam'] = args.adrfam
+def construct_nvme_bdev(client, name, trtype, traddr, adrfam=None, trsvcid=None, subnqn=None):
+    """Construct NVMe namespace block device.
 
-    if args.trsvcid:
-        params['trsvcid'] = args.trsvcid
+    Args:
+        name: bdev name prefix; "n" + namespace ID will be appended to create unique names
+        trtype: transport type ("PCIe", "RDMA")
+        traddr: transport address (PCI BDF or IP address)
+        adrfam: address family ("IPv4", "IPv6", "IB", or "FC") (optional for PCIe)
+        trsvcid: transport service ID (port number for IP-based addresses; optional for PCIe)
+        subnqn: subsystem NQN to connect to (optional)
 
-    if args.subnqn:
-        params['subnqn'] = args.subnqn
+    Returns:
+        Name of created block device.
+    """
+    params = {'name': name,
+              'trtype': trtype,
+              'traddr': traddr}
+
+    if adrfam:
+        params['adrfam'] = adrfam
+
+    if trsvcid:
+        params['trsvcid'] = trsvcid
+
+    if subnqn:
+        params['subnqn'] = subnqn
 
     return client.call('construct_nvme_bdev', params)
 
 
-def construct_rbd_bdev(client, args):
+def construct_rbd_bdev(client, pool_name, rbd_name, block_size, name=None):
+    """Construct a Ceph RBD block device.
+
+    Args:
+        pool_name: Ceph RBD pool name
+        rbd_name: Ceph RBD image name
+        block_size: block size of RBD volume
+        name: name of block device (optional)
+
+    Returns:
+        Name of created block device.
+    """
     params = {
-        'pool_name': args.pool_name,
-        'rbd_name': args.rbd_name,
-        'block_size': args.block_size,
+        'pool_name': pool_name,
+        'rbd_name': rbd_name,
+        'block_size': block_size,
     }
 
-    if args.name:
-        params['name'] = args.name
+    if name:
+        params['name'] = name
 
     return client.call('construct_rbd_bdev', params)
 
 
-def construct_error_bdev(client, args):
-    params = {'base_name': args.base_name}
+def delete_rbd_bdev(client, name):
+    """Remove rbd bdev from the system.
+
+    Args:
+        name: name of rbd bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_rbd_bdev', params)
+
+
+def construct_error_bdev(client, base_name):
+    """Construct an error injection block device.
+
+    Args:
+        base_name: base bdev name
+    """
+    params = {'base_name': base_name}
     return client.call('construct_error_bdev', params)
 
 
-def construct_pmem_bdev(client, args):
+def delete_error_bdev(client, name):
+    """Remove error bdev from the system.
+
+    Args:
+        bdev_name: name of error bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_error_bdev', params)
+
+
+def construct_iscsi_bdev(client, name, url, initiator_iqn):
+    """Construct a iSCSI block device.
+
+    Args:
+        name: name of block device
+        url: iSCSI URL
+        initiator_iqn: IQN name to be used by initiator
+
+    Returns:
+        Name of created block device.
+    """
     params = {
-        'pmem_file': args.pmem_file,
-        'name': args.name
+        'name': name,
+        'url': url,
+        'initiator_iqn': initiator_iqn,
+    }
+    return client.call('construct_iscsi_bdev', params)
+
+
+def delete_iscsi_bdev(client, name):
+    """Remove iSCSI bdev from the system.
+
+    Args:
+        bdev_name: name of iSCSI bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_iscsi_bdev', params)
+
+
+def construct_pmem_bdev(client, pmem_file, name):
+    """Construct a libpmemblk block device.
+
+    Args:
+        pmem_file: path to pmemblk pool file
+        name: name of block device
+
+    Returns:
+        Name of created block device.
+    """
+    params = {
+        'pmem_file': pmem_file,
+        'name': name
     }
     return client.call('construct_pmem_bdev', params)
 
 
-def construct_passthru_bdev(client, args):
+def delete_pmem_bdev(client, name):
+    """Remove pmem bdev from the system.
+
+    Args:
+        name: name of pmem bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_pmem_bdev', params)
+
+
+def construct_passthru_bdev(client, base_bdev_name, passthru_bdev_name):
+    """Construct a pass-through block device.
+
+    Args:
+        base_bdev_name: name of the existing bdev
+        passthru_bdev_name: name of block device
+
+    Returns:
+        Name of created block device.
+    """
     params = {
-        'base_bdev_name': args.base_bdev_name,
-        'passthru_bdev_name': args.passthru_bdev_name,
+        'base_bdev_name': base_bdev_name,
+        'passthru_bdev_name': passthru_bdev_name,
     }
     return client.call('construct_passthru_bdev', params)
 
 
-def construct_split_vbdev(client, args):
+def delete_passthru_bdev(client, name):
+    """Remove pass through bdev from the system.
+
+    Args:
+        name: name of pass through bdev to delete
+    """
+    params = {'name': name}
+    return client.call('delete_passthru_bdev', params)
+
+
+def construct_split_vbdev(client, base_bdev, split_count, split_size_mb=None):
+    """Construct split block devices from a base bdev.
+
+    Args:
+        base_bdev: name of bdev to split
+        split_count: number of split bdevs to create
+        split_size_mb: size of each split volume in MiB (optional)
+
+    Returns:
+        List of created block devices.
+    """
     params = {
-        'base_bdev': args.base_bdev,
-        'split_count': args.split_count,
+        'base_bdev': base_bdev,
+        'split_count': split_count,
     }
-    if args.split_size_mb:
-        params['split_size_mb'] = args.split_size_mb
+    if split_size_mb:
+        params['split_size_mb'] = split_size_mb
 
     return client.call('construct_split_vbdev', params)
 
 
-def destruct_split_vbdev(client, args):
+def destruct_split_vbdev(client, base_bdev):
+    """Destroy split block devices.
+
+    Args:
+        base_bdev: name of previously split bdev
+    """
     params = {
-        'base_bdev': args.base_bdev,
+        'base_bdev': base_bdev,
     }
 
     return client.call('destruct_split_vbdev', params)
 
 
-def get_bdevs(client, args):
+def get_bdevs(client, name=None):
+    """Get information about block devices.
+
+    Args:
+        name: bdev name to query (optional; if omitted, query all bdevs)
+
+    Returns:
+        List of bdev information objects.
+    """
     params = {}
-    if args.name:
-        params['name'] = args.name
+    if name:
+        params['name'] = name
     return client.call('get_bdevs', params)
 
 
-def get_bdevs_config(client, args):
+def get_bdevs_config(client, name=None):
+    """Get configuration for block devices.
+
+    Args:
+        name: bdev name to query (optional; if omitted, query all bdevs)
+
+    Returns:
+        List of RPC methods to reproduce the current bdev configuration.
+    """
     params = {}
-    if args.name:
-        params['name'] = args.name
+    if name:
+        params['name'] = name
     return client.call('get_bdevs_config', params)
 
 
-def delete_bdev(client, args):
-    params = {'name': args.bdev_name}
+def get_bdevs_iostat(client, name=None):
+    """Get I/O statistics for block devices.
+
+    Args:
+        name: bdev name to query (optional; if omitted, query all bdevs)
+
+    Returns:
+        I/O statistics for the requested block devices.
+    """
+    params = {}
+    if name:
+        params['name'] = name
+    return client.call('get_bdevs_iostat', params)
+
+
+def delete_bdev(client, bdev_name):
+    """Remove a bdev from the system.
+
+    Args:
+        bdev_name: name of bdev to delete
+    """
+    params = {'name': bdev_name}
     return client.call('delete_bdev', params)
 
 
-def bdev_inject_error(client, args):
+def bdev_inject_error(client, name, io_type, error_type, num=1):
+    """Inject an error via an error bdev.
+
+    Args:
+        name: name of error bdev
+        io_type: one of "clear", "read", "write", "unmap", "flush", or "all"
+        error_type: one of "failure" or "pending"
+        num: number of commands to fail
+    """
     params = {
-        'name': args.name,
-        'io_type': args.io_type,
-        'error_type': args.error_type,
-        'num': args.num,
+        'name': name,
+        'io_type': io_type,
+        'error_type': error_type,
+        'num': num,
     }
 
     return client.call('bdev_inject_error', params)
 
 
-def set_bdev_qos_limit_iops(client, args):
+def set_bdev_qd_sampling_period(client, name, period):
+    """Enable queue depth tracking on a specified bdev.
+
+    Args:
+        name: name of a bdev on which to track queue depth.
+        period: period (in microseconds) at which to update the queue depth reading. If set to 0, polling will be disabled.
+    """
+
     params = {}
-    params['name'] = args.name
-    params['ios_per_sec'] = args.ios_per_sec
+    params['name'] = name
+    params['period'] = period
+    return client.call('set_bdev_qd_sampling_period', params)
+
+
+def set_bdev_qos_limit_iops(client, name, ios_per_sec):
+    """Set QoS IOPS limit on a block device.
+
+    Args:
+        name: name of block device
+        ios_per_sec: IOs per second limit (>=10000, example: 20000). 0 means unlimited.
+    """
+    params = {}
+    params['name'] = name
+    params['ios_per_sec'] = ios_per_sec
     return client.call('set_bdev_qos_limit_iops', params)
 
 
-def apply_firmware(client, args):
+def apply_firmware(client, bdev_name, filename):
+    """Download and commit firmware to NVMe device.
+
+    Args:
+        bdev_name: name of NVMe block device
+        filename: filename of the firmware to download
+    """
     params = {
-        'filename': args.filename,
-        'bdev_name': args.bdev_name,
+        'filename': filename,
+        'bdev_name': bdev_name,
     }
     return client.call('apply_nvme_firmware', params)
diff --git a/scripts/rpc/ioat.py b/scripts/rpc/ioat.py
new file mode 100644
index 000000000..958e18bb4
--- /dev/null
+++ b/scripts/rpc/ioat.py
@@ -0,0 +1,12 @@
+def scan_ioat_copy_engine(client, pci_whitelist):
+    """Scan and enable IOAT copy engine.
+
+    Args:
+        pci_whitelist: Python list of PCI addresses in
+                       domain:bus:device.function format or
+                       domain.bus.device.function format
+    """
+    params = {}
+    if pci_whitelist:
+        params['pci_whitelist'] = pci_whitelist
+    return client.call('scan_ioat_copy_engine', params)
diff --git a/scripts/rpc/iscsi.py b/scripts/rpc/iscsi.py
index e721ffce3..28c755364 100755
--- a/scripts/rpc/iscsi.py
+++ b/scripts/rpc/iscsi.py
@@ -1,163 +1,354 @@
-def get_portal_groups(client, args):
+
+
+def set_iscsi_options(
+        client,
+        auth_file=None,
+        node_base=None,
+        nop_timeout=None,
+        nop_in_interval=None,
+        no_discovery_auth=None,
+        req_discovery_auth=None,
+        req_discovery_auth_mutual=None,
+        discovery_auth_group=None,
+        max_sessions=None,
+        max_connections_per_session=None,
+        default_time2wait=None,
+        default_time2retain=None,
+        immediate_data=None,
+        error_recovery_level=None,
+        allow_duplicated_isid=None,
+        min_connections_per_session=None):
+    """Set iSCSI target options.
+
+    Args:
+        auth_file: Path to CHAP shared secret file for discovery session (optional)
+        node_base: Prefix of the name of iSCSI target node (optional)
+        nop_timeout: Timeout in seconds to nop-in request to the initiator (optional)
+        nop_in_interval: Time interval in secs between nop-in requests by the target (optional)
+        no_discovery_auth: CHAP for discovery session should be disabled (optional)
+        req_discovery_auth: CHAP for discovery session should be required
+        req_discovery_auth_mutual: CHAP for discovery session should be mutual
+        discovery_auth_group: Authentication group ID for discovery session
+        max_sessions:Maximum number of sessions in the host
+        max_connections_per_session:Negotiated parameter, MaxConnections
+        default_time2wait: Negotiated parameter, DefaultTime2Wait
+        default_time2retain: Negotiated parameter, DefaultTime2Retain
+        immediate_data: Negotiated parameter, ImmediateData
+        error_recovery_level: Negotiated parameter, ErrorRecoveryLevel
+        allow_duplicated_isid: Allow duplicated initiator session ID
+        min_connections_per_session: Allocation unit of connections per core
+
+    Returns:
+        True or False
+    """
+    params = {}
+
+    if auth_file:
+        params['auth_file'] = auth_file
+    if node_base:
+        params['node_base'] = node_base
+    if nop_timeout:
+        params['nop_timeout'] = nop_timeout
+    if nop_in_interval:
+        params['nop_in_interval'] = nop_in_interval
+    if no_discovery_auth:
+        params['no_discovery_auth'] = no_discovery_auth
+    if req_discovery_auth:
+        params['req_discovery_auth'] = req_discovery_auth
+    if req_discovery_auth_mutual:
+        params['req_discovery_auth_mutual'] = req_discovery_auth_mutual
+    if discovery_auth_group:
+        params['discovery_auth_group'] = discovery_auth_group
+    if max_sessions:
+        params['max_sessions'] = max_sessions
+    if max_connections_per_session:
+        params['max_connections_per_session'] = max_connections_per_session
+    if default_time2wait:
+        params['default_time2wait'] = default_time2wait
+    if default_time2retain:
+        params['default_time2retain'] = default_time2retain
+    if immediate_data:
+        params['immediate_data'] = immediate_data
+    if error_recovery_level:
+        params['error_recovery_level'] = error_recovery_level
+    if allow_duplicated_isid:
+        params['allow_duplicated_isid'] = allow_duplicated_isid
+    if min_connections_per_session:
+        params['min_connections_per_session'] = min_connections_per_session
+
+    return client.call('set_iscsi_options', params)
+
+
+def get_portal_groups(client):
+    """Display current portal group configuration.
+
+    Returns:
+        List of current portal group configuration.
+    """
     return client.call('get_portal_groups')
 
 
-def get_initiator_groups(client, args):
+def get_initiator_groups(client):
+    """Display current initiator group configuration.
+
+    Returns:
+        List of current initiator group configuration.
+    """
     return client.call('get_initiator_groups')
 
 
-def get_target_nodes(client, args):
-    return client.call('get_target_nodes')
+def get_target_nodes(client):
+    """Display target nodes.
 
+    Returns:
+        List of ISCSI target node objects.
+    """
+    return client.call('get_target_nodes')
 
-def construct_target_node(client, args):
-    luns = []
-    for u in args.bdev_name_id_pairs.strip().split(" "):
-        bdev_name, lun_id = u.split(":")
-        luns.append({"bdev_name": bdev_name, "lun_id": int(lun_id)})
-
-    pg_ig_maps = []
-    for u in args.pg_ig_mappings.strip().split(" "):
-        pg, ig = u.split(":")
-        pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
 
+def construct_target_node(
+        client,
+        luns,
+        pg_ig_maps,
+        name,
+        alias_name,
+        queue_depth,
+        chap_group=None,
+        disable_chap=None,
+        require_chap=None,
+        mutual_chap=None,
+        header_digest=None,
+        data_digest=None):
+    """Add a target node.
+
+    Args:
+        luns: List of bdev_name_id_pairs, e.g. [{"bdev_name": "Malloc1", "lun_id": 1}]
+        pg_ig_maps: List of pg_ig_mappings, e.g. [{"pg_tag": pg, "ig_tag": ig}]
+        name: Target node name (ASCII)
+        alias_name: Target node alias name (ASCII)
+        queue_depth: Desired target queue depth
+        chap_group: Authentication group ID for this target node
+        disable_chap: CHAP authentication should be disabled for this target node
+        require_chap: CHAP authentication should be required for this target node
+        mutual_chap: CHAP authentication should be mutual/bidirectional
+        header_digest: Header Digest should be required for this target node
+        data_digest: Data Digest should be required for this target node
+
+    Returns:
+        True or False
+    """
     params = {
-        'name': args.name,
-        'alias_name': args.alias_name,
+        'name': name,
+        'alias_name': alias_name,
         'pg_ig_maps': pg_ig_maps,
         'luns': luns,
-        'queue_depth': args.queue_depth,
+        'queue_depth': queue_depth,
     }
 
-    if args.chap_group:
-        params['chap_group'] = args.chap_group
-    if args.disable_chap:
-        params['disable_chap'] = args.disable_chap
-    if args.require_chap:
-        params['require_chap'] = args.require_chap
-    if args.mutual_chap:
-        params['mutual_chap'] = args.mutual_chap
-    if args.header_digest:
-        params['header_digest'] = args.header_digest
-    if args.data_digest:
-        params['data_digest'] = args.data_digest
+    if chap_group:
+        params['chap_group'] = chap_group
+    if disable_chap:
+        params['disable_chap'] = disable_chap
+    if require_chap:
+        params['require_chap'] = require_chap
+    if mutual_chap:
+        params['mutual_chap'] = mutual_chap
+    if header_digest:
+        params['header_digest'] = header_digest
+    if data_digest:
+        params['data_digest'] = data_digest
     return client.call('construct_target_node', params)
 
 
-def target_node_add_lun(client, args):
+def target_node_add_lun(client, name, bdev_name, lun_id=None):
+    """Add LUN to the target node.
+
+    Args:
+        name: Target node name (ASCII)
+        bdev_name: bdev name
+        lun_id: LUN ID (integer >= 0)
+
+    Returns:
+        True or False
+    """
     params = {
-        'name': args.name,
-        'bdev_name': args.bdev_name,
+        'name': name,
+        'bdev_name': bdev_name,
     }
-    if args.lun_id:
-        params['lun_id'] = args.lun_id
+    if lun_id:
+        params['lun_id'] = lun_id
     return client.call('target_node_add_lun', params)
 
 
-def delete_pg_ig_maps(client, args):
-    pg_ig_maps = []
-    for u in args.pg_ig_mappings.strip().split(" "):
-        pg, ig = u.split(":")
-        pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
+def delete_pg_ig_maps(client, pg_ig_maps, name):
+    """Delete PG-IG maps from the target node.
+
+    Args:
+        pg_ig_maps: List of pg_ig_mappings, e.g. [{"pg_tag": pg, "ig_tag": ig}]
+        name: Target node alias name (ASCII)
+
+    Returns:
+        True or False
+    """
     params = {
-        'name': args.name,
+        'name': name,
         'pg_ig_maps': pg_ig_maps,
     }
     return client.call('delete_pg_ig_maps', params)
 
 
-def add_pg_ig_maps(client, args):
-    pg_ig_maps = []
-    for u in args.pg_ig_mappings.strip().split(" "):
-        pg, ig = u.split(":")
-        pg_ig_maps.append({"pg_tag": int(pg), "ig_tag": int(ig)})
+def add_pg_ig_maps(client, pg_ig_maps, name):
+    """Add PG-IG maps to the target node.
+
+    Args:
+        pg_ig_maps: List of pg_ig_mappings, e.g. [{"pg_tag": pg, "ig_tag": ig}]
+        name: Target node alias name (ASCII)
+
+    Returns:
+        True or False
+    """
     params = {
-        'name': args.name,
+        'name': name,
         'pg_ig_maps': pg_ig_maps,
     }
     return client.call('add_pg_ig_maps', params)
 
 
-def add_portal_group(client, args):
-    # parse out portal list host1:port1 host2:port2
-    portals = []
-    for p in args.portal_list:
-        ip, separator, port_cpumask = p.rpartition(':')
-        split_port_cpumask = port_cpumask.split('@')
-        if len(split_port_cpumask) == 1:
-            port = port_cpumask
-            portals.append({'host': ip, 'port': port})
-        else:
-            port = split_port_cpumask[0]
-            cpumask = split_port_cpumask[1]
-            portals.append({'host': ip, 'port': port, 'cpumask': cpumask})
-
-    params = {'tag': args.tag, 'portals': portals}
+def add_portal_group(client, portals, tag):
+    """Add a portal group.
+
+    Args:
+        portals: List of portals, e.g. [{'host': ip, 'port': port}] or [{'host': ip, 'port': port, 'cpumask': cpumask}]
+        tag: Initiator group tag (unique, integer > 0)
+
+    Returns:
+        True or False
+    """
+    params = {'tag': tag, 'portals': portals}
     return client.call('add_portal_group', params)
 
 
-def add_initiator_group(client, args):
-    initiators = []
-    netmasks = []
-    for i in args.initiator_list.strip().split(' '):
-        initiators.append(i)
-    for n in args.netmask_list.strip().split(' '):
-        netmasks.append(n)
+def add_initiator_group(client, tag, initiators, netmasks):
+    """Add an initiator group.
 
-    params = {'tag': args.tag, 'initiators': initiators, 'netmasks': netmasks}
+    Args:
+        tag: Initiator group tag (unique, integer > 0)
+        initiators: List of initiator hostnames or IP addresses, e.g. ["127.0.0.1","192.168.200.100"]
+        netmasks: List of initiator netmasks, e.g. ["255.255.0.0","255.248.0.0"]
+
+    Returns:
+        True or False
+    """
+    params = {'tag': tag, 'initiators': initiators, 'netmasks': netmasks}
     return client.call('add_initiator_group', params)
 
 
-def add_initiators_to_initiator_group(client, args):
-    initiators = []
-    netmasks = []
-    if args.initiator_list:
-        for i in args.initiator_list.strip().split(' '):
-            initiators.append(i)
-    if args.netmask_list:
-        for n in args.netmask_list.strip().split(' '):
-            netmasks.append(n)
+def add_initiators_to_initiator_group(
+        client,
+        tag,
+        initiators=None,
+        netmasks=None):
+    """Add initiators to an existing initiator group.
+
+    Args:
+        tag: Initiator group tag (unique, integer > 0)
+        initiators: List of initiator hostnames or IP addresses, e.g. ["127.0.0.1","192.168.200.100"]
+        netmasks: List of initiator netmasks, e.g. ["255.255.0.0","255.248.0.0"]
 
-    params = {'tag': args.tag, 'initiators': initiators, 'netmasks': netmasks}
+    Returns:
+        True or False
+    """
+    params = {'tag': tag}
+
+    if initiators:
+        params['initiators'] = initiators
+    if netmasks:
+        params['netmasks'] = netmasks
     return client.call('add_initiators_to_initiator_group', params)
 
 
-def delete_initiators_from_initiator_group(client, args):
-    initiators = []
-    netmasks = []
-    if args.initiator_list:
-        for i in args.initiator_list.strip().split(' '):
-            initiators.append(i)
-    if args.netmask_list:
-        for n in args.netmask_list.strip().split(' '):
-            netmasks.append(n)
+def delete_initiators_from_initiator_group(
+        client, tag, initiators=None, netmasks=None):
+    """Delete initiators from an existing initiator group.
+
+    Args:
+        tag: Initiator group tag (unique, integer > 0)
+        initiators: List of initiator hostnames or IP addresses, e.g. ["127.0.0.1","192.168.200.100"]
+        netmasks: List of initiator netmasks, e.g. ["255.255.0.0","255.248.0.0"]
 
-    params = {'tag': args.tag, 'initiators': initiators, 'netmasks': netmasks}
+    Returns:
+        True or False
+    """
+    params = {'tag': tag}
+
+    if initiators:
+        params['initiators'] = initiators
+    if netmasks:
+        params['netmasks'] = netmasks
     return client.call('delete_initiators_from_initiator_group', params)
 
 
-def delete_target_node(client, args):
-    params = {'name': args.target_node_name}
+def delete_target_node(client, target_node_name):
+    """Delete a target node.
+
+    Args:
+        target_node_name: Target node name to be deleted. Example: iqn.2016-06.io.spdk:disk1.
+
+    Returns:
+        True or False
+    """
+    params = {'name': target_node_name}
     return client.call('delete_target_node', params)
 
 
-def delete_portal_group(client, args):
-    params = {'tag': args.tag}
+def delete_portal_group(client, tag):
+    """Delete a portal group.
+
+    Args:
+        tag: Portal group tag (unique, integer > 0)
+
+    Returns:
+        True or False
+    """
+    params = {'tag': tag}
     return client.call('delete_portal_group', params)
 
 
-def delete_initiator_group(client, args):
-    params = {'tag': args.tag}
+def delete_initiator_group(client, tag):
+    """Delete an initiator group.
+
+    Args:
+        tag: Initiator group tag (unique, integer > 0)
+
+    Returns:
+        True or False
+    """
+    params = {'tag': tag}
     return client.call('delete_initiator_group', params)
 
 
-def get_iscsi_connections(client, args):
+def get_iscsi_connections(client):
+    """Display iSCSI connections.
+
+    Returns:
+        List of iSCSI connection.
+    """
     return client.call('get_iscsi_connections')
 
 
-def get_iscsi_global_params(client, args):
+def get_iscsi_global_params(client):
+    """Display iSCSI global parameters.
+
+    Returns:
+        List of iSCSI global parameter.
+    """
     return client.call('get_iscsi_global_params')
 
 
-def get_scsi_devices(client, args):
+def get_scsi_devices(client):
+    """Display SCSI devices.
+
+    Returns:
+        List of SCSI device.
+    """
     return client.call('get_scsi_devices')
diff --git a/scripts/rpc/lvol.py b/scripts/rpc/lvol.py
index 376312ea8..e7e05a3b2 100755
--- a/scripts/rpc/lvol.py
+++ b/scripts/rpc/lvol.py
@@ -40,6 +40,9 @@ def construct_lvol_bdev(client, lvol_name, size, thin_provision=False, uuid=None
         lvs_name: name of logical volume store to create logical volume on (optional)
 
     Either uuid or lvs_name must be specified, but not both.
+
+    Returns:
+        Name of created logical volume block device.
     """
     if (uuid and lvs_name) or (not uuid and not lvs_name):
         raise ValueError("Either uuid or lvs_name must be specified, but not both")
@@ -60,6 +63,9 @@ def snapshot_lvol_bdev(client, lvol_name, snapshot_name):
     Args:
         lvol_name: logical volume to create a snapshot from
         snapshot_name: name for the newly created snapshot
+
+    Returns:
+        Name of created logical volume snapshot.
     """
     params = {
         'lvol_name': lvol_name,
@@ -74,6 +80,9 @@ def clone_lvol_bdev(client, snapshot_name, clone_name):
     Args:
         snapshot_name: snapshot to clone
         clone_name: name of logical volume to create
+
+    Returns:
+        Name of created logical volume clone.
     """
     params = {
         'snapshot_name': snapshot_name,
@@ -122,6 +131,30 @@ def destroy_lvol_bdev(client, name):
     return client.call('destroy_lvol_bdev', params)
 
 
+def inflate_lvol_bdev(client, name):
+    """Inflate a logical volume.
+
+    Args:
+        name: name of logical volume to inflate
+    """
+    params = {
+        'name': name,
+    }
+    return client.call('inflate_lvol_bdev', params)
+
+
+def decouple_parent_lvol_bdev(client, name):
+    """Decouple parent of a logical volume.
+
+    Args:
+        name: name of logical volume to decouple parent
+    """
+    params = {
+        'name': name,
+    }
+    return client.call('decouple_parent_lvol_bdev', params)
+
+
 def destroy_lvol_store(client, uuid=None, lvs_name=None):
     """Destroy a logical volume store.
 
diff --git a/scripts/rpc/nvmf.py b/scripts/rpc/nvmf.py
index 3e17413ab..fb523396c 100755
--- a/scripts/rpc/nvmf.py
+++ b/scripts/rpc/nvmf.py
@@ -1,124 +1,275 @@
-def get_nvmf_subsystems(client, args):
+
+
+def set_nvmf_target_options(client,
+                            max_queue_depth=None,
+                            max_qpairs_per_ctrlr=None,
+                            in_capsule_data_size=None,
+                            max_io_size=None,
+                            max_subsystems=None,
+                            io_unit_size=None):
+    """Set NVMe-oF target options.
+
+    Args:
+        max_queue_depth: Max number of outstanding I/O per queue (optional)
+        max_qpairs_per_ctrlr: Max number of SQ and CQ per controller (optional)
+        in_capsule_data_size: Maximum in-capsule data size in bytes (optional)
+        max_io_size: Maximum I/O data size in bytes (optional)
+        max_subsystems: Maximum number of NVMe-oF subsystems (optional)
+        io_unit_size: I/O unit size in bytes (optional)
+
+    Returns:
+        True or False
+    """
+    params = {}
+
+    if max_queue_depth:
+        params['max_queue_depth'] = max_queue_depth
+    if max_qpairs_per_ctrlr:
+        params['max_qpairs_per_ctrlr'] = max_qpairs_per_ctrlr
+    if in_capsule_data_size:
+        params['in_capsule_data_size'] = in_capsule_data_size
+    if max_io_size:
+        params['max_io_size'] = max_io_size
+    if max_subsystems:
+        params['max_subsystems'] = max_subsystems
+    if io_unit_size:
+        params['io_unit_size'] = io_unit_size
+    return client.call('set_nvmf_target_options', params)
+
+
+def set_nvmf_target_config(client, acceptor_poll_rate=None):
+    """Set NVMe-oF target subsystem configuration.
+
+    Args:
+        acceptor_poll_rate: Acceptor poll period in microseconds (optional)
+
+    Returns:
+        True or False
+    """
+    params = {}
+
+    if acceptor_poll_rate:
+        params['acceptor_poll_rate'] = acceptor_poll_rate
+    return client.call('set_nvmf_target_config', params)
+
+
+def get_nvmf_subsystems(client):
+    """Get list of NVMe-oF subsystems.
+
+    Returns:
+        List of NVMe-oF subsystem objects.
+    """
     return client.call('get_nvmf_subsystems')
 
 
-def construct_nvmf_subsystem(client, args):
+def construct_nvmf_subsystem(client,
+                             nqn,
+                             serial_number,
+                             listen_addresses=None,
+                             hosts=None,
+                             allow_any_host=False,
+                             namespaces=None,
+                             max_namespaces=0):
+    """Construct an NVMe over Fabrics target subsystem.
+
+    Args:
+        nqn: Subsystem NQN.
+        serial_number: Serial number of virtual controller.
+        listen_addresses: Array of listen_address objects (optional).
+        hosts: Array of strings containing allowed host NQNs (optional). Default: No hosts allowed.
+        allow_any_host: Allow any host (True) or enforce allowed host whitelist (False). Default: False.
+        namespaces: Array of namespace objects (optional). Default: No namespaces.
+        max_namespaces: Maximum number of namespaces that can be attached to the subsystem (optional). Default: 0 (Unlimited).
+
+    Returns:
+        True or False
+    """
     params = {
-        'nqn': args.nqn,
-        'serial_number': args.serial_number,
+        'nqn': nqn,
+        'serial_number': serial_number,
     }
 
-    if args.max_namespaces:
-        params['max_namespaces'] = args.max_namespaces
+    if max_namespaces:
+        params['max_namespaces'] = max_namespaces
 
-    if args.listen:
-        params['listen_addresses'] = [dict(u.split(":", 1) for u in a.split(" "))
-                                      for a in args.listen.split(",")]
+    if listen_addresses:
+        params['listen_addresses'] = listen_addresses
 
-    if args.hosts:
-        hosts = []
-        for u in args.hosts.strip().split(" "):
-            hosts.append(u)
+    if hosts:
         params['hosts'] = hosts
 
-    if args.allow_any_host:
+    if allow_any_host:
         params['allow_any_host'] = True
 
-    if args.namespaces:
-        namespaces = []
-        for u in args.namespaces.strip().split(" "):
-            bdev_name = u
-            nsid = 0
-            if ':' in u:
-                (bdev_name, nsid) = u.split(":")
-
-            ns_params = {'bdev_name': bdev_name}
-
-            nsid = int(nsid)
-            if nsid != 0:
-                ns_params['nsid'] = nsid
-
-            namespaces.append(ns_params)
+    if namespaces:
         params['namespaces'] = namespaces
 
     return client.call('construct_nvmf_subsystem', params)
 
 
-def nvmf_subsystem_add_listener(client, args):
-    listen_address = {'trtype': args.trtype,
-                      'traddr': args.traddr,
-                      'trsvcid': args.trsvcid}
+def nvmf_subsystem_add_listener(client, nqn, trtype, traddr, trsvcid, adrfam):
+    """Add a new listen address to an NVMe-oF subsystem.
 
-    if args.adrfam:
-        listen_address['adrfam'] = args.adrfam
+    Args:
+        nqn: Subsystem NQN.
+        trtype: Transport type ("RDMA").
+        traddr: Transport address.
+        trsvcid: Transport service ID.
+        adrfam: Address family ("IPv4", "IPv6", "IB", or "FC").
 
-    params = {'nqn': args.nqn,
-              'listen_address': listen_address}
+    Returns:
+        True or False
+    """
+    listen_address = {'trtype': trtype,
+                      'traddr': traddr,
+                      'trsvcid': trsvcid}
 
-    return client.call('nvmf_subsystem_add_listener', params)
+    if adrfam:
+        listen_address['adrfam'] = adrfam
 
+    params = {'nqn': nqn,
+              'listen_address': listen_address}
 
-def nvmf_subsystem_remove_listener(client, args):
-    listen_address = {'trtype': args.trtype,
-                      'traddr': args.traddr,
-                      'trsvcid': args.trsvcid}
+    return client.call('nvmf_subsystem_add_listener', params)
 
-    if args.adrfam:
-        listen_address['adrfam'] = args.adrfam
 
-    params = {'nqn': args.nqn,
+def nvmf_subsystem_remove_listener(
+        client,
+        nqn,
+        trtype,
+        traddr,
+        trsvcid,
+        adrfam):
+    """Remove existing listen address from an NVMe-oF subsystem.
+
+    Args:
+        nqn: Subsystem NQN.
+        trtype: Transport type ("RDMA").
+        traddr: Transport address.
+        trsvcid: Transport service ID.
+        adrfam: Address family ("IPv4", "IPv6", "IB", or "FC").
+
+    Returns:
+            True or False
+    """
+    listen_address = {'trtype': trtype,
+                      'traddr': traddr,
+                      'trsvcid': trsvcid}
+
+    if adrfam:
+        listen_address['adrfam'] = adrfam
+
+    params = {'nqn': nqn,
               'listen_address': listen_address}
 
     return client.call('nvmf_subsystem_remove_listener', params)
 
 
-def nvmf_subsystem_add_ns(client, args):
-    ns = {'bdev_name': args.bdev_name}
+def nvmf_subsystem_add_ns(client, nqn, bdev_name, nsid=None, nguid=None, eui64=None, uuid=None):
+    """Add a namespace to a subsystem.
+
+    Args:
+        nqn: Subsystem NQN.
+        bdev_name: Name of bdev to expose as a namespace.
+        nsid: Namespace ID (optional).
+        nguid: 16-byte namespace globally unique identifier in hexadecimal (optional).
+        eui64: 8-byte namespace EUI-64 in hexadecimal (e.g. "ABCDEF0123456789") (optional).
+        uuid: Namespace UUID (optional).
+
+    Returns:
+        The namespace ID
+    """
+    ns = {'bdev_name': bdev_name}
 
-    if args.nsid:
-        ns['nsid'] = args.nsid
+    if nsid:
+        ns['nsid'] = nsid
 
-    if args.nguid:
-        ns['nguid'] = args.nguid
+    if nguid:
+        ns['nguid'] = nguid
 
-    if args.eui64:
-        ns['eui64'] = args.eui64
+    if eui64:
+        ns['eui64'] = eui64
 
-    params = {'nqn': args.nqn,
+    if uuid:
+        ns['uuid'] = uuid
+
+    params = {'nqn': nqn,
               'namespace': ns}
 
     return client.call('nvmf_subsystem_add_ns', params)
 
 
-def nvmf_subsystem_remove_ns(client, args):
+def nvmf_subsystem_remove_ns(client, nqn, nsid):
+    """Remove a existing namespace from a subsystem.
+
+    Args:
+        nqn: Subsystem NQN.
+        nsid: Namespace ID.
 
-    params = {'nqn': args.nqn,
-              'nsid': args.nsid}
+    Returns:
+        True or False
+    """
+    params = {'nqn': nqn,
+              'nsid': nsid}
 
     return client.call('nvmf_subsystem_remove_ns', params)
 
 
-def nvmf_subsystem_add_host(client, args):
-    params = {'nqn': args.nqn,
-              'host': args.host}
+def nvmf_subsystem_add_host(client, nqn, host):
+    """Add a host NQN to the whitelist of allowed hosts.
+
+    Args:
+        nqn: Subsystem NQN.
+        host: Host NQN to add to the list of allowed host NQNs
+
+    Returns:
+        True or False
+    """
+    params = {'nqn': nqn,
+              'host': host}
 
     return client.call('nvmf_subsystem_add_host', params)
 
 
-def nvmf_subsystem_remove_host(client, args):
-    params = {'nqn': args.nqn,
-              'host': args.host}
+def nvmf_subsystem_remove_host(client, nqn, host):
+    """Remove a host NQN from the whitelist of allowed hosts.
+
+    Args:
+        nqn: Subsystem NQN.
+        host: Host NQN to remove to the list of allowed host NQNs
+
+    Returns:
+        True or False
+    """
+    params = {'nqn': nqn,
+              'host': host}
 
     return client.call('nvmf_subsystem_remove_host', params)
 
 
-def nvmf_subsystem_allow_any_host(client, args):
-    params = {'nqn': args.nqn}
-    params['allow_any_host'] = False if args.disable else True
+def nvmf_subsystem_allow_any_host(client, nqn, disable):
+    """Configure a subsystem to allow any host to connect or to enforce the host NQN whitelist.
+
+    Args:
+        nqn: Subsystem NQN.
+        disable: Allow any host (true) or enforce allowed host whitelist (false).
+
+    Returns:
+        True or False
+    """
+    params = {'nqn': nqn, 'allow_any_host': False if disable else True}
 
     return client.call('nvmf_subsystem_allow_any_host', params)
 
 
-def delete_nvmf_subsystem(client, args):
-    params = {'nqn': args.subsystem_nqn}
+def delete_nvmf_subsystem(client, nqn):
+    """Delete an existing NVMe-oF subsystem.
+
+    Args:
+        nqn: Subsystem NQN.
+
+    Returns:
+        True or False
+    """
+    params = {'nqn': nqn}
     return client.call('delete_nvmf_subsystem', params)
diff --git a/scripts/rpc/pmem.py b/scripts/rpc/pmem.py
index 7ccf8baf0..4ab38ff31 100755
--- a/scripts/rpc/pmem.py
+++ b/scripts/rpc/pmem.py
@@ -1,16 +1,29 @@
-def create_pmem_pool(client, args):
-    num_blocks = (args.total_size * 1024 * 1024) / args.block_size
-    params = {'pmem_file': args.pmem_file,
+def create_pmem_pool(client, pmem_file, num_blocks, block_size):
+    """Create pmem pool at specified path.
+    Args:
+        pmem_file: path at which to create pmem pool
+        num_blocks: number of blocks for created pmem pool file
+        block_size: block size for pmem pool file
+    """
+    params = {'pmem_file': pmem_file,
               'num_blocks': num_blocks,
-              'block_size': args.block_size}
+              'block_size': block_size}
     return client.call('create_pmem_pool', params)
 
 
-def pmem_pool_info(client, args):
-    params = {'pmem_file': args.pmem_file}
+def pmem_pool_info(client, pmem_file):
+    """Get details about pmem pool.
+    Args:
+        pmem_file: path to pmem pool
+    """
+    params = {'pmem_file': pmem_file}
     return client.call('pmem_pool_info', params)
 
 
-def delete_pmem_pool(client, args):
-    params = {'pmem_file': args.pmem_file}
+def delete_pmem_pool(client, pmem_file):
+    """Delete pmem pool.
+    Args:
+        pmem_file: path to pmem pool
+    """
+    params = {'pmem_file': pmem_file}
     return client.call('delete_pmem_pool', params)
diff --git a/scripts/rpc/vhost.py b/scripts/rpc/vhost.py
index 09d277b47..20ffd277c 100755
--- a/scripts/rpc/vhost.py
+++ b/scripts/rpc/vhost.py
@@ -1,138 +1,231 @@
-def set_vhost_controller_coalescing(client, args):
+def set_vhost_controller_coalescing(client, ctrlr, delay_base_us, iops_threshold):
+    """Set coalescing for vhost controller.
+    Args:
+        ctrlr: controller name
+        delay_base_us: base delay time
+        iops_threshold: IOPS threshold when coalescing is enabled
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'delay_base_us': args.delay_base_us,
-        'iops_threshold': args.iops_threshold,
+        'ctrlr': ctrlr,
+        'delay_base_us': delay_base_us,
+        'iops_threshold': iops_threshold,
     }
     return client.call('set_vhost_controller_coalescing', params)
 
 
-def construct_vhost_scsi_controller(client, args):
-    params = {'ctrlr': args.ctrlr}
+def construct_vhost_scsi_controller(client, ctrlr, cpumask=None):
+    """Construct a vhost scsi controller.
+    Args:
+        ctrlr: controller name
+        cpumask: cpu mask for this controller
+    """
+    params = {'ctrlr': ctrlr}
 
-    if args.cpumask:
-        params['cpumask'] = args.cpumask
+    if cpumask:
+        params['cpumask'] = cpumask
 
     return client.call('construct_vhost_scsi_controller', params)
 
 
-def add_vhost_scsi_lun(client, args):
+def add_vhost_scsi_lun(client, ctrlr, scsi_target_num, bdev_name):
+    """Add LUN to vhost scsi controller target.
+    Args:
+        ctrlr: controller name
+        scsi_target_num: target number to use
+        bdev_name: name of bdev to add to target
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'bdev_name': args.bdev_name,
-        'scsi_target_num': args.scsi_target_num
+        'ctrlr': ctrlr,
+        'scsi_target_num': scsi_target_num,
+        'bdev_name': bdev_name,
     }
     return client.call('add_vhost_scsi_lun', params)
 
 
-def remove_vhost_scsi_target(client, args):
+def remove_vhost_scsi_target(client, ctrlr, scsi_target_num):
+    """Remove target from vhost scsi controller.
+    Args:
+        ctrlr: controller name to remove target from
+        scsi_target_num: number of target to remove from controller
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'scsi_target_num': args.scsi_target_num
+        'ctrlr': ctrlr,
+        'scsi_target_num': scsi_target_num
     }
     return client.call('remove_vhost_scsi_target', params)
 
 
-def construct_vhost_nvme_controller(client, args):
+def construct_vhost_nvme_controller(client, ctrlr, io_queues, cpumask=None):
+    """Construct vhost NVMe controller.
+    Args:
+        ctrlr: controller name
+        io_queues: number of IO queues for the controller
+        cpumask: cpu mask for this controller
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'io_queues': args.io_queues
+        'ctrlr': ctrlr,
+        'io_queues': io_queues
     }
 
-    if args.cpumask:
-        params['cpumask'] = args.cpumask
+    if cpumask:
+        params['cpumask'] = cpumask
 
     return client.call('construct_vhost_nvme_controller', params)
 
 
-def add_vhost_nvme_ns(client, args):
+def add_vhost_nvme_ns(client, ctrlr, bdev_name):
+    """Add namespace to vhost nvme controller.
+    Args:
+        ctrlr: controller name where to add a namespace
+        bdev_name: block device name for a new namespace
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'bdev_name': args.bdev_name,
+        'ctrlr': ctrlr,
+        'bdev_name': bdev_name,
     }
 
     return client.call('add_vhost_nvme_ns', params)
 
 
-def construct_vhost_blk_controller(client, args):
+def construct_vhost_blk_controller(client, ctrlr, dev_name, cpumask=None, readonly=None):
+    """Construct vhost BLK controller.
+    Args:
+        ctrlr: controller name
+        dev_name: device name to add to controller
+        cpumask: cpu mask for this controller
+        readonly: set controller as read-only
+    """
     params = {
-        'ctrlr': args.ctrlr,
-        'dev_name': args.dev_name,
+        'ctrlr': ctrlr,
+        'dev_name': dev_name,
     }
-    if args.cpumask:
-        params['cpumask'] = args.cpumask
-    if args.readonly:
-        params['readonly'] = args.readonly
+    if cpumask:
+        params['cpumask'] = cpumask
+    if readonly:
+        params['readonly'] = readonly
     return client.call('construct_vhost_blk_controller', params)
 
 
-def get_vhost_controllers(client, args):
+def get_vhost_controllers(client):
+    """Get list of configured vhost controllers.
+    Returns:
+        List of vhost controllers.
+    """
     return client.call('get_vhost_controllers')
 
 
-def remove_vhost_controller(client, args):
-    params = {'ctrlr': args.ctrlr}
+def remove_vhost_controller(client, ctrlr):
+    """Remove vhost controller from configuration.
+    Args:
+        ctrlr: controller name to remove
+    """
+    params = {'ctrlr': ctrlr}
     return client.call('remove_vhost_controller', params)
 
 
-def construct_virtio_dev(client, args):
+def construct_virtio_dev(client, name, trtype, traddr, dev_type, vq_count=None, vq_size=None):
+    """Construct new virtio device using provided
+    transport type and device type.
+    Args:
+        name: name base for new created bdevs
+        trtype: virtio target transport type: pci or user
+        traddr: transport type specific target address: e.g. UNIX
+                domain socket path or BDF
+        dev_type: device type: blk or scsi
+        vq_count: number of virtual queues to be used
+        vq_size: size of each queue
+    """
     params = {
-        'name': args.name,
-        'trtype': args.trtype,
-        'traddr': args.traddr,
-        'dev_type': args.dev_type
+        'name': name,
+        'trtype': trtype,
+        'traddr': traddr,
+        'dev_type': dev_type
     }
-    if args.vq_count:
-        params['vq_count'] = args.vq_count
-    if args.vq_size:
-        params['vq_size'] = args.vq_size
+    if vq_count:
+        params['vq_count'] = vq_count
+    if vq_size:
+        params['vq_size'] = vq_size
     return client.call('construct_virtio_dev', params)
 
 
-def construct_virtio_user_scsi_bdev(client, args):
+def construct_virtio_user_scsi_bdev(client, path, name, vq_count=None, vq_size=None):
+    """Connect to virtio user scsi device.
+    Args:
+        path: path to Virtio SCSI socket
+        name: use this name as base instead of 'VirtioScsiN'
+        vq_count: number of virtual queues to be used
+        vq_size: size of each queue
+    """
     params = {
-        'path': args.path,
-        'name': args.name,
+        'path': path,
+        'name': name,
     }
-    if args.vq_count:
-        params['vq_count'] = args.vq_count
-    if args.vq_size:
-        params['vq_size'] = args.vq_size
+    if vq_count:
+        params['vq_count'] = vq_count
+    if vq_size:
+        params['vq_size'] = vq_size
     return client.call('construct_virtio_user_scsi_bdev', params)
 
 
-def construct_virtio_pci_scsi_bdev(client, args):
+def construct_virtio_pci_scsi_bdev(client, pci_address, name):
+    """Create a Virtio SCSI device from a virtio-pci device.
+    Args:
+        pci_address: PCI address in domain:bus:device.function format or
+               domain.bus.device.function format
+        name: Name for the virtio device. It will be inhereted by all created
+               bdevs, which are named n the following format:
+               <name>t<target_id>
+    """
     params = {
-        'pci_address': args.pci_address,
-        'name': args.name,
+        'pci_address': pci_address,
+        'name': name,
     }
     return client.call('construct_virtio_pci_scsi_bdev', params)
 
 
-def remove_virtio_scsi_bdev(client, args):
-    params = {'name': args.name}
+def remove_virtio_scsi_bdev(client, name):
+    """Remove a Virtio-SCSI device
+    This will delete all bdevs exposed by this device.
+    Args:
+        name: virtio device name
+    """
+    params = {'name': name}
     return client.call('remove_virtio_scsi_bdev', params)
 
 
-def get_virtio_scsi_devs(client, args):
+def get_virtio_scsi_devs(client):
+    """Get list of virtio scsi devices."""
     return client.call('get_virtio_scsi_devs')
 
 
-def construct_virtio_user_blk_bdev(client, args):
+def construct_virtio_user_blk_bdev(client, path, name, vq_count=None, vq_size=None):
+    """Connect to virtio user BLK device.
+    Args:
+        path: path to Virtio BLK socket
+        name: use this name as base instead of 'VirtioScsiN'
+        vq_count: number of virtual queues to be used
+        vq_size: size of each queue
+    """
     params = {
-        'path': args.path,
-        'name': args.name,
+        'path': path,
+        'name': name,
     }
-    if args.vq_count:
-        params['vq_count'] = args.vq_count
-    if args.vq_size:
-        params['vq_size'] = args.vq_size
+    if vq_count:
+        params['vq_count'] = vq_count
+    if vq_size:
+        params['vq_size'] = vq_size
     return client.call('construct_virtio_user_blk_bdev', params)
 
 
-def construct_virtio_pci_blk_bdev(client, args):
+def construct_virtio_pci_blk_bdev(client, pci_address, name):
+    """Create a Virtio Blk device from a virtio-pci device.
+    Args:
+        pci_address: PCI address in domain:bus:device.function format or
+               domain.bus.device.function format
+        name: name for the blk device
+    """
     params = {
-        'pci_address': args.pci_address,
-        'name': args.name,
+        'pci_address': pci_address,
+        'name': name,
     }
     return client.call('construct_virtio_pci_blk_bdev', params)
diff --git a/scripts/setup.sh b/scripts/setup.sh
index 39aa13a55..046d49c4a 100755
--- a/scripts/setup.sh
+++ b/scripts/setup.sh
@@ -8,7 +8,7 @@ source "$rootdir/scripts/common.sh"
 function usage()
 {
 	if [ `uname` = Linux ]; then
-		options="[config|reset|status|help]"
+		options="[config|reset|status|cleanup|help]"
 	else
 		options="[config|reset|help]"
 	fi
@@ -22,6 +22,9 @@ function usage()
 	echo
 	echo "$options - as following:"
 	echo "config            Default mode. Allocate hugepages and bind PCI devices."
+	if [ `uname` = Linux ]; then
+		echo "cleanup            Remove any orphaned files that can be left in the system after SPDK application exit"
+	fi
 	echo "reset             Rebind PCI devices back to their original drivers."
 	echo "                  Also cleanup any leftover spdk files/resources."
 	echo "                  Hugepage memory size will remain unchanged."
@@ -234,6 +237,39 @@ function configure_linux_pci {
 	echo "1" > "/sys/bus/pci/rescan"
 }
 
+function cleanup_linux {
+	files_to_clean="$(echo /dev/shm/* | egrep '(spdk_tgt|iscsi|vhost|nvmf|rocksdb)_trace|spdk_iscsi_conns' || true)"
+	files_to_clean="$(readlink -e assert_not_empty $files_to_clean || true)"
+	if [[ -z "$files_to_clean" ]]; then
+		echo "Clean"
+		return 0;
+	fi
+
+	shopt -s extglob
+	for fd_dir in $(echo /proc/+([0-9])); do
+		opened_files+="$(readlink -e assert_not_empty $fd_dir/fd/* || true)"
+	done
+	shopt -u extglob
+
+	if [[ -z "$opened_files" ]]; then
+		echo "Can't get list of opened files!"
+		exit 1
+	fi
+
+	echo 'Cleaning'
+	for f in $files_to_clean; do
+		if ! echo "$opened_files" | egrep -q "^$f\$"; then
+			echo "Removing:    $f"
+			rm $f
+		else
+			echo "Still open: $f"
+		fi
+	done
+	echo "Clean"
+
+	unset files_to_clean opened_files
+}
+
 function configure_linux {
 	configure_linux_pci
 	hugetlbfs_mounts=$(linux_hugetlbfs_mounts)
@@ -466,10 +502,18 @@ function configure_freebsd_pci {
 
 function configure_freebsd {
 	configure_freebsd_pci
-	kldunload contigmem.ko || true
-	kenv hw.contigmem.num_buffers=$((HUGEMEM / 256))
-	kenv hw.contigmem.buffer_size=$((256 * 1024 * 1024))
-	kldload contigmem.ko
+	# If contigmem is already loaded but the HUGEMEM specified doesn't match the
+	#  previous value, unload contigmem so that we can reload with the new value.
+	if kldstat -q -m contigmem; then
+		if [ `kenv hw.contigmem.num_buffers` -ne "$((HUGEMEM / 256))" ]; then
+			kldunload contigmem.ko
+		fi
+	fi
+	if ! kldstat -q -m contigmem; then
+		kenv hw.contigmem.num_buffers=$((HUGEMEM / 256))
+		kenv hw.contigmem.buffer_size=$((256 * 1024 * 1024))
+		kldload contigmem.ko
+	fi
 }
 
 function reset_freebsd {
@@ -510,6 +554,8 @@ if [ `uname` = Linux ]; then
 
 	if [ "$mode" == "config" ]; then
 		configure_linux
+	elif [ "$mode" == "cleanup" ]; then
+		cleanup_linux
 	elif [ "$mode" == "reset" ]; then
 		reset_linux
 	elif [ "$mode" == "status" ]; then
diff --git a/scripts/spdkcli.py b/scripts/spdkcli.py
index c7c3867b0..4d794cab2 100755
--- a/scripts/spdkcli.py
+++ b/scripts/spdkcli.py
@@ -22,7 +22,7 @@ def main():
     root_node = UIRoot(args.socket, shell)
     try:
         root_node.refresh()
-    except:
+    except BaseException:
         pass
 
     if len(args.commands) > 0:
diff --git a/scripts/spdkcli/ui_node.py b/scripts/spdkcli/ui_node.py
index cdbc8d59f..f82554c7e 100644
--- a/scripts/spdkcli/ui_node.py
+++ b/scripts/spdkcli/ui_node.py
@@ -1,5 +1,6 @@
 from configshell_fb import ConfigNode, ExecutionError
 from uuid import UUID
+from rpc.client import JSONRPCException
 import json
 
 
@@ -52,6 +53,14 @@ class UIBdevs(UINode):
         UIAIOBdev(self)
         UILvolBdev(self)
         UINvmeBdev(self)
+        UINullBdev(self)
+        UIErrorBdev(self)
+        UISplitBdev(self)
+        UIPmemBdev(self)
+        UIRbdBdev(self)
+        UIiSCSIBdev(self)
+        UIVirtioBlkBdev(self)
+        UIVirtioScsiBdev(self)
 
     def ui_command_delete(self, name):
         """
@@ -86,7 +95,11 @@ class UILvolStores(UINode):
 
         cluster_size = self.ui_eval_param(cluster_size, "number", None)
 
-        self.get_root().create_lvol_store(lvs_name=name, bdev_name=bdev_name, cluster_sz=cluster_size)
+        try:
+            self.get_root().create_lvol_store(lvs_name=name, bdev_name=bdev_name, cluster_sz=cluster_size)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
         self.get_root().refresh()
         self.refresh()
 
@@ -127,17 +140,67 @@ class UIBdev(UINode):
         Arguments:
         name - Is a unique identifier of the bdev to be deleted - UUID number or name alias.
         """
-        self.get_root().delete_bdev(name=name)
+        try:
+            self.get_root().delete_bdev(name=name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
         self.get_root().refresh()
         self.refresh()
 
+    def ui_command_get_bdev_iostat(self, name=None):
+        try:
+            ret = self.get_root().get_bdevs_iostat(name=name)
+            self.shell.log.info(json.dumps(ret, indent=2))
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+    def ui_command_split_bdev(self, base_bdev, split_count, split_size_mb=None):
+        """
+        Construct split block devices from a base bdev.
+
+        Arguments:
+        base_bdev - Name of bdev to split
+        split_count -  Number of split bdevs to create
+        split_size_mb- Size of each split volume in MiB (optional)
+        """
+
+        split_count = self.ui_eval_param(split_count, "number", None)
+        split_size_mb = self.ui_eval_param(split_size_mb, "number", None)
+
+        try:
+            ret_name = self.get_root().split_bdev(base_bdev=base_bdev,
+                                                  split_count=split_count,
+                                                  split_size_mb=split_size_mb)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.parent.refresh()
+        self.refresh()
+
+    def ui_command_destruct_split_bdev(self, base_bdev):
+        """Destroy split block devices associated with base bdev.
+
+        Args:
+            base_bdev: name of previously split bdev
+        """
+
+        try:
+            self.get_root().destruct_split_bdev(base_bdev=base_bdev)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.parent.refresh()
+        self.refresh()
+
     def summary(self):
         return "Bdevs: %d" % len(self.children), None
 
 
 class UIMallocBdev(UIBdev):
     def __init__(self, parent):
-        UIBdev.__init__(self, "Malloc", parent)
+        UIBdev.__init__(self, "malloc", parent)
 
     def ui_command_create(self, size, block_size, name=None, uuid=None):
         """
@@ -155,17 +218,35 @@ class UIMallocBdev(UIBdev):
         size = self.ui_eval_param(size, "number", None)
         block_size = self.ui_eval_param(block_size, "number", None)
 
-        ret_name = self.get_root().create_malloc_bdev(total_size=size,
-                                                      block_size=block_size,
-                                                      name=name, uuid=uuid)
-        self.shell.log.info(ret_name)
+        try:
+            ret_name = self.get_root().create_malloc_bdev(num_blocks=size * 1024 * 1024 // block_size,
+                                                          block_size=block_size,
+                                                          name=name, uuid=uuid)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+    def ui_command_delete(self, name):
+        """
+        Deletes malloc bdev from configuration.
+
+        Arguments:
+        name - Is a unique identifier of the malloc bdev to be deleted - UUID number or name alias.
+        """
+        try:
+            self.get_root().delete_malloc_bdev(name=name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
         self.get_root().refresh()
         self.refresh()
 
 
 class UIAIOBdev(UIBdev):
     def __init__(self, parent):
-        UIBdev.__init__(self, "AIO", parent)
+        UIBdev.__init__(self, "aio", parent)
 
     def ui_command_create(self, name, filename, block_size):
         """
@@ -181,17 +262,21 @@ class UIAIOBdev(UIBdev):
 
         block_size = self.ui_eval_param(block_size, "number", None)
 
-        ret_name = self.get_root().create_aio_bdev(name=name,
-                                                   block_size=int(block_size),
-                                                   filename=filename)
-        self.shell.log.info(ret_name)
+        try:
+            ret_name = self.get_root().create_aio_bdev(name=name,
+                                                       block_size=int(block_size),
+                                                       filename=filename)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
         self.get_root().refresh()
         self.refresh()
 
 
 class UILvolBdev(UIBdev):
     def __init__(self, parent):
-        UIBdev.__init__(self, "Logical_Volume", parent)
+        UIBdev.__init__(self, "logical_volume", parent)
 
     def ui_command_create(self, name, size, lvs, thin_provision=None):
         """
@@ -217,17 +302,21 @@ class UILvolBdev(UIBdev):
         size *= (1024 * 1024)
         thin_provision = self.ui_eval_param(thin_provision, "bool", False)
 
-        ret_uuid = self.get_root().create_lvol_bdev(lvol_name=name, size=size,
-                                                    lvs_name=lvs_name, uuid=uuid,
-                                                    thin_provision=thin_provision)
-        self.shell.log.info(ret_uuid)
+        try:
+            ret_uuid = self.get_root().create_lvol_bdev(lvol_name=name, size=size,
+                                                        lvs_name=lvs_name, uuid=uuid,
+                                                        thin_provision=thin_provision)
+            self.shell.log.info(ret_uuid)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
         self.get_root().refresh()
         self.refresh()
 
 
 class UINvmeBdev(UIBdev):
     def __init__(self, parent):
-        UIBdev.__init__(self, "NVMe", parent)
+        UIBdev.__init__(self, "nvme", parent)
 
     def ui_command_create(self, name, trtype, traddr,
                           adrfam=None, trsvcid=None, subnqn=None):
@@ -236,10 +325,241 @@ class UINvmeBdev(UIBdev):
             self.shell.log.error("Using RDMA transport type."
                                  "Please provide arguments for adrfam, trsvcid and subnqn.")
 
-        ret_name = self.get_root().create_nvme_bdev(name=name, trtype=trtype,
-                                                    traddr=traddr, adrfam=adrfam,
-                                                    trsvcid=trsvcid, subnqn=subnqn)
-        self.shell.log.info(ret_name)
+        try:
+            ret_name = self.get_root().create_nvme_bdev(name=name, trtype=trtype,
+                                                        traddr=traddr, adrfam=adrfam,
+                                                        trsvcid=trsvcid, subnqn=subnqn)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UINullBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "null", parent)
+
+    def ui_command_create(self, name, size, block_size, uuid=None):
+        """
+        Construct a Null bdev.
+
+        Arguments:
+        name - Name to use for bdev.
+        size - Size in megabytes.
+        block_size - Integer, block size to use when constructing bdev.
+        uuid - Optional parameter. Custom UUID to use. If empty then random
+               will be generated.
+        """
+
+        size = self.ui_eval_param(size, "number", None)
+        block_size = self.ui_eval_param(block_size, "number", None)
+        num_blocks = size * 1024 * 1024 // block_size
+
+        try:
+            ret_name = self.get_root().create_null_bdev(num_blocks=num_blocks,
+                                                        block_size=block_size,
+                                                        name=name, uuid=uuid)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIErrorBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "error", parent)
+
+    def ui_command_create(self, base_name):
+        """
+        Construct a error injection bdev.
+
+        Arguments:
+        base_name - base bdev name on top of which error bdev will be created.
+        """
+
+        try:
+            self.get_root().create_error_bdev(base_name=base_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UISplitBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "split_disk", parent)
+
+
+class UIPmemBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "pmemblk", parent)
+
+    def ui_command_create_pmem_pool(self, pmem_file, total_size, block_size):
+        total_size = self.ui_eval_param(total_size, "number", None)
+        block_size = self.ui_eval_param(block_size, "number", None)
+        num_blocks = int((total_size * 1024 * 1024) / block_size)
+
+        try:
+            self.get_root().create_pmem_pool(pmem_file=pmem_file,
+                                             num_blocks=num_blocks,
+                                             block_size=block_size)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+    def ui_command_delete_pmem_pool(self, pmem_file):
+        try:
+            self.get_root().delete_pmem_pool(pmem_file=pmem_file)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+    def ui_command_info_pmem_pool(self, pmem_file):
+        try:
+            ret = self.get_root().delete_pmem_pool(pmem_file=pmem_file)
+            self.shell.log.info(ret)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+    def ui_command_create(self, pmem_file, name):
+        try:
+            ret_name = self.get_root().create_pmem_bdev(pmem_file=pmem_file,
+                                                        name=name)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIRbdBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "rbd", parent)
+
+    def ui_command_create(self, pool_name, rbd_name, block_size, name=None):
+        block_size = self.ui_eval_param(block_size, "number", None)
+
+        try:
+            ret_name = self.get_root().create_rbd_bdev(pool_name=pool_name,
+                                                       rbd_name=rbd_name,
+                                                       block_size=block_size,
+                                                       name=name)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIiSCSIBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "iscsi", parent)
+
+    def ui_command_create(self, name, url, initiator_iqn):
+        """
+        Create iSCSI bdev in configuration by connecting to remote
+        iSCSI target.
+
+        Arguments:
+        name - name to be used as an ID for created iSCSI bdev.
+        url - iscsi url pointing to LUN on remote iSCSI target.
+              Example: iscsi://127.0.0.1:3260/iqn.2018-06.org.spdk/0.
+        initiator_iqn - IQN to use for initiating connection with the target.
+        """
+        try:
+            ret_name = self.get_root().create_iscsi_bdev(name=name,
+                                                         url=url,
+                                                         initiator_iqn=initiator_iqn)
+            self.shell.log.info(ret_name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+    def ui_command_delete(self, name):
+        """
+        Deletes iSCSI bdev from configuration.
+
+        Arguments:
+        name - name of the iscsi bdev to be deleted.
+        """
+        try:
+            self.get_root().delete_iscsi_bdev(name=name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIVirtioBlkBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "virtioblk_disk", parent)
+
+    def ui_command_create(self, name, trtype, traddr,
+                          vq_count=None, vq_size=None):
+
+        vq_count = self.ui_eval_param(vq_count, "number", None)
+        vq_size = self.ui_eval_param(vq_size, "number", None)
+
+        try:
+            ret = self.get_root().create_virtio_dev(name=name,
+                                                    trtype=trtype,
+                                                    traddr=traddr,
+                                                    dev_type="blk",
+                                                    vq_count=vq_count,
+                                                    vq_size=vq_size)
+
+            self.shell.log.info(ret)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIVirtioScsiBdev(UIBdev):
+    def __init__(self, parent):
+        UIBdev.__init__(self, "virtioscsi_disk", parent)
+
+    def refresh(self):
+        self._children = set([])
+        for bdev in self.get_root().get_virtio_scsi_devs():
+            UIVirtioScsiBdevObj(bdev, self)
+
+    def ui_command_create(self, name, trtype, traddr,
+                          vq_count=None, vq_size=None):
+
+        vq_count = self.ui_eval_param(vq_count, "number", None)
+        vq_size = self.ui_eval_param(vq_size, "number", None)
+
+        try:
+            ret = self.get_root().create_virtio_dev(name=name,
+                                                    trtype=trtype,
+                                                    traddr=traddr,
+                                                    dev_type="scsi",
+                                                    vq_count=vq_count,
+                                                    vq_size=vq_size)
+
+            self.shell.log.info(ret)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+    def ui_command_delete(self, name):
+        try:
+            self.get_root().remove_virtio_scsi_bdev(name=name)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
         self.get_root().refresh()
         self.refresh()
 
@@ -278,6 +598,25 @@ class UIBdevObj(UINode):
         return info, True
 
 
+class UIVirtioScsiBdevObj(UIBdevObj):
+    def __init__(self, bdev, parent):
+        UIBdevObj.__init__(self, bdev, parent)
+        self.refresh()
+
+    def refresh(self):
+        self._children = set([])
+        for bdev in self.get_root().get_bdevs("virtio_scsi_disk"):
+            if self.bdev.name in bdev.name:
+                UIBdevObj(bdev, self)
+
+    def summary(self):
+        if "socket" in self.bdev.virtio.keys():
+            info = self.bdev.virtio["socket"]
+        if "pci_address" in self.bdev.virtio.keys():
+            info = self.bdev.virtio["pci_address"]
+        return info, True
+
+
 class UILvsObj(UINode):
     def __init__(self, lvs, parent):
         UINode.__init__(self, lvs.name, parent)
@@ -295,3 +634,209 @@ class UILvsObj(UINode):
         free = "=".join(["Free", free])
         info = ", ".join([str(size), str(free)])
         return info, True
+
+
+class UIVhosts(UINode):
+    def __init__(self, parent):
+        UINode.__init__(self, "vhost", parent)
+        self.refresh()
+
+    def refresh(self):
+        self._children = set([])
+        self.get_root().list_vhost_ctrls()
+        UIVhostBlk(self)
+        UIVhostScsi(self)
+
+
+class UIVhost(UINode):
+    def __init__(self, name, parent):
+        UINode.__init__(self, name, parent)
+        self.refresh()
+
+    def ui_command_delete(self, name):
+        """
+        Delete a Vhost controller from configuration.
+
+        Arguments:
+        name - Controller name.
+        """
+        self.get_root().remove_vhost_controller(ctrlr=name)
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIVhostBlk(UIVhost):
+    def __init__(self, parent):
+        UIVhost.__init__(self, "block", parent)
+        self.refresh()
+
+    def refresh(self):
+        self._children = set([])
+        for ctrlr in self.get_root().get_vhost_ctrlrs(self.name):
+            UIVhostBlkCtrlObj(ctrlr, self)
+
+    def ui_command_create(self, name, bdev, cpumask=None, readonly=False):
+        """
+        Construct a Vhost BLK controller.
+
+        Arguments:
+        name - Controller name.
+        bdev - Which bdev to attach to the controller.
+        cpumask - Optional. Integer to specify mask of CPUs to use.
+                  Default: 1.
+        readonly - Whether controller should be read only or not.
+                   Default: False.
+        """
+        try:
+            self.get_root().create_vhost_blk_controller(ctrlr=name,
+                                                        dev_name=bdev,
+                                                        cpumask=cpumask,
+                                                        readonly=bool(readonly))
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIVhostScsi(UIVhost):
+    def __init__(self, parent):
+        UIVhost.__init__(self, "scsi", parent)
+        self.refresh()
+
+    def refresh(self):
+        self._children = set([])
+        for ctrlr in self.get_root().get_vhost_ctrlrs(self.name):
+            UIVhostScsiCtrlObj(ctrlr, self)
+
+    def ui_command_create(self, name, cpumask=None):
+        """
+        Construct a Vhost SCSI controller.
+
+        Arguments:
+        name - Controller name.
+        cpumask - Optional. Integer to specify mask of CPUs to use.
+                  Default: 1.
+        """
+        try:
+            self.get_root().create_vhost_scsi_controller(ctrlr=name,
+                                                         cpumask=cpumask)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.get_root().refresh()
+        self.refresh()
+
+
+class UIVhostCtrl(UINode):
+    # Base class for SCSI and BLK controllers, do not instantiate
+    def __init__(self, ctrlr, parent):
+        self.ctrlr = ctrlr
+        UINode.__init__(self, self.ctrlr.ctrlr, parent)
+        self.refresh()
+
+    def ui_command_show_details(self):
+        self.shell.log.info(json.dumps(vars(self.ctrlr), indent=2))
+
+    def ui_command_set_coalescing(self, delay_base_us, iops_threshold):
+        delay_base_us = self.ui_eval_param(delay_base_us, "number", None)
+        iops_threshold = self.ui_eval_param(iops_threshold, "number", None)
+
+        try:
+            self.get_root().set_vhost_controller_coalescing(ctrlr=self.ctrlr.ctrlr,
+                                                            delay_base_us=delay_base_us,
+                                                            iops_threshold=iops_threshold)
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+
+class UIVhostScsiCtrlObj(UIVhostCtrl):
+    def refresh(self):
+        self._children = set([])
+        for lun in self.ctrlr.backend_specific["scsi"]:
+            UIVhostTargetObj(lun, self)
+
+    def ui_command_remove_target(self, target_num):
+        """
+        Remove target node from SCSI controller.
+
+        Arguments:
+        target_num - Integer identifier of target node to delete.
+        """
+        try:
+            self.get_root().remove_vhost_scsi_target(ctrlr=self.ctrlr.ctrlr,
+                                                     scsi_target_num=int(target_num))
+            for ctrlr in self.get_root().get_vhost_ctrlrs("scsi"):
+                if ctrlr.ctrlr == self.ctrlr.ctrlr:
+                    self.ctrlr = ctrlr
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.refresh()
+        self.get_root().refresh()
+
+    def ui_command_add_lun(self, target_num, bdev_name):
+        """
+        Add LUN to SCSI target node.
+        Currently only one LUN (which is LUN ID 0) per target is supported.
+        Adding LUN to not existing target node will create that node.
+
+        Arguments:
+        target_num - Integer identifier of target node to modify.
+        bdev - Which bdev to add as LUN.
+        """
+        try:
+            self.get_root().add_vhost_scsi_lun(ctrlr=self.ctrlr.ctrlr,
+                                               scsi_target_num=int(target_num),
+                                               bdev_name=bdev_name)
+            for ctrlr in self.get_root().get_vhost_ctrlrs("scsi"):
+                if ctrlr.ctrlr == self.ctrlr.ctrlr:
+                    self.ctrlr = ctrlr
+        except JSONRPCException as e:
+            self.shell.log.error(e.message)
+
+        self.refresh()
+
+    def summary(self):
+        info = self.ctrlr.socket
+        return info, True
+
+
+class UIVhostBlkCtrlObj(UIVhostCtrl):
+    def refresh(self):
+        self._children = set([])
+        UIVhostLunDevObj(self.ctrlr.backend_specific["block"]["bdev"], self)
+
+    def summary(self):
+        ro = None
+        if self.ctrlr.backend_specific["block"]["readonly"]:
+            ro = "Readonly"
+        info = ", ".join(filter(None, [self.ctrlr.socket, ro]))
+        return info, True
+
+
+class UIVhostTargetObj(UINode):
+    def __init__(self, target, parent):
+        self.target = target
+        # Next line: configshell does not allow paths with spaces.
+        UINode.__init__(self, target["target_name"].replace(" ", "_"), parent)
+        self.refresh()
+
+    def refresh(self):
+        self._children = set([])
+        for target in self.target["luns"]:
+            UIVhostLunDevObj(target["bdev_name"], self)
+
+    def ui_command_show_details(self):
+        self.shell.log.info(json.dumps(self.target, indent=2))
+
+    def summary(self):
+        luns = "LUNs: %s" % len(self.target["luns"])
+        id = "TargetID: %s" % self.target["scsi_dev_num"]
+        info = ",".join([luns, id])
+        return info, True
+
+
+class UIVhostLunDevObj(UINode):
+    def __init__(self, name, parent):
+        UINode.__init__(self, name, parent)
diff --git a/scripts/spdkcli/ui_root.py b/scripts/spdkcli/ui_root.py
index e4c349f46..8e61b8d20 100644
--- a/scripts/spdkcli/ui_root.py
+++ b/scripts/spdkcli/ui_root.py
@@ -1,7 +1,6 @@
-from .ui_node import UINode, UIBdevs, UILvolStores
+from .ui_node import UINode, UIBdevs, UILvolStores, UIVhosts
 import rpc.client
 import rpc
-from argparse import Namespace as an
 
 
 class UIRoot(UINode):
@@ -12,12 +11,14 @@ class UIRoot(UINode):
         UINode.__init__(self, "/", shell=shell)
         self.current_bdevs = []
         self.current_lvol_stores = []
+        self.current_vhost_ctrls = []
         self.set_rpc_target(s)
 
     def refresh(self):
         self._children = set([])
         UIBdevs(self)
         UILvolStores(self)
+        UIVhosts(self)
 
     def set_rpc_target(self, s):
         self.client = rpc.client.JSONRPCClient(s)
@@ -26,35 +27,71 @@ class UIRoot(UINode):
         return " ".join(a)
 
     def get_bdevs(self, bdev_type):
-        self.current_bdevs = rpc.bdev.get_bdevs(self.client, an(name=""))
+        self.current_bdevs = rpc.bdev.get_bdevs(self.client)
         # Following replace needs to be done in order for some of the bdev
-        # listings to work.
+        # listings to work: logical volumes, split disk.
         # For example logical volumes: listing in menu is "Logical_Volume"
         # (cannot have space), but the product name in SPDK is "Logical Volume"
         bdev_type = bdev_type.replace("_", " ")
-        for bdev in filter(lambda x: bdev_type in x["product_name"],
+        for bdev in filter(lambda x: bdev_type in x["product_name"].lower(),
                            self.current_bdevs):
             test = Bdev(bdev)
             yield test
 
+    def get_bdevs_iostat(self, **kwargs):
+        return rpc.bdev.get_bdevs_iostat(self.client, **kwargs)
+
+    def split_bdev(self, **kwargs):
+        response = rpc.bdev.construct_split_vbdev(self.client, **kwargs)
+        return self.print_array(response)
+
+    def destruct_split_bdev(self, **kwargs):
+        rpc.bdev.destruct_split_vbdev(self.client, **kwargs)
+
     def delete_bdev(self, name):
-        rpc.bdev.delete_bdev(self.client, an(bdev_name=name))
+        rpc.bdev.delete_bdev(self.client, bdev_name=name)
 
     def create_malloc_bdev(self, **kwargs):
-        response = rpc.bdev.construct_malloc_bdev(self.client, an(**kwargs))
-        return self.print_array(response)
+        response = rpc.bdev.construct_malloc_bdev(self.client, **kwargs)
+        return response
+
+    def delete_malloc_bdev(self, **kwargs):
+        rpc.bdev.delete_malloc_bdev(self.client, **kwargs)
+
+    def create_iscsi_bdev(self, **kwargs):
+        response = rpc.bdev.construct_iscsi_bdev(self.client, **kwargs)
+        return response
+
+    def delete_iscsi_bdev(self, **kwargs):
+        rpc.bdev.delete_iscsi_bdev(self.client, **kwargs)
 
     def create_aio_bdev(self, **kwargs):
-        response = rpc.bdev.construct_aio_bdev(self.client, an(**kwargs))
-        return self.print_array(response)
+        response = rpc.bdev.construct_aio_bdev(self.client, **kwargs)
+        return response
+
+    def delete_aio_bdev(self, **kwargs):
+        rpc.bdev.delete_aio_bdev(self.client, **kwargs)
 
     def create_lvol_bdev(self, **kwargs):
         response = rpc.lvol.construct_lvol_bdev(self.client, **kwargs)
-        return self.print_array(response)
+        return response
 
     def create_nvme_bdev(self, **kwargs):
-        response = rpc.bdev.construct_nvme_bdev(self.client, an(**kwargs))
-        return self.print_array(response)
+        response = rpc.bdev.construct_nvme_bdev(self.client, **kwargs)
+        return response
+
+    def create_null_bdev(self, **kwargs):
+        response = rpc.bdev.construct_null_bdev(self.client, **kwargs)
+        return response
+
+    def delete_null_bdev(self, **kwargs):
+        rpc.bdev.delete_null_bdev(self.client, **kwargs)
+
+    def create_error_bdev(self, **kwargs):
+        response = rpc.bdev.construct_error_bdev(self.client, **kwargs)
+
+    def delete_error_bdev(self, **kwargs):
+        rpc.bdev.delete_error_bdev(self.client, **kwargs)
 
     def get_lvol_stores(self):
         self.current_lvol_stores = rpc.lvol.get_lvol_stores(self.client)
@@ -64,13 +101,72 @@ class UIRoot(UINode):
     def create_lvol_store(self, **kwargs):
         response = rpc.lvol.construct_lvol_store(self.client, **kwargs)
         new_lvs = rpc.lvol.get_lvol_stores(self.client,
-                                           self.print_array(response),
+                                           response,
                                            lvs_name=None)
         return new_lvs[0]["name"]
 
     def delete_lvol_store(self, **kwargs):
         rpc.lvol.destroy_lvol_store(self.client, **kwargs)
 
+    def create_pmem_pool(self, **kwargs):
+        response = rpc.pmem.create_pmem_pool(self.client, **kwargs)
+        return response
+
+    def delete_pmem_pool(self, **kwargs):
+        rpc.pmem.delete_pmem_pool(self.client, **kwargs)
+
+    def create_pmem_bdev(self, **kwargs):
+        response = rpc.bdev.construct_pmem_bdev(self.client, **kwargs)
+        return response
+
+    def create_rbd_bdev(self, **kwargs):
+        response = rpc.bdev.construct_rbd_bdev(self.client, **kwargs)
+        return response
+
+    def create_virtio_dev(self, **kwargs):
+        response = rpc.vhost.construct_virtio_dev(self.client, **kwargs)
+        return self.print_array(response)
+
+    def remove_virtio_scsi_bdev(self, **kwargs):
+        response = rpc.vhost.remove_virtio_scsi_bdev(self.client, **kwargs)
+        return response
+
+    def get_virtio_scsi_devs(self):
+        for bdev in rpc.vhost.get_virtio_scsi_devs(self.client):
+            test = Bdev(bdev)
+            yield test
+
+    def list_vhost_ctrls(self):
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def get_vhost_ctrlrs(self, ctrlr_type):
+        for ctrlr in filter(lambda x: ctrlr_type in x["backend_specific"].keys(),
+                            self.current_vhost_ctrls):
+            yield VhostCtrlr(ctrlr)
+
+    def remove_vhost_controller(self, **kwargs):
+        rpc.vhost.remove_vhost_controller(self.client, **kwargs)
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def create_vhost_scsi_controller(self, **kwargs):
+        rpc.vhost.construct_vhost_scsi_controller(self.client, **kwargs)
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def create_vhost_blk_controller(self, **kwargs):
+        rpc.vhost.construct_vhost_blk_controller(self.client, **kwargs)
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def remove_vhost_scsi_target(self, **kwargs):
+        rpc.vhost.remove_vhost_scsi_target(self.client, **kwargs)
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def add_vhost_scsi_lun(self, **kwargs):
+        rpc.vhost.add_vhost_scsi_lun(self.client, **kwargs)
+        self.current_vhost_ctrls = rpc.vhost.get_vhost_controllers(self.client)
+
+    def set_vhost_controller_coalescing(self, **kwargs):
+        rpc.vhost.set_vhost_controller_coalescing(self.client, **kwargs)
+
 
 class Bdev(object):
     def __init__(self, bdev_info):
@@ -94,3 +190,15 @@ class LvolStore(object):
         """
         for i in lvs_info.keys():
             setattr(self, i, lvs_info[i])
+
+
+class VhostCtrlr(object):
+    def __init__(self, ctrlr_info):
+        """
+        All class attributes are set based on what information is received
+        from get_vhost_controllers RPC call.
+        # TODO: Document in docstring parameters which describe bdevs.
+        # TODO: Possible improvement: JSON schema might be used here in future
+        """
+        for i in ctrlr_info.keys():
+            setattr(self, i, ctrlr_info[i])
diff --git a/scripts/vagrant/README.md b/scripts/vagrant/README.md
new file mode 100644
index 000000000..ddef9ba80
--- /dev/null
+++ b/scripts/vagrant/README.md
@@ -0,0 +1,214 @@
+# SPDK Vagrant and VirtualBox
+
+The following guide explains how to use the scripts in the `spdk/scripts/vagrant`. Both Mac and Windows platforms are supported.
+
+1. Install and configure [Git](https://git-scm.com/) on your platform.
+2. Install [VirtualBox 5.1](https://www.virtualbox.org/wiki/Downloads) or newer
+3. Install [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads)
+4. Install and configure [Vagrant 1.9.4](https://www.vagrantup.com) or newer
+
+## Mac OSX Setup (High Sierra)
+
+OSX platforms already have Git installed, however, installing the [Apple xCode](https://developer.apple.com/xcode/) developer kit and [xCode Command Line tools](https://developer.apple.com/xcode/features/) will provide UNIX command line tools such as make, awk, sed, ssh, tar, and zip. xCode can be installed through the App Store on you Mac.
+
+Quick start instructions for OSX:
+
+1. Install Homebrew
+2. Install Virtual Box Cask
+3. Install Virtual Box Extentions
+4. Install Vagrant Cask
+
+```
+   /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
+   brew doctor
+   brew update
+   brew cask install virtualbox
+   brew cask install virtualbox-extension-pack
+   brew cask install vagrant
+```
+
+## Windows 10 Setup
+
+1. Windows platforms should install [Git](https://git-scm.com/download/win) from git-scm.com.
+   - This provides everything needed to use git on Windows, including a `git-bash` command line environment.
+2. Install [VirtualBox 5.1](https://www.virtualbox.org/wiki/Downloads) or newer
+3. Install [VirtualBox Extension Pack](https://www.virtualbox.org/wiki/Downloads)
+4. Install and configure [Vagrant 1.9.4](https://www.vagrantup.com) or newer
+
+- Note: VirtualBox requires virtualization to be enabled in the BIOS.
+- Note: You should disable Hyper-V in Windows RS 3 laptop. Search `windows features` uncheck Hyper-V, restart laptop
+
+## Configure Vagrant
+
+If you are behind a corporate firewall, configure the following proxy settings.
+
+1. Set the http_proxy and https_proxy
+2. Install the proxyconf plugin
+
+```
+  $ export http_proxy=....
+  $ export https_proxy=....
+  $ vagrant plugin install vagrant-proxyconf
+```
+
+## Download SPDK from GitHub
+
+Use git to clone a new spdk repository. GerritHub can also be used. See the instructions at [spdk.io](http://www.spdk.io/development/#gerrithub) to setup your GerritHub account. Note that this spdk repository will be rsync'd into your VM, so you can use this repository to continue development within the VM.
+
+## Create a Virtual Box
+
+Use the `spdk/scripts/vagrant/create_vbox.sh` script to create a VM of your choice.  Supported VM platforms are:
+
+- centos7
+- ubuntu16
+- ubuntu18
+- fedora26
+- fedora27
+- freebsd11
+
+```
+$ spdk/scripts/vagrant/create_vbox.sh -h
+ Usage: create_vbox.sh [-n <num-cpus>] [-s <ram-size>] [-x <http-proxy>] [-hvr] <distro>
+
+  distro = <centos7 | ubuntu16 | ubuntu18 | fedora26 | fedora27 | freebsd11>
+
+  -s <ram-size> in kb       default: 4096
+  -n <num-cpus> 1 to 4      default: 4
+  -x <http-proxy>           default: ""
+  -r dry-run
+  -h help
+  -v verbose
+
+ Examples:
+
+  spdk/scripts/vagrant/create_vbox.sh -x http://user:password@host:port fedora27
+  spdk/scripts/vagrant/create_vbox.sh -s 2048 -n 2 ubuntu16
+  spdk/scripts/vagrant/create_vbox.sh -rv freebsd
+  spdk/scripts/vagrant/create_vbox.sh fedora26
+```
+
+It is recommended that you call the `create_vbox.sh` script from outside of the spdk repository. Call this script from a parent directory. This will allow the creation of multiple VMs in separate <distro> directories, all using the same spdk repository.  For example:
+
+```
+   $ spdk/scripts/vagrant/create_vbox.sh -s 2048 -n 2 fedora26
+```
+
+This script will:
+
+1. create a subdirectory named <distro> in your $PWD
+2. copy the needed files from `spdk/scripts/vagrant/` into the <distro> directory
+3. create a working virtual box in the <distro> directory
+4. rsycn the `~/.gitconfig` file to `/home/vagrant/` in the newly provisioned virtual box
+5. rsync a copy of the source `spdk` repository to `/home/vagrant/spdk_repo/spdk`
+6. rsync a copy of the `~/vagrant_tools` directory to `/home/vagrant/tools` (optional)
+
+This arrangement allows the provisioning of multiple, different VMs within that same directory hiearchy using the same spdk repository. Following the creation of the vm you'll need to ssh into your virtual box and finish the VM initializaton.
+
+```
+  $ cd <distro>
+  $ vagrant ssh
+```
+
+## Finish VM Initializtion
+
+A copy of the `spdk` repository you cloned will exist in the `spdk_repo` directory of the `/home/vagrant` user account. After using `vagrant ssh` to enter your VM you must complete the initialization of your VM by running the `scripts/vagrant/update.sh` script. For example:
+
+```
+   $ script -c 'sudo spdk_repo/spdk/scripts/vagrant/update.sh' update.log
+```
+
+The `update.sh` script completes initialization of the VM by automating the following steps.
+
+1. Runs yum/apt-get update (Linux)
+2. Runs the scripts/pdkdep.sh script
+3. Installs the FreeBSD source in /usr/sys (FreeBSD only)
+
+This only needs to be done once.
+
+## Post VM Initializtion
+
+Following VM initializtion you must:
+
+1. Verify you have an emulated NVMe device
+2. Compile your spdk source tree
+3. Run the hello_world example to validate the environment is set up correctly
+
+### Verify you have an emulated NVMe device
+
+```
+  $ lspci | grep "Non-Volatile"
+  00:0e.0 Non-Volatile memory controller: InnoTek Systemberatung GmbH Device 4e56
+```
+
+### Compile SPDK
+
+```
+  $ cd spdk_repo/spdk
+  $ git submodule update --init
+  $ ./configure --enable-debug
+  $ make
+```
+
+### Run the hello_world example script
+
+```
+  $ sudo scripts/setup.sh
+  $ sudo examples/bdev/hello_world/hello_bdev
+```
+
+## Additional Setup for Fedora 26
+
+As of this writing the `vm_setup.sh` script only supports Fedora 26.  To complete the full installation of all packages needed to run autotest.sh on your fedora26 VM, run the `spdk/test/common/config/vm_setup.sh` script.  Note: this will take some time. It is recommended that the output of vm_setup.sh is captured in a script log.
+
+```
+   $ script -c 'spdk_repo/spdk/test/common/config/vm_setup.sh -i -t librxe,iscsi,rocksdb,fio,flamegraph,libiscsi' vm_setup.log
+```
+
+### Running autorun.sh with vagrant
+
+After running vm_setup.sh the `run-autorun.sh` can be used to run `spdk/autorun.sh` on a Fedora 26 vagrant machine. Note that the `spdk/scripts/vagrant/autorun-spdk.conf` should be copied to `~/autorun-spdk.conf` before starting your tests.
+
+```
+   $ cp spdk/scripts/vagrant/autorun-spdk.conf ~/
+   $ spdk/scripts/vagrant/run-autorun.sh -h
+     Usage: scripts/vagrant/run-autorun.sh -d <path_to_spdk_tree> [-h] | [-q] | [-n]
+       -d : Specify a path to an SPDK source tree
+       -q : No output to screen
+       -n : Noop - dry-run
+       -h : This help
+
+     Examples:
+         run-spdk-autotest.sh -d . -q
+         run-spdk-autotest.sh -d /home/vagrant/spdk_repo/spdk
+```
+
+## FreeBSD Appendix
+
+---
+**NOTE:** As of this writing the FreeBSD Virtualbox instance does not correctly support the vagrant-proxyconf feature.
+---
+
+The following steps are done by the `update.sh` script. It is recommened that you capture the output of `update.sh` with a typescript. E.g.:
+
+```
+  $ script update.log sudo spdk_repo/spdk/scripts/vagrant/update.sh
+```
+
+1. Updates the pkg catalog
+1. Installs the needed FreeBSD packages on the system by calling pkgdep.sh
+2. Installs the FreeBSD source in /usr/src
+
+```
+   $ sudo pkg upgrade -f
+   $ sudo spdk_repo/spdk/scripts/pkgdep.sh
+   $ sudo git clone --depth 10 -b releases/11.1.0 https://github.com/freebsd/freebsd.git /usr/src
+```
+
+To build spdk on FreeBSD use `gmake MAKE=gmake`.  E.g.:
+
+```
+    $ cd spdk_repo/spdk
+    $ git submodule update --init
+    $ ./configure --enable-debug
+    $ gmake MAKE=gmake
+```
diff --git a/scripts/vagrant/Vagrantfile b/scripts/vagrant/Vagrantfile
index 2e243e046..3be024c3e 100644
--- a/scripts/vagrant/Vagrantfile
+++ b/scripts/vagrant/Vagrantfile
@@ -4,23 +4,38 @@
 Vagrant.configure(2) do |config|
 
   # Pick the right distro and bootstrap, default is ubuntu1604
-  distro = ( ENV['SPDK_VAGRANT_DISTRO'] || "ubuntu1604")
-  if distro == 'centos7'
+  distro = ( ENV['SPDK_VAGRANT_DISTRO'] || "fedora26")
+  case distro
+  when "centos7"
     config.vm.box = "puppetlabs/centos-7.2-64-nocm"
     config.ssh.insert_key = false
     # Puppetlabs does not provide libvirt Box so we will use official one
     config.vm.provider :libvirt do |libvirt|
-       config.vm.box = "centos/7"
+      config.vm.box = "centos/7"
     end if Vagrant.has_plugin?('vagrant-libvirt')
-  else
+  when "ubuntu16"
+    # See: https://app.vagrantup.com/puppetlabs/boxes/ubuntu-16.04-64-nocm
     config.vm.box = "puppetlabs/ubuntu-16.04-64-nocm"
+    config.vm.box_version = "1.0.0"
+  when "ubuntu18"
+    # See: https://app.vagrantup.com/bento/boxes/ubuntu-18.04
+    config.vm.box = "bento/ubuntu-18.04"
+    config.vm.box_version = "201803.24.0"
+  when "fedora26"
+    #See: https://app.vagrantup.com/generic/boxes/fedora2
+    config.vm.box = "generic/fedora26"
+  when "fedora27"
+    #See: https://app.vagrantup.com/generic/boxes/fedora27
+    config.vm.box = "generic/fedora27"
+  when "freebsd11"
+    #See: https://app.vagrantup.com/generic/boxes/freebsd11
+    config.vm.box = "generic/freebsd11"
+  else
+    "Invalid argument #{distro}"
+    abort("Invalid argument!")
   end
   config.vm.box_check_update = false
 
-  config.vm.provision :shell, :path => File.join(File.dirname(__FILE__),"update.sh")
-  config.vm.provision :shell, :path => File.join(File.dirname(__FILE__),"build.sh")
-  config.vm.provision :shell, inline: "/spdk/scripts/setup.sh", run: "always"
-
   # Copy in the .gitconfig if it exists
   if File.file?(File.expand_path("~/.gitconfig"))
     config.vm.provision  "file", source: "~/.gitconfig", destination: ".gitconfig"
@@ -46,30 +61,38 @@ Vagrant.configure(2) do |config|
 
   vmcpu=(ENV['SPDK_VAGRANT_VMCPU'] || 2)
   vmram=(ENV['SPDK_VAGRANT_VMRAM'] || 4096)
+  spdk_dir=(ENV['SPDK_DIR'] || "none")
 
   config.ssh.forward_agent = true
   config.ssh.forward_x11 = true
 
   config.vm.provider "virtualbox" do |vb|
-      vb.customize ["modifyvm", :id, "--ioapic", "on"]
-      vb.memory = "#{vmram}"
-      vb.cpus = "#{vmcpu}"
-
-      # rsync the vpp directory if provision hasn't happened yet
-      unless File.exist? (".vagrant/machines/default/virtualbox/action_provision")
-        config.vm.synced_folder "../../", "/spdk", type: "rsync", rsync__auto: false
+    vb.customize ["modifyvm", :id, "--ioapic", "on"]
+    vb.memory = "#{vmram}"
+    vb.cpus = "#{vmcpu}"
+
+    # rsync the spdk directory if provision hasn't happened yet
+    unless File.exist? (".vagrant/machines/default/virtualbox/action_provision")
+      if spdk_dir != "none"
+        config.vm.synced_folder "#{spdk_dir}", "/home/vagrant/spdk_repo/spdk", type: "rsync", rsync__auto: false
       end
 
-      nvme_disk = 'nvme.vdi'
-      unless File.exist? (nvme_disk)
-        vb.customize ["createhd", "--filename", nvme_disk, "--variant", "Fixed", "--size", "1024"]
-        vb.customize ["storagectl", :id, "--name", "nvme", "--add", "pcie", "--controller", "NVMe", "--portcount", "1", "--bootable", "off"]
-        vb.customize ["storageattach", :id, "--storagectl", "nvme", "--type", "hdd", "--medium", nvme_disk, "--port", "0"]
+      # Copy in the user's tools if they exists
+      if File.directory?(File.expand_path("~/vagrant_tools"))
+        config.vm.synced_folder "~/vagrant_tools", "/home/vagrant/tools", type: "rsync", rsync__auto: false
       end
-
-      #support for the SSE4.x instruction is required in some versions of VB.
-      vb.customize ["setextradata", :id, "VBoxInternal/CPUM/SSE4.1", "1"]
-      vb.customize ["setextradata", :id, "VBoxInternal/CPUM/SSE4.2", "1"]
+    end
+
+    nvme_disk = 'nvme.vdi'
+    unless File.exist? (nvme_disk)
+      vb.customize ["createhd", "--filename", nvme_disk, "--variant", "Fixed", "--size", "1024"]
+      vb.customize ["storagectl", :id, "--name", "nvme", "--add", "pcie", "--controller", "NVMe", "--portcount", "1", "--bootable", "off"]
+      vb.customize ["storageattach", :id, "--storagectl", "nvme", "--type", "hdd", "--medium", nvme_disk, "--port", "0"]
+    end
+
+    #support for the SSE4.x instruction is required in some versions of VB.
+    vb.customize ["setextradata", :id, "VBoxInternal/CPUM/SSE4.1", "1"]
+    vb.customize ["setextradata", :id, "VBoxInternal/CPUM/SSE4.2", "1"]
   end
 
   # This setup was Tested on Fedora 27
@@ -77,30 +100,31 @@ Vagrant.configure(2) do |config|
   # There are few limitation for SElinux - The file added outside libvirt must have proper SE ACL policy or setenforce 0
   config.vm.provider "libvirt" do |libvirt, override|
 
-      # we put nvme_disk inside default pool to eliminate libvirt/SELinux Permissions Problems
-      # and to be able to run vagrant from user $HOME directory
-      nvme_disk = '/var/lib/libvirt/images/nvme_disk.img'
-      unless File.exist? (nvme_disk)
-        override.puts "If run with libvirt provider please execute create_nvme_img.sh"
+    # we put nvme_disk inside default pool to eliminate libvirt/SELinux Permissions Problems
+    # and to be able to run vagrant from user $HOME directory
+    nvme_disk = '/var/lib/libvirt/images/nvme_disk.img'
+    unless File.exist? (nvme_disk)
+      override.puts "If run with libvirt provider please execute create_nvme_img.sh"
+    end
+
+    libvirt.qemuargs :value => "-drive"
+    libvirt.qemuargs :value => "file=#{nvme_disk},if=none,id=D22"
+    libvirt.qemuargs :value => "-device"
+    libvirt.qemuargs :value => "nvme,drive=D22,serial=1234"
+    libvirt.driver = "kvm"
+    libvirt.graphics_type = "spice"
+    libvirt.memory = "#{vmram}"
+    libvirt.cpus = "#{vmcpu}"
+    libvirt.video_type = "qxl"
+
+    # Optional field if we want use other storage pools than default
+    # libvirt.storage_pool_name = "vm"
+
+    # rsync the spdk directory if provision hasn't happened yet
+    unless File.exist? (".vagrant/machines/default/virtualbox/action_provision")
+      if spdk_dir != "none"
+        config.vm.synced_folder "#{spdk_dir}", "/home/vagrant/spdk_repo/spdk", type: "rsync"
       end
-
-      libvirt.qemuargs :value => "-drive"
-      libvirt.qemuargs :value => "file=#{nvme_disk},if=none,id=D22"
-      libvirt.qemuargs :value => "-device"
-      libvirt.qemuargs :value => "nvme,drive=D22,serial=1234"
-      libvirt.driver = "kvm"
-      libvirt.graphics_type = "spice"
-      libvirt.memory = "#{vmram}"
-      libvirt.cpus = "#{vmcpu}"
-      libvirt.video_type = "qxl"
-      # Optional field if we want use other storage pools than default
-      # libvirt.storage_pool_name = "vm"
-
-      # rsync the vpp directory if provision hasn't happened yet
-      unless File.exist? (".vagrant/machines/default/libvirt/action_provision")
-        config.vm.synced_folder "../../", "/spdk", type: "rsync"
-      end
-
-   end
-
+    end
+  end
 end
diff --git a/scripts/vagrant/autorun-spdk.conf b/scripts/vagrant/autorun-spdk.conf
new file mode 100644
index 000000000..4a815a518
--- /dev/null
+++ b/scripts/vagrant/autorun-spdk.conf
@@ -0,0 +1,28 @@
+# assign a value of 1 to all of the pertinent tests
+SPDK_BUILD_DOC=1
+SPDK_RUN_CHECK_FORMAT=1
+SPDK_RUN_SCANBUILD=1
+SPDK_RUN_VALGRIND=1
+SPDK_TEST_UNITTEST=1
+SPDK_TEST_ISCSI=0
+SPDK_TEST_ISCSI_INITIATOR=0
+SPDK_TEST_NVME=0
+SPDK_TEST_NVME_CLI=0
+SPDK_TEST_NVMF=1
+SPDK_TEST_RBD=0
+# requires some extra configuration. see TEST_ENV_SETUP_README
+SPDK_TEST_VHOST=0
+SPDK_TEST_VHOST_INIT=0
+SPDK_TEST_BLOCKDEV=1
+# doesn't work on vm
+SPDK_TEST_IOAT=0
+SPDK_TEST_EVENT=1
+SPDK_TEST_BLOBFS=0
+SPDK_TEST_PMDK=0
+SPDK_TEST_LVOL=0
+SPDK_RUN_ASAN=1
+SPDK_RUN_UBSAN=1
+# Reduce the size of the hugepages
+HUGEMEM=1024
+# Set up the DEPENDENCY_DIR
+DEPENDENCY_DIR=/home/vagrant
diff --git a/scripts/vagrant/build.sh b/scripts/vagrant/build.sh
deleted file mode 100755
index a0a133f24..000000000
--- a/scripts/vagrant/build.sh
+++ /dev/null
@@ -1,39 +0,0 @@
-#!/bin/bash
-
-SPDK_DIR=/spdk
-
-SUDOCMD="sudo -H -u vagrant"
-echo 0:$0
-echo 1:$1
-echo 2:$2
-echo SUDOCMD: $SUDOCMD
-
-# Figure out what system we are running on
-if [ -f /etc/lsb-release ];then
-    . /etc/lsb-release
-elif [ -f /etc/redhat-release ];then
-    sudo yum install -y redhat-lsb
-    DISTRIB_ID=`lsb_release -si`
-    DISTRIB_RELEASE=`lsb_release -sr`
-    DISTRIB_CODENAME=`lsb_release -sc`
-    DISTRIB_DESCRIPTION=`lsb_release -sd`
-fi
-KERNEL_OS=`uname -o`
-KERNEL_MACHINE=`uname -m`
-KERNEL_RELEASE=`uname -r`
-KERNEL_VERSION=`uname -v`
-
-echo KERNEL_OS: $KERNEL_OS
-echo KERNEL_MACHINE: $KERNEL_MACHINE
-echo KERNEL_RELEASE: $KERNEL_RELEASE
-echo KERNEL_VERSION: $KERNEL_VERSION
-echo DISTRIB_ID: $DISTRIB_ID
-echo DISTRIB_RELEASE: $DISTRIB_RELEASE
-echo DISTRIB_CODENAME: $DISTRIB_CODENAME
-echo DISTRIB_DESCRIPTION: $DISTRIB_DESCRIPTION
-
-cd $SPDK_DIR
-./scripts/pkgdep.sh
-$SUDOCMD ./configure --enable-debug
-$SUDOCMD make clean
-$SUDOCMD make -j2
diff --git a/scripts/vagrant/create_nvme_img.sh b/scripts/vagrant/create_nvme_img.sh
index 8fb8ff84a..07ed3555c 100755
--- a/scripts/vagrant/create_nvme_img.sh
+++ b/scripts/vagrant/create_nvme_img.sh
@@ -1,12 +1,16 @@
 #!/usr/bin/env bash
-WHICH_OS=`lsb_release -i | awk '{print $3}'`
-nvme_disk='/var/lib/libvirt/images/nvme_disk.img'
+SYSTEM=`uname -s`
 
-qemu-img create -f raw $nvme_disk 1024M
-#Change SE Policy on Fedora
-if [ $WHICH_OS == "Fedora" ]; then
-  sudo chcon -t svirt_image_t $nvme_disk
-fi
+if [ ! "${SYSTEM}" = "FreeBSD" ]; then
+	WHICH_OS=`lsb_release -i | awk '{print $3}'`
+	nvme_disk='/var/lib/libvirt/images/nvme_disk.img'
+
+	qemu-img create -f raw $nvme_disk 1024M
+	#Change SE Policy on Fedora
+	if [ $WHICH_OS == "Fedora" ]; then
+		sudo chcon -t svirt_image_t $nvme_disk
+	fi
 
-chmod 777 $nvme_disk
-chown qemu:qemu $nvme_disk
+	chmod 777 $nvme_disk
+	chown qemu:qemu $nvme_disk
+fi
diff --git a/scripts/vagrant/create_vbox.sh b/scripts/vagrant/create_vbox.sh
new file mode 100755
index 000000000..88f5647db
--- /dev/null
+++ b/scripts/vagrant/create_vbox.sh
@@ -0,0 +1,165 @@
+#!/bin/sh -e
+
+# create_vbox.sh
+#
+# Creates a virtual box with vagrant in the $PWD.
+#
+# This script creates a subdirectory called $PWD/<distro> and copies the Vagrantfile
+# into that directory before running 'vagrant up'
+
+VAGRANT_TARGET="$PWD"
+
+DIR="$( cd "$( dirname $0 )" && pwd )"
+SPDK_DIR="$( cd "${DIR}/../../" && pwd )"
+
+# The command line help
+display_help() {
+	echo
+	echo " Usage: ${0##*/} [-n <num-cpus>] [-s <ram-size>] [-x <http-proxy>] [-hvr] <distro>"
+	echo
+	echo "  distro = <centos7 | ubuntu16 | ubuntu18 | fedora26 | fedora27 | freebsd11> "
+	echo
+	echo "  -s <ram-size> in kb       default: ${SPDK_VAGRANT_VMRAM}"
+	echo "  -n <num-cpus> 1 to 4      default: ${SPDK_VAGRANT_VMCPU}"
+	echo "  -x <http-proxy>           default: \"${SPDK_VAGRANT_HTTP_PROXY}\""
+	echo "  -r dry-run"
+	echo "  -h help"
+	echo "  -v verbose"
+        echo
+	echo " Examples:"
+	echo
+	echo "  $0 -x http://user:password@host:port fedora27"
+	echo "  $0 -s 2048 -n 2 ubuntu16"
+	echo "  $0 -rv freebsd"
+	echo "  $0 fedora26 "
+	echo
+}
+
+# Set up vagrant proxy. Assumes git-bash on Windows
+# https://stackoverflow.com/questions/19872591/how-to-use-vagrant-in-a-proxy-environment
+SPDK_VAGRANT_HTTP_PROXY=""
+
+VERBOSE=0
+HELP=0
+DRY_RUN=0
+SPDK_VAGRANT_DISTRO="distro"
+SPDK_VAGRANT_VMCPU=4
+SPDK_VAGRANT_VMRAM=4096
+OPTIND=1
+
+while getopts ":n:s:x:vrh" opt; do
+	case "${opt}" in
+		x)
+			http_proxy=$OPTARG
+			https_proxy=$http_proxy
+			SPDK_VAGRANT_HTTP_PROXY="${http_proxy}"
+		;;
+		n)
+			SPDK_VAGRANT_VMCPU=$OPTARG
+		;;
+		s)
+			SPDK_VAGRANT_VMRAM=$OPTARG
+		;;
+		v)
+			VERBOSE=1
+		;;
+		r)
+			DRY_RUN=1
+		;;
+		h)
+			display_help >&2
+			exit 0
+		;;
+		*)
+			echo "  Invalid argument: -$OPTARG" >&2
+			echo "  Try: \"$0 -h\"" >&2
+			exit 1
+		;;
+	esac
+done
+
+shift "$((OPTIND-1))"   # Discard the options and sentinel --
+
+SPDK_VAGRANT_DISTRO="$@"
+
+case "$SPDK_VAGRANT_DISTRO" in
+	centos7)
+		export SPDK_VAGRANT_DISTRO
+	;;
+	ubuntu16)
+		export SPDK_VAGRANT_DISTRO
+	;;
+	ubuntu18)
+		export SPDK_VAGRANT_DISTRO
+	;;
+	fedora26)
+		export SPDK_VAGRANT_DISTRO
+	;;
+	fedora27)
+		export SPDK_VAGRANT_DISTRO
+	;;
+        freebsd11)
+                export SPDK_VAGRANT_DISTRO
+        ;;
+	*)
+		echo "  Invalid argument \"${SPDK_VAGRANT_DISTRO}\""
+		echo "  Try: \"$0 -h\"" >&2
+		exit 1
+	;;
+esac
+
+if [ ${VERBOSE} = 1 ]; then
+	echo
+	echo DIR=${DIR}
+	echo SPDK_DIR=${SPDK_DIR}
+	echo VAGRANT_TARGET=${VAGRANT_TARGET}
+	echo HELP=$HELP
+	echo DRY_RUN=$DRY_RUN
+	echo SPDK_VAGRANT_DISTRO=$SPDK_VAGRANT_DISTRO
+	echo SPDK_VAGRANT_VMCPU=$SPDK_VAGRANT_VMCPU
+	echo SPDK_VAGRANT_VMRAM=$SPDK_VAGRANT_VMRAM
+	echo SPDK_VAGRANT_HTTP_PROXY=$SPDK_VAGRANT_HTTP_PROXY
+	echo
+fi
+
+export SPDK_VAGRANT_HTTP_PROXY
+export SPDK_VAGRANT_VMCPU
+export SPDK_VAGRANT_VMRAM
+export SPDK_DIR
+
+if [ ${DRY_RUN} = 1 ]; then
+	echo "Environemnt Variables"
+	printenv SPDK_VAGRANT_DISTRO
+	printenv SPDK_VAGRANT_VMRAM
+	printenv SPDK_VAGRANT_VMCPU
+	printenv SPDK_VAGRANT_HTTP_PROXY
+	printenv SPDK_DIR
+fi
+
+if [ -d "${VAGRANT_TARGET}/${SPDK_VAGRANT_DISTRO}" ]; then
+	echo "Error: ${VAGRANT_TARGET}/${SPDK_VAGRANT_DISTRO} already exists!"
+	exit 1
+fi
+
+if [ ${DRY_RUN} != 1 ]; then
+	mkdir -vp "${VAGRANT_TARGET}/${SPDK_VAGRANT_DISTRO}"
+	cp ${DIR}/Vagrantfile ${VAGRANT_TARGET}/${SPDK_VAGRANT_DISTRO}
+	pushd "${VAGRANT_TARGET}/${SPDK_VAGRANT_DISTRO}"
+	if [ ! -z "${http_proxy}" ]; then
+		export http_proxy
+		export https_proxy
+		if vagrant plugin list | grep -q vagrant-proxyconf; then
+			echo "vagrant-proxyconf already installed... skipping"
+		else
+			vagrant plugin install vagrant-proxyconf
+		fi
+	fi
+	vagrant up
+	echo ""
+	echo "  SUCCESS!"
+	echo ""
+	echo "  cd to ${SPDK_VAGRANT_DISTRO} and type \"vagrant ssh\" to use."
+	echo "  Use vagrant \"suspend\" and vagrant \"resume\" to stop and start."
+	echo "  Use vagrant \"destroy\" followed by \"rm -rf ${SPDK_VAGRANT_DISTRO}\" to destroy all trace of vm."
+	echo ""
+fi
diff --git a/scripts/vagrant/env.sh b/scripts/vagrant/env.sh
deleted file mode 100644
index bcdcf0a9b..000000000
--- a/scripts/vagrant/env.sh
+++ /dev/null
@@ -1,7 +0,0 @@
-#!/usr/bin/env bash
-
-# centos7 also supported
-export SPDK_VAGRANT_DISTRO="ubuntu1604"
-
-export SPDK_VAGRANT_VMCPU=4
-export SPDK_VAGRANT_VMRAM=4096
diff --git a/scripts/vagrant/run-autorun.sh b/scripts/vagrant/run-autorun.sh
new file mode 100755
index 000000000..d01096c70
--- /dev/null
+++ b/scripts/vagrant/run-autorun.sh
@@ -0,0 +1,235 @@
+#!/bin/bash
+
+#
+#  BSD LICENSE
+#
+#  Copyright (c) 2018 by NetApp, Inc.
+#  All Rights Reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+if [ -z "${MAKE}" ]; then
+	export MAKE=make
+fi
+
+if [ -z "${GIT}" ]; then
+	export GIT=git
+fi
+
+if [ -z "${READLINK}" ]; then
+	export READLINK=readlink
+fi
+
+AUTOTEST_DRIVER_PATH=$($READLINK -f ${BASH_SOURCE%/*})
+SPDK_AUTOTEST_LOCAL_PATH=$PWD
+TIMESTAMP=`date +"%Y%m%d%H%M%S"`
+BUILD_NAME="build-${TIMESTAMP}"
+
+# The command line help
+display_help() {
+	echo
+	echo "Usage: $0 -d <path_to_spdk_tree> [-h] | [-q] | [-n]"
+	echo "  -d : Specify a path to an SPDK source tree"
+	echo "  -q : No output to screen"
+	echo "  -n : Noop - dry-run"
+	echo "  -h : This help"
+	echo
+	echo "Examples:"
+	echo "    run-spdk-autotest.sh -d . -q"
+	echo "    run-spdk-autotest.sh -d /home/vagrant/spdk_repo/spdk"
+	echo
+}
+
+set -e
+
+NOOP=0
+METHOD=0
+V=1
+OPTIND=1         # Reset in case getopts has been used previously in the shell.
+while getopts "d:qhn" opt; do
+	case "$opt" in
+		d)  SPDK_SOURCE_PATH=$($READLINK -f $OPTARG)
+			echo Using SPDK source at ${SPDK_SOURCE_PATH}
+			METHOD=1
+		;;
+		q)  V=0
+		;;
+		n)  NOOP=1
+		;;
+		h)  display_help >&2
+			exit 0
+		;;
+	esac
+done
+
+if [ -z "${SPDK_SOURCE_PATH}" ]; then
+	echo "Error: Must specify a source path "
+	display_help
+	exit 1
+fi
+
+# The following code verifies the input parameters and sets up the following variables:
+#
+# SPDK_AUTOTEST_LOCAL_PATH
+# GIT_REPO_PATH
+# GIT_BRANCH
+#
+
+case "$METHOD" in
+	1)
+		if [ ! -d "${SPDK_SOURCE_PATH}" ]; then
+			echo "${SPDK_SOURCE_PATH} does not exist!"
+			exit 1
+		fi
+                if [ ! -d "${SPDK_SOURCE_PATH}/.git" ]; then
+                        echo "${SPDK_SOURCE_PATH} is not a git repository"
+                        exit 1
+                fi
+
+		GIT_REPO_SRC_DIR=$($READLINK -f "${SPDK_SOURCE_PATH}" | tr -t '/' ' ' | awk '{print $NF}')
+
+		if [ ! "${GIT_REPO_SRC_DIR}" = "spdk" ]; then
+			echo "The ${SPDK_SOURCE_PATH} git repository is not named \"spdk\""
+			exit 1
+		fi
+
+                pushd "${SPDK_SOURCE_PATH}"
+                GIT_REPO_SRC=$(git rev-parse --show-toplevel)
+		GIT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
+                popd
+
+		if [ "${SPDK_AUTOTEST_LOCAL_PATH}" = "${SPDK_SOURCE_PATH}" ]; then
+			SPDK_AUTOTEST_LOCAL_PATH=$($READLINK -f ${SPDK_AUTOTEST_LOCAL_PATH}/..)
+                        echo "Set SPDK_AUTOTEST_LOCAL_PATH to ${SPDK_AUTOTEST_LOCAL_PATH}"
+		fi
+
+		if [ -d "${SPDK_AUTOTEST_LOCAL_PATH}/${GIT_BRANCH}" ]; then
+			if [ -d "${SPDK_AUTOTEST_LOCAL_PATH}/${GIT_BRANCH}/.git" ]; then
+				echo "${SPDK_AUTOTEST_LOCAL_PATH}/${GIT_BRANCH} is a git repository!"
+				exit 1
+			fi
+		fi
+
+		GIT_REPO_PATH="${SPDK_AUTOTEST_LOCAL_PATH}/${GIT_BRANCH}/${BUILD_NAME}"
+	;;
+	*)
+		echo "Internal Error: Must specify a source path or branch name"
+		display_help
+		exit 1
+	;;
+esac
+
+AUTOTEST_RESULTS="${SPDK_AUTOTEST_LOCAL_PATH}/${GIT_BRANCH}/${BUILD_NAME}"
+AUTOTEST_OUTPUT_PATH="${GIT_REPO_PATH}/output"
+rootdir="${GIT_REPO_PATH}/spdk"
+BUILD_LOG_FILE="${AUTOTEST_OUTPUT_PATH}/build.log"
+
+if [[ ${NOOP} -eq 1 ]]; then
+	echo "AUTOTEST_DRIVER_PATH $AUTOTEST_DRIVER_PATH"
+	#echo "SPDK_AUTOTEST_LOCAL_PATH $SPDK_AUTOTEST_LOCAL_PATH"
+	echo "AUTOTEST_OUTPUT_PATH $AUTOTEST_OUTPUT_PATH"
+	#echo "rootdir $rootdir"
+	echo "BUILD_LOG_FILE $BUILD_LOG_FILE"
+	#echo "GIT_BRANCH $GIT_BRANCH"
+	#echo "BUILD_NAME $BUILD_NAME"
+	echo "GIT_REPO_PATH $GIT_REPO_PATH"
+	echo "AUTOTEST_RESULTS $AUTOTEST_RESULTS"
+fi
+
+#
+# I'd like to keep these files under source control
+#
+if [[ -e "${AUTOTEST_DRIVER_PATH}/autorun-spdk.conf" ]]; then
+        conf="${AUTOTEST_DRIVER_PATH}/autorun-spdk.conf"
+fi
+if [[ -e ~/autorun-spdk.conf ]]; then
+	conf=~/autorun-spdk.conf
+fi
+
+if [[ -z $conf ]]; then
+	echo Conf file not found.
+	exit 1
+fi
+
+mkdir -pv --mode=775 "${AUTOTEST_OUTPUT_PATH}"
+rm -f latest
+ln -sv ${GIT_REPO_PATH} latest
+
+if [[ ${NOOP} -eq 0 ]]; then
+	echo V=$V
+	if [[ $V -eq 0 ]]; then
+		echo Quieting output
+		exec 3>&1 4>&2 > "${BUILD_LOG_FILE}" 2>&1
+	else
+		echo Teeing to ${BUILD_LOG_FILE}
+		exec > >(tee -a "${BUILD_LOG_FILE}") 2>&1
+	fi
+
+	case "$METHOD" in
+		1)
+			echo "rsync git repository from ${GIT_REPO_SRC} to ${GIT_REPO_PATH}"
+			rsync -av "${GIT_REPO_SRC}" "${GIT_REPO_PATH}"
+			pushd "${GIT_REPO_PATH}/spdk"
+			sudo "${MAKE}" clean -j $(nproc)
+			sudo "${GIT}" clean -d -f
+			popd
+		;;
+		*)
+			echo "Internal Error: Must specify a source path or branch name"
+			display_help
+			exit 1
+		;;
+	esac
+
+	trap "echo ERROR; exit" INT TERM EXIT
+
+	pushd "${AUTOTEST_OUTPUT_PATH}"
+	export output_dir="${AUTOTEST_OUTPUT_PATH}"
+
+	# Runs agent scripts
+	"${rootdir}/autobuild.sh" "$conf"
+	sudo -E "${rootdir}/autotest.sh" "$conf"
+	"${rootdir}/autopackage.sh" "$conf"
+	sudo -E "${rootdir}/autorun_post.py" -d "${AUTOTEST_OUTPUT_PATH}" -r "${rootdir}"
+
+	echo "All Tests Passed" > ${GIT_REPO_PATH}/passed
+
+	# Redirect back to screen
+	if [[ $V -eq 0 ]]; then
+		echo Redirect to screen
+		exec 1>&3 2>&4 > >(tee -a "${BUILD_LOG_FILE}") 2>&1
+	fi
+
+	popd
+
+fi
+
+echo "all tests passed"
+
+echo Output directory: ${GIT_REPO_PATH}
+echo Build log: "${BUILD_LOG_FILE}"
diff --git a/scripts/vagrant/update.sh b/scripts/vagrant/update.sh
old mode 100644
new mode 100755
index bfb9eecef..b2ffbca6b
--- a/scripts/vagrant/update.sh
+++ b/scripts/vagrant/update.sh
@@ -1,44 +1,99 @@
-#!/bin/bash
-
-# Make sure that we get the hugepages we need on provision boot
-# Note: The package install should take care of this at the end
-#       But sometimes after all the work of provisioning, we can't
-#       get the requested number of hugepages without rebooting.
-#       So do it here just in case
-sysctl -w vm.nr_hugepages=1024
-HUGEPAGES=`sysctl -n  vm.nr_hugepages`
-if [ $HUGEPAGES != 1024 ]; then
-    echo "ERROR: Unable to get 1024 hugepages, only got $HUGEPAGES.  Cannot finish."
-    exit
+#!/usr/bin/env bash
+
+if [ ! "$USER" = "root" ]; then
+        echo
+        echo Error: must be run as root!
+        echo
+        exit 1
+fi
+
+set -e
+
+DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
+SPDK_DIR="$( cd "${DIR}/../../" && pwd )"
+echo "SPDK_DIR = $SPDK_DIR"
+
+# Bug fix for vagrant rsync problem
+if [ -d /home/vagrant/spdk_repo ]; then
+	echo "Fixing permissions on /home/vagrant/spdk_repo"
+	chown vagrant /home/vagrant/spdk_repo
+	chgrp vagrant /home/vagrant/spdk_repo
 fi
 
-# Figure out what system we are running on
-if [ -f /etc/lsb-release ];then
-    . /etc/lsb-release
-elif [ -f /etc/redhat-release ];then
-    yum install -y redhat-lsb
-    DISTRIB_ID=`lsb_release -si`
-    DISTRIB_RELEASE=`lsb_release -sr`
-    DISTRIB_CODENAME=`lsb_release -sc`
-    DISTRIB_DESCRIPTION=`lsb_release -sd`
+# Setup for run-autorun.sh
+if [ ! -f /home/vagrant/autorun-spdk.conf ]; then
+	echo "Copying scripts/vagrant/autorun-spdk.conf to /home/vagrant"
+	cp ${SPDK_DIR}/scripts/vagrant/autorun-spdk.conf /home/vagrant
+	chown vagrant /home/vagrant/autorun-spdk.conf
+	chgrp vagrant /home/vagrant/autorun-spdk.conf
 fi
 
-# Do initial setup for the system
-if [ $DISTRIB_ID == "Ubuntu" ]; then
+SYSTEM=`uname -s`
+
+if [ "$SYSTEM" = "FreeBSD" ]; then
+	# Do initial setup for the system
+	pkg upgrade -f
+	${SPDK_DIR}/scripts/pkgdep.sh
+	if [ -d /usr/src/.git ]; then
+		echo
+		echo "/usr/src/ is a git repository"
+		echo "consider \"cd /usr/src/; git pull\" to update"
+		echo
+	else
+		git clone --depth 10 -b release/11.1.0 https://github.com/freebsd/freebsd.git /usr/src
+	fi
+else
 
-    export DEBIAN_PRIORITY=critical
-    export DEBIAN_FRONTEND=noninteractive
-    export DEBCONF_NONINTERACTIVE_SEEN=true
-    APT_OPTS="--assume-yes --no-install-suggests --no-install-recommends -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confold\""
+	# Make sure that we get the hugepages we need on provision boot
+	# Note: The package install should take care of this at the end
+	#       But sometimes after all the work of provisioning, we can't
+	#       get the requested number of hugepages without rebooting.
+	#       So do it here just in case
+	sysctl -w vm.nr_hugepages=1024
+	HUGEPAGES=`sysctl -n  vm.nr_hugepages`
+	if [ $HUGEPAGES != 1024 ]; then
+		echo "Warning: Unable to get 1024 hugepages, only got $HUGEPAGES"
+		echo "Warning: Adjusting HUGEMEM in /home/vagrant/autorun-spdk.conf"
+		sed "s/HUGEMEM=.*$/HUGEMEM=${HUGEPAGES}/g" /home/vagrant/autorun-spdk.conf > /home/vagrant/foo.conf
+		mv -f /home/vagrant/foo.conf /home/vagrant/autorun-spdk.conf
+	fi
 
-    # Standard update + upgrade dance
-    apt-get update ${APT_OPTS}
-    apt-get upgrade ${APT_OPTS}
+	# Figure out what system we are running on
+	if [ -f /etc/lsb-release ];then
+		. /etc/lsb-release
+	elif [ -f /etc/redhat-release ];then
+		yum update -y
+		yum install -y redhat-lsb
+		DISTRIB_ID=`lsb_release -si`
+		DISTRIB_RELEASE=`lsb_release -sr`
+		DISTRIB_CODENAME=`lsb_release -sc`
+		DISTRIB_DESCRIPTION=`lsb_release -sd`
+	fi
 
-    # Install useful but non-mandatory tools
-    apt-get install -y gdb git gdisk sysstat
-elif [ $DISTRIB_ID == "CentOS" ]; then
-    # Standard update + upgrade dance
-    yum check-update
-    yum update -y
+	# Do initial setup for the system
+	if [ "$DISTRIB_ID" == "Ubuntu" ]; then
+		set -xv
+		export DEBIAN_PRIORITY=critical
+		export DEBIAN_FRONTEND=noninteractive
+		export DEBCONF_NONINTERACTIVE_SEEN=true
+		# Standard update + upgrade dance
+		apt-get update --assume-yes --no-install-suggests --no-install-recommends -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold"
+		apt-get upgrade --assume-yes --no-install-suggests --no-install-recommends -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold"
+		${SPDK_DIR}/scripts/pkgdep.sh
+	elif [ "$DISTRIB_ID" == "CentOS" ]; then
+		# Standard update + upgrade dance
+		yum check-update
+		yum update -y
+		${SPDK_DIR}/scripts/pkgdep.sh
+	elif [ "$DISTRIB_ID" == "Fedora" ]; then
+		if [ "$DISTRIB_RELEASE" = "26" ]; then
+			echo
+			echo "  Run \"${SPDK_DIR}/test/common/config/vm_setup.sh\" to complete setup of Fedora 26"
+			echo
+		else
+			yum check-update
+			yum update -y
+			${SPDK_DIR}/scripts/pkgdep.sh
+		fi
+	fi
 fi
diff --git a/shared_lib/Makefile b/shared_lib/Makefile
new file mode 100644
index 000000000..ed32c45a6
--- /dev/null
+++ b/shared_lib/Makefile
@@ -0,0 +1,108 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.modules.mk
+
+# Build combined libspdk.so shared library
+SHARED_LIB = $(SPDK_ROOT_DIR)/build/lib/libspdk.so
+
+SPDK_LIB_LIST += app_rpc
+SPDK_LIB_LIST += bdev
+SPDK_LIB_LIST += bdev_rpc
+SPDK_LIB_LIST += blobfs
+SPDK_LIB_LIST += conf
+SPDK_LIB_LIST += copy
+SPDK_LIB_LIST += event
+SPDK_LIB_LIST += event_bdev
+SPDK_LIB_LIST += event_copy
+SPDK_LIB_LIST += event_iscsi
+SPDK_LIB_LIST += event_net
+SPDK_LIB_LIST += event_nvmf
+SPDK_LIB_LIST += event_scsi
+SPDK_LIB_LIST += iscsi
+SPDK_LIB_LIST += json
+SPDK_LIB_LIST += jsonrpc
+SPDK_LIB_LIST += log
+SPDK_LIB_LIST += log_rpc
+SPDK_LIB_LIST += net
+SPDK_LIB_LIST += nvmf
+SPDK_LIB_LIST += rpc
+SPDK_LIB_LIST += scsi
+SPDK_LIB_LIST += thread
+SPDK_LIB_LIST += trace
+SPDK_LIB_LIST += util
+
+ifeq ($(OS),Linux)
+SPDK_LIB_LIST += event_nbd
+SPDK_LIB_LIST += nbd
+
+ifeq ($(CONFIG_VHOST),y)
+SPDK_LIB_LIST += event_vhost
+SPDK_LIB_LIST += rte_vhost
+SPDK_LIB_LIST += vhost
+endif
+
+endif
+
+LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS)
+LIBS += $(COPY_MODULES_LINKER_ARGS)
+LIBS += $(SOCK_MODULES_LINKER_ARGS)
+LIBS += $(SPDK_LIB_LINKER_ARGS)
+LIBS += $(ENV_LINKER_ARGS)
+
+comma := ,
+
+$(SHARED_LIB): $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS) $(MAKEFILE_LIST) spdk.map
+	$(Q)echo "  SO $(notdir $@)"; \
+	rm -f $@; \
+	$(CC) -o $@ -shared $(CPPFLAGS) $(LDFLAGS) \
+		-Wl,--whole-archive \
+		$(filter-out -Wl$(comma)--no-whole-archive,$(LIBS)) \
+		-Wl,--no-whole-archive \
+		-Wl,--version-script=spdk.map \
+		$(SYS_LIBS)
+
+.PHONY: all clean $(DIRS-y)
+
+all: $(SHARED_LIB)
+
+clean:
+	$(CLEAN_C) $(SHARED_LIB)
+
+install:
+	$(INSTALL_SHARED_LIB)
+
+include $(SPDK_ROOT_DIR)/mk/spdk.subdirs.mk
diff --git a/shared_lib/spdk.map b/shared_lib/spdk.map
new file mode 100644
index 000000000..9467260da
--- /dev/null
+++ b/shared_lib/spdk.map
@@ -0,0 +1,4 @@
+{
+	global: spdk_*;
+	local: *;
+};
diff --git a/test/app/bdev_svc/Makefile b/test/app/bdev_svc/Makefile
index 28b81c08d..43ec095ac 100644
--- a/test/app/bdev_svc/Makefile
+++ b/test/app/bdev_svc/Makefile
@@ -41,7 +41,7 @@ APP = bdev_svc
 C_SRCS := bdev_svc.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += nvmf event log trace conf util bdev copy rpc jsonrpc json
+SPDK_LIB_LIST += nvmf event log trace conf thread util bdev copy rpc jsonrpc json
 SPDK_LIB_LIST += app_rpc log_rpc bdev_rpc
 
 ifeq ($(OS),Linux)
@@ -50,12 +50,13 @@ endif
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
 	$(COPY_MODULES_LINKER_ARGS) \
+	$(SOCK_MODULES_LINKER_ARGS) \
 	$(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(BLOCKDEV_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(SPDK_WHOLE_LIBS) $(COPY_MODULES_FILES) $(BLOCKDEV_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/app/bdev_svc/bdev_svc.c b/test/app/bdev_svc/bdev_svc.c
index 20c3f8aeb..45a9ed2c0 100644
--- a/test/app/bdev_svc/bdev_svc.c
+++ b/test/app/bdev_svc/bdev_svc.c
@@ -37,6 +37,7 @@
 #include "spdk/event.h"
 
 static char g_path[256];
+static bool g_unaffinitize_thread = false;
 
 static void
 bdev_svc_usage(void)
@@ -54,7 +55,9 @@ bdev_svc_start(void *arg1, void *arg2)
 	int fd;
 	int shm_id = (intptr_t)arg1;
 
-	spdk_unaffinitize_thread();
+	if (g_unaffinitize_thread) {
+		spdk_unaffinitize_thread();
+	}
 
 	snprintf(g_path, sizeof(g_path), "/var/run/spdk_bdev%d", shm_id);
 	fd = open(g_path, O_CREAT | O_EXCL | O_RDWR, S_IFREG);
@@ -91,6 +94,16 @@ main(int argc, char **argv)
 		exit(rc);
 	}
 
+	/* User did not specify a reactor mask.  Test scripts may do this when using
+	 *  bdev_svc as a primary process to speed up nvme test programs by running
+	 *  them as secondary processes.  In that case, we will unaffinitize the thread
+	 *  in the bdev_svc_start routine, which will allow the scheduler to move this
+	 *  thread so it doesn't conflict with pinned threads in the secondary processes.
+	 */
+	if (opts.reactor_mask == NULL) {
+		g_unaffinitize_thread = true;
+	}
+
 	rc = spdk_app_start(&opts, bdev_svc_start, (void *)(intptr_t)opts.shm_id, NULL);
 
 	spdk_app_fini();
diff --git a/test/app/histogram_perf/Makefile b/test/app/histogram_perf/Makefile
index 93123bf16..a586307c7 100644
--- a/test/app/histogram_perf/Makefile
+++ b/test/app/histogram_perf/Makefile
@@ -39,7 +39,7 @@ APP = histogram_perf
 
 C_SRCS = histogram_perf.c
 
-SPDK_LIB_LIST = util
+SPDK_LIB_LIST = thread util
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/test/app/jsoncat/Makefile b/test/app/jsoncat/Makefile
index 959c69603..407e86e62 100644
--- a/test/app/jsoncat/Makefile
+++ b/test/app/jsoncat/Makefile
@@ -39,7 +39,7 @@ APP = jsoncat
 
 C_SRCS = jsoncat.c
 
-SPDK_LIB_LIST = json util
+SPDK_LIB_LIST = json thread util
 
 LIBS += $(SPDK_LIB_LINKER_ARGS)
 
diff --git a/test/app/stub/Makefile b/test/app/stub/Makefile
index c08996536..015a2e6e7 100644
--- a/test/app/stub/Makefile
+++ b/test/app/stub/Makefile
@@ -34,13 +34,15 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
+include $(SPDK_ROOT_DIR)/mk/spdk.modules.mk
 
 APP = stub
 
 C_SRCS := stub.c
 
-SPDK_LIB_LIST = event conf nvme log trace rpc jsonrpc json util
+SPDK_LIB_LIST = event conf nvme log trace rpc jsonrpc json thread util
 
+LIBS += $(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS)
 LIBS += $(ENV_LINKER_ARGS)
 
@@ -51,7 +53,7 @@ endif
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SOCK_MODULES_FILES) $(SPDK_LIB_FILES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/app/stub/stub.c b/test/app/stub/stub.c
index d3929d45a..c52917dd2 100644
--- a/test/app/stub/stub.c
+++ b/test/app/stub/stub.c
@@ -141,6 +141,7 @@ main(int argc, char **argv)
 	opts.max_delay_us = 1000 * 1000;
 
 	ch = spdk_app_start(&opts, stub_start, (void *)(intptr_t)opts.shm_id, NULL);
+	spdk_app_fini();
 
 	return ch;
 }
diff --git a/test/bdev/bdev.conf.in b/test/bdev/bdev.conf.in
index 0c074c585..c59b64fd2 100644
--- a/test/bdev/bdev.conf.in
+++ b/test/bdev/bdev.conf.in
@@ -19,7 +19,7 @@
   AIO /tmp/aiofile AIO1 2048
 
 [Ioat]
-  Disable Yes
+  Enable No
 
 [QoS]
   # QoS section defines limitation on performance
diff --git a/test/bdev/bdevio/Makefile b/test/bdev/bdevio/Makefile
index 7348b1698..d973846f6 100644
--- a/test/bdev/bdevio/Makefile
+++ b/test/bdev/bdevio/Makefile
@@ -41,17 +41,18 @@ APP = bdevio
 C_SRCS := bdevio.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += bdev copy event trace log conf util rpc jsonrpc json
+SPDK_LIB_LIST += bdev copy event trace log conf thread util rpc jsonrpc json
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
-	$(COPY_MODULES_LINKER_ARGS)
+	$(COPY_MODULES_LINKER_ARGS) \
+	$(SOCK_MODULES_LINKER_ARGS)
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS) -lcunit
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(COPY_MODULES_FILES) $(BLOCKDEV_MODULES_FILES) $(SOCK_MODULES_FILES) $(LINKER_MODULES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/bdev/bdevio/bdevio.c b/test/bdev/bdevio/bdevio.c
index 99ed265be..4d28b57bb 100644
--- a/test/bdev/bdevio/bdevio.c
+++ b/test/bdev/bdevio/bdevio.c
@@ -38,7 +38,7 @@
 #include "spdk/copy_engine.h"
 #include "spdk/env.h"
 #include "spdk/log.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 #include "CUnit/Basic.h"
 
diff --git a/test/bdev/bdevjson/json_config.sh b/test/bdev/bdevjson/json_config.sh
new file mode 100755
index 000000000..3e5d276ef
--- /dev/null
+++ b/test/bdev/bdevjson/json_config.sh
@@ -0,0 +1,27 @@
+#!/usr/bin/env bash
+set -ex
+BDEV_JSON_DIR=$(readlink -f $(dirname $0))
+. $BDEV_JSON_DIR/../../json_config/common.sh
+
+function test_subsystems() {
+	run_spdk_tgt
+	rootdir=$(readlink -f $BDEV_JSON_DIR/../../..)
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	load_nvme
+	create_bdev_subsystem_config
+	test_json_config
+
+	clear_bdev_subsystem_config
+	test_global_params "spdk_tgt"
+	kill_targets
+}
+
+timing_enter json_config
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"' ERR
+
+test_subsystems
+
+timing_exit json_config
+report_test_completion json_config
diff --git a/test/bdev/bdevjson/rbd_json_config.sh b/test/bdev/bdevjson/rbd_json_config.sh
new file mode 100755
index 000000000..458ecb740
--- /dev/null
+++ b/test/bdev/bdevjson/rbd_json_config.sh
@@ -0,0 +1,26 @@
+#!/usr/bin/env bash
+set -ex
+VHOST_JSON_DIR=$(readlink -f $(dirname $0))
+. $VHOST_JSON_DIR/../../json_config/common.sh
+
+function test_subsystems() {
+	run_spdk_tgt
+	rootdir=$(readlink -f $VHOST_JSON_DIR/../../..)
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	$rpc_py start_subsystem_init
+
+	create_rbd_bdev_subsystem_config
+	test_json_config
+	clear_rbd_bdev_subsystem_config
+
+	kill_targets
+}
+
+trap 'rbd_cleanup; on_error_exit "${FUNCNAME}" "${LINENO}"' ERR
+timing_enter rbd_json_config
+
+test_subsystems
+timing_exit rbd_json_config
+report_test_completion rbd_json_config
diff --git a/test/bdev/bdevperf/Makefile b/test/bdev/bdevperf/Makefile
index de59c62f2..eb5f76aef 100644
--- a/test/bdev/bdevperf/Makefile
+++ b/test/bdev/bdevperf/Makefile
@@ -41,17 +41,18 @@ APP = bdevperf
 C_SRCS := bdevperf.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += bdev copy event trace log conf util rpc jsonrpc json
+SPDK_LIB_LIST += bdev copy event trace log conf thread util rpc jsonrpc json
 
 LIBS += $(BLOCKDEV_MODULES_LINKER_ARGS) \
-	$(COPY_MODULES_LINKER_ARGS)
+	$(COPY_MODULES_LINKER_ARGS) \
+	$(SOCK_MODULES_LINKER_ARGS)
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(ENV_LIBS)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(BLOCKDEV_MODULES_FILES) $(COPY_MODULES_FILES) $(SOCK_MODULES_FILES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/bdev/bdevperf/bdevperf.c b/test/bdev/bdevperf/bdevperf.c
index d2d53d137..a47b8bc31 100644
--- a/test/bdev/bdevperf/bdevperf.c
+++ b/test/bdev/bdevperf/bdevperf.c
@@ -41,7 +41,7 @@
 #include "spdk/event.h"
 #include "spdk/log.h"
 #include "spdk/util.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/string.h"
 
 struct bdevperf_task {
@@ -49,7 +49,9 @@ struct bdevperf_task {
 	struct io_target		*target;
 	void				*buf;
 	uint64_t			offset_blocks;
+	enum spdk_bdev_io_type		io_type;
 	TAILQ_ENTRY(bdevperf_task)	link;
+	struct spdk_bdev_io_wait_entry	bdev_io_wait;
 };
 
 static int g_io_size = 0;
@@ -59,6 +61,7 @@ static int g_is_random;
 static bool g_verify = false;
 static bool g_reset = false;
 static bool g_unmap = false;
+static bool g_flush = false;
 static int g_queue_depth;
 static uint64_t g_time_in_usec;
 static int g_show_performance_real_time = 0;
@@ -98,7 +101,7 @@ struct io_target {
 	TAILQ_HEAD(, bdevperf_task)	task_list;
 };
 
-struct io_target **head;
+struct io_target **g_head;
 uint32_t *coremap;
 static int g_target_count = 0;
 
@@ -116,16 +119,16 @@ blockdev_heads_init(void)
 	uint32_t i, idx = 0;
 	uint32_t core_count = spdk_env_get_core_count();
 
-	head = calloc(core_count, sizeof(struct io_target *));
-	if (!head) {
-		fprintf(stderr, "Cannot allocate head array with size=%u\n",
+	g_head = calloc(core_count, sizeof(struct io_target *));
+	if (!g_head) {
+		fprintf(stderr, "Cannot allocate g_head array with size=%u\n",
 			core_count);
 		return -1;
 	}
 
 	coremap = calloc(core_count, sizeof(uint32_t));
 	if (!coremap) {
-		free(head);
+		free(g_head);
 		fprintf(stderr, "Cannot allocate coremap array with size=%u\n",
 			core_count);
 		return -1;
@@ -159,9 +162,13 @@ blockdev_heads_destroy(void)
 	uint32_t i, core_count;
 	struct io_target *target, *next_target;
 
+	if (!g_head) {
+		return;
+	}
+
 	core_count = spdk_env_get_core_count();
 	for (i = 0; i < core_count; i++) {
-		target = head[i];
+		target = g_head[i];
 		while (target != NULL) {
 			next_target = target->next;
 			bdevperf_free_target(target);
@@ -169,7 +176,7 @@ blockdev_heads_destroy(void)
 		}
 	}
 
-	free(head);
+	free(g_head);
 	free(coremap);
 }
 
@@ -218,7 +225,7 @@ bdevperf_construct_targets(void)
 		target->bdev = bdev;
 		/* Mapping each target to lcore */
 		index = g_target_count % spdk_env_get_core_count();
-		target->next = head[index];
+		target->next = g_head[index];
 		target->lcore = coremap[index];
 		target->io_completed = 0;
 		target->current_queue_depth = 0;
@@ -247,7 +254,7 @@ bdevperf_construct_targets(void)
 		target->reset_timer = NULL;
 		TAILQ_INIT(&target->task_list);
 
-		head[index] = target;
+		g_head[index] = target;
 		g_target_count++;
 
 		bdev = spdk_bdev_next_leaf(bdev);
@@ -291,7 +298,7 @@ bdevperf_complete(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
 			printf("task offset: %lu on target bdev=%s fails\n",
 			       task->offset_blocks, target->name);
 		}
-	} else if (g_verify || g_reset || g_unmap) {
+	} else if (g_verify || g_reset) {
 		spdk_bdev_io_get_iovec(bdev_io, &iovs, &iovcnt);
 		assert(iovcnt == 1);
 		assert(iovs != NULL);
@@ -328,88 +335,48 @@ bdevperf_complete(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
 }
 
 static void
-bdevperf_unmap_complete(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+bdevperf_verify_submit_read(void *cb_arg)
 {
 	struct io_target	*target;
 	struct bdevperf_task	*task = cb_arg;
-	int rc;
+	int			rc;
 
 	target = task->target;
 
-	/* Set the expected buffer to 0. */
-	memset(task->buf, 0, g_io_size);
-
 	/* Read the data back in */
 	rc = spdk_bdev_read_blocks(target->bdev_desc, target->ch, NULL, task->offset_blocks,
 				   target->io_size_blocks, bdevperf_complete, task);
-	if (rc) {
+	if (rc == -ENOMEM) {
+		task->bdev_io_wait.bdev = target->bdev;
+		task->bdev_io_wait.cb_fn = bdevperf_verify_submit_read;
+		task->bdev_io_wait.cb_arg = task;
+		spdk_bdev_queue_io_wait(target->bdev, target->ch, &task->bdev_io_wait);
+	} else if (rc != 0) {
 		printf("Failed to submit read: %d\n", rc);
 		target->is_draining = true;
 		g_run_failed = true;
-		return;
 	}
-
-	spdk_bdev_free_io(bdev_io);
-
 }
 
 static void
 bdevperf_verify_write_complete(struct spdk_bdev_io *bdev_io, bool success,
 			       void *cb_arg)
 {
-	struct io_target	*target;
-	struct bdevperf_task	*task = cb_arg;
-	int			rc;
-
-	target = task->target;
-
-	if (g_unmap) {
-		rc = spdk_bdev_unmap_blocks(target->bdev_desc, target->ch, task->offset_blocks,
-					    target->io_size_blocks, bdevperf_unmap_complete, task);
-		if (rc) {
-			printf("Failed to submit unmap: %d\n", rc);
-			target->is_draining = true;
-			g_run_failed = true;
-			return;
-		}
+	if (success) {
+		spdk_bdev_free_io(bdev_io);
+		bdevperf_verify_submit_read(cb_arg);
 	} else {
-		/* Read the data back in */
-		rc = spdk_bdev_read_blocks(target->bdev_desc, target->ch, NULL, task->offset_blocks,
-					   target->io_size_blocks, bdevperf_complete, task);
-		if (rc) {
-			printf("Failed to submit read: %d\n", rc);
-			target->is_draining = true;
-			g_run_failed = true;
-			return;
-		}
+		bdevperf_complete(bdev_io, success, cb_arg);
 	}
-
-	spdk_bdev_free_io(bdev_io);
 }
 
 static __thread unsigned int seed = 0;
 
 static void
-bdevperf_submit_single(struct io_target *target, struct bdevperf_task *task)
+bdevperf_prep_task(struct bdevperf_task *task)
 {
-	struct spdk_bdev_desc	*desc;
-	struct spdk_io_channel	*ch;
-	uint64_t		offset_in_ios;
-	void			*rbuf;
-	int			rc;
-
-	desc = target->bdev_desc;
-	ch = target->ch;
-
-	if (!task) {
-		if (!TAILQ_EMPTY(&target->task_list)) {
-			task = TAILQ_FIRST(&target->task_list);
-			TAILQ_REMOVE(&target->task_list, task, link);
-		} else {
-			printf("Task allocation failed\n");
-			abort();
-		}
-	}
+	struct io_target *target = task->target;
+	uint64_t offset_in_ios;
 
 	if (g_is_random) {
 		offset_in_ios = rand_r(&seed) % target->size_in_ios;
@@ -421,45 +388,97 @@ bdevperf_submit_single(struct io_target *target, struct bdevperf_task *task)
 	}
 
 	task->offset_blocks = offset_in_ios * target->io_size_blocks;
-	if (g_verify || g_reset || g_unmap) {
+	if (g_verify || g_reset) {
 		memset(task->buf, rand_r(&seed) % 256, g_io_size);
 		task->iov.iov_base = task->buf;
 		task->iov.iov_len = g_io_size;
-		rc = spdk_bdev_writev_blocks(desc, ch, &task->iov, 1, task->offset_blocks,
-					     target->io_size_blocks, bdevperf_verify_write_complete, task);
-		if (rc) {
-			printf("Failed to submit writev: %d\n", rc);
-			target->is_draining = true;
-			g_run_failed = true;
-			return;
-		}
+		task->io_type = SPDK_BDEV_IO_TYPE_WRITE;
+	} else if (g_flush) {
+		task->io_type = SPDK_BDEV_IO_TYPE_FLUSH;
+	} else if (g_unmap) {
+		task->io_type = SPDK_BDEV_IO_TYPE_UNMAP;
 	} else if ((g_rw_percentage == 100) ||
 		   (g_rw_percentage != 0 && ((rand_r(&seed) % 100) < g_rw_percentage))) {
-		rbuf = g_zcopy ? NULL : task->buf;
-		rc = spdk_bdev_read_blocks(desc, ch, rbuf, task->offset_blocks,
-					   target->io_size_blocks, bdevperf_complete, task);
-		if (rc) {
-			printf("Failed to submit read: %d\n", rc);
-			target->is_draining = true;
-			g_run_failed = true;
-			return;
-		}
+		task->io_type = SPDK_BDEV_IO_TYPE_READ;
 	} else {
 		task->iov.iov_base = task->buf;
 		task->iov.iov_len = g_io_size;
+		task->io_type = SPDK_BDEV_IO_TYPE_WRITE;
+	}
+}
+
+static void
+bdevperf_submit_task(void *arg)
+{
+	struct bdevperf_task	*task = arg;
+	struct io_target	*target = task->target;
+	struct spdk_bdev_desc	*desc;
+	struct spdk_io_channel	*ch;
+	spdk_bdev_io_completion_cb cb_fn;
+	void			*rbuf;
+	int			rc;
+
+	desc = target->bdev_desc;
+	ch = target->ch;
+
+	switch (task->io_type) {
+	case SPDK_BDEV_IO_TYPE_WRITE:
+		cb_fn = (g_verify || g_reset) ? bdevperf_verify_write_complete : bdevperf_complete;
 		rc = spdk_bdev_writev_blocks(desc, ch, &task->iov, 1, task->offset_blocks,
-					     target->io_size_blocks, bdevperf_complete, task);
-		if (rc) {
-			printf("Failed to submit writev: %d\n", rc);
-			target->is_draining = true;
-			g_run_failed = true;
-			return;
-		}
+					     target->io_size_blocks, cb_fn, task);
+		break;
+	case SPDK_BDEV_IO_TYPE_FLUSH:
+		rc = spdk_bdev_flush_blocks(desc, ch, task->offset_blocks,
+					    target->io_size_blocks, bdevperf_complete, task);
+		break;
+	case SPDK_BDEV_IO_TYPE_UNMAP:
+		rc = spdk_bdev_unmap_blocks(desc, ch, task->offset_blocks,
+					    target->io_size_blocks, bdevperf_complete, task);
+		break;
+	case SPDK_BDEV_IO_TYPE_READ:
+		rbuf = g_zcopy ? NULL : task->buf;
+		rc = spdk_bdev_read_blocks(desc, ch, rbuf, task->offset_blocks,
+					   target->io_size_blocks, bdevperf_complete, task);
+		break;
+	default:
+		assert(false);
+		rc = -EINVAL;
+		break;
+	}
+
+	if (rc == -ENOMEM) {
+		task->bdev_io_wait.bdev = target->bdev;
+		task->bdev_io_wait.cb_fn = bdevperf_submit_task;
+		task->bdev_io_wait.cb_arg = task;
+		spdk_bdev_queue_io_wait(target->bdev, ch, &task->bdev_io_wait);
+		return;
+	} else if (rc != 0) {
+		printf("Failed to submit bdev_io: %d\n", rc);
+		target->is_draining = true;
+		g_run_failed = true;
+		return;
 	}
 
 	target->current_queue_depth++;
 }
 
+static void
+bdevperf_submit_single(struct io_target *target, struct bdevperf_task *task)
+{
+	if (!task) {
+		if (!TAILQ_EMPTY(&target->task_list)) {
+			task = TAILQ_FIRST(&target->task_list);
+			TAILQ_REMOVE(&target->task_list, task, link);
+		} else {
+			printf("Task allocation failed\n");
+			abort();
+		}
+	}
+
+	bdevperf_prep_task(task);
+	bdevperf_submit_task(task);
+}
+
 static void
 bdevperf_submit_io(struct io_target *target, int queue_depth)
 {
@@ -574,7 +593,7 @@ static void usage(char *program_name)
 	printf("\t[-q io depth]\n");
 	printf("\t[-s io size in bytes]\n");
 	printf("\t[-w io pattern type, must be one of\n");
-	printf("\t\t(read, write, randread, randwrite, rw, randrw, verify, reset)]\n");
+	printf("\t\t(read, write, randread, randwrite, rw, randrw, verify, reset, unmap, flush)]\n");
 	printf("\t[-M rwmixread (100 for reads, 0 for writes)]\n");
 	printf("\t[-t time in seconds]\n");
 	printf("\t[-P Number of moving average period]\n");
@@ -582,6 +601,7 @@ static void usage(char *program_name)
 	printf("\t\t(Formula: M = 2 / (n + 1), EMA[i+1] = IO/s * M + (1 - M) * EMA[i])\n");
 	printf("\t\t(only valid with -S)\n");
 	printf("\t[-S Show performance result in real time in seconds]\n");
+	spdk_tracelog_usage(stdout, "-L");
 }
 
 /*
@@ -624,7 +644,7 @@ performance_dump(uint64_t io_time_in_usec, uint64_t ema_period)
 	total_io_per_second = 0;
 	total_mb_per_second = 0;
 	for (index = 0; index < spdk_env_get_core_count(); index++) {
-		target = head[index];
+		target = g_head[index];
 		if (target != NULL) {
 			lcore_id = target->lcore;
 			printf("\r Logical core: %u\n", lcore_id);
@@ -679,7 +699,7 @@ bdevperf_construct_targets_tasks(void)
 
 	/* Initialize task list for each target */
 	for (i = 0; i < spdk_env_get_core_count(); i++) {
-		target = head[i];
+		target = g_head[i];
 		if (!target) {
 			break;
 		}
@@ -729,6 +749,12 @@ bdevperf_run(void *arg1, void *arg2)
 
 	bdevperf_construct_targets();
 
+	if (g_target_count == 0) {
+		fprintf(stderr, "No valid bdevs found.\n");
+		spdk_app_stop(1);
+		return;
+	}
+
 	rc = bdevperf_construct_targets_tasks();
 	if (rc) {
 		blockdev_heads_destroy();
@@ -749,7 +775,7 @@ bdevperf_run(void *arg1, void *arg2)
 	g_master_core = spdk_env_get_current_core();
 	/* Send events to start all I/O */
 	for (i = 0; i < spdk_env_get_core_count(); i++) {
-		target = head[i];
+		target = g_head[i];
 		if (target == NULL) {
 			break;
 		}
@@ -783,7 +809,10 @@ spdk_bdevperf_shutdown_cb(void)
 
 	/* Send events to stop all I/O on each core */
 	for (i = 0; i < spdk_env_get_core_count(); i++) {
-		target = head[i];
+		if (g_head == NULL) {
+			break;
+		}
+		target = g_head[i];
 		if (target == NULL) {
 			break;
 		}
@@ -805,6 +834,7 @@ main(int argc, char **argv)
 	int time_in_sec;
 	uint64_t show_performance_period_in_usec = 0;
 	int rc;
+	bool debug_mode = false;
 
 	/* default value */
 	config_file = NULL;
@@ -815,7 +845,7 @@ main(int argc, char **argv)
 	mix_specified = false;
 	core_mask = NULL;
 
-	while ((op = getopt(argc, argv, "c:d:m:q:s:t:w:M:P:S:")) != -1) {
+	while ((op = getopt(argc, argv, "c:d:m:q:s:t:w:L:M:P:S:")) != -1) {
 		switch (op) {
 		case 'c':
 			config_file = optarg;
@@ -838,6 +868,22 @@ main(int argc, char **argv)
 		case 'w':
 			workload_type = optarg;
 			break;
+		case 'L':
+#ifndef DEBUG
+			fprintf(stderr, "%s must be built with CONFIG_DEBUG=y for -L flag\n",
+				argv[0]);
+			usage(argv[0]);
+			exit(1);
+#else
+			rc = spdk_log_set_trace_flag(optarg);
+			if (rc < 0) {
+				fprintf(stderr, "unknown flag\n");
+				usage(argv[0]);
+			}
+
+			debug_mode = true;
+			break;
+#endif
 		case 'M':
 			g_rw_percentage = atoi(optarg);
 			mix_specified = true;
@@ -893,10 +939,11 @@ main(int argc, char **argv)
 	    strcmp(workload_type, "randrw") &&
 	    strcmp(workload_type, "verify") &&
 	    strcmp(workload_type, "reset") &&
-	    strcmp(workload_type, "unmap")) {
+	    strcmp(workload_type, "unmap") &&
+	    strcmp(workload_type, "flush")) {
 		fprintf(stderr,
 			"io pattern type must be one of\n"
-			"(read, write, randread, randwrite, rw, randrw, verify, reset, unmap)\n");
+			"(read, write, randread, randwrite, rw, randrw, verify, reset, unmap, flush)\n");
 		exit(1);
 	}
 
@@ -910,9 +957,16 @@ main(int argc, char **argv)
 		g_rw_percentage = 0;
 	}
 
+	if (!strcmp(workload_type, "unmap")) {
+		g_unmap = true;
+	}
+
+	if (!strcmp(workload_type, "flush")) {
+		g_flush = true;
+	}
+
 	if (!strcmp(workload_type, "verify") ||
-	    !strcmp(workload_type, "reset") ||
-	    !strcmp(workload_type, "unmap")) {
+	    !strcmp(workload_type, "reset")) {
 		g_rw_percentage = 50;
 		if (g_io_size > SPDK_BDEV_LARGE_BUF_MAX_SIZE) {
 			fprintf(stderr, "Unable to exceed max I/O size of %d for verify. (%d provided).\n",
@@ -927,9 +981,6 @@ main(int argc, char **argv)
 		if (!strcmp(workload_type, "reset")) {
 			g_reset = true;
 		}
-		if (!strcmp(workload_type, "unmap")) {
-			g_unmap = true;
-		}
 	}
 
 	if (!strcmp(workload_type, "read") ||
@@ -938,7 +989,8 @@ main(int argc, char **argv)
 	    !strcmp(workload_type, "randwrite") ||
 	    !strcmp(workload_type, "verify") ||
 	    !strcmp(workload_type, "reset") ||
-	    !strcmp(workload_type, "unmap")) {
+	    !strcmp(workload_type, "unmap") ||
+	    !strcmp(workload_type, "flush")) {
 		if (mix_specified) {
 			fprintf(stderr, "Ignoring -M option... Please use -M option"
 				" only when using rw or randrw.\n");
@@ -974,6 +1026,9 @@ main(int argc, char **argv)
 	}
 
 	bdevtest_init(config_file, core_mask, &opts);
+	if (debug_mode) {
+		opts.print_level = SPDK_LOG_DEBUG;
+	}
 	opts.rpc_addr = NULL;
 	if (g_mem_size) {
 		opts.mem_size = g_mem_size;
@@ -992,13 +1047,14 @@ main(int argc, char **argv)
 	}
 
 	if (g_time_in_usec) {
-		performance_dump(g_time_in_usec, 0);
+		if (!g_run_failed) {
+			performance_dump(g_time_in_usec, 0);
+		}
 	} else {
 		printf("Test time less than one microsecond, no performance data will be shown\n");
 	}
 
 	blockdev_heads_destroy();
 	spdk_app_fini();
-	printf("done.\n");
 	return g_run_failed;
 }
diff --git a/test/bdev/blockdev.sh b/test/bdev/blockdev.sh
index dcdef04ee..9653ab9ee 100755
--- a/test/bdev/blockdev.sh
+++ b/test/bdev/blockdev.sh
@@ -5,6 +5,7 @@ set -e
 testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $testdir/../..)
 plugindir=$rootdir/examples/bdev/fio_plugin
+rpc_py="python $rootdir/scripts/rpc.py"
 
 function run_fio()
 {
@@ -42,6 +43,8 @@ function nbd_function_test() {
 
 		nbd_rpc_data_verify $rpc_server "${bdev_list[*]}" "${nbd_list[*]}"
 
+		$rpc_py -s $rpc_server delete_passthru_bdev TestPT
+
 		killprocess $nbd_pid
 	fi
 
@@ -71,6 +74,12 @@ if hash pmempool; then
 	echo "  Blk /tmp/spdk-pmem-pool Pmem0" >> $testdir/bdev.conf
 fi
 
+timing_enter hello_bdev
+if grep -q Nvme0 $testdir/bdev.conf; then
+	$rootdir/examples/bdev/hello_world/hello_bdev -c $testdir/bdev.conf -b Nvme0n1
+fi
+timing_exit hello_bdev
+
 timing_enter bounds
 $testdir/bdevio/bdevio $testdir/bdev.conf
 timing_exit bounds
diff --git a/test/blobfs/fuse/Makefile b/test/blobfs/fuse/Makefile
index 56a19de00..847da50ea 100644
--- a/test/blobfs/fuse/Makefile
+++ b/test/blobfs/fuse/Makefile
@@ -41,7 +41,7 @@ APP = fuse
 C_SRCS := fuse.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event util conf trace \
+SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event thread util conf trace \
 		log jsonrpc json rpc
 
 LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS)
@@ -51,7 +51,7 @@ LIBS+= -L/usr/local/lib -lfuse3
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(COPY_MODULES_FILES) $(BLOCKDEV_MODULES_FILES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/blobfs/fuse/fuse.c b/test/blobfs/fuse/fuse.c
index 9cba34c44..2cdaa5a22 100644
--- a/test/blobfs/fuse/fuse.c
+++ b/test/blobfs/fuse/fuse.c
@@ -40,7 +40,7 @@
 #include "spdk/blobfs.h"
 #include "spdk/bdev.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/blob_bdev.h"
 #include "spdk/log.h"
 
diff --git a/test/blobfs/mkfs/Makefile b/test/blobfs/mkfs/Makefile
index 54f860ad1..8367571e5 100644
--- a/test/blobfs/mkfs/Makefile
+++ b/test/blobfs/mkfs/Makefile
@@ -41,16 +41,16 @@ APP = mkfs
 C_SRCS := mkfs.c
 
 SPDK_LIB_LIST = event_bdev event_copy
-SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event util conf trace \
+SPDK_LIB_LIST += blobfs blob bdev blob_bdev copy event thread util conf trace \
 		log jsonrpc json rpc
 
-LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS)
+LIBS += $(COPY_MODULES_LINKER_ARGS) $(BLOCKDEV_MODULES_LINKER_ARGS) $(SOCK_MODULES_LINKER_ARGS)
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
 all : $(APP)
 	@:
 
-$(APP) : $(OBJS) $(SPDK_LIB_FILES)
+$(APP) : $(OBJS) $(SPDK_LIB_FILES) $(COPY_MODULES_FILES) $(BLOCKDEV_MODULES_FILES) $(SOCK_MODULES_FILES) $(ENV_LIBS)
 	$(LINK_C)
 
 clean :
diff --git a/test/blobfs/rocksdb/rocksdb.sh b/test/blobfs/rocksdb/rocksdb.sh
index ffeb52135..88900f312 100755
--- a/test/blobfs/rocksdb/rocksdb.sh
+++ b/test/blobfs/rocksdb/rocksdb.sh
@@ -17,6 +17,10 @@ run_step() {
 	echo done.
 }
 
+run_bsdump() {
+	$rootdir/examples/blob/cli/blobcli -c $ROCKSDB_CONF -b Nvme0n1 -D &> bsdump.txt
+}
+
 testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $testdir/../../..)
 source $rootdir/test/common/autotest_common.sh
@@ -44,7 +48,7 @@ timing_exit db_bench_build
 cp $rootdir/etc/spdk/rocksdb.conf.in $ROCKSDB_CONF
 $rootdir/scripts/gen_nvme.sh >> $ROCKSDB_CONF
 
-trap 'rm -f $ROCKSDB_CONF; exit 1' SIGINT SIGTERM EXIT
+trap 'run_bsdump; rm -f $ROCKSDB_CONF; exit 1' SIGINT SIGTERM EXIT
 
 timing_enter mkfs
 $rootdir/test/blobfs/mkfs/mkfs $ROCKSDB_CONF Nvme0n1
@@ -124,6 +128,7 @@ timing_exit rocksdb_randread
 
 trap - SIGINT SIGTERM EXIT
 
+run_bsdump
 rm -f $ROCKSDB_CONF
 
 report_test_completion "blobfs"
diff --git a/test/common/autotest_common.sh b/test/common/autotest_common.sh
index f8d98f68d..229f6cb4f 100755
--- a/test/common/autotest_common.sh
+++ b/test/common/autotest_common.sh
@@ -6,6 +6,10 @@ fi
 
 set -e
 
+# Export flag to skip the known bug that exists in librados
+# Bug is reported on ceph bug tracker with number 24078
+export ASAN_OPTIONS=new_delete_type_mismatch=0
+
 PS4=' \t	\$ '
 ulimit -c unlimited
 
@@ -21,9 +25,17 @@ if [[ ! -z $1 ]]; then
 	fi
 fi
 
+# If certain utilities are not installed, preemptively disable the tests
+if ! hash ceph; then
+	SPDK_TEST_RBD=0
+fi
+
+if ! hash pmempool; then
+	SPDK_TEST_PMDK=0
+fi
+
 # Set defaults for missing test config options
 : ${SPDK_BUILD_DOC=1}; export SPDK_BUILD_DOC
-: ${SPDK_BUILD_IOAT_KMOD=1}; export SPDK_BUILD_IOAT_KMOD
 : ${SPDK_RUN_CHECK_FORMAT=1}; export SPDK_RUN_CHECK_FORMAT
 : ${SPDK_RUN_SCANBUILD=1}; export SPDK_RUN_SCANBUILD
 : ${SPDK_RUN_VALGRIND=1}; export SPDK_RUN_VALGRIND
@@ -31,6 +43,7 @@ fi
 : ${SPDK_TEST_ISCSI=1}; export SPDK_TEST_ISCSI
 : ${SPDK_TEST_ISCSI_INITIATOR=1}; export SPDK_TEST_ISCSI_INITIATOR
 : ${SPDK_TEST_NVME=1}; export SPDK_TEST_NVME
+: ${SPDK_TEST_NVME_CLI=1}; export SPDK_TEST_NVME_CLI
 : ${SPDK_TEST_NVMF=1}; export SPDK_TEST_NVMF
 : ${SPDK_TEST_RBD=1}; export SPDK_TEST_RBD
 : ${SPDK_TEST_VHOST=1}; export SPDK_TEST_VHOST
@@ -44,6 +57,16 @@ fi
 : ${SPDK_RUN_ASAN=1}; export SPDK_RUN_ASAN
 : ${SPDK_RUN_UBSAN=1}; export SPDK_RUN_UBSAN
 
+if [ -z "$DEPENDENCY_DIR" ]; then
+	export DEPENDENCY_DIR=/home/sys_sgsw
+else
+	export DEPENDENCY_DIR
+fi
+
+if [ ! -z "$HUGEMEM" ]; then
+	export HUGEMEM
+fi
+
 # pass our valgrind desire on to unittest.sh
 if [ $SPDK_RUN_VALGRIND -eq 0 ]; then
 	export valgrind=''
@@ -53,8 +76,12 @@ config_params='--enable-debug --enable-werror'
 
 export UBSAN_OPTIONS='halt_on_error=1:print_stacktrace=1:abort_on_error=1'
 
-# Override the default HUGEMEM in scripts/setup.sh
-export HUGEMEM=8192
+# On Linux systems, override the default HUGEMEM in scripts/setup.sh to
+#  allocate 8GB in hugepages.
+# FreeBSD runs a much more limited set of tests, so keep the default 2GB.
+if [ `uname -s` = "Linux" ]; then
+	export HUGEMEM=8192
+fi
 
 DEFAULT_RPC_ADDR=/var/tmp/spdk.sock
 
@@ -116,8 +143,8 @@ if [ -d /usr/src/fio ]; then
 	config_params+=' --with-fio=/usr/src/fio'
 fi
 
-if [ -d /home/sys_sgsw/vtune_codes ]; then
-	config_params+=' --with-vtune=/home/sys_sgsw/vtune_codes'
+if [ -d ${DEPENDENCY_DIR}/vtune_codes ]; then
+	config_params+=' --with-vtune='${DEPENDENCY_DIR}'/vtune_codes'
 fi
 
 if [ -d /usr/include/rbd ] &&  [ -d /usr/include/rados ]; then
@@ -135,6 +162,10 @@ else
 	export SPDK_TEST_ISCSI_INITIATOR=0
 fi
 
+if [ ! -d "${DEPENDENCY_DIR}/nvme-cli" ]; then
+	export SPDK_TEST_NVME_CLI=0
+fi
+
 export config_params
 
 if [ -z "$output_dir" ]; then
@@ -355,9 +386,8 @@ function rbd_cleanup() {
 
 function start_stub() {
 	# Disable ASLR for multi-process testing.  SPDK does support using DPDK multi-process,
-	# but ASAN instrumentation will result in mmap hints in our specified virt address
-	# region getting ignored.   We will reenable it again after multi-process testing
-	# is complete in kill_stub()
+	# but ASLR can still be unreliable in some cases.
+	# We will reenable it again after multi-process testing is complete in kill_stub()
 	echo 0 > /proc/sys/kernel/randomize_va_space
 	$rootdir/test/app/stub/stub $1 &
 	stubpid=$!
@@ -366,7 +396,7 @@ function start_stub() {
 		sleep 1s
 	done
 	# dump process memory map contents to help debug random ASLR failures
-	pmap -pX $stubpid
+	pmap -pX $stubpid || pmap -x $stubpid || true
 	echo done.
 }
 
@@ -599,9 +629,14 @@ function get_bdev_size()
 function autotest_cleanup()
 {
 	$rootdir/scripts/setup.sh reset
+}
 
-	if [ $SPDK_BUILD_IOAT_KMOD -eq 1 ]; then
-		$rootdir/scripts/build_kmod.sh clean
+function freebsd_update_contigmem_mod()
+{
+	if [ `uname` = FreeBSD ]; then
+		kldunload contigmem.ko || true
+		cp -f $rootdir/dpdk/build/kmod/contigmem.ko /boot/modules/
+		cp -f $rootdir/dpdk/build/kmod/contigmem.ko /boot/kernel/
 	fi
 }
 
diff --git a/test/common/config/vm_setup.conf b/test/common/config/vm_setup.conf
new file mode 100644
index 000000000..9b810cff8
--- /dev/null
+++ b/test/common/config/vm_setup.conf
@@ -0,0 +1,10 @@
+GIT_REPO_SPDK=https://review.gerrithub.io/spdk/spdk
+GIT_REPO_DPDK=https://github.com/spdk/dpdk.git
+GIT_REPO_LIBRXE=https://github.com/SoftRoCE/librxe-dev.git
+GIT_REPO_OPEN_ISCSI=https://github.com/open-iscsi/open-iscsi
+GIT_REPO_ROCKSDB=https://review.gerrithub.io/spdk/rocksdb
+GIT_REPO_FIO=http://git.kernel.dk/fio.git
+GIT_REPO_FLAMEGRAPH=https://github.com/brendangregg/FlameGraph.git
+GIT_REPO_QEMU=https://github.com/spdk/qemu
+GIT_REPO_VPP=https://gerrit.fd.io/r/vpp
+GIT_REPO_LIBISCSI=https://github.com/sahlberg/libiscsi
diff --git a/test/common/config/vm_setup.sh b/test/common/config/vm_setup.sh
index bdaead346..eadaa9ebc 100755
--- a/test/common/config/vm_setup.sh
+++ b/test/common/config/vm_setup.sh
@@ -17,217 +17,316 @@
 #     intel_iommu=on kvm-intel.nested=1
 
 # We have made a lot of progress with removing hardcoded paths from the tests,
-# but it may be easiest if you create your user with the name sys_sgsw for now.
 
 set -e
 
-jobs=$(($(nproc)*2))
+VM_SETUP_PATH=$(readlink -f ${BASH_SOURCE%/*})
 
-sudo dnf upgrade -y
-sudo dnf install -y gcc
-sudo dnf install -y gcc-c++
-sudo dnf install -y make
-sudo dnf install -y git
-sudo dnf install -y jq
-sudo dnf install -y valgrind
-sudo dnf install -y nvme-cli
-sudo dnf install -y ceph
-sudo dnf install -y gdb
-sudo dnf install -y sg3_utils
-sudo dnf install -y fio
-sudo dnf install -y librbd-devel
-sudo dnf install -y kernel-devel
-sudo dnf install -y gflags-devel
-sudo dnf install -y libasan
-sudo dnf install -y libubsan
-sudo dnf install -y autoconf
-sudo dnf install -y automake
-sudo dnf install -y libtool
-sudo dnf install -y libmount-devel
-sudo dnf install -y isns-utils-devel
-sudo dnf install -y openssl-devel
-sudo dnf install -y numactl-devel
-sudo dnf install -y libaio-devel
-sudo dnf install -y CUnit-devel
-sudo dnf install -y clang-analyzer
-sudo dnf install -y libpmemblk-devel nvml-tools
-sudo dnf install -y libibverbs libibverbs-devel librdmacm librdmacm-devel
-sudo dnf install -y perl-open
-sudo dnf install -y glib2-devel
-sudo dnf install -y pixman-devel
-sudo dnf install -y libiscsi-devel
-sudo dnf install -y doxygen
-sudo dnf install -y astyle-devel
-sudo dnf install -y python
-sudo dnf install -y python-pep8
-sudo dnf install -y lcov
-sudo dnf install -y libuuid-devel
-sudo dnf install -y elfutils-libelf-devel
-sudo dnf install -y flex
-sudo dnf install -y bison
-sudo dnf install -y targetcli
+UPGRADE=false
+INSTALL=false
+CONF="librxe,iscsi,rocksdb,fio,flamegraph,tsocks,qemu,vpp,libiscsi"
+CONF_PATH="${VM_SETUP_PATH}/vm_setup.conf"
 
-cd ~
+function usage()
+{
+    echo "This script is intended to automate the environment setup for a fedora linux virtual machine."
+    echo "Please run this script as your regular user. The script will make calls to sudo as needed."
+    echo ""
+    echo "./vm_setup.sh"
+    echo "  -h --help"
+    echo "  -u --upgrade Run dnf upgrade"
+    echo "  -i --install-deps Install dnf based dependencies"
+    echo "  -t --test-conf List of test configurations to enable (${CONF})"
+    echo "  -c --conf-path Path to configuration file"
+    exit 0
+}
 
-mkdir -p spdk_repo
+while getopts 'iuht:c:-:' optchar; do
+    case "$optchar" in
+        -)
+        case "$OPTARG" in
+            help) usage;;
+            upgrade) UPGRADE=true;;
+            install-deps) INSTALL=true;;
+            test-conf=*) CONF="${OPTARG#*=}";;
+            conf-path=*) CONF_PATH="${OPTARG#*=}";;
+            *) echo "Invalid argument '$OPTARG'"
+            usage;;
+        esac
+        ;;
+    h) usage;;
+    u) UPGRADE=true;;
+    i) INSTALL=true;;
+    t) CONF="$OPTARG";;
+    c) CONF_PATH="$OPTARG";;
+    *) echo "Invalid argument '$OPTARG'"
+    usage;;
+    esac
+done
 
-# The librxe-dev repository provides a command line tool called rxe_cfg which makes it
-# very easy to use Soft-RoCE. The build pool utilizes this command line tool in the absence
-# of any real RDMA NICs to simulate one for the NVMe-oF tests.
-if [ -d librxe-dev ]; then
-    echo "librxe-dev source already present, not cloning"
-elif [ hash rxe_cfg ]; then
-    echo "rxe_cfg is already installed. skipping"
-else
-    git clone https://github.com/SoftRoCE/librxe-dev.git
-    cd librxe-dev
-    ./configure --libdir=/usr/lib64/ --prefix=
-    make -j${jobs}
-    sudo make install
-    cd ~
+if [ ! -f "$CONF_PATH" ]; then
+	echo Configuration file does not exist: "$CONF_PATH"
+	exit 1
 fi
-sudo dnf install -y perl-Switch librdmacm-utils libibverbs-utils
+
+source "$CONF_PATH"
+
+jobs=$(($(nproc)*2))
+
+if $UPGRADE; then
+    sudo dnf upgrade -y
+fi
+
+if $INSTALL; then
+    sudo dnf install -y git
+fi
+
+cd ~
+mkdir -p spdk_repo
 
 cd spdk_repo
 mkdir -p output
 if [ -d spdk ]; then
     echo "spdk source already present, not cloning"
 else
-    git clone https://review.gerrithub.io/spdk/spdk
+    git clone "${GIT_REPO_SPDK}"
 fi
 cd spdk
+git config submodule.dpdk.url "${GIT_REPO_DPDK}"
 git submodule update --init --recursive
+
+if $INSTALL; then
+    sudo ./scripts/pkgdep.sh
+
+    if echo $CONF | grep -q tsocks; then
+        sudo dnf install -y tsocks
+    fi
+
+    sudo dnf install -y valgrind
+    sudo dnf install -y jq
+    sudo dnf install -y nvme-cli
+    sudo dnf install -y ceph
+    sudo dnf install -y gdb
+    sudo dnf install -y fio
+    sudo dnf install -y librbd-devel
+    sudo dnf install -y kernel-devel
+    sudo dnf install -y gflags-devel
+    sudo dnf install -y libasan
+    sudo dnf install -y libubsan
+    sudo dnf install -y autoconf
+    sudo dnf install -y automake
+    sudo dnf install -y libtool
+    sudo dnf install -y libmount-devel
+    sudo dnf install -y iscsi-initiator-utils
+    sudo dnf install -y isns-utils-devel
+    sudo dnf install -y pmempool
+    sudo dnf install -y perl-open
+    sudo dnf install -y glib2-devel
+    sudo dnf install -y pixman-devel
+    sudo dnf install -y astyle-devel
+    sudo dnf install -y elfutils-libelf-devel
+    sudo dnf install -y flex
+    sudo dnf install -y bison
+    sudo dnf install -y targetcli
+    sudo dnf install -y perl-Switch
+    sudo dnf install -y librdmacm-utils
+    sudo dnf install -y libibverbs-utils
+fi
+
 cd ~
 
-# The version of iscsiadm that ships with fedora 26 was broken as of November 3 2017.
-# There is already a bug report out about it, and hopefully it is fixed soon, but in the event that
-# that version is still broken when you do your setup, the below steps will fix the issue.
-CURRENT_VERSION=$(iscsiadm --version)
-OPEN_ISCSI_VER='iscsiadm version 6.2.0.874'
-if [ "$CURRENT_VERSION" == "$OPEN_ISCSI_VER" ]; then
-    if [ ! -d open-iscsi-install ]; then
-        mkdir -p open-iscsi-install
-        cd open-iscsi-install
-        sudo dnf download --source iscsi-initiator-utils
-        rpm2cpio iscsi-initiator-utils-6.2.0.874-3.git86e8892.fc26.src.rpm | cpio -idmv
-        mkdir -p patches
-        mv 00* patches/
-        git clone https://github.com/open-iscsi/open-iscsi
-
-        cd open-iscsi
-
-        # the configurations of username and email are needed for applying patches to iscsiadm.
-        git config user.name none
-        git config user.email none
-
-        git checkout 86e8892
-        for patch in `ls ../patches`; do
-            git am ../patches/$patch
-        done
-        sed -i '427s/.*/-1);/' usr/session_info.c
+if echo $CONF | grep -q librxe; then
+    # rxe_cfg is used in the NVMe-oF tests
+    # The librxe-dev repository provides a command line tool called rxe_cfg which makes it
+    # very easy to use Soft-RoCE. The build pool utilizes this command line tool in the absence
+    # of any real RDMA NICs to simulate one for the NVMe-oF tests.
+    if hash rxe_cfg 2> /dev/null; then
+        echo "rxe_cfg is already installed. skipping"
+    else
+        if [ -d librxe-dev ]; then
+            echo "librxe-dev source already present, not cloning"
+        else
+            git clone "${GIT_REPO_LIBRXE}"
+        fi
+
+        cd librxe-dev
+        ./configure --libdir=/usr/lib64/ --prefix=
         make -j${jobs}
         sudo make install
         cd ~
-    else
-        echo "custom open-iscsi install located, not reinstalling"
     fi
 fi
 
+if echo $CONF | grep -q iscsi; then
+    # iscsiadm is used in the iscsi_tgt tests
+    # The version of iscsiadm that ships with fedora 26 was broken as of November 3 2017.
+    # There is already a bug report out about it, and hopefully it is fixed soon, but in the event that
+    # that version is still broken when you do your setup, the below steps will fix the issue.
+    CURRENT_VERSION=$(iscsiadm --version)
+    OPEN_ISCSI_VER='iscsiadm version 6.2.0.874'
+    if [ "$CURRENT_VERSION" == "$OPEN_ISCSI_VER" ]; then
+        if [ ! -d open-iscsi-install ]; then
+            mkdir -p open-iscsi-install
+            cd open-iscsi-install
+            sudo dnf download --source iscsi-initiator-utils
+            rpm2cpio $(ls) | cpio -idmv
+            mkdir -p patches
+            mv 00* patches/
+            git clone "${GIT_REPO_OPEN_ISCSI}"
+
+            cd open-iscsi
+
+            # the configurations of username and email are needed for applying patches to iscsiadm.
+            git config user.name none
+            git config user.email none
+
+            git checkout 86e8892
+            for patch in `ls ../patches`; do
+                git am ../patches/$patch
+            done
+            sed -i '427s/.*/-1);/' usr/session_info.c
+            make -j${jobs}
+            sudo make install
+            cd ~
+        else
+            echo "custom open-iscsi install located, not reinstalling"
+        fi
+    fi
+fi
 
 sudo mkdir -p /usr/src
 
-# Rocksdb is installed for use with the blobfs tests.
-if [ ! -d /usr/src/rocksdb ]; then
-    git clone https://review.gerrithub.io/spdk/rocksdb
-    git -C ./rocksdb checkout spdk-v5.6.1
-    sudo mv rocksdb /usr/src/
-else
-    sudo git -C /usr/src/rocksdb checkout spdk-v5.6.1
-    echo "rocksdb already in /usr/src. Not checking out again"
+if echo $CONF | grep -q rocksdb; then
+
+    # Rocksdb is installed for use with the blobfs tests.
+    if [ ! -d /usr/src/rocksdb ]; then
+	git clone "${GIT_REPO_ROCKSDB}"
+        git -C ./rocksdb checkout spdk-v5.6.1
+        sudo mv rocksdb /usr/src/
+    else
+        sudo git -C /usr/src/rocksdb checkout spdk-v5.6.1
+        echo "rocksdb already in /usr/src. Not checking out again"
+    fi
 fi
-if [ ! -d /usr/src/fio ]; then
-    if [ ! -d fio ]; then
-        git clone http://git.kernel.dk/fio.git
-        sudo mv fio /usr/src/
+
+if echo $CONF | grep -q fio; then
+    # This version of fio is installed in /usr/src/fio to enable
+    # building the spdk fio plugin.
+    if [ ! -d /usr/src/fio ]; then
+        if [ ! -d fio ]; then
+            git clone "${GIT_REPO_FIO}"
+            sudo mv fio /usr/src/
+        else
+            sudo mv fio /usr/src/
+        fi
+        (
+            cd /usr/src/fio &&
+            git checkout master &&
+            git pull &&
+            git checkout fio-3.3 &&
+            make -j${jobs} &&
+            sudo make install
+        )
     else
-        sudo mv fio /usr/src/
+        echo "fio already in /usr/src/fio. Not installing"
     fi
-    (
-        cd /usr/src/fio &&
-        git checkout master &&
-        git pull &&
-        git checkout fio-3.3 &&
-        make -j${jobs} &&
-        sudo make install
-    )
-else
-    echo "fio already in /usr/src/fio. Not installing"
 fi
+
 cd ~
 
-if [ ! -d /usr/local/FlameGraph ]; then
-    git clone https://github.com/brendangregg/FlameGraph.git
-    mkdir -p /usr/local
-    sudo mv FlameGraph /usr/local/FlameGraph
-else
-    echo "flamegraph already installed. Skipping"
-fi
-SPDK_QEMU_BRANCH=spdk-2.12-pre
-mkdir -p qemu
-cd qemu
-if [ ! -d "$SPDK_QEMU_BRANCH" ]; then
-    git clone https://github.com/spdk/qemu -b "$SPDK_QEMU_BRANCH" "$SPDK_QEMU_BRANCH"
-else
-    echo "qemu already checked out. Skipping"
+if echo $CONF | grep -q flamegraph; then
+    # Flamegraph is used when printing out timing graphs for the tests.
+    if [ ! -d /usr/local/FlameGraph ]; then
+        git clone "${GIT_REPO_FLAMEGRAPH}"
+        mkdir -p /usr/local
+        sudo mv FlameGraph /usr/local/FlameGraph
+    else
+        echo "flamegraph already installed. Skipping"
+    fi
 fi
-cd "$SPDK_QEMU_BRANCH"
-if hash tsocks &> /dev/null; then
-    git_param="--with-git='tsocks git'"
+
+if echo $CONF | grep -q qemu; then
+    # Qemu is used in the vhost tests.
+    SPDK_QEMU_BRANCH=spdk-2.12-pre
+    mkdir -p qemu
+    cd qemu
+    if [ ! -d "$SPDK_QEMU_BRANCH" ]; then
+        git clone "${GIT_REPO_QEMU}" -b "$SPDK_QEMU_BRANCH" "$SPDK_QEMU_BRANCH"
+    else
+        echo "qemu already checked out. Skipping"
+    fi
+
+    cd "$SPDK_QEMU_BRANCH"
+
+    declare -a opt_params=("--prefix=/usr/local/qemu/$SPDK_QEMU_BRANCH")
+
+    # Most tsocks proxies rely on a configuration file in /etc/tsocks.conf.
+    # If using tsocks, please make sure to complete this config before trying to build qemu.
+    if echo $CONF | grep -q tsocks; then
+        if hash tsocks 2> /dev/null; then
+            opt_params+=(--with-git='tsocks git')
+        fi
+    fi
+
+    ./configure "${opt_params[@]}" --target-list="x86_64-softmmu" --enable-kvm --enable-linux-aio --enable-numa
+
+    make -j${jobs}
+    sudo make install
 fi
-./configure "$git_param" --prefix=/usr/local/qemu/$SPDK_QEMU_BRANCH --target-list="x86_64-softmmu" --enable-kvm --enable-linux-aio --enable-numa
-make -j${jobs}
-sudo make install
-cd ~
 
-# Vector packet processing (VPP) is installed for use with iSCSI tests.
-git clone https://gerrit.fd.io/r/vpp
-cd vpp
-git checkout v18.01.1
-# VPP 18.01.1 does not support OpenSSL 1.1.
-# For compilation, a compatibility package is used temporarily.
-sudo dnf install -y --allowerasing compat-openssl10-devel
-# Installing required dependencies for building VPP
-yes | make install-dep
-
-make pkg-rpm -j${jobs}
-# Reinstall latest OpenSSL devel package.
-sudo dnf install -y --allowerasing openssl-devel
-cd build-root
-sudo dnf install -y \
-		./vpp-lib-18.01.1-release.x86_64.rpm \
-		./vpp-devel-18.01.1-release.x86_64.rpm \
-		./vpp-18.01.1-release.x86_64.rpm
-# Since hugepage configuration is done via spdk/scripts/setup.sh,
-# this default config is not needed.
-#
-# NOTE: Parameters kernel.shmmax and vm.max_map_count are set to
-# very low count and cause issues with hugepage total sizes above 1GB.
-sudo rm -f /etc/sysctl.d/80-vpp.conf
 cd ~
 
-# We currently don't make any changes to the libiscsi repository for our tests, but it is possible that we will need
-# to later. Cloning from git is just future proofing the machines.
-if [ ! -d libiscsi ]; then
-    git clone https://github.com/sahlberg/libiscsi
-else
-    echo "libiscsi already checked out. Skipping"
+if echo $CONF | grep -q vpp; then
+    # Vector packet processing (VPP) is installed for use with iSCSI tests.
+    if [ -d vpp ]; then
+        echo "vpp already cloned."
+        if [ ! -d vpp/build-root ]; then
+            echo "build-root has not been done"
+            echo "remove the `pwd` and start again"
+            exit 1
+        fi
+    else
+        git clone "${GIT_REPO_VPP}"
+        cd vpp
+        git checkout v18.01.1
+        # VPP 18.01.1 does not support OpenSSL 1.1.
+        # For compilation, a compatibility package is used temporarily.
+        sudo dnf install -y --allowerasing compat-openssl10-devel
+        # Installing required dependencies for building VPP
+        yes | make install-dep
+
+        make pkg-rpm -j${jobs}
+        # Reinstall latest OpenSSL devel package.
+        sudo dnf install -y --allowerasing openssl-devel
+        cd build-root
+        sudo dnf install -y \
+            ./vpp-lib-18.01.1-release.x86_64.rpm \
+            ./vpp-devel-18.01.1-release.x86_64.rpm \
+            ./vpp-18.01.1-release.x86_64.rpm
+        # Since hugepage configuration is done via spdk/scripts/setup.sh,
+        # this default config is not needed.
+        #
+        # NOTE: Parameters kernel.shmmax and vm.max_map_count are set to
+        # very low count and cause issues with hugepage total sizes above 1GB.
+        sudo rm -f /etc/sysctl.d/80-vpp.conf
+        cd ~
+    fi
 fi
-cd libiscsi
-./autogen.sh
-./configure --prefix=/usr/local/libiscsi
-make -j${jobs}
-sudo make install
 
+if echo $CONF | grep -q libiscsi; then
+    # We currently don't make any changes to the libiscsi repository for our tests, but it is possible that we will need
+    # to later. Cloning from git is just future proofing the machines.
+    if [ ! -d libiscsi ]; then
+        git clone "${GIT_REPO_LIBISCSI}"
+    else
+        echo "libiscsi already checked out. Skipping"
+    fi
+    cd libiscsi
+    ./autogen.sh
+    ./configure --prefix=/usr/local/libiscsi
+    make -j${jobs}
+    sudo make install
+fi
 
 # create autorun-spdk.conf in home folder. This is sourced by the autotest_common.sh file.
 # By setting any one of the values below to 0, you can skip that specific test. If you are
@@ -239,7 +338,6 @@ if [ ! -e ~/autorun-spdk.conf ]; then
 	cat > ~/autorun-spdk.conf << EOF
 # assign a value of 1 to all of the pertinent tests
 SPDK_BUILD_DOC=1
-SPDK_BUILD_IOAT_KMOD=1
 SPDK_RUN_CHECK_FORMAT=1
 SPDK_RUN_SCANBUILD=1
 SPDK_RUN_VALGRIND=1
@@ -247,6 +345,7 @@ SPDK_TEST_UNITTEST=1
 SPDK_TEST_ISCSI=1
 SPDK_TEST_ISCSI_INITIATOR=1
 SPDK_TEST_NVME=1
+SPDK_TEST_NVME_CLI=1
 SPDK_TEST_NVMF=1
 SPDK_TEST_RBD=1
 # requires some extra configuration. see TEST_ENV_SETUP_README
diff --git a/test/common/lib/test_env.c b/test/common/lib/test_env.c
index e0fcf828c..66c0b9410 100644
--- a/test/common/lib/test_env.c
+++ b/test/common/lib/test_env.c
@@ -36,6 +36,7 @@
 #include "spdk_internal/mock.h"
 
 #include "spdk/env.h"
+#include "spdk/queue.h"
 
 /*
  * NOTE:
@@ -74,17 +75,38 @@ spdk_memzone_reserve(const char *name, size_t len, int socket_id, unsigned flags
 	}
 }
 
+/* setup the mock control to pass thru by default */
+void *ut_p_spdk_memzone_reserve_aligned = MOCK_PASS_THRU_P;
 void *
-spdk_dma_malloc(size_t size, size_t align, uint64_t *phys_addr)
+spdk_memzone_reserve_aligned(const char *name, size_t len, int socket_id,
+			     unsigned flags, unsigned align)
 {
-	void *buf = NULL;
-	if (posix_memalign(&buf, align, size)) {
-		return NULL;
+	if (ut_p_spdk_memzone_reserve_aligned &&
+	    ut_p_spdk_memzone_reserve_aligned == MOCK_PASS_THRU_P) {
+		return malloc(len);
+	} else {
+		return ut_p_spdk_memzone_reserve_aligned;
 	}
-	if (phys_addr) {
-		*phys_addr = (uint64_t)buf;
+}
+
+int ut_spdk_dma_malloc = (int)MOCK_PASS_THRU;
+void *ut_p_spdk_dma_malloc = &ut_spdk_dma_malloc;
+void *
+spdk_dma_malloc(size_t size, size_t align, uint64_t *phys_addr)
+{
+	if (ut_p_spdk_dma_malloc &&
+	    ut_spdk_dma_malloc == (int)MOCK_PASS_THRU) {
+		void *buf = NULL;
+		if (posix_memalign(&buf, align, size)) {
+			return NULL;
+		}
+		if (phys_addr) {
+			*phys_addr = (uint64_t)buf;
+		}
+		return buf;
+	} else {
+		return ut_p_spdk_dma_malloc;
 	}
-	return buf;
 }
 
 int ut_spdk_dma_zmalloc = (int)MOCK_PASS_THRU;
@@ -212,6 +234,14 @@ spdk_mempool_put(struct spdk_mempool *_mp, void *ele)
 	free(ele);
 }
 
+void
+spdk_mempool_put_bulk(struct spdk_mempool *mp, void **ele_arr, size_t count)
+{
+	for (size_t i = 0; i < count; i++) {
+		spdk_mempool_put(mp, ele_arr[i]);
+	}
+}
+
 size_t
 spdk_mempool_count(const struct spdk_mempool *_mp)
 {
@@ -224,6 +254,78 @@ spdk_mempool_count(const struct spdk_mempool *_mp)
 	}
 }
 
+struct spdk_ring_ele {
+	void *ele;
+	TAILQ_ENTRY(spdk_ring_ele) link;
+};
+
+struct spdk_ring {
+	TAILQ_HEAD(, spdk_ring_ele) elements;
+};
+
+struct spdk_ring *
+spdk_ring_create(enum spdk_ring_type type, size_t count, int socket_id)
+{
+	struct spdk_ring *ring;
+
+	ring = calloc(1, sizeof(*ring));
+	if (ring) {
+		TAILQ_INIT(&ring->elements);
+	}
+
+	return ring;
+}
+
+
+void
+spdk_ring_free(struct spdk_ring *ring)
+{
+	free(ring);
+}
+
+size_t
+spdk_ring_enqueue(struct spdk_ring *ring, void **objs, size_t count)
+{
+	struct spdk_ring_ele *ele;
+	size_t i;
+
+	for (i = 0; i < count; i++) {
+		ele = calloc(1, sizeof(*ele));
+		if (!ele) {
+			break;
+		}
+
+		ele->ele = objs[i];
+		TAILQ_INSERT_TAIL(&ring->elements, ele, link);
+	}
+
+	return i;
+}
+
+size_t
+spdk_ring_dequeue(struct spdk_ring *ring, void **objs, size_t count)
+{
+	struct spdk_ring_ele *ele, *tmp;
+	size_t i = 0;
+
+	if (count == 0) {
+		return 0;
+	}
+
+	TAILQ_FOREACH_SAFE(ele, &ring->elements, link, tmp) {
+		TAILQ_REMOVE(&ring->elements, ele, link);
+		objs[i] = ele->ele;
+		free(ele);
+		i++;
+		if (i >= count) {
+			break;
+		}
+	}
+
+	return i;
+
+}
+
 uint64_t ut_tsc = 0;
 uint64_t spdk_get_ticks(void)
 {
@@ -316,9 +418,3 @@ spdk_pci_addr_compare(const struct spdk_pci_addr *a1, const struct spdk_pci_addr
 
 	return 0;
 }
-
-uint32_t
-spdk_env_get_core_count(void)
-{
-	return 1;
-}
diff --git a/test/common/lib/ut_multithread.c b/test/common/lib/ut_multithread.c
index 724186fdb..71c164819 100644
--- a/test/common/lib/ut_multithread.c
+++ b/test/common/lib/ut_multithread.c
@@ -32,7 +32,7 @@
  */
 
 #include "spdk_cunit.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk_internal/mock.h"
 
 static uint32_t g_ut_num_threads;
@@ -226,7 +226,7 @@ poll_thread(uintptr_t thread_id)
 		poller = TAILQ_FIRST(&thread->pollers);
 		TAILQ_REMOVE(&thread->pollers, poller, tailq);
 
-		while (g_current_time_in_us >= poller->next_expiration_in_us) {
+		if (g_current_time_in_us >= poller->next_expiration_in_us) {
 			if (poller->fn) {
 				poller->fn(poller->arg);
 			}
diff --git a/test/env/Makefile b/test/env/Makefile
index e340bd6ab..d90696a10 100644
--- a/test/env/Makefile
+++ b/test/env/Makefile
@@ -34,7 +34,13 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = memory pci vtophys
+ENV_NAME := $(notdir $(CONFIG_ENV))
+
+DIRS-y = vtophys
+
+ifeq ($(ENV_NAME),env_dpdk)
+DIRS-y += memory pci
+endif
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/test/env/memory/memory_ut.c b/test/env/memory/memory_ut.c
index 369af98c8..d1cf58eec 100644
--- a/test/env/memory/memory_ut.c
+++ b/test/env/memory/memory_ut.c
@@ -50,6 +50,16 @@ rte_eal_get_configuration(void)
 	return &g_cfg;
 }
 
+#if RTE_VERSION >= RTE_VERSION_NUM(18, 05, 0, 0)
+typedef void (*rte_mem_event_callback_t)(enum rte_mem_event event_type,
+		const void *addr, size_t len, void *arg);
+typedef int (*rte_memseg_contig_walk_t)(const struct rte_memseg_list *msl,
+					const struct rte_memseg *ms, size_t len, void *arg);
+DEFINE_STUB(rte_mem_event_callback_register, int, (const char *name, rte_mem_event_callback_t clb,
+		void *arg), 0);
+DEFINE_STUB(rte_memseg_contig_walk, int, (rte_memseg_contig_walk_t func, void *arg), 0);
+#endif
+
 #define PAGE_ARRAY_SIZE (100)
 static struct spdk_bit_array *g_page_array;
 
@@ -115,7 +125,7 @@ test_mem_map_translation(void)
 	SPDK_CU_ASSERT_FATAL(map != NULL);
 
 	/* Try to get translation for address with no translation */
-	addr = spdk_mem_map_translate(map, 10);
+	addr = spdk_mem_map_translate(map, 10, VALUE_2MB);
 	CU_ASSERT(addr == default_translation);
 
 	/* Set translation for region of non-2MB multiple size */
@@ -139,15 +149,15 @@ test_mem_map_translation(void)
 	CU_ASSERT(rc == 0);
 
 	/* Get translation for first page */
-	addr = spdk_mem_map_translate(map, 0);
+	addr = spdk_mem_map_translate(map, 0, VALUE_2MB);
 	CU_ASSERT(addr == 0);
 
 	/* Verify translation for 2nd page is the default */
-	addr = spdk_mem_map_translate(map, VALUE_2MB);
+	addr = spdk_mem_map_translate(map, VALUE_2MB, VALUE_2MB);
 	CU_ASSERT(addr == default_translation);
 
 	/* Get translation for third page */
-	addr = spdk_mem_map_translate(map, 2 * VALUE_2MB);
+	addr = spdk_mem_map_translate(map, 2 * VALUE_2MB, VALUE_2MB);
 	/*
 	 * Note that addr should be 0, not 4MB. When we set the
 	 * translation above, we said the whole 6MB region
@@ -160,7 +170,7 @@ test_mem_map_translation(void)
 	CU_ASSERT(rc == 0);
 
 	/* Get translation for the first page */
-	addr = spdk_mem_map_translate(map, 0);
+	addr = spdk_mem_map_translate(map, 0, VALUE_2MB);
 	CU_ASSERT(addr == default_translation);
 
 	/* Clear translation for the third page */
@@ -168,9 +178,25 @@ test_mem_map_translation(void)
 	CU_ASSERT(rc == 0);
 
 	/* Get translation for the third page */
-	addr = spdk_mem_map_translate(map, 2 * VALUE_2MB);
+	addr = spdk_mem_map_translate(map, 2 * VALUE_2MB, VALUE_2MB);
 	CU_ASSERT(addr == default_translation);
 
+	/* Set translation for the last valid 2MB region */
+	rc = spdk_mem_map_set_translation(map, 0xffffffe00000ULL, VALUE_2MB, 0x1234);
+	CU_ASSERT(rc == 0);
+
+	/* Verify translation for last valid 2MB region */
+	addr = spdk_mem_map_translate(map, 0xffffffe00000ULL, VALUE_2MB);
+	CU_ASSERT(addr == 0x1234);
+
+	/* Attempt to set translation for the first invalid address */
+	rc = spdk_mem_map_set_translation(map, 0x1000000000000ULL, VALUE_2MB, 0x5678);
+	CU_ASSERT(rc == -EINVAL);
+
+	/* Attempt to set translation starting at a valid address but exceeding the valid range */
+	rc = spdk_mem_map_set_translation(map, 0xffffffe00000ULL, VALUE_2MB * 2, 0x123123);
+	CU_ASSERT(rc != 0);
+
 	spdk_mem_map_free(&map);
 	CU_ASSERT(map == NULL);
 }
diff --git a/test/event/event_perf/Makefile b/test/event/event_perf/Makefile
index 8cd9c8a3e..a3aef2ea0 100644
--- a/test/event/event_perf/Makefile
+++ b/test/event/event_perf/Makefile
@@ -38,7 +38,7 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 APP = event_perf
 C_SRCS := event_perf.c
 
-SPDK_LIB_LIST = event trace conf util log rpc jsonrpc json
+SPDK_LIB_LIST = event trace conf thread util log rpc jsonrpc json
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/test/event/reactor/Makefile b/test/event/reactor/Makefile
index bab970cf2..c5a6168a7 100644
--- a/test/event/reactor/Makefile
+++ b/test/event/reactor/Makefile
@@ -38,7 +38,7 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 APP = reactor
 C_SRCS := reactor.c
 
-SPDK_LIB_LIST = event trace conf util log rpc jsonrpc json
+SPDK_LIB_LIST = event trace conf thread util log rpc jsonrpc json
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/test/event/reactor/reactor.c b/test/event/reactor/reactor.c
index bd94303c9..d79f94baa 100644
--- a/test/event/reactor/reactor.c
+++ b/test/event/reactor/reactor.c
@@ -34,7 +34,7 @@
 #include "spdk/stdinc.h"
 
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 static int g_time_in_sec;
 static struct spdk_poller *test_end_poller;
diff --git a/test/event/reactor_perf/Makefile b/test/event/reactor_perf/Makefile
index 4b19e52fb..820a6042a 100644
--- a/test/event/reactor_perf/Makefile
+++ b/test/event/reactor_perf/Makefile
@@ -38,7 +38,7 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 APP = reactor_perf
 C_SRCS := reactor_perf.c
 
-SPDK_LIB_LIST = event trace conf util log rpc jsonrpc json
+SPDK_LIB_LIST = event trace conf thread util log rpc jsonrpc json
 
 LIBS += $(SPDK_LIB_LINKER_ARGS) $(ENV_LINKER_ARGS)
 
diff --git a/test/event/reactor_perf/reactor_perf.c b/test/event/reactor_perf/reactor_perf.c
index df9680988..357f9038a 100644
--- a/test/event/reactor_perf/reactor_perf.c
+++ b/test/event/reactor_perf/reactor_perf.c
@@ -35,7 +35,7 @@
 
 #include "spdk/env.h"
 #include "spdk/event.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 static int g_time_in_sec;
 static int g_queue_depth;
diff --git a/test/ioat/ioat.sh b/test/ioat/ioat.sh
index f70db5523..b15f635e8 100755
--- a/test/ioat/ioat.sh
+++ b/test/ioat/ioat.sh
@@ -16,16 +16,5 @@ timing_enter verify
 $rootdir/examples/ioat/verify/verify -t 1
 timing_exit verify
 
-if [ `uname` = Linux ]; then
-	timing_enter kperf
-	$rootdir/scripts/setup.sh reset
-	insmod $rootdir/examples/ioat/kperf/kmod/dmaperf.ko
-	$rootdir/examples/ioat/kperf/ioat_kperf -n 4 -q 4 -s 12 -t 32
-	rmmod dmaperf.ko
-	$rootdir/scripts/setup.sh
-	report_test_completion "ioat_kperf"
-	timing_exit kperf
-fi
-
 report_test_completion "ioat"
 timing_exit ioat
diff --git a/test/iscsi_tgt/calsoft/calsoft.sh b/test/iscsi_tgt/calsoft/calsoft.sh
index e50a4129b..13b844796 100755
--- a/test/iscsi_tgt/calsoft/calsoft.sh
+++ b/test/iscsi_tgt/calsoft/calsoft.sh
@@ -4,6 +4,11 @@ rootdir=$(readlink -f $testdir/../../..)
 source $rootdir/test/common/autotest_common.sh
 source $rootdir/test/iscsi_tgt/common.sh
 
+delete_tmp_conf_files() {
+	rm -f /usr/local/etc/its.conf
+	rm -f /usr/local/etc/auth.conf
+}
+
 if [ ! -d /usr/local/calsoft ]; then
 	echo "skipping calsoft tests"
 	exit 0
@@ -31,7 +36,7 @@ $ISCSI_APP -c $testdir/iscsi.conf -m 0x1 &
 pid=$!
 echo "Process pid: $pid"
 
-trap "killprocess $pid; exit 1 " SIGINT SIGTERM EXIT
+trap "killprocess $pid; delete_tmp_conf_files; exit 1 " SIGINT SIGTERM EXIT
 
 waitforlisten $pid
 echo "iscsi_tgt is listening. Running tests..."
@@ -59,5 +64,6 @@ fi
 trap - SIGINT SIGTERM EXIT
 
 killprocess $pid
+delete_tmp_conf_files
 timing_exit calsoft
 exit $failed
diff --git a/test/iscsi_tgt/common.sh b/test/iscsi_tgt/common.sh
index 30fbb3ee7..1928449b5 100644
--- a/test/iscsi_tgt/common.sh
+++ b/test/iscsi_tgt/common.sh
@@ -16,9 +16,12 @@ ISCSI_APP="$TARGET_NS_CMD ./app/iscsi_tgt/iscsi_tgt -i 0"
 ISCSI_TEST_CORE_MASK=0xFF
 
 function create_veth_interfaces() {
+	# $1 = test type (posix/vpp)
 	ip netns del $TARGET_NAMESPACE || true
 	ip link delete $INITIATOR_INTERFACE || true
 
+	trap "cleanup_veth_interfaces $1; exit 1" SIGINT SIGTERM EXIT
+
 	# Create veth (Virtual ethernet) interface pair
 	ip link add $INITIATOR_INTERFACE type veth peer name $TARGET_INTERFACE
 	ip addr add $INITIATOR_IP/24 dev $INITIATOR_INTERFACE
@@ -32,10 +35,14 @@ function create_veth_interfaces() {
 	$TARGET_NS_CMD ip addr add $TARGET_IP/24 dev $TARGET_INTERFACE
 	$TARGET_NS_CMD ip link set $TARGET_INTERFACE up
 
-	trap "cleanup_veth_interfaces; exit 1" SIGINT SIGTERM EXIT
+	# Verify connectivity
+	ping -c 1 $TARGET_IP
+	ip netns exec $TARGET_NAMESPACE ping -c 1 $INITIATOR_IP
 }
 
 function cleanup_veth_interfaces() {
+	# $1 = test type (posix/vpp)
+
 	# Cleanup veth interfaces and network namespace
 	# Note: removing one veth, removes the pair
 	ip link delete $INITIATOR_INTERFACE
diff --git a/test/iscsi_tgt/ext4test/ext4test.sh b/test/iscsi_tgt/ext4test/ext4test.sh
index b90dfc363..ce63eb9b1 100755
--- a/test/iscsi_tgt/ext4test/ext4test.sh
+++ b/test/iscsi_tgt/ext4test/ext4test.sh
@@ -23,7 +23,7 @@ $ISCSI_APP -c $testdir/iscsi.conf &
 pid=$!
 echo "Process pid: $pid"
 
-trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+trap "killprocess $pid; rm -f $testdir/iscsi.conf; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
 echo "iscsi_tgt is listening. Running tests..."
@@ -43,7 +43,7 @@ iscsiadm -m discovery -t sendtargets -p $TARGET_IP:$ISCSI_PORT
 iscsiadm -m node --login -p $TARGET_IP:$ISCSI_PORT
 
 trap 'for new_dir in `dir -d /mnt/*dir`; do umount $new_dir; rm -rf $new_dir; done; \
-	iscsicleanup; killprocess $pid; exit 1' SIGINT SIGTERM EXIT
+	iscsicleanup; killprocess $pid; rm -f $testdir/iscsi.conf; exit 1' SIGINT SIGTERM EXIT
 
 sleep 1
 
@@ -117,6 +117,7 @@ trap - SIGINT SIGTERM EXIT
 
 rm -f $testdir/iscsi.conf
 iscsicleanup
+$rpc_py delete_error_bdev EE_Malloc0
 killprocess $pid
 report_test_completion "nightly_iscsi_ext4test"
 timing_exit ext4test
diff --git a/test/iscsi_tgt/filesystem/filesystem.sh b/test/iscsi_tgt/filesystem/filesystem.sh
index f43b0e99c..1ec388899 100755
--- a/test/iscsi_tgt/filesystem/filesystem.sh
+++ b/test/iscsi_tgt/filesystem/filesystem.sh
@@ -125,7 +125,7 @@ rm -rf /mnt/device
 
 trap - SIGINT SIGTERM EXIT
 
-remove_backends
 iscsicleanup
+remove_backends
 killprocess $pid
 timing_exit filesystem
diff --git a/test/iscsi_tgt/fio/fio.sh b/test/iscsi_tgt/fio/fio.sh
index 13337fa90..093d9695c 100755
--- a/test/iscsi_tgt/fio/fio.sh
+++ b/test/iscsi_tgt/fio/fio.sh
@@ -5,6 +5,11 @@ rootdir=$(readlink -f $testdir/../../..)
 source $rootdir/test/common/autotest_common.sh
 source $rootdir/test/iscsi_tgt/common.sh
 
+delete_tmp_files() {
+	rm -f $testdir/iscsi.conf
+	rm -f ./local-job0-0-verify.state
+}
+
 function running_config() {
 	# generate a config file from the running iscsi_tgt
 	#  running_config.sh will leave the file at /tmp/iscsi.conf
@@ -15,14 +20,14 @@ function running_config() {
 	# keep the same iscsiadm configuration to confirm that the
 	#  config file matched the running configuration
 	killprocess $pid
-	trap "iscsicleanup; exit 1" SIGINT SIGTERM EXIT
+	trap "iscsicleanup; delete_tmp_files; exit 1" SIGINT SIGTERM EXIT
 
 	timing_enter start_iscsi_tgt2
 
 	$ISCSI_APP -c /tmp/iscsi.conf &
 	pid=$!
 	echo "Process pid: $pid"
-	trap "iscsicleanup; killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+	trap "iscsicleanup; killprocess $pid; delete_tmp_files; exit 1" SIGINT SIGTERM EXIT
 	waitforlisten $pid
 	echo "iscsi_tgt is listening. Running tests..."
 
@@ -58,7 +63,7 @@ $ISCSI_APP -c $testdir/iscsi.conf &
 pid=$!
 echo "Process pid: $pid"
 
-trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+trap "killprocess $pid; rm -f $testdir/iscsi.conf; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
 echo "iscsi_tgt is listening. Running tests..."
@@ -78,7 +83,7 @@ sleep 1
 iscsiadm -m discovery -t sendtargets -p $TARGET_IP:$ISCSI_PORT
 iscsiadm -m node --login -p $TARGET_IP:$ISCSI_PORT
 
-trap "iscsicleanup; killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+trap "iscsicleanup; killprocess $pid; delete_tmp_files; exit 1" SIGINT SIGTERM EXIT
 
 sleep 1
 $fio_py 4096 1 randrw 1 verify
@@ -100,19 +105,17 @@ fio_pid=$!
 
 sleep 3
 set +e
-$rpc_py delete_bdev 'Malloc0'
+$rpc_py delete_malloc_bdev 'Malloc0'
 
 wait $fio_pid
 fio_status=$?
 
 if [ $fio_status -eq 0 ]; then
-       echo "iscsi hotplug test: fio successful - expected failure"
-       iscsicleanup
-       rm -f $testdir/iscsi.conf
-       killprocess $pid
-       exit 1
+	echo "iscsi hotplug test: fio successful - expected failure"
+	set -e
+	exit 1
 else
-       echo "iscsi hotplug test: fio failed as expected"
+	echo "iscsi hotplug test: fio failed as expected"
 fi
 
 set -e
@@ -120,10 +123,10 @@ set -e
 iscsicleanup
 $rpc_py delete_target_node 'iqn.2016-06.io.spdk:Target3'
 
-rm -f ./local-job0-0-verify.state
+delete_tmp_files
+
 trap - SIGINT SIGTERM EXIT
-iscsicleanup
-rm -f $testdir/iscsi.conf
+
 killprocess $pid
 #echo 1 > /sys/bus/pci/rescan
 #sleep 2
diff --git a/test/iscsi_tgt/initiator/bdev.conf.in b/test/iscsi_tgt/initiator/bdev.conf.in
index f23f7e478..09094ea82 100644
--- a/test/iscsi_tgt/initiator/bdev.conf.in
+++ b/test/iscsi_tgt/initiator/bdev.conf.in
@@ -1,2 +1,2 @@
 [Ioat]
-  Disable Yes
+  Enable No
diff --git a/test/iscsi_tgt/initiator/initiator.sh b/test/iscsi_tgt/initiator/initiator.sh
index dbdfde05b..3197533fb 100755
--- a/test/iscsi_tgt/initiator/initiator.sh
+++ b/test/iscsi_tgt/initiator/initiator.sh
@@ -34,7 +34,7 @@ $rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE
 # "-d" ==> disable CHAP authentication
 $rpc_py construct_target_node disk1 disk1_alias 'Malloc0:0' $PORTAL_TAG:$INITIATOR_TAG 256 -d
 sleep 1
-trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+trap "killprocess $pid; rm -f $testdir/bdev.conf; exit 1" SIGINT SIGTERM EXIT
 
 # Prepare config file for iSCSI initiator
 cp $testdir/bdev.conf.in $testdir/bdev.conf
diff --git a/test/iscsi_tgt/iscsi_tgt.sh b/test/iscsi_tgt/iscsi_tgt.sh
index fdfd9c4a1..a8c9ce49d 100755
--- a/test/iscsi_tgt/iscsi_tgt.sh
+++ b/test/iscsi_tgt/iscsi_tgt.sh
@@ -11,8 +11,16 @@ source $rootdir/test/iscsi_tgt/common.sh
 
 timing_enter iscsi_tgt
 
+# $1 = test type (posix/vpp)
+if [ "$1" == "posix" ] || [ "$1" == "vpp" ]; then
+	TEST_TYPE=$1
+else
+	echo "No iSCSI test type specified"
+	exit 1
+fi
+
 # Network configuration
-create_veth_interfaces
+create_veth_interfaces $TEST_TYPE
 
 # ISCSI_TEST_CORE_MASK is the biggest core mask specified by
 #  any of the iscsi_tgt tests.  Using this mask for the stub
@@ -22,14 +30,15 @@ create_veth_interfaces
 #  core 0) so there is no impact to the iscsi_tgt tests by
 #  specifying the bigger core mask.
 start_stub "-s 2048 -i 0 -m $ISCSI_TEST_CORE_MASK"
-trap "kill_stub; cleanup_veth_interfaces; exit 1" SIGINT SIGTERM EXIT
+trap "kill_stub; cleanup_veth_interfaces $TEST_TYPE; exit 1" SIGINT SIGTERM EXIT
 
 run_test ./test/iscsi_tgt/calsoft/calsoft.sh
 run_test ./test/iscsi_tgt/filesystem/filesystem.sh
 run_test ./test/iscsi_tgt/reset/reset.sh
-run_test ./test/iscsi_tgt/rpc_config/rpc_config.sh
+run_test ./test/iscsi_tgt/rpc_config/rpc_config.sh $TEST_TYPE
 run_test ./test/iscsi_tgt/lvol/iscsi_lvol.sh
 run_test ./test/iscsi_tgt/fio/fio.sh
+run_test ./test/iscsi_tgt/qos/qos.sh
 
 if [ $RUN_NIGHTLY -eq 1 ]; then
 	if [ $SPDK_TEST_PMDK -eq 1 ]; then
@@ -43,7 +52,7 @@ if [ $SPDK_TEST_RBD -eq 1 ]; then
 	run_test ./test/iscsi_tgt/rbd/rbd.sh
 fi
 
-trap "cleanup_veth_interfaces; exit 1" SIGINT SIGTERM EXIT
+trap "cleanup_veth_interfaces $TEST_TYPE; exit 1" SIGINT SIGTERM EXIT
 kill_stub
 
 if [ $SPDK_TEST_NVMF -eq 1 ]; then
@@ -61,6 +70,6 @@ if [ $SPDK_TEST_ISCSI_INITIATOR -eq 1 ]; then
 	run_test ./test/iscsi_tgt/initiator/initiator.sh
 fi
 
-cleanup_veth_interfaces
+cleanup_veth_interfaces $TEST_TYPE
 trap - SIGINT SIGTERM EXIT
 timing_exit iscsi_tgt
diff --git a/test/iscsi_tgt/iscsijson/json_config.sh b/test/iscsi_tgt/iscsijson/json_config.sh
new file mode 100755
index 000000000..ea4668086
--- /dev/null
+++ b/test/iscsi_tgt/iscsijson/json_config.sh
@@ -0,0 +1,43 @@
+#!/usr/bin/env bash
+set -xe
+ISCSI_JSON_DIR=$(readlink -f $(dirname $0))
+. $ISCSI_JSON_DIR/../../json_config/common.sh
+. $JSON_DIR/../iscsi_tgt/common.sh
+base_iscsi_config=$JSON_DIR/base_iscsi_config.json
+last_iscsi_config=$JSON_DIR/last_iscsi_config.json
+rpc_py="$spdk_rpc_py"
+clear_config_py="$spdk_clear_config_py"
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"; rm -f $base_iscsi_config $last_iscsi_config' ERR
+
+timing_enter iscsi_json_config
+run_spdk_tgt
+$rpc_py start_subsystem_init
+
+timing_enter iscsi_json_config_create_setup
+$rpc_py add_portal_group $PORTAL_TAG 127.0.0.1:$ISCSI_PORT
+$rpc_py add_initiator_group $INITIATOR_TAG $INITIATOR_NAME $NETMASK
+$rpc_py construct_malloc_bdev 64 4096 --name Malloc0
+$rpc_py construct_target_node Target3 Target3_alias 'Malloc0:0' $PORTAL_TAG:$INITIATOR_TAG 64 -d
+$rpc_py save_config -f $base_iscsi_config
+timing_exit iscsi_json_config_create_setup
+
+timing_enter iscsi_json_config_test
+test_json_config
+timing_exit iscsi_json_config_test
+
+timing_enter iscsi_json_config_restart_spdk
+$clear_config_py clear_config
+kill_targets
+run_spdk_tgt
+$rpc_py load_config -f $base_iscsi_config
+$rpc_py save_config -f $last_iscsi_config
+timing_exit iscsi_json_config_restart_spdk
+
+diff $base_iscsi_config $last_iscsi_config
+
+$clear_config_py clear_config
+kill_targets
+rm -f $base_iscsi_config $last_iscsi_config
+
+timing_exit iscsi_json_config
+report_test_completion iscsi_json_config
diff --git a/test/iscsi_tgt/multiconnection/multiconnection.sh b/test/iscsi_tgt/multiconnection/multiconnection.sh
index 464973039..08fd0460c 100755
--- a/test/iscsi_tgt/multiconnection/multiconnection.sh
+++ b/test/iscsi_tgt/multiconnection/multiconnection.sh
@@ -86,10 +86,10 @@ $fio_py 262144 16 randwrite 10
 sync
 
 trap - SIGINT SIGTERM EXIT
-remove_backends
 
 rm -f $testdir/iscsi.conf
 rm -f ./local-job*
 iscsicleanup
+remove_backends
 killprocess $iscsipid
 timing_exit multiconnection
diff --git a/test/iscsi_tgt/nvme_remote/fio_remote_nvme.sh b/test/iscsi_tgt/nvme_remote/fio_remote_nvme.sh
index 1d1e4d0d7..01df214fe 100755
--- a/test/iscsi_tgt/nvme_remote/fio_remote_nvme.sh
+++ b/test/iscsi_tgt/nvme_remote/fio_remote_nvme.sh
@@ -31,6 +31,7 @@ function run_nvme_remote() {
 
 	if [ "$1" = "remote" ]; then
 		echo "[NVMe]" >> $testdir/iscsi.conf.tmp
+		echo "  HostNQN nqn.2016-06.io.spdk:host1" >> $testdir/iscsi.conf.tmp
 		echo "  TransportID \"trtype:RDMA adrfam:ipv4 traddr:$NVMF_FIRST_TARGET_IP trsvcid:4420 subnqn:nqn.2016-06.io.spdk:cnode1\" Nvme0" >> $testdir/iscsi.conf.tmp
 	fi
 	# Start the iSCSI target without using stub
@@ -39,7 +40,7 @@ function run_nvme_remote() {
 	$ISCSI_APP -r "$iscsi_rpc_addr" -c $testdir/iscsi.conf.tmp -m 0x1 -p 0 -s 512 &
 	iscsipid=$!
 	echo "iSCSI target launched. pid: $iscsipid"
-	trap "killprocess $iscsipid; killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
+	trap "killprocess $iscsipid; killprocess $nvmfpid; rm -f $testdir/iscsi.conf.tmp; exit 1" SIGINT SIGTERM EXIT
 	waitforlisten $iscsipid "$iscsi_rpc_addr"
 	echo "iSCSI target has started."
 
@@ -66,7 +67,7 @@ NVMF_APP="$rootdir/app/nvmf_tgt/nvmf_tgt"
 $NVMF_APP -c $rootdir/test/nvmf/nvmf.conf -m 0x2 -p 1 -s 512 &
 nvmfpid=$!
 echo "NVMf target launched. pid: $nvmfpid"
-trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
+trap "killprocess $nvmfpid; rm -f $testdir/iscsi.conf.tmp; exit 1" SIGINT SIGTERM EXIT
 waitforlisten $nvmfpid
 echo "NVMf target has started."
 bdevs=$($rpc_py construct_malloc_bdev 64 512)
@@ -77,7 +78,8 @@ timing_enter start_iscsi_tgt
 
 run_nvme_remote "local"
 
-trap "iscsicleanup; killprocess $iscsipid; killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
+trap "iscsicleanup; killprocess $iscsipid; killprocess $nvmfpid; rm -f $testdir/iscsi.conf.tmp; \
+	rm -f ./local-job0-0-verify.state; exit 1" SIGINT SIGTERM EXIT
 sleep 1
 
 echo "Running FIO"
diff --git a/test/iscsi_tgt/pmem/iscsi_pmem.sh b/test/iscsi_tgt/pmem/iscsi_pmem.sh
index 930bd558d..5d2bb2781 100755
--- a/test/iscsi_tgt/pmem/iscsi_pmem.sh
+++ b/test/iscsi_tgt/pmem/iscsi_pmem.sh
@@ -58,7 +58,7 @@ timing_exit fio_test
 iscsicleanup
 
 for pmem in $PMEM_BDEVS; do
-	$rpc_py delete_bdev $pmem
+	$rpc_py delete_pmem_bdev $pmem
 done
 
 for i in `seq 1 $TGT_NR`; do
diff --git a/test/iscsi_tgt/qos/qos.sh b/test/iscsi_tgt/qos/qos.sh
new file mode 100755
index 000000000..04b34a7ae
--- /dev/null
+++ b/test/iscsi_tgt/qos/qos.sh
@@ -0,0 +1,94 @@
+#!/usr/bin/env bash
+
+testdir=$(readlink -f $(dirname $0))
+rootdir=$(readlink -f $testdir/../../..)
+source $rootdir/test/common/autotest_common.sh
+source $rootdir/test/iscsi_tgt/common.sh
+
+function check_qos_works_well() {
+	local enable_limit=$1
+	local iops_limit=$2/1000
+	local retval=0
+	local read_iops=$($fio_py 8192 64 randread 5 | grep "\(read: IOPS=\|write: IOPS=\)" \
+		| awk -F, '{print $1}' | awk -F= '{print $2}' | tr -d [k])
+	if [ $enable_limit = true ]; then
+		retval=$(echo "$iops_limit*0.9 < $read_iops && $read_iops < $iops_limit*1.01" | bc)
+		if [ $retval -eq 0 ]; then
+			echo "Failed to limit the io read rate of malloc bdev by qos"
+			exit 1
+		fi
+	else
+		retval=$(echo "$read_iops > $iops_limit" | bc)
+		if [ $retval -eq 0 ]; then
+			echo "$read_iops less than $iops_limit - expected greater than"
+			exit 1
+		fi
+	fi
+}
+
+if [ -z "$TARGET_IP" ]; then
+	echo "TARGET_IP not defined in environment"
+	exit 1
+fi
+
+if [ -z "$INITIATOR_IP" ]; then
+	echo "INITIATOR_IP not defined in environment"
+	exit 1
+fi
+
+timing_enter qos
+
+MALLOC_BDEV_SIZE=64
+MALLOC_BLOCK_SIZE=4096
+IOPS_LIMIT=20000
+rpc_py="python $rootdir/scripts/rpc.py"
+fio_py="python $rootdir/scripts/fio.py"
+
+timing_enter start_iscsi_tgt
+
+$ISCSI_APP &
+pid=$!
+echo "Process pid: $pid"
+trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+waitforlisten $pid
+echo "iscsi_tgt is listening. Running tests..."
+
+timing_exit start_iscsi_tgt
+
+$rpc_py add_portal_group $PORTAL_TAG $TARGET_IP:$ISCSI_PORT
+$rpc_py add_initiator_group $INITIATOR_TAG $INITIATOR_NAME $NETMASK
+$rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE
+# "Malloc0:0" ==> use Malloc0 blockdev for LUN0
+# "1:2" ==> map PortalGroup1 to InitiatorGroup2
+# "64" ==> iSCSI queue depth 64
+# "-d" ==> disable CHAP authentication
+$rpc_py construct_target_node Target1 Target1_alias 'Malloc0:0' $PORTAL_TAG:$INITIATOR_TAG 64 -d
+sleep 1
+
+iscsiadm -m discovery -t sendtargets -p $TARGET_IP:$ISCSI_PORT
+iscsiadm -m node --login -p $TARGET_IP:$ISCSI_PORT
+
+trap "iscsicleanup; killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+
+# Limit the I/O rate by RPC, then confirm the observed rate matches.
+$rpc_py set_bdev_qos_limit_iops Malloc0 $IOPS_LIMIT
+check_qos_works_well true $IOPS_LIMIT
+
+# Now disable the rate limiting, and confirm the observed rate is not limited anymore.
+$rpc_py set_bdev_qos_limit_iops Malloc0 0
+check_qos_works_well false $IOPS_LIMIT
+
+# Limit the I/O rate again.
+$rpc_py set_bdev_qos_limit_iops Malloc0 $IOPS_LIMIT
+check_qos_works_well true $IOPS_LIMIT
+echo "I/O rate limiting tests successful"
+
+iscsicleanup
+$rpc_py delete_target_node 'iqn.2016-06.io.spdk:Target1'
+
+rm -f ./local-job0-0-verify.state
+rm -f $testdir/iscsi.conf
+trap - SIGINT SIGTERM EXIT
+killprocess $pid
+
+timing_exit qos
diff --git a/test/iscsi_tgt/rbd/rbd.sh b/test/iscsi_tgt/rbd/rbd.sh
index 4abb73e76..53547e2a4 100755
--- a/test/iscsi_tgt/rbd/rbd.sh
+++ b/test/iscsi_tgt/rbd/rbd.sh
@@ -34,7 +34,7 @@ timing_exit start_iscsi_tgt
 
 $rpc_py add_portal_group $PORTAL_TAG $TARGET_IP:$ISCSI_PORT
 $rpc_py add_initiator_group $INITIATOR_TAG $INITIATOR_NAME $NETMASK
-$rpc_py construct_rbd_bdev $RBD_POOL $RBD_NAME 4096
+rbd_bdev="$($rpc_py construct_rbd_bdev $RBD_POOL $RBD_NAME 4096)"
 $rpc_py get_bdevs
 # "Ceph0:0" ==> use Ceph0 blockdev for LUN0
 # "1:2" ==> map PortalGroup1 to InitiatorGroup2
@@ -57,6 +57,7 @@ rm -f ./local-job0-0-verify.state
 trap - SIGINT SIGTERM EXIT
 
 iscsicleanup
+$rpc_py delete_rbd_bdev $rbd_bdev
 killprocess $pid
 rbd_cleanup
 
diff --git a/test/iscsi_tgt/rpc_config/rpc_config.py b/test/iscsi_tgt/rpc_config/rpc_config.py
index 404c25b3e..0af4ab39f 100755
--- a/test/iscsi_tgt/rpc_config/rpc_config.py
+++ b/test/iscsi_tgt/rpc_config/rpc_config.py
@@ -10,12 +10,13 @@ import json
 import random
 from subprocess import check_call, call, check_output, Popen, PIPE, CalledProcessError
 
-if (len(sys.argv) == 7):
+if (len(sys.argv) == 8):
     target_ip = sys.argv[2]
     initiator_ip = sys.argv[3]
     port = sys.argv[4]
     netmask = sys.argv[5]
     namespace = sys.argv[6]
+    test_type = sys.argv[7]
 
 ns_cmd = 'ip netns exec ' + namespace
 other_ip = '127.0.0.6'
@@ -89,7 +90,7 @@ def verify_trace_flag_rpc_methods(rpc_py, rpc_param):
     verify(not jsonvalue[rpc_param['trace_flag']], 1,
            "get_trace_flags returned {}, expected false".format(jsonvalue))
 
-    print "verify_trace_flag_rpc_methods passed"
+    print("verify_trace_flag_rpc_methods passed")
 
 
 def verify_iscsi_connection_rpc_methods(rpc_py):
@@ -130,7 +131,7 @@ def verify_iscsi_connection_rpc_methods(rpc_py):
     verify(not jsonvalues, 1,
            "get_iscsi_connections returned {}, expected empty".format(jsonvalues))
 
-    print "verify_iscsi_connection_rpc_methods passed"
+    print("verify_iscsi_connection_rpc_methods passed")
 
 
 def verify_scsi_devices_rpc_methods(rpc_py):
@@ -170,7 +171,7 @@ def verify_scsi_devices_rpc_methods(rpc_py):
     verify(not jsonvalues, 1,
            "get_scsi_devices returned {}, expected empty".format(jsonvalues))
 
-    print "verify_scsi_devices_rpc_methods passed"
+    print("verify_scsi_devices_rpc_methods passed")
 
 
 def create_malloc_bdevs_rpc_methods(rpc_py, rpc_param):
@@ -179,7 +180,7 @@ def create_malloc_bdevs_rpc_methods(rpc_py, rpc_param):
     for i in range(1, rpc_param['lun_total'] + 1):
         rpc.construct_malloc_bdev(rpc_param['malloc_bdev_size'], rpc_param['malloc_block_size'])
 
-    print "create_malloc_bdevs_rpc_methods passed"
+    print("create_malloc_bdevs_rpc_methods passed")
 
 
 def verify_portal_groups_rpc_methods(rpc_py, rpc_param):
@@ -238,7 +239,7 @@ def verify_portal_groups_rpc_methods(rpc_py, rpc_param):
         if x["ifc_index"] == 'lo':
             rpc.delete_ip_address(x["ifc_index"], lo_ip[1])
 
-    print "verify_portal_groups_rpc_methods passed"
+    print("verify_portal_groups_rpc_methods passed")
 
 
 def verify_initiator_groups_rpc_methods(rpc_py, rpc_param):
@@ -319,7 +320,7 @@ def verify_initiator_groups_rpc_methods(rpc_py, rpc_param):
             verify(jvalue['netmasks'][0] == rpc_param['netmask'][idx + jidx + 1], 1,
                    "netmasks value is {}, expected {}".format(jvalue['netmasks'][0], rpc_param['netmask'][idx + jidx + 1]))
 
-    print "verify_initiator_groups_rpc_method passed."
+    print("verify_initiator_groups_rpc_method passed.")
 
 
 def verify_target_nodes_rpc_methods(rpc_py, rpc_param):
@@ -351,8 +352,8 @@ def verify_target_nodes_rpc_methods(rpc_py, rpc_param):
            "target name value is {}, expected {}".format(name, nodebase + ":" + rpc_param['target_name']))
     verify(jsonvalues[0]['alias_name'] == rpc_param['alias_name'], 1,
            "target alias_name value is {}, expected {}".format(jsonvalues[0]['alias_name'], rpc_param['alias_name']))
-    verify(jsonvalues[0]['luns'][0]['id'] == 0, 1,
-           "lun id value is {}, expected 0".format(jsonvalues[0]['luns'][0]['id']))
+    verify(jsonvalues[0]['luns'][0]['lun_id'] == 0, 1,
+           "lun id value is {}, expected 0".format(jsonvalues[0]['luns'][0]['lun_id']))
     verify(jsonvalues[0]['pg_ig_maps'][0]['ig_tag'] == int(initiator_tag), 1,
            "initiator group tag value is {}, expected {}".format(jsonvalues[0]['pg_ig_maps'][0]['ig_tag'], initiator_tag))
     verify(jsonvalues[0]['queue_depth'] == rpc_param['queue_depth'], 1,
@@ -377,8 +378,8 @@ def verify_target_nodes_rpc_methods(rpc_py, rpc_param):
     jsonvalues = json.loads(output)
     verify(jsonvalues[0]['luns'][1]['bdev_name'] == "Malloc" + str(rpc_param['lun_total']), 1,
            "bdev_name value is {}, expected Malloc{}".format(jsonvalues[0]['luns'][0]['bdev_name'], str(rpc_param['lun_total'])))
-    verify(jsonvalues[0]['luns'][1]['id'] == 1, 1,
-           "lun id value is {}, expected 1".format(jsonvalues[0]['luns'][1]['id']))
+    verify(jsonvalues[0]['luns'][1]['lun_id'] == 1, 1,
+           "lun id value is {}, expected 1".format(jsonvalues[0]['luns'][1]['lun_id']))
 
     rpc.delete_target_node(name)
     output = rpc.get_target_nodes()
@@ -394,26 +395,26 @@ def verify_target_nodes_rpc_methods(rpc_py, rpc_param):
     output = rpc.get_target_nodes()
     jsonvalues = json.loads(output)
     if not jsonvalues:
-        print "This issue will be fixed later."
+        print("This issue will be fixed later.")
 
-    print "verify_target_nodes_rpc_methods passed."
+    print("verify_target_nodes_rpc_methods passed.")
 
 
 def verify_get_interfaces(rpc_py):
     rpc = spdk_rpc(rpc_py)
     nics = json.loads(rpc.get_interfaces())
-    nics_names = set(x["name"].encode('ascii', 'ignore') for x in nics)
+    nics_names = set(x["name"] for x in nics)
     # parse ip link show to verify the get_interfaces result
     ip_show = ns_cmd + " ip link show"
-    ifcfg_nics = set(re.findall("\S+:\s(\S+?)(?:@\S+){0,1}:\s<.*", check_output(ip_show.split())))
+    ifcfg_nics = set(re.findall("\S+:\s(\S+?)(?:@\S+){0,1}:\s<.*", check_output(ip_show.split()).decode()))
     verify(nics_names == ifcfg_nics, 1, "get_interfaces returned {}".format(nics))
-    print "verify_get_interfaces passed."
+    print("verify_get_interfaces passed.")
 
 
 def help_get_interface_ip_list(rpc_py, nic_name):
     rpc = spdk_rpc(rpc_py)
     nics = json.loads(rpc.get_interfaces())
-    nic = filter(lambda x: x["name"] == nic_name, nics)
+    nic = list(filter(lambda x: x["name"] == nic_name, nics))
     verify(len(nic) != 0, 1,
            "Nic name: {} is not found in {}".format(nic_name, [x["name"] for x in nics]))
     return nic[0]["ip_addr"]
@@ -431,7 +432,7 @@ def verify_add_delete_ip_address(rpc_py):
                "add ip {} to nic {} failed.".format(faked_ip, x["name"]))
         try:
             check_call(ping_cmd.split())
-        except:
+        except BaseException:
             verify(False, 1,
                    "ping ip {} for {} was failed(adding was successful)".format
                    (faked_ip, x["name"]))
@@ -452,29 +453,29 @@ def verify_add_delete_ip_address(rpc_py):
             verify(False, 1,
                    "ip {} for {} could be pinged after delete ip(adding/ping/delete were successful)".format
                    (faked_ip, x["name"]))
-    print "verify_add_delete_ip_address passed."
+    print("verify_add_delete_ip_address passed.")
 
 
 def verify_add_nvme_bdev_rpc_methods(rpc_py):
     rpc = spdk_rpc(rpc_py)
     test_pass = 0
     output = check_output(["lspci", "-mm", "-nn"])
-    addrs = re.findall('^([0-9]{2}:[0-9]{2}.[0-9]) "Non-Volatile memory controller \[0108\]".*-p02', output, re.MULTILINE)
+    addrs = re.findall('^([0-9]{2}:[0-9]{2}.[0-9]) "Non-Volatile memory controller \[0108\]".*-p02', output.decode(), re.MULTILINE)
     for addr in addrs:
-        ctrlr_address = "-b Nvme0 -t pcie -a 0000:{}".format(addr)
+        ctrlr_address = "-b Nvme{} -t pcie -a 0000:{}".format(addrs.index(addr), addr)
         rpc.construct_nvme_bdev(ctrlr_address)
-        print "add nvme device passed first time"
+        print("add nvme device passed first time")
         test_pass = 0
         try:
             rpc.construct_nvme_bdev(ctrlr_address)
         except Exception as e:
-            print "add nvme device passed second time"
+            print("add nvme device passed second time")
             test_pass = 1
             pass
         else:
             pass
         verify(test_pass == 1, 1, "add nvme device passed second time")
-    print "verify_add_nvme_bdev_rpc_methods passed."
+    print("verify_add_nvme_bdev_rpc_methods passed.")
 
 
 if __name__ == "__main__":
@@ -493,7 +494,7 @@ if __name__ == "__main__":
         verify_iscsi_connection_rpc_methods(rpc_py)
         verify_add_nvme_bdev_rpc_methods(rpc_py)
     except RpcException as e:
-        print "{}. Exiting with status {}".format(e.message, e.retval)
+        print("{}. Exiting with status {}".format(e.message, e.retval))
         raise e
     except Exception as e:
         raise e
diff --git a/test/iscsi_tgt/rpc_config/rpc_config.sh b/test/iscsi_tgt/rpc_config/rpc_config.sh
index 0e7048c14..0013cb2b2 100755
--- a/test/iscsi_tgt/rpc_config/rpc_config.sh
+++ b/test/iscsi_tgt/rpc_config/rpc_config.sh
@@ -7,8 +7,15 @@ source $rootdir/test/iscsi_tgt/common.sh
 
 timing_enter rpc_config
 
-MALLOC_BDEV_SIZE=64
+# $1 = test type (posix/vpp)
+if [ "$1" == "posix" ] || [ "$1" == "vpp" ]; then
+       TEST_TYPE=$1
+else
+       echo "No iSCSI test type specified"
+       exit 1
+fi
 
+MALLOC_BDEV_SIZE=64
 
 rpc_py=$rootdir/scripts/rpc.py
 rpc_config_py="python $testdir/rpc_config.py"
@@ -26,7 +33,7 @@ echo "iscsi_tgt is listening. Running tests..."
 
 timing_exit start_iscsi_tgt
 
-$rpc_config_py $rpc_py $TARGET_IP $INITIATOR_IP $ISCSI_PORT $NETMASK $TARGET_NAMESPACE
+$rpc_config_py $rpc_py $TARGET_IP $INITIATOR_IP $ISCSI_PORT $NETMASK $TARGET_NAMESPACE $TEST_TYPE
 
 $rpc_py get_bdevs
 
diff --git a/test/json_config/clear_config.py b/test/json_config/clear_config.py
new file mode 100755
index 000000000..ebde9fd39
--- /dev/null
+++ b/test/json_config/clear_config.py
@@ -0,0 +1,209 @@
+#!/usr/bin/python
+
+import os
+import sys
+import argparse
+sys.path.append(os.path.join(os.path.dirname(__file__), "../../scripts"))
+import rpc   # noqa
+from rpc.client import print_dict, JSONRPCException  # noqa
+
+
+def get_bdev_name_key(bdev):
+    bdev_name_key = 'name'
+    if 'method' in bdev and bdev['method'] == 'construct_split_vbdev':
+        bdev_name_key = "base_bdev"
+
+    return bdev_name_key
+
+
+def get_bdev_name(bdev):
+    bdev_name = None
+    if 'params' in bdev:
+        if 'name' in bdev['params']:
+            bdev_name = bdev['params']['name']
+        elif 'base_name' in bdev['params']:
+            bdev_name = bdev['params']['base_name']
+        elif 'base_bdev' in bdev['params']:
+            bdev_name = bdev['params']['base_bdev']
+    if 'method' in bdev and bdev['method'] == 'construct_error_bdev':
+        bdev_name = "EE_%s" % bdev_name
+
+    return bdev_name
+
+
+def delete_subbdevs(args, bdev, rpc_bdevs):
+    ret_value = False
+    bdev_name = get_bdev_name(bdev)
+    if bdev_name and 'method' in bdev:
+        construct_method = bdev['method']
+        if construct_method == 'construct_nvme_bdev':
+            for rpc_bdev in rpc_bdevs:
+                if bdev_name in rpc_bdev['name'] and rpc_bdev['product_name'] == "NVMe disk":
+                    args.client.call('delete_bdev', {'name': "%s" % rpc_bdev['name']})
+                    ret_value = True
+
+    return ret_value
+
+
+def get_bdev_destroy_method(bdev):
+    destroy_method_map = {'construct_nvme_bdev': "delete_bdev",
+                          'construct_malloc_bdev': "delete_malloc_bdev",
+                          'construct_null_bdev': "delete_null_bdev",
+                          'construct_rbd_bdev': "delete_rbd_bdev",
+                          'construct_pmem_bdev': "delete_pmem_bdev",
+                          'construct_aio_bdev': "delete_aio_bdev",
+                          'construct_error_bdev': "delete_error_bdev",
+                          'construct_split_vbdev': "destruct_split_vbdev",
+                          'construct_virtio_dev': {
+                              'blk': "delete_bdev",
+                              'scsi': "remove_virtio_scsi_bdev"
+                              }
+                          }
+    destroy_method = None
+    if 'method' in bdev:
+        construct_method = bdev['method']
+        if construct_method in destroy_method_map.keys():
+            destroy_method = destroy_method_map[construct_method]
+            if construct_method == 'construct_virtio_dev':
+                if bdev['params']['dev_type'] == 'blk':
+                    destroy_method = destroy_method['blk']
+                else:
+                    destroy_method = destroy_method['scsi']
+
+    return destroy_method
+
+
+def clear_bdev_subsystem(args, bdev_config):
+    rpc_bdevs = args.client.call("get_bdevs")
+    for bdev in bdev_config:
+        if delete_subbdevs(args, bdev, rpc_bdevs):
+            continue
+        bdev_name_key = get_bdev_name_key(bdev)
+        bdev_name = get_bdev_name(bdev)
+        destroy_method = get_bdev_destroy_method(bdev)
+        if destroy_method:
+            args.client.call(destroy_method, {bdev_name_key: bdev_name})
+
+
+def get_nvmf_destroy_method(nvmf):
+    destroy_method_map = {'construct_nvmf_subsystem': "delete_nvmf_subsystem",
+                          'set_nvmf_target_config': None,
+                          'set_nvmf_target_options': None
+                          }
+    return destroy_method_map[nvmf['method']]
+
+
+def clear_nvmf_subsystem(args, nvmf_config):
+    for nvmf in nvmf_config:
+        destroy_method = get_nvmf_destroy_method(nvmf)
+        if destroy_method:
+            args.client.call(destroy_method, {'nqn': nvmf['params']['nqn']})
+
+
+def get_iscsi_destroy_method(iscsi):
+    destroy_method_map = {'add_portal_group': "delete_portal_group",
+                          'add_initiator_group': "delete_initiator_group",
+                          'construct_target_node': "delete_target_node",
+                          'set_iscsi_options': None
+                          }
+    return destroy_method_map[iscsi['method']]
+
+
+def get_iscsi_name(iscsi):
+    if 'name' in iscsi['params']:
+        return iscsi['params']['name']
+    else:
+        return iscsi['params']['tag']
+
+
+def get_iscsi_name_key(iscsi):
+    if iscsi['method'] == 'construct_target_node':
+        return "name"
+    else:
+        return 'tag'
+
+
+def clear_iscsi_subsystem(args, iscsi_config):
+    for iscsi in iscsi_config:
+        destroy_method = get_iscsi_destroy_method(iscsi)
+        if destroy_method:
+            args.client.call(destroy_method, {get_iscsi_name_key(iscsi): get_iscsi_name(iscsi)})
+
+
+def clear_nbd_subsystem(args, scsi_config):
+    pass
+
+
+def clear_net_framework_subsystem(args, net_framework_config):
+    pass
+
+
+def clear_copy_subsystem(args, copy_config):
+    pass
+
+
+def clear_interface_subsystem(args, interface_config):
+    pass
+
+
+def clear_vhost_subsystem(args, vhost_config):
+    for vhost in reversed(vhost_config):
+        if 'method' in vhost:
+            method = vhost['method']
+            if method in ['add_vhost_scsi_lun']:
+                args.client.call("remove_vhost_scsi_target",
+                                 {"ctrlr": vhost['params']['ctrlr'],
+                                  "scsi_target_num": vhost['params']['scsi_target_num']})
+            elif method in ['construct_vhost_scsi_controller', 'construct_vhost_blk_controller',
+                            'construct_vhost_nvme_controller']:
+                args.client.call("remove_vhost_controller", {'ctrlr': vhost['params']['ctrlr']})
+
+
+def call_test_cmd(func):
+    def rpc_test_cmd(*args, **kwargs):
+        try:
+            func(*args, **kwargs)
+        except JSONRPCException as ex:
+            print(ex.message)
+            exit(1)
+    return rpc_test_cmd
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser(description='Clear config command')
+    parser.add_argument('-s', dest='server_addr', default='/var/tmp/spdk.sock')
+    parser.add_argument('-p', dest='port', default=5260, type=int)
+    parser.add_argument('-t', dest='timeout', default=60.0, type=float)
+    parser.add_argument('-v', dest='verbose', action='store_true')
+    subparsers = parser.add_subparsers(help='RPC methods')
+
+    @call_test_cmd
+    def clear_config(args):
+        for subsystem_item in reversed(args.client.call('get_subsystems')):
+            args.subsystem = subsystem_item['subsystem']
+            clear_subsystem(args)
+
+    p = subparsers.add_parser('clear_config', help="""Clear configuration of all SPDK subsystems and targets using JSON RPC""")
+    p.set_defaults(func=clear_config)
+
+    @call_test_cmd
+    def clear_subsystem(args):
+        config = args.client.call('get_subsystem_config', {"name": args.subsystem})
+        if config is None:
+            return
+        if args.verbose:
+            print "Calling clear_%s_subsystem" % args.subsystem
+        globals()["clear_%s_subsystem" % args.subsystem](args, config)
+
+    p = subparsers.add_parser('clear_subsystem', help="""Clear configuration of SPDK subsystem using JSON RPC""")
+    p.add_argument('--subsystem', help="""Subsystem name""")
+    p.set_defaults(func=clear_subsystem)
+
+    args = parser.parse_args()
+
+    try:
+        args.client = rpc.client.JSONRPCClient(args.server_addr, args.port, args.verbose, args.timeout)
+    except JSONRPCException as ex:
+        print(ex.message)
+        exit(1)
+    args.func(args)
diff --git a/test/json_config/common.sh b/test/json_config/common.sh
new file mode 100644
index 000000000..55ec252eb
--- /dev/null
+++ b/test/json_config/common.sh
@@ -0,0 +1,219 @@
+JSON_DIR=$(readlink -f $(dirname ${BASH_SOURCE[0]}))
+SPDK_BUILD_DIR=$JSON_DIR/../../
+source $JSON_DIR/../common/autotest_common.sh
+source $JSON_DIR/../nvmf/common.sh
+
+spdk_rpc_py="python $SPDK_BUILD_DIR/scripts/rpc.py -s /var/tmp/spdk.sock"
+spdk_clear_config_py="$JSON_DIR/clear_config.py -s /var/tmp/spdk.sock"
+initiator_rpc_py="python $SPDK_BUILD_DIR/scripts/rpc.py -s /var/tmp/virtio.sock"
+initiator_clear_config_py="$JSON_DIR/clear_config.py -s /var/tmp/virtio.sock"
+base_json_config=$JSON_DIR/base_config.json
+last_json_config=$JSON_DIR/last_config.json
+full_config=$JSON_DIR/full_config.json
+base_bdevs=$JSON_DIR/bdevs_base.txt
+last_bdevs=$JSON_DIR/bdevs_last.txt
+tmp_config=$JSON_DIR/tmp_config.json
+null_json_config=$JSON_DIR/null_json_config.json
+
+function run_spdk_tgt() {
+	echo "Running spdk target"
+	$SPDK_BUILD_DIR/app/spdk_tgt/spdk_tgt -m 0x1 -p 0 -s 1024 -w &
+	spdk_tgt_pid=$!
+
+	echo "Waiting for app to run..."
+	waitforlisten $spdk_tgt_pid
+	echo "spdk_tgt started - pid=$spdk_tgt_pid but waits for subsystem initialization"
+
+	echo ""
+}
+
+function load_nvme() {
+	echo '{"subsystems": [' > nvme_config.json
+	$SPDK_BUILD_DIR/scripts/gen_nvme.sh --json >> nvme_config.json
+	echo ']}' >> nvme_config.json
+	$rpc_py load_config -f nvme_config.json
+	rm nvme_config.json
+}
+
+function run_initiator() {
+	$SPDK_BUILD_DIR/app/spdk_tgt/spdk_tgt -m 0x2 -p 0 -g -u -s 1024 -r /var/tmp/virtio.sock -w &
+	virtio_pid=$!
+	waitforlisten $virtio_pid /var/tmp/virtio.sock
+}
+
+function upload_vhost() {
+	$rpc_py construct_split_vbdev Nvme0n1 8
+	$rpc_py construct_vhost_scsi_controller sample1
+	$rpc_py add_vhost_scsi_lun sample1 0 Nvme0n1p3
+	$rpc_py add_vhost_scsi_lun sample1 1 Nvme0n1p4
+	$rpc_py set_vhost_controller_coalescing sample1 1 100
+	$rpc_py construct_vhost_blk_controller sample2 Nvme0n1p5
+	$rpc_py construct_vhost_nvme_controller sample3 16
+	$rpc_py add_vhost_nvme_ns sample3 Nvme0n1p6
+}
+
+function kill_targets() {
+	if [ ! -z $virtio_pid ]; then
+		killprocess $virtio_pid
+	fi
+	if [ ! -z $spdk_tgt_pid ]; then
+		killprocess $spdk_tgt_pid
+	fi
+}
+
+# This function test if json config was properly saved and loaded.
+# 1. Get a list of bdevs and save it to the file "base_bdevs".
+# 2. Save only configuration of the running spdk_tgt to the file "base_json_config"
+#    (global parameters are not saved).
+# 3. Clear configuration of the running spdk_tgt.
+# 4. Save only configuration of the running spdk_tgt to the file "null_json_config"
+#    (global parameters are not saved).
+# 5. Check if configuration of the running spdk_tgt is cleared by checking
+#    if the file "null_json_config" doesn't have any configuration.
+# 6. Load the file "base_json_config" to the running spdk_tgt.
+# 7. Get a list of bdevs and save it to the file "last_bdevs".
+# 8. Save only configuration of the running spdk_tgt to the file "last_json_config".
+# 9. Check if the file "base_json_config" matches the file "last_json_config".
+# 10. Check if the file "base_bdevs" matches the file "last_bdevs".
+# 11. Remove all files.
+function test_json_config() {
+	$rpc_py get_bdevs | jq '.|sort_by(.name)' > $base_bdevs
+	$rpc_py save_config -f $full_config
+	$JSON_DIR/config_filter.py -method "delete_global_parameters" -filename $full_config > $base_json_config
+	$clear_config_py clear_config
+	$rpc_py save_config -f $tmp_config
+	$JSON_DIR/config_filter.py -method "delete_global_parameters" -filename $tmp_config > $null_json_config
+	if [ "[]" != "$(jq '.subsystems | map(select(.config != null)) | map(select(.config != []))' $null_json_config)" ]; then
+		echo "Config has not been cleared"
+		return 1
+	fi
+	$rpc_py load_config -f $base_json_config
+	$rpc_py get_bdevs | jq '.|sort_by(.name)' > $last_bdevs
+	$rpc_py save_config -f $tmp_config
+	$JSON_DIR/config_filter.py -method "delete_global_parameters" -filename $tmp_config > $last_json_config
+	diff $base_json_config $last_json_config
+	diff $base_bdevs $last_bdevs
+	remove_config_files_after_test_json_config
+}
+
+function remove_config_files_after_test_json_config() {
+	rm -f $last_bdevs $base_bdevs
+	rm -f $last_json_config $base_json_config
+	rm -f $tmp_config $full_config $null_json_config
+}
+
+function create_pmem_bdev_subsytem_config() {
+        $rpc_py create_pmem_pool /tmp/pool_file1 128 512
+        $rpc_py construct_pmem_bdev -n pmem1 /tmp/pool_file1
+}
+
+function clear_pmem_bdev_subsystem_config() {
+	$clear_config_py clear_config
+	$rpc_py  delete_pmem_pool /tmp/pool_file1
+}
+
+function create_rbd_bdev_subsystem_config() {
+	rbd_setup 127.0.0.1
+	$rpc_py construct_rbd_bdev $RBD_POOL $RBD_NAME 4096
+}
+
+function clear_rbd_bdev_subsystem_config() {
+	$clear_config_py clear_config
+	rbd_cleanup
+}
+
+function create_bdev_subsystem_config() {
+	$rpc_py construct_split_vbdev Nvme0n1 2
+	$rpc_py construct_null_bdev Null0 32 512
+	$rpc_py construct_malloc_bdev 128 512 --name Malloc0
+	$rpc_py construct_malloc_bdev 64 4096 --name Malloc1
+	$rpc_py construct_malloc_bdev 8 1024 --name Malloc2
+	$rpc_py construct_error_bdev Malloc2
+	if [ $(uname -s) = Linux ]; then
+		dd if=/dev/zero of=/tmp/sample_aio bs=2048 count=5000
+		$rpc_py construct_aio_bdev /tmp/sample_aio aio_disk 1024
+	fi
+	$rpc_py construct_lvol_store -c 1048576 Nvme0n1p0 lvs_test
+	$rpc_py construct_lvol_bdev -l lvs_test lvol0 32
+	$rpc_py construct_lvol_bdev -l lvs_test -t lvol1 32
+	$rpc_py snapshot_lvol_bdev lvs_test/lvol0 snapshot0
+	$rpc_py clone_lvol_bdev lvs_test/snapshot0 clone0
+}
+
+function create_nvmf_subsystem_config() {
+	rdma_device_init
+	RDMA_IP_LIST=$(get_available_rdma_ips)
+	NVMF_FIRST_TARGET_IP=$(echo "$RDMA_IP_LIST" | head -n 1)
+	if [ -z $NVMF_FIRST_TARGET_IP ]; then
+		echo "Error: no NIC for nvmf test"
+		return 1
+	fi
+
+	bdevs="$($rpc_py construct_malloc_bdev 64 512) "
+	bdevs+="$($rpc_py construct_malloc_bdev 64 512)"
+	$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 '' '' -a -s SPDK00000000000001 -n "$bdevs"
+	$rpc_py nvmf_subsystem_add_listener nqn.2016-06.io.spdk:cnode1 -t RDMA -a $NVMF_FIRST_TARGET_IP -s "$NVMF_PORT"
+	$rpc_py nvmf_subsystem_add_host nqn.2016-06.io.spdk:cnode1 nqn.2016-06.io.spdk:host1
+	$rpc_py nvmf_subsystem_allow_any_host nqn.2016-06.io.spdk:cnode1
+}
+
+function clear_nvmf_subsystem_config() {
+	$clear_config_py clear_config
+}
+
+function clear_bdev_subsystem_config() {
+	$rpc_py destroy_lvol_bdev lvs_test/clone0
+	$rpc_py destroy_lvol_bdev lvs_test/lvol0
+	$rpc_py destroy_lvol_bdev lvs_test/snapshot0
+	$rpc_py destroy_lvol_store -l lvs_test
+	$clear_config_py clear_config
+	if [ $(uname -s) = Linux ]; then
+		rm -f /tmp/sample_aio
+	fi
+}
+
+# In this test, target is spdk_tgt or virtio_initiator.
+# 1. Save current spdk config to full_config
+#    and save only global parameters to the file "base_json_config".
+# 2. Exit the running spdk target.
+# 3. Start the spdk target and wait for loading config.
+# 4. Load global parameters and configuration to the spdk target from the file full_config.
+# 5. Save json config to the file "full_config".
+# 6. Save only global parameters to the file "last_json_config".
+# 7. Check if the file "base_json_config" matches the file "last_json_config".
+# 8. Delete all files.
+function test_global_params() {
+	target=$1
+	$rpc_py save_config -f $full_config
+	python $JSON_DIR/config_filter.py -method "delete_configs" -filename $full_config > $base_json_config
+	if [ $target == "spdk_tgt" ]; then
+		killprocess $spdk_tgt_pid
+		run_spdk_tgt
+	elif [ $target == "virtio_initiator" ]; then
+		killprocess $virtio_pid
+                run_initiator
+	else
+		echo "Target is not specified for test_global_params"
+		return 1
+	fi
+	$rpc_py load_config -f $full_config
+	$rpc_py save_config -f $full_config
+	python $JSON_DIR/config_filter.py -method "delete_configs" -filename $full_config > $last_json_config
+	diff $base_json_config $last_json_config
+	rm $base_json_config $last_json_config
+	rm $full_config
+}
+
+function on_error_exit() {
+	set +e
+	echo "Error on $1 - $2"
+	remove_config_files_after_test_json_config
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	clear_bdev_subsystem_config
+
+	kill_targets
+
+	print_backtrace
+	exit 1
+}
diff --git a/test/json_config/config_filter.py b/test/json_config/config_filter.py
new file mode 100755
index 000000000..db91d4514
--- /dev/null
+++ b/test/json_config/config_filter.py
@@ -0,0 +1,44 @@
+#!/usr/bin/python
+import json
+import argparse
+
+
+def filter_methods(filename, do_remove_startup_rpcs):
+    startup_rpcs = [
+        'set_iscsi_options',
+        'set_nvmf_target_config',
+        'set_nvmf_target_options',
+        'set_bdev_options'
+    ]
+
+    with open(filename) as json_file:
+        data = json.loads(json_file.read())
+    out = {'subsystems': []}
+    for s in data['subsystems']:
+        if s['config']:
+            s_config = []
+            for config in s['config']:
+                m_name = config['method']
+                is_startup_rpc = m_name in startup_rpcs
+                if do_remove_startup_rpcs != is_startup_rpc:
+                    s_config.append(config)
+        else:
+            s_config = None
+        out['subsystems'].append({
+            'subsystem': s['subsystem'],
+            'config': s_config,
+        })
+
+    print json.dumps(out, indent=2)
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument('-method', dest='method')
+    parser.add_argument('-filename', dest='filename')
+
+    args = parser.parse_args()
+    if args.method == "delete_global_parameters":
+        filter_methods(args.filename, True)
+    if args.method == "delete_configs":
+        filter_methods(args.filename, False)
diff --git a/test/lvol/lvol.sh b/test/lvol/lvol.sh
index 6bb88f245..7786de4f7 100755
--- a/test/lvol/lvol.sh
+++ b/test/lvol/lvol.sh
@@ -64,6 +64,8 @@ function usage() {
                                     753: 'snapshot_of_snapshot',
                                     754: 'clone_bdev_only',
                                     755: 'clone_writing_clone',
+                                    756: 'clone_and_snapshot_consistency',
+                                    757: 'clone_inflate',
                                     800: 'rename_positive',
                                     801: 'rename_lvs_nonexistent',
                                     802: 'rename_lvs_EEXIST',
diff --git a/test/lvol/lvol_test.py b/test/lvol/lvol_test.py
index 684430827..0eca30ed8 100755
--- a/test/lvol/lvol_test.py
+++ b/test/lvol/lvol_test.py
@@ -50,6 +50,6 @@ if __name__ == "__main__":
             print("RESULT: Some test cases FAIL")
             print(tc_failed)
             sys.exit(1)
-    except:
+    except BaseException:
         print("Test: {num_test} - FAIL".format(num_test=num_test))
         sys.exit(1)
diff --git a/test/lvol/rpc_commands_lib.py b/test/lvol/rpc_commands_lib.py
index 4af06d57e..1db578447 100644
--- a/test/lvol/rpc_commands_lib.py
+++ b/test/lvol/rpc_commands_lib.py
@@ -14,13 +14,13 @@ class Spdk_Rpc(object):
                 cmd += " {}".format(arg)
             try:
                 output = check_output(cmd, shell=True)
-                return output.rstrip('\n'), 0
+                return output.decode('ascii').rstrip('\n'), 0
             except CalledProcessError as e:
                 print("ERROR: RPC Command {cmd} "
                       "execution failed:". format(cmd=cmd))
                 print("Failed command output:")
                 print(e.output)
-                return e.output, e.returncode
+                return e.output.decode('ascii'), e.returncode
         return call
 
 
@@ -147,6 +147,11 @@ class Commands_Rpc(object):
         output, rc = self.rpc.delete_bdev(base_name)
         return rc
 
+    def delete_malloc_bdev(self, base_name):
+        print("INFO: RPC COMMAND delete_malloc_bdev")
+        output, rc = self.rpc.delete_malloc_bdev(base_name)
+        return rc
+
     def destroy_lvol_bdev(self, bdev_name):
         print("INFO: RPC COMMAND destroy_lvol_bdev")
         output, rc = self.rpc.destroy_lvol_bdev(bdev_name)
@@ -215,3 +220,8 @@ class Commands_Rpc(object):
         print("INFO: RPC COMMAND clone_lvol_bdev")
         output, rc = self.rpc.clone_lvol_bdev(snapshot_name, clone_name)
         return rc
+
+    def inflate_lvol_bdev(self, clone_name):
+        print("INFO: RPC COMMAND inflate_lvol_bdev")
+        output, rc = self.rpc.inflate_lvol_bdev(clone_name)
+        return rc
diff --git a/test/lvol/test_cases.py b/test/lvol/test_cases.py
index e5a8c0fd9..911ea36e8 100644
--- a/test/lvol/test_cases.py
+++ b/test/lvol/test_cases.py
@@ -133,6 +133,8 @@ def case_message(func):
             753: 'snapshot_of_snapshot',
             754: 'clone_bdev_only',
             755: 'clone_writing_clone',
+            756: 'clone_and_snapshot_consistency',
+            757: 'clone_inflate',
             800: 'rename_positive',
             801: 'rename_lvs_nonexistent',
             802: 'rename_lvs_EEXIST',
@@ -176,7 +178,7 @@ class TestCases(object):
         try:
             process = subprocess.check_output(cmp_cmd, stderr=subprocess.STDOUT, shell=True)
             rv = 0
-        except subprocess.CalledProcessError, ex:
+        except subprocess.CalledProcessError as ex:
             rv = 1
         except Exception as e:
             print("ERROR: Cmp ended with unexpected exception.")
@@ -204,7 +206,7 @@ class TestCases(object):
                     for count in range(30):
                         sleep(1)
                         kill(pid, 0)
-                except OSError, err:
+                except OSError as err:
                     if err.errno == ESRCH:
                         pass
                     else:
@@ -276,7 +278,7 @@ class TestCases(object):
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
         return fail_count
@@ -297,7 +299,7 @@ class TestCases(object):
                                                      self.total_size - 1)
         self.c.destroy_lvol_bdev(uuid_bdev)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -309,7 +311,7 @@ class TestCases(object):
                                                  self.cluster_size)
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
-        size = ((self.total_size - 1) / 4)
+        size = int((self.total_size - 1) / 4)
 
         for j in range(2):
             uuid_bdevs = []
@@ -324,7 +326,7 @@ class TestCases(object):
                 self.c.destroy_lvol_bdev(uuid_bdev)
 
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -347,7 +349,7 @@ class TestCases(object):
 
         fail_count += self.c.destroy_lvol_bdev(uuid_bdev)
         fail_count += self.c.destroy_lvol_store(uuid_store)
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -381,8 +383,8 @@ class TestCases(object):
         fail_count += self.c.destroy_lvol_bdev(uuid_bdev_2)
         fail_count += self.c.destroy_lvol_store(uuid_store_1)
         fail_count += self.c.destroy_lvol_store(uuid_store_2)
-        fail_count += self.c.delete_bdev(base_name_1)
-        fail_count += self.c.delete_bdev(base_name_2)
+        fail_count += self.c.delete_malloc_bdev(base_name_1)
+        fail_count += self.c.delete_malloc_bdev(base_name_2)
         return fail_count
 
     @case_message
@@ -415,12 +417,12 @@ class TestCases(object):
 
         self.c.destroy_lvol_bdev(uuid_bdev)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
     def test_case102(self):
-        size = (self.total_size / 2) - 1
+        size = int((self.total_size / 2) - 1)
         base_name = self.c.construct_malloc_bdev(self.total_size,
                                                  self.block_size)
         uuid_store = self.c.construct_lvol_store(base_name,
@@ -440,7 +442,7 @@ class TestCases(object):
 
         self.c.destroy_lvol_bdev(uuid_bdev)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -453,12 +455,12 @@ class TestCases(object):
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
         # size is equal to one quarter of size malloc bdev
-        size = self.total_size / 4
+        size = int(self.total_size / 4)
         uuid_bdev = self.c.construct_lvol_bdev(uuid_store, self.lbd_name, size)
         fail_count += self.c.check_get_bdevs_methods(uuid_bdev, size)
 
         # size is equal to half  of size malloc bdev
-        size = self.total_size / 2
+        size = int(self.total_size / 2)
         self.c.resize_lvol_bdev(uuid_bdev, size)
         fail_count += self.c.check_get_bdevs_methods(uuid_bdev, size)
 
@@ -474,7 +476,7 @@ class TestCases(object):
 
         self.c.destroy_lvol_bdev(uuid_bdev)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -503,7 +505,7 @@ class TestCases(object):
 
         self.c.destroy_lvol_bdev(uuid_bdev)
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -518,7 +520,7 @@ class TestCases(object):
         self.c.destroy_lvol_store(uuid_store)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -533,7 +535,7 @@ class TestCases(object):
         fail_count += self.c.destroy_lvol_store(self.lvs_name)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -555,7 +557,7 @@ class TestCases(object):
 
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -567,7 +569,7 @@ class TestCases(object):
                                                  self.cluster_size)
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
-        size = ((self.total_size - 1) / 4)
+        size = int((self.total_size - 1) / 4)
 
         for i in range(4):
             uuid_bdev = self.c.construct_lvol_bdev(uuid_store,
@@ -578,7 +580,7 @@ class TestCases(object):
         self.c.destroy_lvol_store(uuid_store)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -590,7 +592,7 @@ class TestCases(object):
                                                  self.cluster_size)
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
-        size = ((self.total_size - 1) / 4)
+        size = int((self.total_size - 1) / 4)
         uuid_bdev = self.c.construct_lvol_bdev(uuid_store,
                                                self.lbd_name,
                                                size)
@@ -615,7 +617,7 @@ class TestCases(object):
         self.c.destroy_lvol_store(uuid_store)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -660,7 +662,7 @@ class TestCases(object):
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
 
-        if self.c.delete_bdev(base_name) != 0:
+        if self.c.delete_malloc_bdev(base_name) != 0:
             fail_count += 1
 
         if self.c.destroy_lvol_store(uuid_store) == 0:
@@ -703,7 +705,7 @@ class TestCases(object):
                                        self.cluster_size) == 0:
             fail_count += 1
         self.c.destroy_lvol_store(uuid_store)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -725,8 +727,8 @@ class TestCases(object):
             fail_count += 1
 
         fail_count += self.c.destroy_lvol_store(uuid_store_1)
-        fail_count += self.c.delete_bdev(base_name_1)
-        fail_count += self.c.delete_bdev(base_name_2)
+        fail_count += self.c.delete_malloc_bdev(base_name_1)
+        fail_count += self.c.delete_malloc_bdev(base_name_2)
 
         return fail_count
 
@@ -744,7 +746,7 @@ class TestCases(object):
                                                  self.cluster_size)
         fail_count = self.c.check_get_lvol_stores(base_name, uuid_store,
                                                   self.cluster_size)
-        self.c.delete_bdev(base_name)
+        self.c.delete_malloc_bdev(base_name)
         if self.c.check_get_lvol_stores("", "", "") == 1:
             fail_count += 1
         return fail_count
@@ -759,7 +761,7 @@ class TestCases(object):
                                                 (self.total_size * 1024 * 1024) + 1) == 0
         if self.c.check_get_lvol_stores(base_name, lvol_uuid) == 0:
             fail_count += 1
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -770,7 +772,7 @@ class TestCases(object):
         lvol_uuid = self.c.construct_lvol_store(base_name, self.lvs_name, 8191)
         if self.c.check_get_lvol_stores(base_name, lvol_uuid) == 0:
             fail_count += 1
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
         return fail_count
 
     @case_message
@@ -792,7 +794,7 @@ class TestCases(object):
                                                   self.cluster_size)
         lvs = self.c.get_lvol_stores(self.lvs_name)[0]
         free_clusters_start = int(lvs['free_clusters'])
-        bdev_size = int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE
+        bdev_size = int(int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE)
         # create thin provisioned lvol bdev with size equals to lvol store free space
         bdev_name = self.c.construct_lvol_bdev(uuid_store, self.lbd_name,
                                                bdev_size, thin=True)
@@ -875,7 +877,7 @@ class TestCases(object):
         lbd_name0 = self.lbd_name + str("0")
         lbd_name1 = self.lbd_name + str("1")
         # calculate bdev size in megabytes
-        bdev_size = int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE
+        bdev_size = int(int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE)
         # create thick provisioned lvol bvdev with size equal to lvol store
         bdev_name0 = self.c.construct_lvol_bdev(uuid_store, lbd_name0,
                                                 bdev_size, thin=False)
@@ -930,7 +932,7 @@ class TestCases(object):
                                                   self.cluster_size)
         lvs = self.c.get_lvol_stores(self.lvs_name)[0]
         free_clusters_start = int(lvs['free_clusters'])
-        bdev_size = int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE
+        bdev_size = int(int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE)
         # construct thin provisioned lvol bdev with size equal to lvol store
         bdev_name = self.c.construct_lvol_bdev(uuid_store, self.lbd_name,
                                                bdev_size, thin=True)
@@ -1006,7 +1008,7 @@ class TestCases(object):
         free_clusters_start = int(lvs['free_clusters'])
         lbd_name0 = self.lbd_name + str("0")
         lbd_name1 = self.lbd_name + str("1")
-        bdev_size = int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE
+        bdev_size = int(int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE)
         # construct two thin provisioned lvol bdevs on created lvol store
         # with size equals to free lvs size
         bdev_name0 = self.c.construct_lvol_bdev(uuid_store, lbd_name0,
@@ -1077,7 +1079,7 @@ class TestCases(object):
         free_clusters_start = int(lvs['free_clusters'])
         lbd_name0 = self.lbd_name + str("0")
         lbd_name1 = self.lbd_name + str("1")
-        lvs_size = int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE
+        lvs_size = int(int(lvs['cluster_size']) * int(lvs['free_clusters']) / MEGABYTE)
         bdev_size = int(lvs_size * 0.7)
         # construct two thin provisioned lvol bdevs on created lvol store
         # with size equal to 70% of lvs size
@@ -1117,6 +1119,15 @@ class TestCases(object):
 
     @case_message
     def test_case700(self):
+        """
+        tasting_positive
+
+        Positive test for tasting a multi lvol bdev configuration.
+        Create a lvol store with some lvol bdevs on NVMe drive and restart vhost app.
+        After restarting configuration should be automatically loaded and should be exactly
+        the same as before restarting.
+        Check that running configuration can be modified after restarting and tasting.
+        """
         fail_count = 0
         uuid_bdevs = []
         base_name = "Nvme0n1p0"
@@ -1145,6 +1156,7 @@ class TestCases(object):
                                                    self.lbd_name + str(i),
                                                    size)
             uuid_bdevs.append(uuid_bdev)
+            # Using get_bdevs command verify lvol bdevs were correctly created
             fail_count += self.c.check_get_bdevs_methods(uuid_bdev, size)
 
         old_bdevs = sorted(self.c.get_lvol_bdevs(), key=lambda x: x["name"])
@@ -1201,6 +1213,8 @@ class TestCases(object):
 
         uuid_bdevs = []
 
+        # Create lvol store on NVMe bdev, create ten lvol bdevs on lvol store and
+        # verify all configuration call results
         uuid_store = self.c.construct_lvol_store(base_name,
                                                  self.lvs_name,
                                                  self.cluster_size)
@@ -1215,6 +1229,7 @@ class TestCases(object):
             uuid_bdevs.append(uuid_bdev)
             fail_count += self.c.check_get_bdevs_methods(uuid_bdev, size)
 
+        # Destroy lvol store
         if self.c.destroy_lvol_store(uuid_store) != 0:
             fail_count += 1
 
@@ -1222,7 +1237,13 @@ class TestCases(object):
 
     @case_message
     def test_case701(self):
+        """
+        tasting_lvol_store_positive
+
+        Positive test for tasting lvol store.
+        """
         base_name = "Nvme0n1p0"
+        # construct lvol store on NVMe bdev
         uuid_store = self.c.construct_lvol_store(base_name,
                                                  self.lvs_name,
                                                  self.cluster_size)
@@ -1230,15 +1251,19 @@ class TestCases(object):
                                                   self.cluster_size)
         traddr = self._find_traddress_for_nvme("Nvme0")
         if traddr != -1:
+            # delete NVMe bdev
             self.c.delete_bdev("Nvme0n1")
+            # add NVMe bdev
             self.c.construct_nvme_bdev("Nvme0", "PCIe", traddr)
             # wait 1 second to allow time for lvolstore tasting
             sleep(1)
         else:
             fail_count += 1
+        # check if lvol store still exists in vhost configuration
         if self.c.check_get_lvol_stores(base_name, uuid_store,
                                         self.cluster_size) != 0:
             fail_count += 1
+        # destroy lvol store from NVMe bdev
         if self.c.destroy_lvol_store(uuid_store) != 0:
             fail_count += 1
         return fail_count
@@ -1288,7 +1313,7 @@ class TestCases(object):
         # Destroy lvol store
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Delete malloc bdev
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1365,7 +1390,7 @@ class TestCases(object):
         # Destroy snapshot
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Delete malloc bdev
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1425,7 +1450,7 @@ class TestCases(object):
         # Destroy lvol store
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Delete malloc bdevs
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1472,7 +1497,7 @@ class TestCases(object):
         # Destroy lvol store
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Delete malloc bdev
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1535,7 +1560,7 @@ class TestCases(object):
         # Delete lvol store
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Destroy malloc bdev
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1609,7 +1634,192 @@ class TestCases(object):
         # Destroy lvol store
         fail_count += self.c.destroy_lvol_store(uuid_store)
         # Delete malloc
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
+
+        # Expected result:
+        # - calls successful, return code = 0
+        # - no other operation fails
+        return fail_count
+
+    @case_message
+    def test_case756(self):
+        """
+        clone_and_snapshot_relations
+
+        Check if relations between clones and snapshots
+        are properly set in configuration
+        """
+        fail_count = 0
+        snapshot_name = 'snapshot'
+        clone_name0 = 'clone1'
+        clone_name1 = 'clone2'
+        lbd_name = clone_name1
+
+        # Create malloc bdev
+        base_name = self.c.construct_malloc_bdev(self.total_size,
+                                                 self.block_size)
+        # Create lvol store
+        uuid_store = self.c.construct_lvol_store(base_name,
+                                                 self.lvs_name,
+                                                 self.cluster_size)
+        fail_count += self.c.check_get_lvol_stores(base_name, uuid_store,
+                                                   self.cluster_size)
+        lvs = self.c.get_lvol_stores()
+        size = int(int(lvs[0]['free_clusters'] * lvs[0]['cluster_size']) / 6 / MEGABYTE)
+
+        # Construct thick provisioned lvol bdev
+        uuid_bdev = self.c.construct_lvol_bdev(uuid_store,
+                                               lbd_name, size, thin=False)
+        lvol_bdev = self.c.get_lvol_bdev_with_name(uuid_bdev)
+
+        # Create snapshot of thick provisioned lvol bdev
+        fail_count += self.c.snapshot_lvol_bdev(lvol_bdev['name'], snapshot_name)
+        snapshot_bdev = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + snapshot_name)
+
+        # Create clone of created snapshot
+        fail_count += self.c.clone_lvol_bdev(snapshot_bdev['name'], clone_name0)
+
+        # Get current bdevs configuration
+        snapshot_bdev = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + snapshot_name)
+        lvol_clone0 = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + clone_name0)
+        lvol_clone1 = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + clone_name1)
+
+        # Check snapshot consistency
+        snapshot_lvol = snapshot_bdev['driver_specific']['lvol']
+        if snapshot_lvol['snapshot'] is not True:
+            fail_count += 1
+        if snapshot_lvol['clone'] is not False:
+            fail_count += 1
+        if sorted([clone_name0, clone_name1]) != sorted(snapshot_lvol['clones']):
+            fail_count += 1
+
+        # Check first clone consistency
+        lvol_clone0_lvol = lvol_clone0['driver_specific']['lvol']
+        if lvol_clone0_lvol['snapshot'] is not False:
+            fail_count += 1
+        if lvol_clone0_lvol['clone'] is not True:
+            fail_count += 1
+        if lvol_clone0_lvol['base_snapshot'] != 'snapshot':
+            fail_count += 1
+
+        # Check second clone consistency
+        lvol_clone1_lvol = lvol_clone1['driver_specific']['lvol']
+        if lvol_clone1_lvol['snapshot'] is not False:
+            fail_count += 1
+        if lvol_clone1_lvol['clone'] is not True:
+            fail_count += 1
+        if lvol_clone1_lvol['base_snapshot'] != 'snapshot':
+            fail_count += 1
+
+        # Destroy first clone and check if it is deleted from snapshot
+        fail_count += self.c.destroy_lvol_bdev(lvol_clone0['name'])
+        snapshot_bdev = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + snapshot_name)
+        if [clone_name1] != snapshot_bdev['driver_specific']['lvol']['clones']:
+            fail_count += 1
+
+        # Destroy second clone
+        fail_count += self.c.destroy_lvol_bdev(lvol_clone1['name'])
+
+        # Delete snapshot
+        fail_count += self.c.destroy_lvol_bdev(snapshot_bdev['name'])
+
+        # Destroy lvol store
+        fail_count += self.c.destroy_lvol_store(uuid_store)
+
+        # Delete malloc
+        fail_count += self.c.delete_malloc_bdev(base_name)
+
+        # Expected result:
+        # - calls successful, return code = 0
+        # - no other operation fails
+        return fail_count
+
+    @case_message
+    def test_case757(self):
+        """
+        clone_inflate
+
+
+        Test inflate rpc method
+        """
+        fail_count = 0
+        snapshot_name = "snapshot"
+        nbd_name = "/dev/nbd0"
+
+        # Create malloc bdev
+        base_name = self.c.construct_malloc_bdev(self.total_size,
+                                                 self.block_size)
+
+        # Create lvol store
+        uuid_store = self.c.construct_lvol_store(base_name,
+                                                 self.lvs_name,
+                                                 self.cluster_size)
+        fail_count += self.c.check_get_lvol_stores(base_name, uuid_store,
+                                                   self.cluster_size)
+        lvs = self.c.get_lvol_stores()
+        size = int(int(lvs[0][u'free_clusters'] * lvs[0]['cluster_size']) / 4 / MEGABYTE)
+
+        # Construct thick provisioned lvol bdev
+        uuid_bdev0 = self.c.construct_lvol_bdev(uuid_store,
+                                                self.lbd_name, size, thin=False)
+        lvol_bdev = self.c.get_lvol_bdev_with_name(uuid_bdev0)
+
+        # Fill bdev with data of knonw pattern
+        fail_count += self.c.start_nbd_disk(lvol_bdev['name'], nbd_name)
+        fill_size = size * MEGABYTE
+        fail_count += self.run_fio_test(nbd_name, 0, fill_size, "write", "0xcc", 0)
+        self.c.stop_nbd_disk(nbd_name)
+
+        # Create snapshot of thick provisioned lvol bdev
+        fail_count += self.c.snapshot_lvol_bdev(lvol_bdev['name'], snapshot_name)
+        snapshot_bdev = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + snapshot_name)
+
+        # Create two clones of created snapshot
+        lvol_clone = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + self.lbd_name)
+        if lvol_clone['driver_specific']['lvol']['thin_provision'] is not True:
+            fail_count += 1
+
+        # Fill part of clone with data of known pattern
+        fail_count += self.c.start_nbd_disk(lvol_clone['name'], nbd_name)
+        first_fill = 0
+        second_fill = int(size * 3 / 4)
+        fail_count += self.run_fio_test(nbd_name, first_fill * MEGABYTE,
+                                        MEGABYTE, "write", "0xdd", 0)
+        fail_count += self.run_fio_test(nbd_name, second_fill * MEGABYTE,
+                                        MEGABYTE, "write", "0xdd", 0)
+        self.c.stop_nbd_disk(nbd_name)
+
+        # Do inflate
+        fail_count += self.c.inflate_lvol_bdev(lvol_clone['name'])
+        lvol_clone = self.c.get_lvol_bdev_with_name(self.lvs_name + "/" + self.lbd_name)
+        if lvol_clone['driver_specific']['lvol']['thin_provision'] is not False:
+            fail_count += 1
+
+        # Delete snapshot
+        fail_count += self.c.delete_bdev(snapshot_bdev['name'])
+
+        # Check data consistency
+        fail_count += self.c.start_nbd_disk(lvol_clone['name'], nbd_name)
+        fail_count += self.run_fio_test(nbd_name, first_fill * MEGABYTE,
+                                        MEGABYTE, "read", "0xdd")
+        fail_count += self.run_fio_test(nbd_name, (first_fill + 1) * MEGABYTE,
+                                        (second_fill - first_fill - 1) * MEGABYTE,
+                                        "read", "0xcc")
+        fail_count += self.run_fio_test(nbd_name, (second_fill) * MEGABYTE,
+                                        MEGABYTE, "read", "0xdd")
+        fail_count += self.run_fio_test(nbd_name, (second_fill + 1) * MEGABYTE,
+                                        (size - second_fill - 1) * MEGABYTE,
+                                        "read", "0xcc")
+        self.c.stop_nbd_disk(nbd_name)
+
+        # Destroy lvol bdev
+        fail_count += self.c.delete_bdev(lvol_bdev['name'])
+
+        # Destroy lvol store
+        fail_count += self.c.destroy_lvol_store(uuid_store)
+
+        # Delete malloc
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         # Expected result:
         # - calls successful, return code = 0
@@ -1620,7 +1830,7 @@ class TestCases(object):
     def test_case800(self):
         fail_count = 0
 
-        bdev_size = (self.total_size - 1) / 4
+        bdev_size = int((self.total_size - 1) / 4)
         bdev_uuids = []
         bdev_names = [self.lbd_name + str(i) for i in range(4)]
         bdev_aliases = ["/".join([self.lvs_name, name]) for name in bdev_names]
@@ -1684,7 +1894,7 @@ class TestCases(object):
         for bdev in new_bdev_aliases:
             fail_count += self.c.destroy_lvol_bdev(bdev)
         fail_count += self.c.destroy_lvol_store(new_lvs_name)
-        fail_count += self.c.delete_bdev(base_name)
+        fail_count += self.c.delete_malloc_bdev(base_name)
 
         return fail_count
 
@@ -1709,7 +1919,7 @@ class TestCases(object):
         bdev_names_2 = ["lvol_2_" + str(i) for i in range(4)]
         bdev_aliases_2 = ["/".join([lvs_name_2, name]) for name in bdev_names_2]
         bdev_uuids_2 = []
-        bdev_size = (self.total_size - 1) / 4
+        bdev_size = int((self.total_size - 1) / 4)
 
         base_bdev_1 = self.c.construct_malloc_bdev(self.total_size,
                                                    self.block_size)
@@ -1779,8 +1989,8 @@ class TestCases(object):
             fail_count += self.c.destroy_lvol_bdev(lvol_uuid)
         fail_count += self.c.destroy_lvol_store(lvs_uuid_1)
         fail_count += self.c.destroy_lvol_store(lvs_uuid_2)
-        fail_count += self.c.delete_bdev(base_bdev_1)
-        fail_count += self.c.delete_bdev(base_bdev_2)
+        fail_count += self.c.delete_malloc_bdev(base_bdev_1)
+        fail_count += self.c.delete_malloc_bdev(base_bdev_2)
 
         return fail_count
 
@@ -1794,7 +2004,7 @@ class TestCases(object):
     @case_message
     def test_case804(self):
         fail_count = 0
-        bdev_size = (self.total_size - 1) / 2
+        bdev_size = int((self.total_size - 1) / 2)
 
         base_bdev = self.c.construct_malloc_bdev(self.total_size,
                                                  self.block_size)
@@ -1825,7 +2035,7 @@ class TestCases(object):
         fail_count += self.c.destroy_lvol_bdev(bdev_uuid_1)
         fail_count += self.c.destroy_lvol_bdev(bdev_uuid_2)
         fail_count += self.c.destroy_lvol_store(lvs_uuid)
-        fail_count += self.c.delete_bdev(base_bdev)
+        fail_count += self.c.delete_malloc_bdev(base_bdev)
 
         return fail_count
 
diff --git a/test/lvol/test_plan.md b/test/lvol/test_plan.md
index b09f44157..d51ccb770 100644
--- a/test/lvol/test_plan.md
+++ b/test/lvol/test_plan.md
@@ -554,180 +554,6 @@ Expected result:
 - construct lvol store return code != 0
 - Error code response printed to stdout
 
-### logical volume tasting tests
-
-#### TEST CASE 700 - Name: tasting_positive
-Positive test for tasting a multi lvol bdev configuration.
-Create a lvol store with some lvol bdevs on NVMe drive and restart vhost app.
-After restarting configuration should be automatically loaded and should be exactly
-the same as before restarting.
-Check that running configuration can be modified after restarting and tasting.
-Steps:
-- run vhost app with NVMe bdev
-- construct lvol store on NVMe bdev
-- using get_lvol_stores command verify lvol store was correctly created
-- construct five lvol bdevs on previously created lvol store;
-  each lvol bdev size is approximately equal to 2% of total lvol store size
-  (approximately because of the lvol metadata which consumes some of the space)
-- using get_bdevs command verify lvol bdevs were correctly created
-- shutdown vhost application by sending SIGTERM signal
-- start vhost application with the same NVMe bdev as in the first step
-- using get_lvol_stores command verify that previously created lvol strore
-  was correctly discovered and loaded by tasting feature (including UUID's)
-- using get_bdevs command verify that previously created lvol bdevs were
-  correctly discovered and loaded by tasting feature (including UUID's)
-- verify if configuration can be modified after tasting:
-  construct five more lvol bdevs to fill up loaded lvol store,
-  delete all existing lvol bdevs,
-  destroy existing lvol store,
-  verify removal results using get_lvol_stores and get_bdevs commands
-- re-create initial configuration by repeating steps 2-5:
-  create lvol store on NVMe bdev, create four lvol bdevs on lvol store and
-  verify all configuration call results
-- clean running configuration:
-  delete all lvol bdevs,
-  destroy lvol store
-  verify removal results using get_lvol_stores and get_bdevs commands
-
-Expected results:
-- configuration is successfully tasted and loaded after restarting vhost
-- lvol store attributes (UUID, total size, cluster size, etc.) remain the same after
-  loading existing configuration
-- lvol bdev attributes (UUID, size, etc.) remain the same after
-  loading existing configuration
-- all RPC configuration calls successful, return code = 0
-- no other operation fails
-
-#### TEST CASE 701 - Name: tasting_lvol_store_positive
-Positive test for tasting lvol store.
-Steps:
-- run vhost app with NVMe bdev
-- construct lvol store on NVMe bdev
-- delete NVMe bdev
-- add NVMe bdev
-- check if lvol store still exists in vhost configuration
-- destroy lvol store from NVMe bdev
-
-Expected result:
-- calls successful (lvol store should be tasted correctly), return code = 0
-- no other operation fails
-
-### snapshot and clone
-
-#### TEST CASE 750 - Name: snapshot_readonly
-- constrcut malloc bdev
-- construct lvol store on malloc bdev
-- construct lvol bdev
-- fill lvol bdev with 100% of its space using write operation
-- create snapshot of created lvol bdev
-- check if created snapshot has readonly status
-- try to perform write operation on created snapshot
-- check if write failed
-- destroy lvol bdev
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- no other operation fails
-
-#### TEST CASE 751 - Name: snapshot_compare_with_lvol_bdev
-- construct malloc bdev
-- construct lvol store on malloc bdev
-- construct thin provisioned lvol bdev with size less than 25% of lvs
-- construct thick provisioned lvol bdev with size less than 25% of lvs
-- fill first lvol bdev with 50% of its space
-- fill second lvol bdev with 100% of their space
-- create snapshots of created lvol bdevs and check that they are readonly
-- check using cmp program if data on corresponding lvol bdevs
-  and snapshots are the same
-- fill lvol bdev again with 50% of its space using write operation
-- compare thin provisioned bdev clusters with snapshot clusters
-  and check that 50% of data are the same and 50% are different
-- destroy lvol bdevs
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- removing snapshot should always end with success
-- no other operation fails
-
-#### TEST CASE 752 - Name: snapshot_during_io_traffic
-- construct malloc bdev
-- construct lvol store on malloc bdev
-- construct thin provisioned lvol bdev
-- perform write operation with verification to created lvol bdev
-- during write operation create snapshot of created lvol bdev
-- check that snapshot has been created successfully and check that it is readonly
-- check that write operation ended with success
-- destroy lvol bdev
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- no other operation fails
-
-#### TEST CASE 753 - Name: snapshot_of_snapshot
-- construct malloc bdev
-- construct lvol store on malloc bdev
-- construct thick provisioned lvol bdev
-- create snapshot of created lvol bdev and check that it is readonly
-- create snapshot of previously created snapshot
-- check if operation fails
-- destroy lvol bdev
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- creating snapshot of snapshot should fail
-- no other operation fails
-
-#### TEST CASE 754 - Name: clone_bdev_only
-- construct malloc bdev
-- construct lvol store on malloc
-- construct thick provisioned lvol bdev
-- create clone of created lvol bdev
-- check if operation fails
-- create snapshot of lvol bdev and check that it is readonly
-- create clone of created lvol bdev
-- check if operation failed
-- create clone of snapshot on the same lvs
-  where snaphot was created
-- check if operation ends with success
-- check if clone is not readonly
-- check that clone is thin provisioned
-- destroy lvol bdev
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- cloning thick provisioned lvol bdev should fail
-- no other operation fails
-
-#### TEST CASE 755 - Name: clone_writing_to_clone
-- construct with malloc bdev
-- construct lvol store on malloc bdev
-- construct thick provisioned lvol bdev
-- fill lvol bdev with 100% of its space
-- create snapshot of thick provisioned lvol bdev
-- create two clones of created snapshot
-- perform write operation to first clone
-  and verify that data were written correctly
-- check that operation ended with success
-- compare second clone with snapshot and check
-  that data on both bdevs are the same
-- destroy lvol bdev
-- destroy lvol store
-- destroy malloc bdev
-
-Expected result:
-- calls successful, return code = 0
-- no other operation fails
-
 ### logical volume rename tests
 
 #### TEST CASE 800 - Name: rename_positive
diff --git a/test/nvme/Makefile b/test/nvme/Makefile
index 2a8236682..9fae60f6e 100644
--- a/test/nvme/Makefile
+++ b/test/nvme/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = aer reset sgl e2edp overhead deallocated_value
+DIRS-y = aer reset sgl e2edp overhead deallocated_value err_injection
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/test/nvme/aer/aer.c b/test/nvme/aer/aer.c
index e090e08fc..43e21ea1c 100644
--- a/test/nvme/aer/aer.c
+++ b/test/nvme/aer/aer.c
@@ -293,7 +293,7 @@ usage(const char *program_name)
 	printf("     subnqn      Subsystem NQN (default: %s)\n", SPDK_NVMF_DISCOVERY_NQN);
 	printf("    Example: -r 'trtype:RDMA adrfam:IPv4 traddr:192.168.100.8 trsvcid:4420'\n");
 
-	spdk_tracelog_usage(stdout, "-t");
+	spdk_tracelog_usage(stdout, "-L");
 
 	printf(" -v         verbose (enable warnings)\n");
 	printf(" -H         show this usage\n");
@@ -307,12 +307,18 @@ parse_args(int argc, char **argv)
 	g_trid.trtype = SPDK_NVME_TRANSPORT_PCIE;
 	snprintf(g_trid.subnqn, sizeof(g_trid.subnqn), "%s", SPDK_NVMF_DISCOVERY_NQN);
 
-	while ((op = getopt(argc, argv, "n:r:t:H:T")) != -1) {
+	while ((op = getopt(argc, argv, "n:r:HL:T")) != -1) {
 		switch (op) {
 		case 'n':
 			expected_ns_test = atoi(optarg);
 			break;
-		case 't':
+		case 'r':
+			if (spdk_nvme_transport_id_parse(&g_trid, optarg) != 0) {
+				fprintf(stderr, "Error parsing transport address\n");
+				return 1;
+			}
+			break;
+		case 'L':
 			rc = spdk_log_set_trace_flag(optarg);
 			if (rc < 0) {
 				fprintf(stderr, "unknown flag\n");
@@ -321,18 +327,12 @@ parse_args(int argc, char **argv)
 			}
 			spdk_log_set_print_level(SPDK_LOG_DEBUG);
 #ifndef DEBUG
-			fprintf(stderr, "%s must be rebuilt with CONFIG_DEBUG=y for -t flag.\n",
+			fprintf(stderr, "%s must be rebuilt with CONFIG_DEBUG=y for -L flag.\n",
 				argv[0]);
 			usage(argv[0]);
 			return 0;
 #endif
 			break;
-		case 'r':
-			if (spdk_nvme_transport_id_parse(&g_trid, optarg) != 0) {
-				fprintf(stderr, "Error parsing transport address\n");
-				return 1;
-			}
-			break;
 		case 'T':
 			enable_temp_test = 1;
 			break;
diff --git a/test/nvme/err_injection/.gitignore b/test/nvme/err_injection/.gitignore
new file mode 100644
index 000000000..3572a8e78
--- /dev/null
+++ b/test/nvme/err_injection/.gitignore
@@ -0,0 +1 @@
+err_injection
diff --git a/test/nvme/err_injection/Makefile b/test/nvme/err_injection/Makefile
new file mode 100644
index 000000000..4f5f18514
--- /dev/null
+++ b/test/nvme/err_injection/Makefile
@@ -0,0 +1,39 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+
+APP = err_injection
+
+include $(SPDK_ROOT_DIR)/mk/nvme.libtest.mk
diff --git a/test/nvme/err_injection/err_injection.c b/test/nvme/err_injection/err_injection.c
new file mode 100644
index 000000000..942e31ed1
--- /dev/null
+++ b/test/nvme/err_injection/err_injection.c
@@ -0,0 +1,273 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/stdinc.h"
+
+#include "spdk/log.h"
+#include "spdk/nvme.h"
+#include "spdk/env.h"
+
+#define MAX_DEVS 64
+
+struct dev {
+	bool						error_expected;
+	struct spdk_nvme_ctrlr				*ctrlr;
+	struct spdk_nvme_ns				*ns;
+	struct spdk_nvme_qpair				*qpair;
+	void						*data;
+	char						name[SPDK_NVMF_TRADDR_MAX_LEN + 1];
+};
+
+static struct dev devs[MAX_DEVS];
+static int num_devs = 0;
+
+#define foreach_dev(iter) \
+	for (iter = devs; iter - devs < num_devs; iter++)
+
+static int outstanding_commands = 0;
+static int failed = 0;
+
+static bool
+probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
+	 struct spdk_nvme_ctrlr_opts *opts)
+{
+	printf("Attaching to %s\n", trid->traddr);
+
+	return true;
+}
+
+static void
+attach_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
+	  struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_ctrlr_opts *opts)
+{
+	struct dev *dev;
+	uint32_t nsid;
+
+	/* add to dev list */
+	dev = &devs[num_devs++];
+	if (num_devs >= MAX_DEVS) {
+		return;
+	}
+
+	dev->ctrlr = ctrlr;
+	nsid = spdk_nvme_ctrlr_get_first_active_ns(ctrlr);
+	dev->ns = spdk_nvme_ctrlr_get_ns(ctrlr, nsid);
+	if (dev->ns == NULL) {
+		failed = 1;
+		return;
+	}
+	dev->qpair = spdk_nvme_ctrlr_alloc_io_qpair(ctrlr, NULL, 0);
+	if (dev->qpair == NULL) {
+		failed = 1;
+		return;
+	}
+
+	snprintf(dev->name, sizeof(dev->name), "%s",
+		 trid->traddr);
+
+	printf("Attached to %s\n", dev->name);
+}
+
+static void
+get_feature_test_cb(void *cb_arg, const struct spdk_nvme_cpl *cpl)
+{
+	struct dev *dev = cb_arg;
+
+	outstanding_commands--;
+
+	if (spdk_nvme_cpl_is_error(cpl) && dev->error_expected) {
+		if (cpl->status.sct != SPDK_NVME_SCT_GENERIC ||
+		    cpl->status.sc != SPDK_NVME_SC_INVALID_FIELD) {
+			failed = 1;
+		}
+		printf("%s: get features failed as expected\n", dev->name);
+		return;
+	}
+
+	if (!spdk_nvme_cpl_is_error(cpl) && !dev->error_expected) {
+		printf("%s: get features successfully as expected\n", dev->name);
+		return;
+	}
+
+	failed = 1;
+}
+
+static void
+get_feature_test(bool error_expected)
+{
+	struct dev *dev;
+	struct spdk_nvme_cmd cmd;
+
+	memset(&cmd, 0, sizeof(cmd));
+	cmd.opc = SPDK_NVME_OPC_GET_FEATURES;
+	cmd.cdw10 = SPDK_NVME_FEAT_NUMBER_OF_QUEUES;
+
+	foreach_dev(dev) {
+		dev->error_expected = error_expected;
+		if (spdk_nvme_ctrlr_cmd_admin_raw(dev->ctrlr, &cmd, NULL, 0,
+						  get_feature_test_cb, dev) != 0) {
+			printf("Error: failed to send Get Features command for dev=%p\n", dev);
+			failed = 1;
+			goto cleanup;
+		}
+		outstanding_commands++;
+	}
+
+cleanup:
+
+	while (outstanding_commands) {
+		foreach_dev(dev) {
+			spdk_nvme_ctrlr_process_admin_completions(dev->ctrlr);
+		}
+	}
+}
+
+static void
+read_test_cb(void *cb_arg, const struct spdk_nvme_cpl *cpl)
+{
+	struct dev *dev = cb_arg;
+
+	outstanding_commands--;
+	spdk_dma_free(dev->data);
+
+	if (spdk_nvme_cpl_is_error(cpl) && dev->error_expected) {
+		if (cpl->status.sct != SPDK_NVME_SCT_MEDIA_ERROR ||
+		    cpl->status.sc != SPDK_NVME_SC_UNRECOVERED_READ_ERROR) {
+			failed = 1;
+		}
+		printf("%s: read failed as expected\n", dev->name);
+		return;
+	}
+
+	if (!spdk_nvme_cpl_is_error(cpl) && !dev->error_expected) {
+		printf("%s: read successfully as expected\n", dev->name);
+		return;
+	}
+
+	failed = 1;
+}
+
+static void
+read_test(bool error_expected)
+{
+	struct dev *dev;
+
+	foreach_dev(dev) {
+		dev->error_expected = error_expected;
+		dev->data = spdk_dma_zmalloc(0x1000, 0x1000, NULL);
+		if (!dev->data) {
+			failed = 1;
+			goto cleanup;
+		}
+
+		if (spdk_nvme_ns_cmd_read(dev->ns, dev->qpair, dev->data,
+					  0, 1, read_test_cb, dev, 0) != 0) {
+			printf("Error: failed to send Read command for dev=%p\n", dev);
+			failed = 1;
+			goto cleanup;
+		}
+
+		outstanding_commands++;
+	}
+
+cleanup:
+
+	while (outstanding_commands) {
+		foreach_dev(dev) {
+			spdk_nvme_qpair_process_completions(dev->qpair, 0);
+		}
+	}
+}
+
+int main(int argc, char **argv)
+{
+	struct dev		*dev;
+	int			i;
+	struct spdk_env_opts	opts;
+	int			rc;
+
+	spdk_env_opts_init(&opts);
+	opts.name = "err_injection";
+	opts.core_mask = "0x1";
+	opts.mem_size = 64;
+	if (spdk_env_init(&opts) < 0) {
+		fprintf(stderr, "Unable to initialize SPDK env\n");
+		return 1;
+	}
+
+	printf("NVMe Error Injection test\n");
+
+	if (spdk_nvme_probe(NULL, NULL, probe_cb, attach_cb, NULL) != 0) {
+		fprintf(stderr, "spdk_nvme_probe() failed\n");
+		return 1;
+	}
+
+	if (failed) {
+		goto exit;
+	}
+
+	foreach_dev(dev) {
+		/* Admin error injection at submission path */
+		rc = spdk_nvme_qpair_add_cmd_error_injection(dev->ctrlr, NULL,
+				SPDK_NVME_OPC_GET_FEATURES, true, 5000, 1,
+				SPDK_NVME_SCT_GENERIC, SPDK_NVME_SC_INVALID_FIELD);
+		failed += rc;
+		/* IO error injection at completion path */
+		rc = spdk_nvme_qpair_add_cmd_error_injection(dev->ctrlr, dev->qpair,
+				SPDK_NVME_OPC_READ, false, 0, 1,
+				SPDK_NVME_SCT_MEDIA_ERROR, SPDK_NVME_SC_UNRECOVERED_READ_ERROR);
+		failed += rc;
+	}
+
+	if (failed) {
+		goto exit;
+	}
+
+	/* Admin Get Feature, expect error return */
+	get_feature_test(true);
+	/* Admin Get Feature, expect successful return */
+	get_feature_test(false);
+	/* Read, expect error return */
+	read_test(true);
+	/* Read, expect successful return */
+	read_test(false);
+
+exit:
+	printf("Cleaning up...\n");
+	for (i = 0; i < num_devs; i++) {
+		struct dev *dev = &devs[i];
+		spdk_nvme_detach(dev->ctrlr);
+	}
+
+	return failed;
+}
diff --git a/test/nvme/hotplug.sh b/test/nvme/hotplug.sh
index b6e8f250d..ca661b6f8 100755
--- a/test/nvme/hotplug.sh
+++ b/test/nvme/hotplug.sh
@@ -6,6 +6,11 @@ testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $testdir/../..)
 source $rootdir/test/common/autotest_common.sh
 
+if [ -z "${DEPENDENCY_DIR}" ]; then
+	echo DEPENDENCY_DIR not defined!
+	exit 1
+fi
+
 function ssh_vm() {
 	sshpass -p "$password" ssh -o PubkeyAuthentication=no -o StrictHostKeyChecking=no -p 10022 root@localhost "$@"
 }
@@ -72,9 +77,9 @@ function devices_delete() {
 }
 
 password=$1
-base_img=/home/sys_sgsw/fedora24.img
-test_img=/home/sys_sgsw/fedora24_test.img
-qemu_pidfile=/home/sys_sgsw/qemupid
+base_img=${DEPENDENCY_DIR}/fedora24.img
+test_img=${DEPENDENCY_DIR}/fedora24_test.img
+qemu_pidfile=${DEPENDENCY_DIR}/qemupid
 
 if [ ! -e "$base_img" ]; then
 	echo "Hotplug VM image not found; skipping test"
diff --git a/test/nvme/nvme.sh b/test/nvme/nvme.sh
index 59d2a261f..18b8800f5 100755
--- a/test/nvme/nvme.sh
+++ b/test/nvme/nvme.sh
@@ -139,6 +139,10 @@ timing_enter e2edp
 $testdir/e2edp/nvme_dp
 timing_exit e2edp
 
+timing_enter err_injection
+$testdir/err_injection/err_injection
+timing_exit err_injection
+
 timing_enter overhead
 $testdir/overhead/overhead -s 4096 -t 1 -H
 timing_exit overhead
diff --git a/test/nvme/overhead/overhead.c b/test/nvme/overhead/overhead.c
index 834a353a9..86c37f268 100644
--- a/test/nvme/overhead/overhead.c
+++ b/test/nvme/overhead/overhead.c
@@ -293,7 +293,7 @@ submit_single_io(void)
 	offset_in_ios = rand_r(&seed) % entry->size_in_ios;
 
 	start = spdk_get_ticks();
-	spdk_mb();
+	spdk_rmb();
 #if HAVE_LIBAIO
 	if (entry->type == ENTRY_TYPE_AIO_FILE) {
 		rc = aio_submit(g_ns->u.aio.ctx, &g_task->iocb, entry->u.aio.fd, IO_CMD_PREAD, g_task->buf,
@@ -306,7 +306,7 @@ submit_single_io(void)
 					   entry->io_size_blocks, io_complete, g_task, 0);
 	}
 
-	spdk_mb();
+	spdk_rmb();
 	tsc_submit = spdk_get_ticks() - start;
 	g_tsc_submit += tsc_submit;
 	if (tsc_submit < g_tsc_submit_min) {
@@ -334,11 +334,12 @@ io_complete(void *ctx, const struct spdk_nvme_cpl *completion)
 
 uint64_t g_complete_tsc_start;
 
-static void
+static uint64_t
 check_io(void)
 {
 	uint64_t end, tsc_complete;
-	spdk_mb();
+
+	spdk_rmb();
 #if HAVE_LIBAIO
 	if (g_ns->type == ENTRY_TYPE_AIO_FILE) {
 		aio_check_io();
@@ -347,7 +348,7 @@ check_io(void)
 	{
 		spdk_nvme_qpair_process_completions(g_ns->u.nvme.qpair, 0);
 	}
-	spdk_mb();
+	spdk_rmb();
 	end = spdk_get_ticks();
 	if (g_ns->current_queue_depth == 1) {
 		/*
@@ -377,8 +378,10 @@ check_io(void)
 		if (!g_ns->is_draining) {
 			submit_single_io();
 		}
-		g_complete_tsc_start = spdk_get_ticks();
+		end = g_complete_tsc_start = spdk_get_ticks();
 	}
+
+	return end;
 }
 
 static void
@@ -437,7 +440,7 @@ cleanup_ns_worker_ctx(void)
 static int
 work_fn(void)
 {
-	uint64_t tsc_end;
+	uint64_t tsc_end, current;
 
 	/* Allocate a queue pair for each namespace. */
 	if (init_ns_worker_ctx() != 0) {
@@ -457,9 +460,9 @@ work_fn(void)
 		 * I/O will be submitted in the io_complete callback
 		 * to replace each I/O that is completed.
 		 */
-		check_io();
+		current = check_io();
 
-		if (spdk_get_ticks() > tsc_end) {
+		if (current > tsc_end) {
 			break;
 		}
 	}
@@ -585,7 +588,7 @@ probe_cb(void *cb_ctx, const struct spdk_nvme_transport_id *trid,
 	static uint32_t ctrlr_found = 0;
 
 	if (ctrlr_found == 1) {
-		fprintf(stderr, "only attching to one controller, so skipping\n");
+		fprintf(stderr, "only attaching to one controller, so skipping\n");
 		fprintf(stderr, " controller at PCI address %s\n",
 			trid->traddr);
 		return false;
@@ -680,9 +683,11 @@ int main(int argc, char **argv)
 	print_stats();
 
 cleanup:
-	spdk_histogram_data_free(g_ns->submit_histogram);
-	spdk_histogram_data_free(g_ns->complete_histogram);
-	free(g_ns);
+	if (g_ns) {
+		spdk_histogram_data_free(g_ns->submit_histogram);
+		spdk_histogram_data_free(g_ns->complete_histogram);
+		free(g_ns);
+	}
 	if (g_ctrlr) {
 		spdk_nvme_detach(g_ctrlr->ctrlr);
 		free(g_ctrlr);
diff --git a/test/nvme/spdk_nvme_cli.sh b/test/nvme/spdk_nvme_cli.sh
index a3cff6d7d..9984f8c4a 100755
--- a/test/nvme/spdk_nvme_cli.sh
+++ b/test/nvme/spdk_nvme_cli.sh
@@ -6,7 +6,13 @@ testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $testdir/../..)
 source $rootdir/scripts/common.sh
 source $rootdir/test/common/autotest_common.sh
-spdk_nvme_cli="/home/sys_sgsw/nvme-cli"
+
+if [ -z "${DEPENDENCY_DIR}" ]; then
+        echo DEPENDENCY_DIR not defined!
+        exit 1
+fi
+
+spdk_nvme_cli="${DEPENDENCY_DIR}/nvme-cli"
 
 if [ ! -d $spdk_nvme_cli ]; then
 	echo "nvme-cli repository not found at $spdk_nvme_cli; skipping tests."
diff --git a/test/nvmf/discovery/discovery.sh b/test/nvmf/discovery/discovery.sh
index 57d6d1069..45a417f13 100755
--- a/test/nvmf/discovery/discovery.sh
+++ b/test/nvmf/discovery/discovery.sh
@@ -27,22 +27,24 @@ fi
 timing_enter discovery
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
-bdevs="$bdevs $($rpc_py construct_null_bdev Null0 $NULL_BDEV_SIZE $NULL_BLOCK_SIZE)"
-bdevs="$bdevs $($rpc_py construct_null_bdev Null1 $NULL_BDEV_SIZE $NULL_BLOCK_SIZE)"
+null_bdevs="$($rpc_py construct_null_bdev Null0 $NULL_BDEV_SIZE $NULL_BLOCK_SIZE) "
+null_bdevs+="$($rpc_py construct_null_bdev Null1 $NULL_BDEV_SIZE $NULL_BLOCK_SIZE)"
 
 modprobe -v nvme-rdma
 
 $rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:4420" "" -a -s SPDK00000000000001
-for bdev in $bdevs; do
-	$rpc_py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 $bdev
+for null_bdev in $null_bdevs; do
+	$rpc_py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 $null_bdev
 done
 
 nvme discover -t rdma -a $NVMF_FIRST_TARGET_IP -s $NVMF_PORT
@@ -52,8 +54,9 @@ $rpc_py get_nvmf_subsystems
 
 $rpc_py delete_nvmf_subsystem nqn.2016-06.io.spdk:cnode1
 
-$rpc_py delete_bdev Null1
-$rpc_py delete_bdev Null0
+for null_bdev in $null_bdevs; do
+	$rpc_py delete_null_bdev $null_bdev
+done
 
 check_bdevs=$($rpc_py get_bdevs | jq -r '.[].name')
 if [ -n "$check_bdevs" ]; then
diff --git a/test/nvmf/filesystem/filesystem.sh b/test/nvmf/filesystem/filesystem.sh
index 583adecc4..175f9e4dd 100755
--- a/test/nvmf/filesystem/filesystem.sh
+++ b/test/nvmf/filesystem/filesystem.sh
@@ -20,67 +20,73 @@ if [ -z $NVMF_FIRST_TARGET_IP ]; then
 fi
 
 timing_enter fs_test
-timing_enter start_nvmf_tgt
-# Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
-nvmfpid=$!
 
-trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
+for incapsule in 0 4096; do
+	# Start up the NVMf target in another process
+	$NVMF_APP -m 0xF -w &
+	nvmfpid=$!
 
-waitforlisten $nvmfpid
-timing_exit start_nvmf_tgt
+	trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
-bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
-bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
+	waitforlisten $nvmfpid
+	$rpc_py set_nvmf_target_options -u 8192 -p 4 -c $incapsule
+	$rpc_py start_subsystem_init
 
-modprobe -v nvme-rdma
+	bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
+	bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
 
-$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:4420" "" -a -s SPDK00000000000001 -n "$bdevs"
+	modprobe -v nvme-rdma
 
-nvme connect -t rdma -n "nqn.2016-06.io.spdk:cnode1" -a "$NVMF_FIRST_TARGET_IP" -s "$NVMF_PORT"
+	$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:4420" "" -a -s SPDK00000000000001 -n "$bdevs"
 
-waitforblk "nvme0n1"
-waitforblk "nvme0n2"
+	nvme connect -t rdma -n "nqn.2016-06.io.spdk:cnode1" -a "$NVMF_FIRST_TARGET_IP" -s "$NVMF_PORT"
 
-mkdir -p /mnt/device
+	waitforblk "nvme0n1"
+	waitforblk "nvme0n2"
 
-devs=`lsblk -l -o NAME | grep nvme`
+	mkdir -p /mnt/device
 
-for dev in $devs; do
-	timing_enter parted
-	parted -s /dev/$dev mklabel msdos  mkpart primary '0%' '100%'
-	timing_exit parted
-	sleep 1
+	devs=`lsblk -l -o NAME | grep nvme`
 
-	for fstype in "ext4" "btrfs" "xfs"; do
-		timing_enter $fstype
-		if [ $fstype = ext4 ]; then
-			force=-F
-		else
-			force=-f
-		fi
+	for dev in $devs; do
+		timing_enter parted
+		parted -s /dev/$dev mklabel msdos  mkpart primary '0%' '100%'
+		timing_exit parted
+		sleep 1
 
-		mkfs.${fstype} $force /dev/${dev}p1
+		for fstype in "ext4" "btrfs" "xfs"; do
+			timing_enter $fstype
+			if [ $fstype = ext4 ]; then
+				force=-F
+			else
+				force=-f
+			fi
 
-		mount /dev/${dev}p1 /mnt/device
-		touch /mnt/device/aaa
-		sync
-		rm /mnt/device/aaa
-		sync
-		umount /mnt/device
-		timing_exit $fstype
+			mkfs.${fstype} $force /dev/${dev}p1
+
+			mount /dev/${dev}p1 /mnt/device
+			touch /mnt/device/aaa
+			sync
+			rm /mnt/device/aaa
+			sync
+			umount /mnt/device
+			timing_exit $fstype
+		done
+
+		parted -s /dev/$dev rm 1
 	done
 
-	parted -s /dev/$dev rm 1
-done
+	sync
+	nvme disconnect -n "nqn.2016-06.io.spdk:cnode1" || true
 
-sync
-nvme disconnect -n "nqn.2016-06.io.spdk:cnode1" || true
+	$rpc_py delete_nvmf_subsystem nqn.2016-06.io.spdk:cnode1
 
-$rpc_py delete_nvmf_subsystem nqn.2016-06.io.spdk:cnode1
+	trap - SIGINT SIGTERM EXIT
+
+	nvmfcleanup
+	killprocess $nvmfpid
+done
 
-trap - SIGINT SIGTERM EXIT
+rm -f /tmp/nvmf.conf
 
-nvmfcleanup
-killprocess $nvmfpid
 timing_exit fs_test
diff --git a/test/nvmf/fio/fio.sh b/test/nvmf/fio/fio.sh
index b3bd579e7..a35332df4 100755
--- a/test/nvmf/fio/fio.sh
+++ b/test/nvmf/fio/fio.sh
@@ -22,23 +22,25 @@ fi
 timing_enter fio
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
-bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
-bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
+malloc_bdevs="$($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE) "
+malloc_bdevs+="$($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
 
 modprobe -v nvme-rdma
 
 $rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:4420" "" -a -s SPDK00000000000001
 
-for bdev in $bdevs; do
-	$rpc_py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 "$bdev"
+for malloc_bdev in $malloc_bdevs; do
+	$rpc_py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 "$malloc_bdev"
 done
 
 nvme connect -t rdma -n "nqn.2016-06.io.spdk:cnode1" -a "$NVMF_FIRST_TARGET_IP" -s "$NVMF_PORT"
@@ -60,8 +62,8 @@ fio_pid=$!
 sleep 3
 set +e
 
-for bdev in $bdevs; do
-	$rpc_py delete_bdev "$bdev"
+for malloc_bdev in $malloc_bdevs; do
+	$rpc_py delete_malloc_bdev "$malloc_bdev"
 done
 
 wait $fio_pid
diff --git a/test/nvmf/host/aer.sh b/test/nvmf/host/aer.sh
index 28644fcdc..6ef2d79b4 100755
--- a/test/nvmf/host/aer.sh
+++ b/test/nvmf/host/aer.sh
@@ -19,18 +19,21 @@ fi
 timing_enter aer
 timing_enter start_nvmf_tgt
 
-$NVMF_APP -s 512 -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 modprobe -v nvme-rdma
 
 $rpc_py construct_malloc_bdev 64 512 --name Malloc0
-$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:$NVMF_PORT" '' -a -s SPDK00000000000001 -n Malloc0
+$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode1 "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:$NVMF_PORT" '' -a -s SPDK00000000000001 -n Malloc0 -m 2
+$rpc_py get_nvmf_subsystems
 
 # TODO: this aer test tries to invoke an AER completion by setting the temperature
 #threshold to a very low value.  This does not work with emulated controllers
@@ -58,11 +61,12 @@ sleep 5
 # Add a new namespace
 $rpc_py construct_malloc_bdev 64 4096 --name Malloc1
 $rpc_py nvmf_subsystem_add_ns nqn.2016-06.io.spdk:cnode1 Malloc1 -n 2
+$rpc_py get_nvmf_subsystems
 
 wait $aerpid
 
-$rpc_py delete_bdev Malloc0
-$rpc_py delete_bdev Malloc1
+$rpc_py delete_malloc_bdev Malloc0
+$rpc_py delete_malloc_bdev Malloc1
 $rpc_py delete_nvmf_subsystem nqn.2016-06.io.spdk:cnode1
 
 trap - SIGINT SIGTERM EXIT
diff --git a/test/nvmf/host/bdevperf.sh b/test/nvmf/host/bdevperf.sh
index 2124eb0ea..972ab31f4 100755
--- a/test/nvmf/host/bdevperf.sh
+++ b/test/nvmf/host/bdevperf.sh
@@ -22,12 +22,14 @@ fi
 timing_enter bdevperf
 timing_enter start_nvmf_tgt
 
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
diff --git a/test/nvmf/host/fio.sh b/test/nvmf/host/fio.sh
index d497019fa..a06d0907e 100755
--- a/test/nvmf/host/fio.sh
+++ b/test/nvmf/host/fio.sh
@@ -25,12 +25,14 @@ fi
 timing_enter fio
 timing_enter start_nvmf_tgt
 
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 bdevs="$bdevs $($rpc_py construct_malloc_bdev 64 512)"
diff --git a/test/nvmf/host/identify.sh b/test/nvmf/host/identify.sh
index fc1b0b2b7..7ac10d96e 100755
--- a/test/nvmf/host/identify.sh
+++ b/test/nvmf/host/identify.sh
@@ -21,12 +21,14 @@ fi
 timing_enter identify
 timing_enter start_nvmf_tgt
 
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
@@ -49,13 +51,13 @@ $rootdir/examples/nvme/identify/identify -r "\
         adrfam:IPv4 \
         traddr:$NVMF_FIRST_TARGET_IP \
         trsvcid:$NVMF_PORT \
-        subnqn:nqn.2014-08.org.nvmexpress.discovery" -t all
+        subnqn:nqn.2014-08.org.nvmexpress.discovery" -L all
 $rootdir/examples/nvme/identify/identify -r "\
         trtype:RDMA \
         adrfam:IPv4 \
         traddr:$NVMF_FIRST_TARGET_IP \
         trsvcid:$NVMF_PORT \
-        subnqn:nqn.2016-06.io.spdk:cnode1" -t all
+        subnqn:nqn.2016-06.io.spdk:cnode1" -L all
 sync
 $rpc_py delete_nvmf_subsystem nqn.2016-06.io.spdk:cnode1
 
diff --git a/test/nvmf/host/perf.sh b/test/nvmf/host/perf.sh
index 916d4eb6c..c9234c913 100755
--- a/test/nvmf/host/perf.sh
+++ b/test/nvmf/host/perf.sh
@@ -22,19 +22,18 @@ fi
 timing_enter perf
 timing_enter start_nvmf_tgt
 
-cp $testdir/../nvmf.conf $testdir/nvmf.conf
-$rootdir/scripts/gen_nvme.sh >> $testdir/nvmf.conf
-
-local_nvme_trid=$(grep TransportID $testdir/nvmf.conf | head -n1 | awk -F"\"" '{print $2}')
-
-$NVMF_APP -c $testdir/nvmf.conf -i 0 &
+$NVMF_APP -m 0xF -w -i 0 &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
+$rootdir/scripts/gen_nvme.sh --json | $rpc_py load_subsystem_config
 timing_exit start_nvmf_tgt
 
+local_nvme_trid="trtype:PCIe traddr:"$($rpc_py get_subsystem_config bdev | jq -r '.[].params | select(.name=="Nvme0").traddr')
 bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
 
 if [ -n "$local_nvme_trid" ]; then
@@ -87,7 +86,5 @@ fi
 
 trap - SIGINT SIGTERM EXIT
 
-rm -f $testdir/nvmf.conf
-
 killprocess $nvmfpid
 timing_exit perf
diff --git a/test/nvmf/lvol/nvmf_lvol.sh b/test/nvmf/lvol/nvmf_lvol.sh
index e24c26086..b76f9fc5d 100755
--- a/test/nvmf/lvol/nvmf_lvol.sh
+++ b/test/nvmf/lvol/nvmf_lvol.sh
@@ -39,12 +39,14 @@ fi
 timing_enter lvol_integrity
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 pid=$!
 
 trap "disconnect_nvmf; killprocess $pid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 modprobe -v nvme-rdma
diff --git a/test/nvmf/multiconnection/multiconnection.sh b/test/nvmf/multiconnection/multiconnection.sh
index 4f6b688e8..afd49fbab 100755
--- a/test/nvmf/multiconnection/multiconnection.sh
+++ b/test/nvmf/multiconnection/multiconnection.sh
@@ -31,12 +31,14 @@ fi
 timing_enter multiconnection
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 pid=$!
 
 trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 modprobe -v nvme-rdma
@@ -51,9 +53,7 @@ for i in `seq 1 $NVMF_SUBSYS`; do
 	k=$[$i-1]
 	nvme connect -t rdma -n "nqn.2016-06.io.spdk:cnode${i}" -a "$NVMF_FIRST_TARGET_IP" -s "$NVMF_PORT"
 
-	for j in `seq 1 10`; do
-		waitforblk "nvme${k}n${j}"
-	done
+	waitforblk "nvme${k}n1"
 done
 
 $testdir/../fio/nvmf_fio.py 262144 64 read 10
diff --git a/test/nvmf/nvme_cli/nvme_cli.sh b/test/nvmf/nvme_cli/nvme_cli.sh
index 8028897c0..6c1e27772 100755
--- a/test/nvmf/nvme_cli/nvme_cli.sh
+++ b/test/nvmf/nvme_cli/nvme_cli.sh
@@ -4,7 +4,13 @@ testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $testdir/../../..)
 source $rootdir/test/common/autotest_common.sh
 source $rootdir/test/nvmf/common.sh
-spdk_nvme_cli="/home/sys_sgsw/nvme-cli"
+
+if [ -z "${DEPENDENCY_DIR}" ]; then
+        echo DEPENDENCY_DIR not defined!
+        exit 1
+fi
+
+spdk_nvme_cli="${DEPENDENCY_DIR}/nvme-cli"
 
 MALLOC_BDEV_SIZE=64
 MALLOC_BLOCK_SIZE=512
@@ -22,12 +28,14 @@ fi
 
 timing_enter nvme_cli
 timing_enter start_nvmf_tgt
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 nvmfpid=$!
 
 trap "killprocess $nvmfpid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $nvmfpid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 bdevs="$bdevs $($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
@@ -78,4 +86,5 @@ trap - SIGINT SIGTERM EXIT
 
 nvmfcleanup
 killprocess $nvmfpid
+report_test_completion "nvmf_spdk_nvme_cli"
 timing_exit nvme_cli
diff --git a/test/nvmf/nvmf.conf b/test/nvmf/nvmf.conf
index ac6a5d9e2..abe62e8dc 100644
--- a/test/nvmf/nvmf.conf
+++ b/test/nvmf/nvmf.conf
@@ -4,3 +4,4 @@
 
 [Nvmf]
   MaxQueuesPerSession 4
+  IOUnitSize 8192
diff --git a/test/nvmf/nvmf.sh b/test/nvmf/nvmf.sh
index b923ddea3..14720cfbd 100755
--- a/test/nvmf/nvmf.sh
+++ b/test/nvmf/nvmf.sh
@@ -25,11 +25,13 @@ export NVMF_APP="./app/nvmf_tgt/nvmf_tgt -i 0"
 
 run_test test/nvmf/filesystem/filesystem.sh
 run_test test/nvmf/discovery/discovery.sh
-run_test test/nvmf/nvme_cli/nvme_cli.sh
+if [ $SPDK_TEST_NVME_CLI -eq 1 ]; then
+	run_test test/nvmf/nvme_cli/nvme_cli.sh
+fi
 run_test test/nvmf/lvol/nvmf_lvol.sh
 run_test test/nvmf/shutdown/shutdown.sh
 
-if [ $RUN_NIGHTLY_FAILING -eq 1 ]; then
+if [ $RUN_NIGHTLY -eq 1 ]; then
 	run_test test/nvmf/multiconnection/multiconnection.sh
 fi
 
@@ -38,7 +40,8 @@ timing_enter host
 run_test test/nvmf/host/bdevperf.sh
 run_test test/nvmf/host/identify.sh
 run_test test/nvmf/host/perf.sh
-run_test test/nvmf/host/identify_kernel_nvmf.sh
+# TODO: disabled due to intermittent failures (RDMA_CM_EVENT_UNREACHABLE/ETIMEDOUT)
+#run_test test/nvmf/host/identify_kernel_nvmf.sh
 run_test test/nvmf/host/aer.sh
 run_test test/nvmf/host/fio.sh
 
diff --git a/test/nvmf/nvmfjson/json_config.sh b/test/nvmf/nvmfjson/json_config.sh
new file mode 100755
index 000000000..b98b3cf11
--- /dev/null
+++ b/test/nvmf/nvmfjson/json_config.sh
@@ -0,0 +1,39 @@
+#!/usr/bin/env bash
+set -xe
+NVMF_JSON_DIR=$(readlink -f $(dirname $0))
+. $NVMF_JSON_DIR/../../json_config/common.sh
+base_nvmf_config=$JSON_DIR/base_nvmf_config.json
+last_nvmf_config=$JSON_DIR/last_nvmf_config.json
+
+function test_subsystems() {
+	run_spdk_tgt
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+
+	$rpc_py start_subsystem_init
+	create_nvmf_subsystem_config
+	$rpc_py save_config -f $base_nvmf_config
+	test_json_config
+
+	clear_nvmf_subsystem_config
+	kill_targets
+
+	run_spdk_tgt
+	$rpc_py load_config -f $base_nvmf_config
+	$rpc_py save_config -f $last_nvmf_config
+
+	diff $base_nvmf_config $last_nvmf_config
+
+	clear_nvmf_subsystem_config
+	kill_targets
+	rm -f $base_nvmf_config $last_nvmf_config
+}
+
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"; rm -f $base_nvmf_config $last_nvmf_config' ERR
+
+timing_enter nvmf_json_config
+test_subsystems
+timing_exit nvmf_json_config
+
+report_test_completion nvmf_json_config
diff --git a/test/nvmf/rpc/rpc.sh b/test/nvmf/rpc/rpc.sh
index f99a99794..5b3ab33d8 100755
--- a/test/nvmf/rpc/rpc.sh
+++ b/test/nvmf/rpc/rpc.sh
@@ -19,12 +19,14 @@ fi
 timing_enter rpc
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$rootdir/app/nvmf_tgt/nvmf_tgt -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 pid=$!
 
 trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
 # set times for subsystem construct/delete
diff --git a/test/nvmf/shutdown/shutdown.sh b/test/nvmf/shutdown/shutdown.sh
index cbd6d0fc1..1e0411414 100755
--- a/test/nvmf/shutdown/shutdown.sh
+++ b/test/nvmf/shutdown/shutdown.sh
@@ -22,25 +22,45 @@ fi
 timing_enter shutdown
 timing_enter start_nvmf_tgt
 # Start up the NVMf target in another process
-$NVMF_APP -c $testdir/../nvmf.conf &
+$NVMF_APP -m 0xF -w &
 pid=$!
 
-trap "killprocess $pid; exit 1" SIGINT SIGTERM EXIT
+trap "killprocess $pid; nvmfcleanup; exit 1" SIGINT SIGTERM EXIT
 
 waitforlisten $pid
+$rpc_py set_nvmf_target_options -u 8192 -p 4
+$rpc_py start_subsystem_init
 timing_exit start_nvmf_tgt
 
-# Create 10 subsystems
-for i in `seq 1 10`
+num_subsystems=10
+# SoftRoce does not have enough queues available for
+# this test. Detect if we're using software RDMA.
+# If so, only use one subsystem.
+if check_ip_is_soft_roce "$NVMF_FIRST_TARGET_IP"; then
+	num_subsystems=1
+fi
+
+# Create subsystems
+for i in `seq 1 $num_subsystems`
 do
 	bdevs="$($rpc_py construct_malloc_bdev $MALLOC_BDEV_SIZE $MALLOC_BLOCK_SIZE)"
 	$rpc_py construct_nvmf_subsystem nqn.2016-06.io.spdk:cnode${i} "trtype:RDMA traddr:$NVMF_FIRST_TARGET_IP trsvcid:$NVMF_PORT" '' -a -s SPDK${i} -n "$bdevs"
 done
 
+modprobe -v nvme-rdma
+modprobe -v nvme-fabrics
+
+# Connect kernel host to subsystems
+for i in `seq 1 $num_subsystems`; do
+	nvme connect -t rdma -n "nqn.2016-06.io.spdk:cnode${i}" -a "$NVMF_FIRST_TARGET_IP" -s "$NVMF_PORT"
+done
+
 # Kill nvmf tgt without removing any subsystem to check whether it can shutdown correctly
 rm -f ./local-job0-0-verify.state
 
 trap - SIGINT SIGTERM EXIT
 
 killprocess $pid
+
+nvmfcleanup
 timing_exit shutdown
diff --git a/test/pmem/json_config/json_config.sh b/test/pmem/json_config/json_config.sh
new file mode 100755
index 000000000..bd232b8f3
--- /dev/null
+++ b/test/pmem/json_config/json_config.sh
@@ -0,0 +1,25 @@
+#!/usr/bin/env bash
+set -ex
+VHOST_JSON_DIR=$(readlink -f $(dirname $0))
+. $VHOST_JSON_DIR/../../json_config/common.sh
+
+function test_subsystems() {
+	run_spdk_tgt
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	$rpc_py start_subsystem_init
+
+	create_pmem_bdev_subsytem_config
+	test_json_config
+	clear_pmem_bdev_subsystem_config
+
+	kill_targets
+}
+
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"' ERR
+timing_enter json_config_pmem
+
+test_subsystems
+timing_exit json_config_pmem
+report_test_completion json_config_pmem
diff --git a/test/pmem/pmem.sh b/test/pmem/pmem.sh
index 524b23fd1..15188635d 100755
--- a/test/pmem/pmem.sh
+++ b/test/pmem/pmem.sh
@@ -101,7 +101,7 @@ function pmem_pool_info_tc3()
 	if hash pmempool; then
 		pmempool create -s 32000000 obj $obj_pool_file
 	else
-		echo "Warning: nvml-tools package not found! Creating stub file."
+		echo "Warning: pmempool package not found! Creating stub file."
 		truncate -s "32M" $obj_pool_file
 	fi
 
@@ -392,7 +392,7 @@ function delete_pmem_pool_tc2()
 	if hash pmempool; then
 		pmempool create -s 32000000 obj $obj_pool_file
 	else
-		echo "Warning: nvml-tools package not found! Creating stub file."
+		echo "Warning: pmempool package not found! Creating stub file."
 		truncate -s "32M" $obj_pool_file
 	fi
 
@@ -499,7 +499,7 @@ function construct_pmem_bdev_tc4()
 	if hash pmempool; then
 		pmempool create -s 32000000 obj $obj_pool_file
 	else
-		echo "Warning: nvml-tools package not found! Creating stub file."
+		echo "Warning: pmempool package not found! Creating stub file."
 		truncate -s "32M" $obj_pool_file
 	fi
 
@@ -532,7 +532,7 @@ function construct_pmem_bdev_tc5()
 		error "Pmem bdev not found!"
 	fi
 
-	if ! $rpc_py delete_bdev $pmem_bdev_name; then
+	if ! $rpc_py delete_pmem_bdev $pmem_bdev_name; then
 		error "Failed to delete pmem bdev!"
 	fi
 
@@ -568,7 +568,7 @@ function construct_pmem_bdev_tc6()
 		error "Constructed pmem bdev with occupied path!"
 	fi
 
-	if ! $rpc_py delete_bdev $pmem_bdev_name; then
+	if ! $rpc_py delete_pmem_bdev $pmem_bdev_name; then
 		error "Failed to delete pmem bdev!"
 	fi
 
@@ -604,7 +604,7 @@ function delete_bdev_tc1()
 		error "$pmem_bdev_name bdev not found!"
 	fi
 
-	if ! $rpc_py delete_bdev $pmem_bdev_name; then
+	if ! $rpc_py delete_pmem_bdev $pmem_bdev_name; then
 		error "Failed to delete $pmem_bdev_name bdev!"
 	fi
 
@@ -637,12 +637,12 @@ function delete_bdev_tc2()
 		error "Pmem bdev not found!"
 	fi
 
-	if ! $rpc_py delete_bdev $pmem_bdev_name; then
+	if ! $rpc_py delete_pmem_bdev $pmem_bdev_name; then
 		error "Failed to delete pmem bdev!"
 	fi
 
-	if $rpc_py delete_bdev $pmem_bdev_name; then
-		error "delete_bdev deleted pmem bdev for second time!"
+	if $rpc_py delete_pmem_bdev $pmem_bdev_name; then
+		error "delete_pmem_bdev deleted pmem bdev for second time!"
 	fi
 
 	pmem_clean_pool_file
diff --git a/test/spdk_cunit.h b/test/spdk_cunit.h
index 0d0ecf1d1..6696bff35 100644
--- a/test/spdk_cunit.h
+++ b/test/spdk_cunit.h
@@ -53,6 +53,4 @@
 		}				\
 	} while (0)
 
-int spdk_cunit_print_results(const char *filename);
-
 #endif /* SPDK_CUNIT_H */
diff --git a/test/unit/lib/Makefile b/test/unit/lib/Makefile
index 190ff9762..205835ee4 100644
--- a/test/unit/lib/Makefile
+++ b/test/unit/lib/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = bdev blob blobfs event ioat iscsi json jsonrpc log lvol net nvme nvmf scsi util
+DIRS-y = bdev blob blobfs event ioat iscsi json jsonrpc log lvol nvme nvmf scsi sock thread util
 ifeq ($(OS),Linux)
 DIRS-$(CONFIG_VHOST) += vhost
 endif
diff --git a/test/unit/lib/bdev/Makefile b/test/unit/lib/bdev/Makefile
index d105e8450..3721b5eea 100644
--- a/test/unit/lib/bdev/Makefile
+++ b/test/unit/lib/bdev/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = bdev.c part.c scsi_nvme.c gpt vbdev_lvol.c mt
+DIRS-y = bdev.c part.c scsi_nvme.c gpt vbdev_lvol.c mt bdev_raid.c
 
 DIRS-$(CONFIG_PMDK) += pmem
 
diff --git a/test/unit/lib/bdev/bdev.c/bdev_ut.c b/test/unit/lib/bdev/bdev.c/bdev_ut.c
index 51e96955d..97ee20242 100644
--- a/test/unit/lib/bdev/bdev.c/bdev_ut.c
+++ b/test/unit/lib/bdev/bdev.c/bdev_ut.c
@@ -41,19 +41,11 @@
 
 #include "bdev/bdev.c"
 
-/* Return NULL to test hardcoded defaults. */
-struct spdk_conf_section *
-spdk_conf_find_section(struct spdk_conf *cp, const char *name)
-{
-	return NULL;
-}
-
-/* Return NULL to test hardcoded defaults. */
-char *
-spdk_conf_section_get_nmval(struct spdk_conf_section *sp, const char *key, int idx1, int idx2)
-{
-	return NULL;
-}
+DEFINE_STUB(spdk_conf_find_section, struct spdk_conf_section *, (struct spdk_conf *cp,
+		const char *name), NULL);
+DEFINE_STUB(spdk_conf_section_get_nmval, char *,
+	    (struct spdk_conf_section *sp, const char *key, int idx1, int idx2), NULL);
+DEFINE_STUB(spdk_conf_section_get_intval, int, (struct spdk_conf_section *sp, const char *key), -1);
 
 static void
 _bdev_send_msg(spdk_thread_fn fn, void *ctx, void *thread_ctx)
@@ -85,19 +77,113 @@ stub_destruct(void *ctx)
 	return 0;
 }
 
+struct bdev_ut_channel {
+	TAILQ_HEAD(, spdk_bdev_io)	outstanding_io;
+	uint32_t			outstanding_io_count;
+};
+
+static uint32_t g_bdev_ut_io_device;
+static struct bdev_ut_channel *g_bdev_ut_channel;
+
+static void
+stub_submit_request(struct spdk_io_channel *_ch, struct spdk_bdev_io *bdev_io)
+{
+	struct bdev_ut_channel *ch = spdk_io_channel_get_ctx(_ch);
+
+	TAILQ_INSERT_TAIL(&ch->outstanding_io, bdev_io, module_link);
+	ch->outstanding_io_count++;
+}
+
+static uint32_t
+stub_complete_io(uint32_t num_to_complete)
+{
+	struct bdev_ut_channel *ch = g_bdev_ut_channel;
+	struct spdk_bdev_io *bdev_io;
+	uint32_t num_completed = 0;
+
+	while (num_completed < num_to_complete) {
+		if (TAILQ_EMPTY(&ch->outstanding_io)) {
+			break;
+		}
+		bdev_io = TAILQ_FIRST(&ch->outstanding_io);
+		TAILQ_REMOVE(&ch->outstanding_io, bdev_io, module_link);
+		ch->outstanding_io_count--;
+		spdk_bdev_io_complete(bdev_io, SPDK_BDEV_IO_STATUS_SUCCESS);
+		num_completed++;
+	}
+
+	return num_completed;
+}
+
+static struct spdk_io_channel *
+bdev_ut_get_io_channel(void *ctx)
+{
+	return spdk_get_io_channel(&g_bdev_ut_io_device);
+}
+
 static struct spdk_bdev_fn_table fn_table = {
 	.destruct = stub_destruct,
+	.submit_request = stub_submit_request,
+	.get_io_channel = bdev_ut_get_io_channel,
 };
 
+static int
+bdev_ut_create_ch(void *io_device, void *ctx_buf)
+{
+	struct bdev_ut_channel *ch = ctx_buf;
+
+	CU_ASSERT(g_bdev_ut_channel == NULL);
+	g_bdev_ut_channel = ch;
+
+	TAILQ_INIT(&ch->outstanding_io);
+	ch->outstanding_io_count = 0;
+	return 0;
+}
+
+static void
+bdev_ut_destroy_ch(void *io_device, void *ctx_buf)
+{
+	CU_ASSERT(g_bdev_ut_channel != NULL);
+	g_bdev_ut_channel = NULL;
+}
+
+static int
+bdev_ut_module_init(void)
+{
+	spdk_io_device_register(&g_bdev_ut_io_device, bdev_ut_create_ch, bdev_ut_destroy_ch,
+				sizeof(struct bdev_ut_channel));
+	return 0;
+}
+
+static void
+bdev_ut_module_fini(void)
+{
+}
+
 struct spdk_bdev_module bdev_ut_if = {
 	.name = "bdev_ut",
+	.module_init = bdev_ut_module_init,
+	.module_fini = bdev_ut_module_fini,
 };
 
 static void vbdev_ut_examine(struct spdk_bdev *bdev);
 
+static int
+vbdev_ut_module_init(void)
+{
+	return 0;
+}
+
+static void
+vbdev_ut_module_fini(void)
+{
+}
+
 struct spdk_bdev_module vbdev_ut_if = {
 	.name = "vbdev_ut",
-	.examine = vbdev_ut_examine,
+	.module_init = vbdev_ut_module_init,
+	.module_fini = vbdev_ut_module_fini,
+	.examine_config = vbdev_ut_examine,
 };
 
 SPDK_BDEV_MODULE_REGISTER(&bdev_ut_if)
@@ -129,8 +215,8 @@ is_base_bdev(struct spdk_bdev *base, struct spdk_bdev *vbdev)
 	size_t i;
 	int found = 0;
 
-	for (i = 0; i < vbdev->base_bdevs_cnt; i++) {
-		found += vbdev->base_bdevs[i] == base;
+	for (i = 0; i < vbdev->internal.base_bdevs_cnt; i++) {
+		found += vbdev->internal.base_bdevs[i] == base;
 	}
 
 	CU_ASSERT(found <= 1);
@@ -160,10 +246,11 @@ allocate_bdev(char *name)
 	bdev->name = name;
 	bdev->fn_table = &fn_table;
 	bdev->module = &bdev_ut_if;
+	bdev->blockcnt = 1;
 
 	rc = spdk_bdev_register(bdev);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(bdev->base_bdevs_cnt == 0);
+	CU_ASSERT(bdev->internal.base_bdevs_cnt == 0);
 	CU_ASSERT(bdev->vbdevs_cnt == 0);
 
 	return bdev;
@@ -191,7 +278,7 @@ allocate_vbdev(char *name, struct spdk_bdev *base1, struct spdk_bdev *base2)
 
 	rc = spdk_vbdev_register(bdev, array, base2 == NULL ? 1 : 2);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(bdev->base_bdevs_cnt > 0);
+	CU_ASSERT(bdev->internal.base_bdevs_cnt > 0);
 	CU_ASSERT(bdev->vbdevs_cnt == 0);
 
 	CU_ASSERT(check_base_and_vbdev(base1, bdev) == true);
@@ -214,12 +301,41 @@ free_bdev(struct spdk_bdev *bdev)
 static void
 free_vbdev(struct spdk_bdev *bdev)
 {
-	CU_ASSERT(bdev->base_bdevs_cnt != 0);
+	CU_ASSERT(bdev->internal.base_bdevs_cnt != 0);
 	spdk_bdev_unregister(bdev, NULL, NULL);
 	memset(bdev, 0xFF, sizeof(*bdev));
 	free(bdev);
 }
 
+static void
+get_device_stat_cb(struct spdk_bdev *bdev, struct spdk_bdev_io_stat *stat, void *cb_arg, int rc)
+{
+	const char *bdev_name;
+
+	CU_ASSERT(bdev != NULL);
+	CU_ASSERT(rc == 0);
+	bdev_name = spdk_bdev_get_name(bdev);
+	CU_ASSERT_STRING_EQUAL(bdev_name, "bdev0");
+
+	free(stat);
+	free_bdev(bdev);
+}
+
+static void
+get_device_stat_test(void)
+{
+	struct spdk_bdev *bdev;
+	struct spdk_bdev_io_stat *stat;
+
+	bdev = allocate_bdev("bdev0");
+	stat = calloc(1, sizeof(struct spdk_bdev_io_stat));
+	if (stat == NULL) {
+		free_bdev(bdev);
+		return;
+	}
+	spdk_bdev_get_device_stat(bdev, stat, get_device_stat_cb, NULL);
+}
+
 static void
 open_write_test(void)
 {
@@ -316,7 +432,7 @@ open_write_test(void)
 	/* Open bdev0 read-only.  This should succeed. */
 	rc = spdk_bdev_open(bdev[0], false, NULL, NULL, &desc[0]);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(desc[0] != NULL);
+	SPDK_CU_ASSERT_FATAL(desc[0] != NULL);
 	spdk_bdev_close(desc[0]);
 
 	/*
@@ -336,7 +452,7 @@ open_write_test(void)
 	/* Open bdev4 read-only.  This should succeed. */
 	rc = spdk_bdev_open(bdev[4], false, NULL, NULL, &desc[4]);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(desc[4] != NULL);
+	SPDK_CU_ASSERT_FATAL(desc[4] != NULL);
 	spdk_bdev_close(desc[4]);
 
 	/*
@@ -345,7 +461,7 @@ open_write_test(void)
 	 */
 	rc = spdk_bdev_open(bdev[8], true, NULL, NULL, &desc[8]);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(desc[8] != NULL);
+	SPDK_CU_ASSERT_FATAL(desc[8] != NULL);
 	spdk_bdev_close(desc[8]);
 
 	/*
@@ -358,7 +474,7 @@ open_write_test(void)
 	/* Open bdev4 read-only.  This should succeed. */
 	rc = spdk_bdev_open(bdev[5], false, NULL, NULL, &desc[5]);
 	CU_ASSERT(rc == 0);
-	CU_ASSERT(desc[5] != NULL);
+	SPDK_CU_ASSERT_FATAL(desc[5] != NULL);
 	spdk_bdev_close(desc[5]);
 
 	free_vbdev(bdev[8]);
@@ -403,7 +519,8 @@ static void
 num_blocks_test(void)
 {
 	struct spdk_bdev bdev;
-	struct spdk_bdev_desc *desc;
+	struct spdk_bdev_desc *desc = NULL;
+	int rc;
 
 	memset(&bdev, 0, sizeof(bdev));
 	bdev.name = "num_blocks";
@@ -418,7 +535,9 @@ num_blocks_test(void)
 	CU_ASSERT(spdk_bdev_notify_blockcnt_change(&bdev, 30) == 0);
 
 	/* In case bdev opened */
-	spdk_bdev_open(&bdev, false, NULL, NULL, &desc);
+	rc = spdk_bdev_open(&bdev, false, NULL, NULL, &desc);
+	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(desc != NULL);
 
 	/* Growing block number */
 	CU_ASSERT(spdk_bdev_notify_blockcnt_change(&bdev, 80) == 0);
@@ -522,6 +641,110 @@ alias_add_del_test(void)
 	free(bdev[1]);
 }
 
+static void
+io_done(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
+{
+	spdk_bdev_free_io(bdev_io);
+}
+
+static void
+bdev_init_cb(void *arg, int rc)
+{
+	CU_ASSERT(rc == 0);
+}
+
+struct bdev_ut_io_wait_entry {
+	struct spdk_bdev_io_wait_entry	entry;
+	struct spdk_io_channel		*io_ch;
+	struct spdk_bdev_desc		*desc;
+	bool				submitted;
+};
+
+static void
+io_wait_cb(void *arg)
+{
+	struct bdev_ut_io_wait_entry *entry = arg;
+	int rc;
+
+	rc = spdk_bdev_read_blocks(entry->desc, entry->io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == 0);
+	entry->submitted = true;
+}
+
+static void
+bdev_io_wait_test(void)
+{
+	struct spdk_bdev *bdev;
+	struct spdk_bdev_desc *desc;
+	struct spdk_io_channel *io_ch;
+	struct spdk_bdev_opts bdev_opts = {
+		.bdev_io_pool_size = 4,
+		.bdev_io_cache_size = 2,
+	};
+	struct bdev_ut_io_wait_entry io_wait_entry;
+	struct bdev_ut_io_wait_entry io_wait_entry2;
+	int rc;
+
+	rc = spdk_bdev_set_opts(&bdev_opts);
+	CU_ASSERT(rc == 0);
+	spdk_bdev_initialize(bdev_init_cb, NULL);
+
+	bdev = allocate_bdev("bdev0");
+
+	rc = spdk_bdev_open(bdev, true, NULL, NULL, &desc);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(desc != NULL);
+	io_ch = spdk_bdev_get_io_channel(desc);
+	CU_ASSERT(io_ch != NULL);
+
+	rc = spdk_bdev_read_blocks(desc, io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == 0);
+	rc = spdk_bdev_read_blocks(desc, io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == 0);
+	rc = spdk_bdev_read_blocks(desc, io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == 0);
+	rc = spdk_bdev_read_blocks(desc, io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(g_bdev_ut_channel->outstanding_io_count == 4);
+
+	rc = spdk_bdev_read_blocks(desc, io_ch, NULL, 0, 1, io_done, NULL);
+	CU_ASSERT(rc == -ENOMEM);
+
+	io_wait_entry.entry.bdev = bdev;
+	io_wait_entry.entry.cb_fn = io_wait_cb;
+	io_wait_entry.entry.cb_arg = &io_wait_entry;
+	io_wait_entry.io_ch = io_ch;
+	io_wait_entry.desc = desc;
+	io_wait_entry.submitted = false;
+	/* Cannot use the same io_wait_entry for two different calls. */
+	memcpy(&io_wait_entry2, &io_wait_entry, sizeof(io_wait_entry));
+	io_wait_entry2.entry.cb_arg = &io_wait_entry2;
+
+	/* Queue two I/O waits. */
+	rc = spdk_bdev_queue_io_wait(bdev, io_ch, &io_wait_entry.entry);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(io_wait_entry.submitted == false);
+	rc = spdk_bdev_queue_io_wait(bdev, io_ch, &io_wait_entry2.entry);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(io_wait_entry2.submitted == false);
+
+	stub_complete_io(1);
+	CU_ASSERT(g_bdev_ut_channel->outstanding_io_count == 4);
+	CU_ASSERT(io_wait_entry.submitted == true);
+	CU_ASSERT(io_wait_entry2.submitted == false);
+
+	stub_complete_io(1);
+	CU_ASSERT(g_bdev_ut_channel->outstanding_io_count == 4);
+	CU_ASSERT(io_wait_entry2.submitted == true);
+
+	stub_complete_io(4);
+	CU_ASSERT(g_bdev_ut_channel->outstanding_io_count == 0);
+
+	spdk_put_io_channel(io_ch);
+	spdk_bdev_close(desc);
+	free_bdev(bdev);
+}
+
 int
 main(int argc, char **argv)
 {
@@ -543,7 +766,9 @@ main(int argc, char **argv)
 		CU_add_test(suite, "num_blocks_test", num_blocks_test) == NULL ||
 		CU_add_test(suite, "io_valid", io_valid_test) == NULL ||
 		CU_add_test(suite, "open_write", open_write_test) == NULL ||
-		CU_add_test(suite, "alias_add_del", alias_add_del_test) == NULL
+		CU_add_test(suite, "alias_add_del", alias_add_del_test) == NULL ||
+		CU_add_test(suite, "get_device_stat", get_device_stat_test) == NULL ||
+		CU_add_test(suite, "bdev_io_wait", bdev_io_wait_test) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/bdev/bdev_raid.c/.gitignore b/test/unit/lib/bdev/bdev_raid.c/.gitignore
new file mode 100644
index 000000000..98d1a166e
--- /dev/null
+++ b/test/unit/lib/bdev/bdev_raid.c/.gitignore
@@ -0,0 +1 @@
+bdev_raid_ut
diff --git a/examples/ioat/kperf/Makefile b/test/unit/lib/bdev/bdev_raid.c/Makefile
similarity index 86%
rename from examples/ioat/kperf/Makefile
rename to test/unit/lib/bdev/bdev_raid.c/Makefile
index a338b22a6..239f72187 100644
--- a/examples/ioat/kperf/Makefile
+++ b/test/unit/lib/bdev/bdev_raid.c/Makefile
@@ -31,19 +31,23 @@
 #  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #
 
-SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../..)
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
 
-APP = ioat_kperf
+SPDK_LIB_LIST = log
 
-C_SRCS := ioat_kperf.c
+CFLAGS += -I$(SPDK_ROOT_DIR)/test
+CFLAGS += -I$(SPDK_ROOT_DIR)/lib/bdev
+LIBS += $(SPDK_LIB_LINKER_ARGS)
+LIBS += -lcunit
 
+APP = bdev_raid_ut
+C_SRCS = bdev_raid_ut.c
 
 all: $(APP)
-	@:
 
-$(APP): $(OBJS)
+$(APP): $(OBJS) $(SPDK_LIB_FILES)
 	$(LINK_C)
 
 clean:
diff --git a/test/unit/lib/bdev/bdev_raid.c/bdev_raid_ut.c b/test/unit/lib/bdev/bdev_raid.c/bdev_raid_ut.c
new file mode 100644
index 000000000..02b73c52d
--- /dev/null
+++ b/test/unit/lib/bdev/bdev_raid.c/bdev_raid_ut.c
@@ -0,0 +1,2123 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/stdinc.h"
+#include "spdk_cunit.h"
+#include "spdk/env.h"
+#include "spdk_internal/mock.h"
+#include "raid/bdev_raid.c"
+#include "raid/bdev_raid_rpc.c"
+
+#define MAX_BASE_DRIVES 255
+#define MAX_RAIDS 31
+#define INVALID_IO_SUBMIT 0xFFFF
+
+/* Data structure to capture the output of IO for verification */
+struct io_output {
+	struct spdk_bdev_desc       *desc;
+	struct spdk_io_channel      *ch;
+	void                        *buf;
+	uint64_t                    offset_blocks;
+	uint64_t                    num_blocks;
+	spdk_bdev_io_completion_cb  cb;
+	void                        *cb_arg;
+	enum spdk_bdev_io_type      iotype;
+};
+
+/* Different test options, more options to test can be added here */
+uint32_t g_blklen_opts[] = {512, 4096};
+uint32_t g_strip_opts[] = {64, 128, 256, 512, 1024, 2048};
+uint32_t g_iosize_opts[] = {256, 512, 1024};
+uint32_t g_max_qd_opts[] = {64, 128, 256, 512, 1024, 2048};
+
+/* Globals */
+int g_bdev_io_submit_status;
+struct io_output *g_io_output = NULL;
+uint32_t g_io_output_index;
+uint32_t g_io_comp_status;
+bool g_child_io_status_flag;
+void *rpc_req;
+uint32_t rpc_req_size;
+TAILQ_HEAD(bdev, spdk_bdev);
+struct bdev g_bdev_list;
+TAILQ_HEAD(waitq, spdk_bdev_io_wait_entry);
+struct waitq g_io_waitq;
+uint32_t g_block_len;
+uint32_t g_strip_size;
+uint32_t g_max_io_size;
+uint32_t g_max_qd;
+uint8_t g_max_base_drives;
+uint8_t g_max_raids;
+uint8_t g_ignore_io_output;
+uint8_t g_rpc_err;
+char *g_get_raids_output[MAX_RAIDS];
+uint32_t g_get_raids_count;
+uint8_t g_json_beg_res_ret_err;
+uint8_t g_json_decode_obj_err;
+uint8_t g_config_level_create = 0;
+uint8_t g_test_multi_raids;
+
+/* Set randomly test options, in every run it is different */
+static void
+set_test_opts(void)
+{
+	uint32_t seed = time(0);
+
+	/* Generate random test options */
+	srand(seed);
+	g_max_base_drives = (rand() % MAX_BASE_DRIVES) + 1;
+	g_max_raids = (rand() % MAX_RAIDS) + 1;
+	g_block_len = g_blklen_opts[rand() % SPDK_COUNTOF(g_blklen_opts)];
+	g_strip_size = g_strip_opts[rand() % SPDK_COUNTOF(g_strip_opts)];
+	g_max_io_size = g_iosize_opts[rand() % SPDK_COUNTOF(g_iosize_opts)];
+	g_max_qd = g_max_qd_opts[rand() % SPDK_COUNTOF(g_max_qd_opts)];
+
+	printf("Test Options, seed = %u\n", seed);
+	printf("blocklen = %u, strip_size = %u, max_io_size = %u, max_qd = %u, g_max_base_drives = %u, g_max_raids = %u\n",
+	       g_block_len, g_strip_size, g_max_io_size, g_max_qd, g_max_base_drives, g_max_raids);
+}
+
+/* Set globals before every test run */
+static void
+set_globals(void)
+{
+	uint32_t max_splits;
+
+	g_bdev_io_submit_status = 0;
+	if (g_max_io_size < g_strip_size) {
+		max_splits = 2;
+	} else {
+		max_splits = (g_max_io_size / g_strip_size) + 1;
+	}
+	g_io_output = calloc(max_splits, sizeof(struct io_output));
+	SPDK_CU_ASSERT_FATAL(g_io_output != NULL);
+	g_io_output_index = 0;
+	memset(g_get_raids_output, 0, sizeof(g_get_raids_output));
+	g_get_raids_count = 0;
+	g_io_comp_status = 0;
+	g_ignore_io_output = 0;
+	g_config_level_create = 0;
+	g_rpc_err = 0;
+	g_test_multi_raids = 0;
+	g_child_io_status_flag = true;
+	TAILQ_INIT(&g_bdev_list);
+	TAILQ_INIT(&g_io_waitq);
+	rpc_req = NULL;
+	rpc_req_size = 0;
+	g_json_beg_res_ret_err = 0;
+	g_json_decode_obj_err = 0;
+}
+
+static void
+base_bdevs_cleanup(void)
+{
+	struct spdk_bdev *bdev;
+	struct spdk_bdev *bdev_next;
+
+	if (!TAILQ_EMPTY(&g_bdev_list)) {
+		TAILQ_FOREACH_SAFE(bdev, &g_bdev_list, internal.link, bdev_next) {
+			free(bdev->name);
+			TAILQ_REMOVE(&g_bdev_list, bdev, internal.link);
+			free(bdev);
+		}
+	}
+}
+
+/* Reset globals */
+static void
+reset_globals(void)
+{
+	if (g_io_output) {
+		free(g_io_output);
+		g_io_output = NULL;
+	}
+	rpc_req = NULL;
+	rpc_req_size = 0;
+}
+
+/* Store the IO completion status in global variable to verify by various tests */
+void
+spdk_bdev_io_complete(struct spdk_bdev_io *bdev_io, enum spdk_bdev_io_status status)
+{
+	g_io_comp_status = ((status == SPDK_BDEV_IO_STATUS_SUCCESS) ? true : false);
+}
+
+/* It will cache the split IOs for verification */
+int
+spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
+		       void *buf, uint64_t offset_blocks, uint64_t num_blocks,
+		       spdk_bdev_io_completion_cb cb, void *cb_arg)
+{
+	struct io_output *p = &g_io_output[g_io_output_index];
+	struct spdk_bdev_io *child_io;
+
+	if (g_ignore_io_output) {
+		return 0;
+	}
+
+	if (g_max_io_size < g_strip_size) {
+		SPDK_CU_ASSERT_FATAL(g_io_output_index < 2);
+	} else {
+		SPDK_CU_ASSERT_FATAL(g_io_output_index < (g_max_io_size / g_strip_size) + 1);
+	}
+	if (g_bdev_io_submit_status == 0) {
+		p->desc = desc;
+		p->ch = ch;
+		p->buf = buf;
+		p->offset_blocks = offset_blocks;
+		p->num_blocks = num_blocks;
+		p->cb = cb;
+		p->cb_arg = cb_arg;
+		p->iotype = SPDK_BDEV_IO_TYPE_WRITE;
+		g_io_output_index++;
+		child_io = calloc(1, sizeof(struct spdk_bdev_io));
+		SPDK_CU_ASSERT_FATAL(child_io != NULL);
+		cb(child_io, g_child_io_status_flag, cb_arg);
+	}
+
+	return g_bdev_io_submit_status;
+}
+
+void
+spdk_bdev_unregister(struct spdk_bdev *bdev, spdk_bdev_unregister_cb cb_fn, void *cb_arg)
+{
+	bdev->fn_table->destruct(bdev->ctxt);
+}
+
+int
+spdk_bdev_open(struct spdk_bdev *bdev, bool write, spdk_bdev_remove_cb_t remove_cb,
+	       void *remove_ctx, struct spdk_bdev_desc **_desc)
+{
+	*_desc = (void *)0x1;
+	return 0;
+}
+
+void
+spdk_put_io_channel(struct spdk_io_channel *ch)
+{
+	CU_ASSERT(ch == (void *)1);
+}
+
+struct spdk_io_channel *
+spdk_get_io_channel(void *io_device)
+{
+	return NULL;
+}
+
+void
+spdk_poller_unregister(struct spdk_poller **ppoller)
+{
+}
+
+struct spdk_poller *
+spdk_poller_register(spdk_poller_fn fn,
+		     void *arg,
+		     uint64_t period_microseconds)
+{
+	return (void *)1;
+}
+
+void
+spdk_io_device_unregister(void *io_device, spdk_io_device_unregister_cb unregister_cb)
+{
+}
+
+char *
+spdk_sprintf_alloc(const char *format, ...)
+{
+	return strdup(format);
+}
+
+void
+spdk_io_device_register(void *io_device, spdk_io_channel_create_cb create_cb,
+			spdk_io_channel_destroy_cb destroy_cb, uint32_t ctx_size)
+{
+}
+
+int
+spdk_json_write_name(struct spdk_json_write_ctx *w, const char *name)
+{
+	return 0;
+}
+
+int spdk_json_write_named_uint32(struct spdk_json_write_ctx *w, const char *name, uint32_t val)
+{
+	struct rpc_construct_raid_bdev  *req = rpc_req;
+	if (strcmp(name, "strip_size") == 0) {
+		CU_ASSERT(req->strip_size * 1024 / g_block_len == val);
+	} else if (strcmp(name, "blocklen_shift") == 0) {
+		CU_ASSERT(spdk_u32log2(g_block_len) == val);
+	} else if (strcmp(name, "raid_level") == 0) {
+		CU_ASSERT(req->raid_level == val);
+	} else if (strcmp(name, "num_base_bdevs") == 0) {
+		CU_ASSERT(req->base_bdevs.num_base_bdevs == val);
+	} else if (strcmp(name, "state") == 0) {
+		CU_ASSERT(val == RAID_BDEV_STATE_ONLINE);
+	} else if (strcmp(name, "destruct_called") == 0) {
+		CU_ASSERT(val == 0);
+	} else if (strcmp(name, "num_base_bdevs_discovered") == 0) {
+		CU_ASSERT(req->base_bdevs.num_base_bdevs == val);
+	}
+	return 0;
+}
+
+int spdk_json_write_named_string(struct spdk_json_write_ctx *w, const char *name, const char *val)
+{
+	return 0;
+}
+
+int
+spdk_json_write_object_begin(struct spdk_json_write_ctx *w)
+{
+	return 0;
+}
+
+int
+spdk_json_write_array_end(struct spdk_json_write_ctx *w)
+{
+	return 0;
+}
+
+int
+spdk_json_write_object_end(struct spdk_json_write_ctx *w)
+{
+	return 0;
+}
+
+int
+spdk_json_write_bool(struct spdk_json_write_ctx *w, bool val)
+{
+	return 0;
+}
+
+int spdk_json_write_null(struct spdk_json_write_ctx *w)
+{
+	return 0;
+}
+
+struct spdk_io_channel *
+spdk_bdev_get_io_channel(struct spdk_bdev_desc *desc)
+{
+	return (void *)1;
+}
+
+void
+spdk_for_each_thread(spdk_thread_fn fn, void *ctx, spdk_thread_fn cpl)
+{
+	fn(ctx);
+	cpl(ctx);
+}
+
+struct spdk_thread *
+spdk_get_thread(void)
+{
+	return NULL;
+}
+
+void
+spdk_thread_send_msg(const struct spdk_thread *thread, spdk_thread_fn fn, void *ctx)
+{
+	fn(ctx);
+}
+
+uint32_t
+spdk_env_get_current_core(void)
+{
+	return 0;
+}
+
+void
+spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
+{
+	if (bdev_io) {
+		free(bdev_io);
+	}
+}
+
+/* It will cache split IOs for verification */
+int
+spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
+		      void *buf, uint64_t offset_blocks, uint64_t num_blocks,
+		      spdk_bdev_io_completion_cb cb, void *cb_arg)
+{
+	struct io_output *p = &g_io_output[g_io_output_index];
+	struct spdk_bdev_io *child_io;
+
+	if (g_ignore_io_output) {
+		return 0;
+	}
+
+	SPDK_CU_ASSERT_FATAL(g_io_output_index <= (g_max_io_size / g_strip_size) + 1);
+	if (g_bdev_io_submit_status == 0) {
+		p->desc = desc;
+		p->ch = ch;
+		p->buf = buf;
+		p->offset_blocks = offset_blocks;
+		p->num_blocks = num_blocks;
+		p->cb = cb;
+		p->cb_arg = cb_arg;
+		p->iotype = SPDK_BDEV_IO_TYPE_READ;
+		g_io_output_index++;
+		child_io = calloc(1, sizeof(struct spdk_bdev_io));
+		SPDK_CU_ASSERT_FATAL(child_io != NULL);
+		cb(child_io, g_child_io_status_flag, cb_arg);
+	}
+
+	return g_bdev_io_submit_status;
+}
+
+void
+spdk_bdev_module_release_bdev(struct spdk_bdev *bdev)
+{
+	CU_ASSERT(bdev->internal.claim_module != NULL);
+	bdev->internal.claim_module = NULL;
+}
+
+void
+spdk_bdev_module_examine_done(struct spdk_bdev_module *module)
+{
+}
+
+struct spdk_conf_section *
+spdk_conf_first_section(struct spdk_conf *cp)
+{
+	if (g_config_level_create) {
+		return (void *) 0x1;
+	}
+
+	return NULL;
+}
+
+bool
+spdk_conf_section_match_prefix(const struct spdk_conf_section *sp, const char *name_prefix)
+{
+	if (g_config_level_create) {
+		return true;
+	}
+
+	return false;
+}
+
+char *
+spdk_conf_section_get_val(struct spdk_conf_section *sp, const char *key)
+{
+	struct rpc_construct_raid_bdev  *req = rpc_req;
+
+	if (g_config_level_create) {
+		if (strcmp(key, "Name") == 0) {
+			return req->name;
+		}
+	}
+
+	return NULL;
+}
+
+int
+spdk_conf_section_get_intval(struct spdk_conf_section *sp, const char *key)
+{
+	struct rpc_construct_raid_bdev  *req = rpc_req;
+
+	if (g_config_level_create) {
+		if (strcmp(key, "StripSize") == 0) {
+			return req->strip_size;
+		} else if (strcmp(key, "NumDevices") == 0) {
+			return req->base_bdevs.num_base_bdevs;
+		} else if (strcmp(key, "RaidLevel") == 0) {
+			return req->raid_level;
+		}
+	}
+
+	return 0;
+}
+
+struct spdk_conf_section *
+spdk_conf_next_section(struct spdk_conf_section *sp)
+{
+	return NULL;
+}
+
+char *
+spdk_conf_section_get_nmval(struct spdk_conf_section *sp, const char *key, int idx1, int idx2)
+{
+	struct rpc_construct_raid_bdev  *req = rpc_req;
+
+	if (g_config_level_create) {
+		if (strcmp(key, "Devices") == 0) {
+			if (idx2 >= g_max_base_drives) {
+				return NULL;
+			}
+			return req->base_bdevs.base_bdevs[idx2];
+		}
+	}
+
+	return NULL;
+}
+
+void
+spdk_bdev_close(struct spdk_bdev_desc *desc)
+{
+}
+
+int
+spdk_bdev_module_claim_bdev(struct spdk_bdev *bdev, struct spdk_bdev_desc *desc,
+			    struct spdk_bdev_module *module)
+{
+	if (bdev->internal.claim_module != NULL) {
+		return -1;
+	}
+	bdev->internal.claim_module = module;
+	return 0;
+}
+
+int
+spdk_bdev_register(struct spdk_bdev *bdev)
+{
+	return 0;
+}
+
+uint32_t
+spdk_env_get_last_core(void)
+{
+	return 0;
+}
+
+int
+spdk_json_decode_string(const struct spdk_json_val *val, void *out)
+{
+	return 0;
+}
+
+int
+spdk_json_decode_object(const struct spdk_json_val *values,
+			const struct spdk_json_object_decoder *decoders, size_t num_decoders, void *out)
+{
+	if (g_json_decode_obj_err) {
+		return -1;
+	} else {
+		memcpy(out, rpc_req, rpc_req_size);
+		return 0;
+	}
+}
+
+struct spdk_json_write_ctx *
+spdk_jsonrpc_begin_result(struct spdk_jsonrpc_request *request)
+{
+	if (g_json_beg_res_ret_err) {
+		return NULL;
+	} else {
+		return (void *)1;
+	}
+}
+
+int
+spdk_json_write_array_begin(struct spdk_json_write_ctx *w)
+{
+	return 0;
+}
+
+int
+spdk_json_write_string(struct spdk_json_write_ctx *w, const char *val)
+{
+	if (g_test_multi_raids) {
+		g_get_raids_output[g_get_raids_count] = strdup(val);
+		SPDK_CU_ASSERT_FATAL(g_get_raids_output[g_get_raids_count] != NULL);
+		g_get_raids_count++;
+	}
+
+	return 0;
+}
+
+void
+spdk_jsonrpc_send_error_response(struct spdk_jsonrpc_request *request,
+				 int error_code, const char *msg)
+{
+	g_rpc_err = 1;
+}
+
+void
+spdk_jsonrpc_end_result(struct spdk_jsonrpc_request *request, struct spdk_json_write_ctx *w)
+{
+}
+
+struct spdk_bdev *
+spdk_bdev_get_by_name(const char *bdev_name)
+{
+	struct spdk_bdev *bdev;
+
+	if (!TAILQ_EMPTY(&g_bdev_list)) {
+		TAILQ_FOREACH(bdev, &g_bdev_list, internal.link) {
+			if (strcmp(bdev_name, bdev->name) == 0) {
+				return bdev;
+			}
+		}
+	}
+
+	return NULL;
+}
+
+const char *
+spdk_strerror(int errnum)
+{
+	return NULL;
+}
+
+int
+spdk_json_decode_array(const struct spdk_json_val *values, spdk_json_decode_fn decode_func,
+		       void *out, size_t max_size, size_t *out_size, size_t stride)
+{
+	return 0;
+}
+
+void
+spdk_rpc_register_method(const char *method, spdk_rpc_method_handler func, uint32_t state_mask)
+{
+}
+
+int
+spdk_json_decode_uint32(const struct spdk_json_val *val, void *out)
+{
+	return 0;
+}
+
+
+void
+spdk_bdev_module_list_add(struct spdk_bdev_module *bdev_module)
+{
+}
+
+static void
+bdev_io_cleanup(struct spdk_bdev_io *bdev_io)
+{
+	if (bdev_io->u.bdev.iovs) {
+		if (bdev_io->u.bdev.iovs->iov_base) {
+			free(bdev_io->u.bdev.iovs->iov_base);
+			bdev_io->u.bdev.iovs->iov_base = NULL;
+		}
+		free(bdev_io->u.bdev.iovs);
+		bdev_io->u.bdev.iovs = NULL;
+	}
+}
+
+static void
+bdev_io_initialize(struct spdk_bdev_io *bdev_io, uint64_t lba, uint64_t blocks, int16_t iotype)
+{
+	bdev_io->u.bdev.offset_blocks = lba;
+	bdev_io->u.bdev.num_blocks = blocks;
+	bdev_io->type = iotype;
+	bdev_io->u.bdev.iovcnt = 1;
+	bdev_io->u.bdev.iovs = calloc(1, sizeof(struct iovec));
+	SPDK_CU_ASSERT_FATAL(bdev_io->u.bdev.iovs != NULL);
+	bdev_io->u.bdev.iovs->iov_base = calloc(1, bdev_io->u.bdev.num_blocks * g_block_len);
+	SPDK_CU_ASSERT_FATAL(bdev_io->u.bdev.iovs->iov_base != NULL);
+	bdev_io->u.bdev.iovs->iov_len = bdev_io->u.bdev.num_blocks * g_block_len;
+	bdev_io->u.bdev.iovs = bdev_io->u.bdev.iovs;
+}
+
+static void
+verify_io(struct spdk_bdev_io *bdev_io, uint8_t num_base_drives,
+	  struct raid_bdev_io_channel *ch_ctx, struct raid_bdev *raid_bdev, uint32_t io_status)
+{
+	uint32_t strip_shift = spdk_u32log2(g_strip_size);
+	uint64_t start_strip = bdev_io->u.bdev.offset_blocks >> strip_shift;
+	uint64_t end_strip = (bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) >>
+			     strip_shift;
+	uint32_t splits_reqd = (end_strip - start_strip + 1);
+	uint32_t strip;
+	uint64_t pd_strip;
+	uint64_t pd_idx;
+	uint32_t offset_in_strip;
+	uint64_t pd_lba;
+	uint64_t pd_blocks;
+	uint32_t index = 0;
+	uint8_t *buf = bdev_io->u.bdev.iovs->iov_base;
+
+	if (io_status == INVALID_IO_SUBMIT) {
+		CU_ASSERT(g_io_comp_status == false);
+		return;
+	}
+	SPDK_CU_ASSERT_FATAL(raid_bdev != NULL);
+	SPDK_CU_ASSERT_FATAL(num_base_drives != 0);
+
+	if (raid_bdev->num_base_bdevs > 1) {
+		CU_ASSERT(splits_reqd == g_io_output_index);
+		for (strip = start_strip; strip <= end_strip; strip++, index++) {
+			pd_strip = strip / num_base_drives;
+			pd_idx = strip % num_base_drives;
+			if (strip == start_strip) {
+				offset_in_strip = bdev_io->u.bdev.offset_blocks & (g_strip_size - 1);
+				pd_lba = (pd_strip << strip_shift) + offset_in_strip;
+				if (strip == end_strip) {
+					pd_blocks = bdev_io->u.bdev.num_blocks;
+				} else {
+					pd_blocks = g_strip_size - offset_in_strip;
+				}
+			} else if (strip == end_strip) {
+				pd_lba = pd_strip << strip_shift;
+				pd_blocks = ((bdev_io->u.bdev.offset_blocks + bdev_io->u.bdev.num_blocks - 1) &
+					     (g_strip_size - 1)) + 1;
+			} else {
+				pd_lba = pd_strip << raid_bdev->strip_size_shift;
+				pd_blocks = raid_bdev->strip_size;
+			}
+			CU_ASSERT(pd_lba == g_io_output[index].offset_blocks);
+			CU_ASSERT(pd_blocks == g_io_output[index].num_blocks);
+			CU_ASSERT(ch_ctx->base_bdevs_io_channel[pd_idx] == g_io_output[index].ch);
+			CU_ASSERT(raid_bdev->base_bdev_info[pd_idx].base_bdev_desc == g_io_output[index].desc);
+			CU_ASSERT(buf == g_io_output[index].buf);
+			CU_ASSERT(bdev_io->type == g_io_output[index].iotype);
+			buf += (pd_blocks << spdk_u32log2(g_block_len));
+		}
+	} else {
+		CU_ASSERT(g_io_output_index == 1);
+		CU_ASSERT(bdev_io->u.bdev.offset_blocks == g_io_output[0].offset_blocks);
+		CU_ASSERT(bdev_io->u.bdev.num_blocks == g_io_output[0].num_blocks);
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel[0] == g_io_output[0].ch);
+		CU_ASSERT(raid_bdev->base_bdev_info[0].base_bdev_desc == g_io_output[0].desc);
+		CU_ASSERT(buf == g_io_output[index].buf);
+	}
+	CU_ASSERT(g_io_comp_status == io_status);
+}
+
+static void
+verify_raid_config_present(const char *name, bool presence)
+{
+	uint32_t iter;
+	bool cfg_found;
+
+	cfg_found = false;
+	for (iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+		if (strcmp(name, g_spdk_raid_config.raid_bdev_config[iter].name) == 0) {
+			cfg_found = true;
+			break;
+		}
+	}
+
+	if (presence == true) {
+		CU_ASSERT(cfg_found == true);
+	} else {
+		CU_ASSERT(cfg_found == false);
+	}
+}
+
+static void
+verify_raid_bdev_present(const char *name, bool presence)
+{
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct raid_bdev *pbdev;
+	bool   pbdev_found;
+
+	pbdev_found = false;
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, name) == 0) {
+			pbdev_found = true;
+			break;
+		}
+	}
+	if (presence == true) {
+		CU_ASSERT(pbdev_found == true);
+	} else {
+		CU_ASSERT(pbdev_found == false);
+	}
+}
+static void
+verify_raid_config(struct rpc_construct_raid_bdev *r, bool presence)
+{
+	struct raid_bdev_config *raid_cfg = NULL;
+	uint32_t iter, iter2;
+	int val;
+
+	for (iter = 0; iter < g_spdk_raid_config.total_raid_bdev; iter++) {
+		if (strcmp(r->name, g_spdk_raid_config.raid_bdev_config[iter].name) == 0) {
+			raid_cfg = &g_spdk_raid_config.raid_bdev_config[iter];
+			if (presence == false) {
+				break;
+			}
+			CU_ASSERT(raid_cfg->raid_bdev_ctxt != NULL);
+			CU_ASSERT(raid_cfg->strip_size == r->strip_size);
+			CU_ASSERT(raid_cfg->num_base_bdevs == r->base_bdevs.num_base_bdevs);
+			CU_ASSERT(raid_cfg->raid_level == r->raid_level);
+			for (iter2 = 0; iter2 < raid_cfg->num_base_bdevs; iter2++) {
+				val = strcmp(raid_cfg->base_bdev[iter2].bdev_name, r->base_bdevs.base_bdevs[iter2]);
+				CU_ASSERT(val == 0);
+			}
+			break;
+		}
+	}
+
+	if (presence == true) {
+		CU_ASSERT(raid_cfg != NULL);
+	} else {
+		CU_ASSERT(raid_cfg == NULL);
+	}
+}
+
+static void
+verify_raid_bdev(struct rpc_construct_raid_bdev *r, bool presence, uint32_t raid_state)
+{
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct raid_bdev *pbdev;
+	uint32_t iter;
+	struct spdk_bdev *bdev = NULL;
+	bool   pbdev_found;
+	uint64_t min_blockcnt = 0xFFFFFFFFFFFFFFFF;
+
+	pbdev_found = false;
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, r->name) == 0) {
+			pbdev_found = true;
+			if (presence == false) {
+				break;
+			}
+			CU_ASSERT(pbdev->raid_bdev_config->raid_bdev_ctxt == pbdev_ctxt);
+			CU_ASSERT(pbdev->base_bdev_info != NULL);
+			CU_ASSERT(pbdev->strip_size == ((r->strip_size * 1024) / g_block_len));
+			CU_ASSERT(pbdev->strip_size_shift == spdk_u32log2(((r->strip_size * 1024) / g_block_len)));
+			CU_ASSERT(pbdev->blocklen_shift == spdk_u32log2(g_block_len));
+			CU_ASSERT(pbdev->state == raid_state);
+			CU_ASSERT(pbdev->num_base_bdevs == r->base_bdevs.num_base_bdevs);
+			CU_ASSERT(pbdev->num_base_bdevs_discovered == r->base_bdevs.num_base_bdevs);
+			CU_ASSERT(pbdev->raid_level == r->raid_level);
+			CU_ASSERT(pbdev->destruct_called == false);
+			for (iter = 0; iter < pbdev->num_base_bdevs; iter++) {
+				if (pbdev->base_bdev_info && pbdev->base_bdev_info[iter].base_bdev) {
+					bdev = spdk_bdev_get_by_name(pbdev->base_bdev_info[iter].base_bdev->name);
+					CU_ASSERT(bdev != NULL);
+					CU_ASSERT(pbdev->base_bdev_info[iter].base_bdev_remove_scheduled == false);
+				} else {
+					CU_ASSERT(0);
+				}
+
+				if (bdev && bdev->blockcnt < min_blockcnt) {
+					min_blockcnt = bdev->blockcnt;
+				}
+			}
+			CU_ASSERT((((min_blockcnt / (r->strip_size * 1024 / g_block_len)) * (r->strip_size * 1024 /
+					g_block_len)) * r->base_bdevs.num_base_bdevs) == pbdev_ctxt->bdev.blockcnt);
+			CU_ASSERT(strcmp(pbdev_ctxt->bdev.product_name, "Pooled Device") == 0);
+			CU_ASSERT(pbdev_ctxt->bdev.write_cache == 0);
+			CU_ASSERT(pbdev_ctxt->bdev.blocklen == g_block_len);
+			CU_ASSERT(pbdev_ctxt->bdev.optimal_io_boundary == 0);
+			CU_ASSERT(pbdev_ctxt->bdev.ctxt == pbdev_ctxt);
+			CU_ASSERT(pbdev_ctxt->bdev.fn_table == &g_raid_bdev_fn_table);
+			CU_ASSERT(pbdev_ctxt->bdev.module == &g_raid_if);
+			break;
+		}
+	}
+	if (presence == true) {
+		CU_ASSERT(pbdev_found == true);
+	} else {
+		CU_ASSERT(pbdev_found == false);
+	}
+	pbdev_found = false;
+	if (raid_state == RAID_BDEV_STATE_ONLINE) {
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_configured_list, link_specific_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, r->name) == 0) {
+				pbdev_found = true;
+				break;
+			}
+		}
+	} else if (raid_state == RAID_BDEV_STATE_CONFIGURING) {
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_configuring_list, link_specific_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, r->name) == 0) {
+				pbdev_found = true;
+				break;
+			}
+		}
+	} else if (raid_state == RAID_BDEV_STATE_OFFLINE) {
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_offline_list, link_specific_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, r->name) == 0) {
+				pbdev_found = true;
+				break;
+			}
+		}
+	}
+	if (presence == true) {
+		CU_ASSERT(pbdev_found == true);
+	} else {
+		CU_ASSERT(pbdev_found == false);
+	}
+}
+
+int
+spdk_bdev_queue_io_wait(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
+			struct spdk_bdev_io_wait_entry *entry)
+{
+	CU_ASSERT(bdev == entry->bdev);
+	CU_ASSERT(entry->cb_fn != NULL);
+	CU_ASSERT(entry->cb_arg != NULL);
+	TAILQ_INSERT_TAIL(&g_io_waitq, entry, link);
+	return 0;
+}
+
+
+static uint32_t
+get_num_elts_in_waitq(void)
+{
+	struct spdk_bdev_io_wait_entry *ele;
+	uint32_t count = 0;
+
+	TAILQ_FOREACH(ele, &g_io_waitq, link) {
+		count++;
+	}
+
+	return count;
+}
+
+static void
+process_io_waitq(void)
+{
+	struct spdk_bdev_io_wait_entry *ele;
+	struct spdk_bdev_io_wait_entry *next_ele;
+
+	TAILQ_FOREACH_SAFE(ele, &g_io_waitq, link, next_ele) {
+		TAILQ_REMOVE(&g_io_waitq, ele, link);
+		ele->cb_fn(ele->cb_arg);
+	}
+}
+
+static void
+verify_get_raids(struct rpc_construct_raid_bdev *construct_req,
+		 uint8_t g_max_raids,
+		 char **g_get_raids_output, uint32_t g_get_raids_count)
+{
+	uint32_t iter, iter2;
+	bool found;
+
+	CU_ASSERT(g_max_raids == g_get_raids_count);
+	if (g_max_raids == g_get_raids_count) {
+		for (iter = 0; iter < g_max_raids; iter++) {
+			found = false;
+			for (iter2 = 0; iter2 < g_max_raids; iter2++) {
+				if (construct_req[iter].name && strcmp(construct_req[iter].name, g_get_raids_output[iter]) == 0) {
+					found = true;
+					break;
+				}
+			}
+			CU_ASSERT(found == true);
+		}
+	}
+}
+
+static void
+create_base_bdevs(uint32_t bbdev_start_idx)
+{
+	uint32_t iter;
+	struct spdk_bdev *base_bdev;
+	char name[16];
+	uint16_t num_chars;
+
+	for (iter = 0; iter < g_max_base_drives; iter++, bbdev_start_idx++) {
+		num_chars = snprintf(name, 16, "%s%u%s", "Nvme", bbdev_start_idx, "n1");
+		name[num_chars] = '\0';
+		base_bdev = calloc(1, sizeof(struct spdk_bdev));
+		SPDK_CU_ASSERT_FATAL(base_bdev != NULL);
+		base_bdev->name = strdup(name);
+		SPDK_CU_ASSERT_FATAL(base_bdev->name != NULL);
+		base_bdev->blocklen = g_block_len;
+		base_bdev->blockcnt = (uint64_t)1024 * 1024 * 1024 * 1024;
+		TAILQ_INSERT_TAIL(&g_bdev_list, base_bdev, internal.link);
+	}
+}
+
+static void
+create_test_req(struct rpc_construct_raid_bdev *r, const char *raid_name, uint32_t bbdev_start_idx,
+		bool create_base_bdev)
+{
+	uint32_t iter;
+	char name[16];
+	uint16_t num_chars;
+	uint32_t bbdev_idx = bbdev_start_idx;
+
+	r->name = strdup(raid_name);
+	SPDK_CU_ASSERT_FATAL(r->name != NULL);
+	r->strip_size = (g_strip_size * g_block_len) / 1024;
+	r->raid_level = 0;
+	r->base_bdevs.num_base_bdevs = g_max_base_drives;
+	for (iter = 0; iter < g_max_base_drives; iter++, bbdev_idx++) {
+		num_chars = snprintf(name, 16, "%s%u%s", "Nvme", bbdev_idx, "n1");
+		name[num_chars] = '\0';
+		r->base_bdevs.base_bdevs[iter] = strdup(name);
+		SPDK_CU_ASSERT_FATAL(r->base_bdevs.base_bdevs[iter] != NULL);
+	}
+	if (create_base_bdev == true) {
+		create_base_bdevs(bbdev_start_idx);
+	}
+}
+
+static void
+free_test_req(struct rpc_construct_raid_bdev *r)
+{
+	uint8_t iter;
+
+	free(r->name);
+	for (iter = 0; iter < r->base_bdevs.num_base_bdevs; iter++) {
+		free(r->base_bdevs.base_bdevs[iter]);
+	}
+}
+
+static void
+test_construct_raid(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_destroy_raid(void)
+{
+	struct rpc_construct_raid_bdev construct_req;
+	struct rpc_destroy_raid_bdev destroy_req;
+
+	set_globals();
+	create_test_req(&construct_req, "raid1", 0, true);
+	rpc_req = &construct_req;
+	rpc_req_size = sizeof(construct_req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(construct_req.name, false);
+	verify_raid_bdev_present(construct_req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&construct_req, true);
+	verify_raid_bdev(&construct_req, true, RAID_BDEV_STATE_ONLINE);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_construct_raid_invalid_args(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+
+	set_globals();
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+
+	create_test_req(&req, "raid1", 0, true);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	req.raid_level = 1;
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	g_json_decode_obj_err = 1;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	g_json_decode_obj_err = 0;
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.strip_size = 1231;
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+
+	create_test_req(&req, "raid1", 0, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+
+	create_test_req(&req, "raid2", 0, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	verify_raid_config_present("raid2", false);
+	verify_raid_bdev_present("raid2", false);
+
+	create_test_req(&req, "raid2", g_max_base_drives, true);
+	free(req.base_bdevs.base_bdevs[g_max_base_drives - 1]);
+	req.base_bdevs.base_bdevs[g_max_base_drives - 1] = strdup("Nvme0n1");
+	SPDK_CU_ASSERT_FATAL(req.base_bdevs.base_bdevs[g_max_base_drives - 1] != NULL);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	verify_raid_config_present("raid2", false);
+	verify_raid_bdev_present("raid2", false);
+
+	create_test_req(&req, "raid2", g_max_base_drives, true);
+	free(req.base_bdevs.base_bdevs[g_max_base_drives - 1]);
+	req.base_bdevs.base_bdevs[g_max_base_drives - 1] = strdup("Nvme100000n1");
+	SPDK_CU_ASSERT_FATAL(req.base_bdevs.base_bdevs[g_max_base_drives - 1] != NULL);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	verify_raid_config_present("raid2", false);
+	verify_raid_bdev_present("raid2", false);
+
+	create_test_req(&req, "raid2", g_max_base_drives, false);
+	g_rpc_err = 0;
+	g_json_beg_res_ret_err = 1;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid2", true);
+	verify_raid_bdev_present("raid2", true);
+	verify_raid_config_present("raid1", true);
+	verify_raid_bdev_present("raid1", true);
+	g_json_beg_res_ret_err = 0;
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	destroy_req.name = strdup("raid2");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_destroy_raid_invalid_args(void)
+{
+	struct rpc_construct_raid_bdev construct_req;
+	struct rpc_destroy_raid_bdev destroy_req;
+
+	set_globals();
+	create_test_req(&construct_req, "raid1", 0, true);
+	rpc_req = &construct_req;
+	rpc_req_size = sizeof(construct_req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(construct_req.name, false);
+	verify_raid_bdev_present(construct_req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&construct_req, true);
+	verify_raid_bdev(&construct_req, true, RAID_BDEV_STATE_ONLINE);
+
+	destroy_req.name = strdup("raid2");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+
+	destroy_req.name = strdup("raid1");
+	g_rpc_err = 0;
+	g_json_decode_obj_err = 1;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	g_json_decode_obj_err = 0;
+	g_rpc_err = 0;
+	free(destroy_req.name);
+	verify_raid_config_present("raid1", true);
+	verify_raid_bdev_present("raid1", true);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_io_channel(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct raid_bdev_io_channel *ch_ctx;
+	uint32_t iter;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	CU_ASSERT(pbdev_ctxt != NULL);
+	ch_ctx = calloc(1, sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+
+	CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+	for (iter = 0; iter < req.base_bdevs.num_base_bdevs; iter++) {
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel && ch_ctx->base_bdevs_io_channel[iter] == (void *)0x1);
+	}
+	raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+	CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	free(ch_ctx);
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_write_io(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct spdk_io_channel *ch;
+	struct raid_bdev_io_channel *ch_ctx;
+	uint32_t iter;
+	struct spdk_bdev_io *bdev_io;
+	uint32_t count;
+	uint64_t io_len;
+	uint64_t lba;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	CU_ASSERT(pbdev_ctxt != NULL);
+	ch = calloc(1, sizeof(struct spdk_io_channel) + sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch != NULL);
+	ch_ctx = spdk_io_channel_get_ctx(ch);
+	SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+
+	CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+	for (iter = 0; iter < req.base_bdevs.num_base_bdevs; iter++) {
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel && ch_ctx->base_bdevs_io_channel[iter] == (void *)0x1);
+	}
+
+	lba = 0;
+	for (count = 0; count < g_max_qd; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		io_len = (rand() % g_max_io_size) + 1;
+		bdev_io_initialize(bdev_io, lba, io_len, SPDK_BDEV_IO_TYPE_WRITE);
+		lba += io_len;
+		memset(g_io_output, 0, (g_max_io_size / g_strip_size) + 1 * sizeof(struct io_output));
+		g_io_output_index = 0;
+		raid_bdev_submit_request(ch, bdev_io);
+		verify_io(bdev_io, req.base_bdevs.num_base_bdevs, ch_ctx, &pbdev_ctxt->raid_bdev,
+			  g_child_io_status_flag);
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+	raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+	CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+	free(ch);
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_read_io(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct spdk_io_channel *ch;
+	struct raid_bdev_io_channel *ch_ctx;
+	uint32_t iter;
+	struct spdk_bdev_io *bdev_io;
+	uint32_t count;
+	uint64_t io_len;
+	uint64_t lba;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	CU_ASSERT(pbdev_ctxt != NULL);
+	ch = calloc(1, sizeof(struct spdk_io_channel) + sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch != NULL);
+	ch_ctx = spdk_io_channel_get_ctx(ch);
+	SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+
+	CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+	for (iter = 0; iter < req.base_bdevs.num_base_bdevs; iter++) {
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel && ch_ctx->base_bdevs_io_channel[iter] == (void *)0x1);
+	}
+
+	lba = 0;
+	for (count = 0; count < g_max_qd; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		io_len = (rand() % g_max_io_size) + 1;
+		bdev_io_initialize(bdev_io, lba, io_len, SPDK_BDEV_IO_TYPE_READ);
+		lba += io_len;
+		memset(g_io_output, 0, (g_max_io_size / g_strip_size) + 1 * sizeof(struct io_output));
+		g_io_output_index = 0;
+		raid_bdev_submit_request(ch, bdev_io);
+		verify_io(bdev_io, req.base_bdevs.num_base_bdevs, ch_ctx, &pbdev_ctxt->raid_bdev,
+			  g_child_io_status_flag);
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+	raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+	CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+	free(ch);
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+/* Test IO failures */
+static void
+test_io_failure(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct spdk_io_channel *ch;
+	struct raid_bdev_io_channel *ch_ctx;
+	uint32_t iter;
+	struct spdk_bdev_io *bdev_io;
+	uint32_t count;
+	uint64_t io_len;
+	uint64_t lba;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	CU_ASSERT(pbdev_ctxt != NULL);
+	ch = calloc(1, sizeof(struct spdk_io_channel) + sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch != NULL);
+	ch_ctx = spdk_io_channel_get_ctx(ch);
+	SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+
+	CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+	for (iter = 0; iter < req.base_bdevs.num_base_bdevs; iter++) {
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel && ch_ctx->base_bdevs_io_channel[iter] == (void *)0x1);
+	}
+
+	lba = 0;
+	for (count = 0; count < 1; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		io_len = (rand() % g_max_io_size) + 1;
+		bdev_io_initialize(bdev_io, lba, io_len, SPDK_BDEV_IO_TYPE_INVALID);
+		lba += io_len;
+		memset(g_io_output, 0, (g_max_io_size / g_strip_size) + 1 * sizeof(struct io_output));
+		g_io_output_index = 0;
+		raid_bdev_submit_request(ch, bdev_io);
+		verify_io(bdev_io, req.base_bdevs.num_base_bdevs, ch_ctx, &pbdev_ctxt->raid_bdev,
+			  INVALID_IO_SUBMIT);
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+
+	lba = 0;
+	g_child_io_status_flag = false;
+	for (count = 0; count < 1; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		io_len = (rand() % g_max_io_size) + 1;
+		bdev_io_initialize(bdev_io, lba, io_len, SPDK_BDEV_IO_TYPE_WRITE);
+		lba += io_len;
+		memset(g_io_output, 0, (g_max_io_size / g_strip_size) + 1 * sizeof(struct io_output));
+		g_io_output_index = 0;
+		raid_bdev_submit_request(ch, bdev_io);
+		verify_io(bdev_io, req.base_bdevs.num_base_bdevs, ch_ctx, &pbdev_ctxt->raid_bdev,
+			  g_child_io_status_flag);
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+	raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+	CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+	free(ch);
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+/* Test waitq logic */
+static void
+test_io_waitq(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct spdk_io_channel *ch;
+	struct raid_bdev_io_channel *ch_ctx;
+	uint32_t iter;
+	struct spdk_bdev_io *bdev_io;
+	struct spdk_bdev_io *bdev_io_next;
+	uint32_t count;
+	uint64_t io_len;
+	uint64_t lba;
+	TAILQ_HEAD(, spdk_bdev_io) head_io;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	SPDK_CU_ASSERT_FATAL(pbdev_ctxt != NULL);
+	ch = calloc(1, sizeof(struct spdk_io_channel) + sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch != NULL);
+	ch_ctx = spdk_io_channel_get_ctx(ch);
+	SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+
+	CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+	SPDK_CU_ASSERT_FATAL(ch_ctx->base_bdevs_io_channel != NULL);
+	for (iter = 0; iter < req.base_bdevs.num_base_bdevs; iter++) {
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel[iter] == (void *)0x1);
+	}
+
+	lba = 0;
+	TAILQ_INIT(&head_io);
+	for (count = 0; count < g_max_qd; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		TAILQ_INSERT_TAIL(&head_io, bdev_io, module_link);
+		io_len = (rand() % g_max_io_size) + 1;
+		bdev_io_initialize(bdev_io, lba, io_len, SPDK_BDEV_IO_TYPE_WRITE);
+		g_bdev_io_submit_status = -ENOMEM;
+		lba += io_len;
+		raid_bdev_submit_request(ch, bdev_io);
+	}
+
+	g_ignore_io_output = 1;
+
+	count = get_num_elts_in_waitq();
+	CU_ASSERT(count == g_max_qd);
+	g_bdev_io_submit_status = 0;
+	process_io_waitq();
+	CU_ASSERT(TAILQ_EMPTY(&g_io_waitq));
+
+	TAILQ_FOREACH_SAFE(bdev_io, &head_io, module_link, bdev_io_next) {
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+	raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+	CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+	CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+	g_ignore_io_output = 0;
+	free(ch);
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+/* Create multiple raids, destroy raids without IO, get_raids related tests */
+static void
+test_multi_raid_no_io(void)
+{
+	struct rpc_construct_raid_bdev *construct_req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct rpc_get_raid_bdevs get_raids_req;
+	uint32_t iter;
+	char name[16];
+	uint32_t count;
+	uint32_t bbdev_idx = 0;
+
+	set_globals();
+	construct_req = calloc(MAX_RAIDS, sizeof(struct rpc_construct_raid_bdev));
+	SPDK_CU_ASSERT_FATAL(construct_req != NULL);
+	CU_ASSERT(raid_bdev_init() == 0);
+	for (iter = 0; iter < g_max_raids; iter++) {
+		count = snprintf(name, 16, "%s%u", "raid", iter);
+		name[count] = '\0';
+		create_test_req(&construct_req[iter], name, bbdev_idx, true);
+		verify_raid_config_present(name, false);
+		verify_raid_bdev_present(name, false);
+		bbdev_idx += g_max_base_drives;
+		rpc_req = &construct_req[iter];
+		rpc_req_size = sizeof(construct_req[0]);
+		g_rpc_err = 0;
+		spdk_rpc_construct_raid_bdev(NULL, NULL);
+		CU_ASSERT(g_rpc_err == 0);
+		verify_raid_config(&construct_req[iter], true);
+		verify_raid_bdev(&construct_req[iter], true, RAID_BDEV_STATE_ONLINE);
+	}
+
+	get_raids_req.category = strdup("all");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	g_test_multi_raids = 1;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_get_raids(construct_req, g_max_raids, g_get_raids_output, g_get_raids_count);
+	for (iter = 0; iter < g_get_raids_count; iter++) {
+		free(g_get_raids_output[iter]);
+	}
+	g_get_raids_count = 0;
+
+	get_raids_req.category = strdup("online");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_get_raids(construct_req, g_max_raids, g_get_raids_output, g_get_raids_count);
+	for (iter = 0; iter < g_get_raids_count; iter++) {
+		free(g_get_raids_output[iter]);
+	}
+	g_get_raids_count = 0;
+
+	get_raids_req.category = strdup("configuring");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	CU_ASSERT(g_get_raids_count == 0);
+
+	get_raids_req.category = strdup("offline");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	CU_ASSERT(g_get_raids_count == 0);
+
+	get_raids_req.category = strdup("invalid_category");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	CU_ASSERT(g_get_raids_count == 0);
+
+	get_raids_req.category = strdup("all");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	g_json_decode_obj_err = 1;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 1);
+	g_json_decode_obj_err = 0;
+	free(get_raids_req.category);
+	CU_ASSERT(g_get_raids_count == 0);
+
+	get_raids_req.category = strdup("all");
+	rpc_req = &get_raids_req;
+	rpc_req_size = sizeof(get_raids_req);
+	g_rpc_err = 0;
+	g_json_beg_res_ret_err = 1;
+	spdk_rpc_get_raid_bdevs(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	g_json_beg_res_ret_err = 0;
+	CU_ASSERT(g_get_raids_count == 0);
+
+	for (iter = 0; iter < g_max_raids; iter++) {
+		SPDK_CU_ASSERT_FATAL(construct_req[iter].name != NULL);
+		destroy_req.name = strdup(construct_req[iter].name);
+		count = snprintf(name, 16, "%s", destroy_req.name);
+		name[count] = '\0';
+		rpc_req = &destroy_req;
+		rpc_req_size = sizeof(destroy_req);
+		g_rpc_err = 0;
+		spdk_rpc_destroy_raid_bdev(NULL, NULL);
+		CU_ASSERT(g_rpc_err == 0);
+		verify_raid_config_present(name, false);
+		verify_raid_bdev_present(name, false);
+	}
+	g_test_multi_raids = 0;
+	raid_bdev_exit();
+	free(construct_req);
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+/* Create multiple raids, fire IOs randomly on various raids */
+static void
+test_multi_raid_with_io(void)
+{
+	struct rpc_construct_raid_bdev *construct_req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	uint32_t iter, iter2;
+	char name[16];
+	uint32_t count;
+	uint32_t bbdev_idx = 0;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+	struct spdk_io_channel *ch;
+	struct raid_bdev_io_channel *ch_ctx;
+	struct spdk_bdev_io *bdev_io;
+	uint64_t io_len;
+	uint64_t lba;
+	struct spdk_io_channel *ch_random;
+	struct raid_bdev_io_channel *ch_ctx_random;
+	int16_t iotype;
+	uint32_t raid_random;
+
+	set_globals();
+	construct_req = calloc(g_max_raids, sizeof(struct rpc_construct_raid_bdev));
+	SPDK_CU_ASSERT_FATAL(construct_req != NULL);
+	CU_ASSERT(raid_bdev_init() == 0);
+	ch = calloc(g_max_raids, sizeof(struct spdk_io_channel) + sizeof(struct raid_bdev_io_channel));
+	SPDK_CU_ASSERT_FATAL(ch != NULL);
+	for (iter = 0; iter < g_max_raids; iter++) {
+		count = snprintf(name, 16, "%s%u", "raid", iter);
+		name[count] = '\0';
+		create_test_req(&construct_req[iter], name, bbdev_idx, true);
+		verify_raid_config_present(name, false);
+		verify_raid_bdev_present(name, false);
+		bbdev_idx += g_max_base_drives;
+		rpc_req = &construct_req[iter];
+		rpc_req_size = sizeof(construct_req[0]);
+		g_rpc_err = 0;
+		spdk_rpc_construct_raid_bdev(NULL, NULL);
+		CU_ASSERT(g_rpc_err == 0);
+		verify_raid_config(&construct_req[iter], true);
+		verify_raid_bdev(&construct_req[iter], true, RAID_BDEV_STATE_ONLINE);
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, construct_req[iter].name) == 0) {
+				break;
+			}
+		}
+		CU_ASSERT(pbdev_ctxt != NULL);
+		ch_ctx = spdk_io_channel_get_ctx(&ch[iter]);
+		SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+		CU_ASSERT(raid_bdev_create_cb(&pbdev_ctxt->raid_bdev, ch_ctx) == 0);
+		CU_ASSERT(ch_ctx->raid_bdev_ctxt == pbdev_ctxt);
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel != NULL);
+		for (iter2 = 0; iter2 < construct_req[iter].base_bdevs.num_base_bdevs; iter2++) {
+			CU_ASSERT(ch_ctx->base_bdevs_io_channel[iter2] == (void *)0x1);
+		}
+	}
+
+	lba = 0;
+	for (count = 0; count < g_max_qd; count++) {
+		bdev_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct raid_bdev_io));
+		SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+		io_len = (rand() % g_max_io_size) + 1;
+		iotype = (rand() % 2) ? SPDK_BDEV_IO_TYPE_WRITE : SPDK_BDEV_IO_TYPE_READ;
+		bdev_io_initialize(bdev_io, lba, io_len, iotype);
+		lba += io_len;
+		memset(g_io_output, 0, (g_max_io_size / g_strip_size) + 1 * sizeof(struct io_output));
+		g_io_output_index = 0;
+		raid_random = rand() % g_max_raids;
+		ch_random = &ch[raid_random];
+		ch_ctx_random = spdk_io_channel_get_ctx(ch_random);
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, construct_req[raid_random].name) == 0) {
+				break;
+			}
+		}
+		CU_ASSERT(pbdev_ctxt != NULL);
+		raid_bdev_submit_request(ch_random, bdev_io);
+		verify_io(bdev_io, g_max_base_drives, ch_ctx_random, &pbdev_ctxt->raid_bdev,
+			  g_child_io_status_flag);
+		bdev_io_cleanup(bdev_io);
+		free(bdev_io);
+	}
+
+	for (iter = 0; iter < g_max_raids; iter++) {
+		TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+			pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+			if (strcmp(pbdev_ctxt->bdev.name, construct_req[iter].name) == 0) {
+				break;
+			}
+		}
+		CU_ASSERT(pbdev_ctxt != NULL);
+		ch_ctx = spdk_io_channel_get_ctx(&ch[iter]);
+		SPDK_CU_ASSERT_FATAL(ch_ctx != NULL);
+		raid_bdev_destroy_cb(&pbdev_ctxt->raid_bdev, ch_ctx);
+		CU_ASSERT(ch_ctx->raid_bdev_ctxt == NULL);
+		CU_ASSERT(ch_ctx->base_bdevs_io_channel == NULL);
+		destroy_req.name = strdup(construct_req[iter].name);
+		count = snprintf(name, 16, "%s", destroy_req.name);
+		name[count] = '\0';
+		rpc_req = &destroy_req;
+		rpc_req_size = sizeof(destroy_req);
+		g_rpc_err = 0;
+		spdk_rpc_destroy_raid_bdev(NULL, NULL);
+		CU_ASSERT(g_rpc_err == 0);
+		verify_raid_config_present(name, false);
+		verify_raid_bdev_present(name, false);
+	}
+	raid_bdev_exit();
+	free(construct_req);
+	free(ch);
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_io_type_supported(void)
+{
+	CU_ASSERT(raid_bdev_io_type_supported(NULL, SPDK_BDEV_IO_TYPE_READ) == true);
+	CU_ASSERT(raid_bdev_io_type_supported(NULL, SPDK_BDEV_IO_TYPE_WRITE) == true);
+	CU_ASSERT(raid_bdev_io_type_supported(NULL, SPDK_BDEV_IO_TYPE_FLUSH) == true);
+	CU_ASSERT(raid_bdev_io_type_supported(NULL, SPDK_BDEV_IO_TYPE_INVALID) == false);
+}
+
+static void
+test_create_raid_from_config(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct spdk_bdev *bdev;
+	struct rpc_destroy_raid_bdev destroy_req;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	g_config_level_create = 1;
+	CU_ASSERT(raid_bdev_init() == 0);
+	g_config_level_create = 0;
+
+	verify_raid_config_present("raid1", true);
+	verify_raid_bdev_present("raid1", false);
+
+	TAILQ_FOREACH(bdev, &g_bdev_list, internal.link) {
+		raid_bdev_examine(bdev);
+	}
+
+	bdev = calloc(1, sizeof(struct spdk_bdev));
+	SPDK_CU_ASSERT_FATAL(bdev != NULL);
+	bdev->name = strdup("Invalid");
+	SPDK_CU_ASSERT_FATAL(bdev->name != NULL);
+	CU_ASSERT(raid_bdev_add_base_device(bdev) != 0);
+	free(bdev->name);
+	free(bdev);
+
+	verify_raid_config(&req, true);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	free_test_req(&req);
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_create_raid_from_config_invalid_params(void)
+{
+	struct rpc_construct_raid_bdev req;
+	uint8_t count;
+
+	set_globals();
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	g_config_level_create = 1;
+
+	create_test_req(&req, "raid1", 0, true);
+	free(req.name);
+	req.name = NULL;
+	CU_ASSERT(raid_bdev_init() != 0);
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.strip_size = 1234;
+	CU_ASSERT(raid_bdev_init() != 0);
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.raid_level = 1;
+	CU_ASSERT(raid_bdev_init() != 0);
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.raid_level = 1;
+	CU_ASSERT(raid_bdev_init() != 0);
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.base_bdevs.num_base_bdevs++;
+	CU_ASSERT(raid_bdev_init() != 0);
+	req.base_bdevs.num_base_bdevs--;
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	create_test_req(&req, "raid1", 0, false);
+	req.base_bdevs.num_base_bdevs--;
+	CU_ASSERT(raid_bdev_init() != 0);
+	req.base_bdevs.num_base_bdevs++;
+	free_test_req(&req);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	if (g_max_base_drives > 1) {
+		create_test_req(&req, "raid1", 0, false);
+		count = snprintf(req.base_bdevs.base_bdevs[g_max_base_drives - 1], 15, "%s", "Nvme0n1");
+		req.base_bdevs.base_bdevs[g_max_base_drives - 1][count] = '\0';
+		CU_ASSERT(raid_bdev_init() != 0);
+		free_test_req(&req);
+		verify_raid_config_present("raid1", false);
+		verify_raid_bdev_present("raid1", false);
+	}
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_raid_json_dump_info(void)
+{
+	struct rpc_construct_raid_bdev req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct raid_bdev *pbdev;
+	struct raid_bdev_ctxt *pbdev_ctxt = NULL;
+
+	set_globals();
+	create_test_req(&req, "raid1", 0, true);
+	rpc_req = &req;
+	rpc_req_size = sizeof(req);
+	CU_ASSERT(raid_bdev_init() == 0);
+
+	verify_raid_config_present(req.name, false);
+	verify_raid_bdev_present(req.name, false);
+	g_rpc_err = 0;
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_bdev(&req, true, RAID_BDEV_STATE_ONLINE);
+
+	TAILQ_FOREACH(pbdev, &g_spdk_raid_bdev_list, link_global_list) {
+		pbdev_ctxt = SPDK_CONTAINEROF(pbdev, struct raid_bdev_ctxt, raid_bdev);
+		if (strcmp(pbdev_ctxt->bdev.name, req.name) == 0) {
+			break;
+		}
+	}
+	CU_ASSERT(pbdev_ctxt != NULL);
+
+	CU_ASSERT(raid_bdev_dump_info_json(pbdev_ctxt, NULL) == 0);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+static void
+test_context_size(void)
+{
+	CU_ASSERT(raid_bdev_get_ctx_size() == sizeof(struct raid_bdev_io));
+}
+
+static void
+test_asym_base_drives_blockcnt(void)
+{
+	struct rpc_construct_raid_bdev construct_req;
+	struct rpc_destroy_raid_bdev destroy_req;
+	struct spdk_bdev *bbdev;
+	uint32_t iter;
+
+	set_globals();
+	create_test_req(&construct_req, "raid1", 0, true);
+	rpc_req = &construct_req;
+	rpc_req_size = sizeof(construct_req);
+	CU_ASSERT(raid_bdev_init() == 0);
+	verify_raid_config_present(construct_req.name, false);
+	verify_raid_bdev_present(construct_req.name, false);
+	g_rpc_err = 0;
+	for (iter = 0; iter < construct_req.base_bdevs.num_base_bdevs; iter++) {
+		bbdev = spdk_bdev_get_by_name(construct_req.base_bdevs.base_bdevs[iter]);
+		SPDK_CU_ASSERT_FATAL(bbdev != NULL);
+		bbdev->blockcnt = rand() + 1;
+	}
+	spdk_rpc_construct_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config(&construct_req, true);
+	verify_raid_bdev(&construct_req, true, RAID_BDEV_STATE_ONLINE);
+
+	destroy_req.name = strdup("raid1");
+	rpc_req = &destroy_req;
+	rpc_req_size = sizeof(destroy_req);
+	g_rpc_err = 0;
+	spdk_rpc_destroy_raid_bdev(NULL, NULL);
+	CU_ASSERT(g_rpc_err == 0);
+	verify_raid_config_present("raid1", false);
+	verify_raid_bdev_present("raid1", false);
+
+	raid_bdev_exit();
+	base_bdevs_cleanup();
+	reset_globals();
+}
+
+int main(int argc, char **argv)
+{
+	CU_pSuite       suite = NULL;
+	unsigned int    num_failures;
+
+	if (CU_initialize_registry() != CUE_SUCCESS) {
+		return CU_get_error();
+	}
+
+	suite = CU_add_suite("raid", NULL, NULL);
+	if (suite == NULL) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	if (
+		CU_add_test(suite, "test_construct_raid", test_construct_raid) == NULL ||
+		CU_add_test(suite, "test_destroy_raid", test_destroy_raid) == NULL ||
+		CU_add_test(suite, "test_construct_raid_invalid_args", test_construct_raid_invalid_args) == NULL ||
+		CU_add_test(suite, "test_destroy_raid_invalid_args", test_destroy_raid_invalid_args) == NULL ||
+		CU_add_test(suite, "test_io_channel", test_io_channel) == NULL ||
+		CU_add_test(suite, "test_write_io", test_write_io) == NULL    ||
+		CU_add_test(suite, "test_read_io", test_read_io) == NULL     ||
+		CU_add_test(suite, "test_io_failure", test_io_failure) == NULL ||
+		CU_add_test(suite, "test_io_waitq", test_io_waitq) == NULL ||
+		CU_add_test(suite, "test_multi_raid_no_io", test_multi_raid_no_io) == NULL ||
+		CU_add_test(suite, "test_multi_raid_with_io", test_multi_raid_with_io) == NULL ||
+		CU_add_test(suite, "test_io_type_supported", test_io_type_supported) == NULL ||
+		CU_add_test(suite, "test_create_raid_from_config", test_create_raid_from_config) == NULL ||
+		CU_add_test(suite, "test_create_raid_from_config_invalid_params",
+			    test_create_raid_from_config_invalid_params) == NULL ||
+		CU_add_test(suite, "test_raid_json_dump_info", test_raid_json_dump_info) == NULL ||
+		CU_add_test(suite, "test_context_size", test_context_size) == NULL ||
+		CU_add_test(suite, "test_asym_base_drives_blockcnt", test_asym_base_drives_blockcnt) == NULL
+	) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	CU_basic_set_mode(CU_BRM_VERBOSE);
+	set_test_opts();
+	CU_basic_run_tests();
+	num_failures = CU_get_number_of_failures();
+	CU_cleanup_registry();
+	return num_failures;
+}
diff --git a/test/unit/lib/bdev/mt/bdev.c/bdev_ut.c b/test/unit/lib/bdev/mt/bdev.c/bdev_ut.c
index 3cb1493e2..7644f45a3 100644
--- a/test/unit/lib/bdev/mt/bdev.c/bdev_ut.c
+++ b/test/unit/lib/bdev/mt/bdev.c/bdev_ut.c
@@ -47,19 +47,11 @@
 DEFINE_STUB_V(spdk_scsi_nvme_translate, (const struct spdk_bdev_io *bdev_io,
 		int *sc, int *sk, int *asc, int *ascq));
 
-/* Return NULL to test hardcoded defaults. */
-struct spdk_conf_section *
-spdk_conf_find_section(struct spdk_conf *cp, const char *name)
-{
-	return NULL;
-}
-
-/* Return NULL to test hardcoded defaults. */
-char *
-spdk_conf_section_get_nmval(struct spdk_conf_section *sp, const char *key, int idx1, int idx2)
-{
-	return NULL;
-}
+DEFINE_STUB(spdk_conf_find_section, struct spdk_conf_section *, (struct spdk_conf *cp,
+		const char *name), NULL);
+DEFINE_STUB(spdk_conf_section_get_nmval, char *,
+	    (struct spdk_conf_section *sp, const char *key, int idx1, int idx2), NULL);
+DEFINE_STUB(spdk_conf_section_get_intval, int, (struct spdk_conf_section *sp, const char *key), -1);
 
 struct ut_bdev {
 	struct spdk_bdev	bdev;
@@ -279,7 +271,7 @@ bdev_io_tailq_cnt(bdev_io_tailq_t *tailq)
 	struct spdk_bdev_io *io;
 	uint32_t cnt = 0;
 
-	TAILQ_FOREACH(io, tailq, link) {
+	TAILQ_FOREACH(io, tailq, internal.link) {
 		cnt++;
 	}
 
@@ -313,94 +305,6 @@ basic(void)
 	teardown_test();
 }
 
-static int
-poller_run_done(void *ctx)
-{
-	bool	*poller_run = ctx;
-
-	*poller_run = true;
-
-	return -1;
-}
-
-static int
-poller_run_times_done(void *ctx)
-{
-	int	*poller_run_times = ctx;
-
-	(*poller_run_times)++;
-
-	return -1;
-}
-
-static void
-basic_poller(void)
-{
-	struct spdk_poller	*poller = NULL;
-	bool			poller_run = false;
-	int			poller_run_times = 0;
-
-	setup_test();
-
-	set_thread(0);
-	reset_time();
-	/* Register a poller with no-wait time and test execution */
-	poller = spdk_poller_register(poller_run_done, &poller_run, 0);
-	CU_ASSERT(poller != NULL);
-
-	poll_threads();
-	CU_ASSERT(poller_run == true);
-
-	spdk_poller_unregister(&poller);
-	CU_ASSERT(poller == NULL);
-
-	/* Register a poller with 1000us wait time and test single execution */
-	poller_run = false;
-	poller = spdk_poller_register(poller_run_done, &poller_run, 1000);
-	CU_ASSERT(poller != NULL);
-
-	poll_threads();
-	CU_ASSERT(poller_run == false);
-
-	increment_time(1000);
-	poll_threads();
-	CU_ASSERT(poller_run == true);
-
-	reset_time();
-	poller_run = false;
-	poll_threads();
-	CU_ASSERT(poller_run == false);
-
-	increment_time(1000);
-	poll_threads();
-	CU_ASSERT(poller_run == true);
-
-	spdk_poller_unregister(&poller);
-	CU_ASSERT(poller == NULL);
-
-	reset_time();
-	/* Register a poller with 1000us wait time and test multiple execution */
-	poller = spdk_poller_register(poller_run_times_done, &poller_run_times, 1000);
-	CU_ASSERT(poller != NULL);
-
-	poll_threads();
-	CU_ASSERT(poller_run_times == 0);
-
-	increment_time(1000);
-	poll_threads();
-	CU_ASSERT(poller_run_times == 1);
-
-	poller_run_times = 0;
-	increment_time(2000);
-	poll_threads();
-	CU_ASSERT(poller_run_times == 2);
-
-	spdk_poller_unregister(&poller);
-	CU_ASSERT(poller == NULL);
-
-	teardown_test();
-}
-
 static void
 reset_done(struct spdk_bdev_io *bdev_io, bool success, void *cb_arg)
 {
@@ -449,7 +353,8 @@ static void
 aborted_reset(void)
 {
 	struct spdk_io_channel *io_ch[2];
-	enum spdk_bdev_io_status status1, status2;
+	enum spdk_bdev_io_status status1 = SPDK_BDEV_IO_STATUS_PENDING,
+				 status2 = SPDK_BDEV_IO_STATUS_PENDING;
 
 	setup_test();
 
@@ -458,7 +363,7 @@ aborted_reset(void)
 	CU_ASSERT(io_ch[0] != NULL);
 	spdk_bdev_reset(g_desc, io_ch[0], aborted_reset_done, &status1);
 	poll_threads();
-	CU_ASSERT(g_bdev.bdev.reset_in_progress != NULL);
+	CU_ASSERT(g_bdev.bdev.internal.reset_in_progress != NULL);
 
 	/*
 	 * First reset has been submitted on ch0.  Now submit a second
@@ -470,32 +375,32 @@ aborted_reset(void)
 	CU_ASSERT(io_ch[1] != NULL);
 	spdk_bdev_reset(g_desc, io_ch[1], aborted_reset_done, &status2);
 	poll_threads();
-	CU_ASSERT(g_bdev.bdev.reset_in_progress != NULL);
+	CU_ASSERT(g_bdev.bdev.internal.reset_in_progress != NULL);
 
 	/*
 	 * Now destroy ch1.  This will abort the queued reset.  Check that
 	 *  the second reset was completed with failed status.  Also check
-	 *  that bdev->reset_in_progress != NULL, since the original reset
-	 *  has not been completed yet.  This ensures that the bdev code is
-	 *  correctly noticing that the failed reset is *not* the one that
-	 *  had been submitted to the bdev module.
+	 *  that bdev->internal.reset_in_progress != NULL, since the
+	 *  original reset has not been completed yet.  This ensures that
+	 *  the bdev code is correctly noticing that the failed reset is
+	 *  *not* the one that had been submitted to the bdev module.
 	 */
 	set_thread(1);
 	spdk_put_io_channel(io_ch[1]);
 	poll_threads();
 	CU_ASSERT(status2 == SPDK_BDEV_IO_STATUS_FAILED);
-	CU_ASSERT(g_bdev.bdev.reset_in_progress != NULL);
+	CU_ASSERT(g_bdev.bdev.internal.reset_in_progress != NULL);
 
 	/*
 	 * Now complete the first reset, verify that it completed with SUCCESS
-	 *  status and that bdev->reset_in_progress is also set back to NULL.
+	 *  status and that bdev->internal.reset_in_progress is also set back to NULL.
 	 */
 	set_thread(0);
 	spdk_put_io_channel(io_ch[0]);
 	stub_complete_io(g_bdev.io_target, 0);
 	poll_threads();
 	CU_ASSERT(status1 == SPDK_BDEV_IO_STATUS_SUCCESS);
-	CU_ASSERT(g_bdev.bdev.reset_in_progress == NULL);
+	CU_ASSERT(g_bdev.bdev.internal.reset_in_progress == NULL);
 
 	teardown_test();
 }
@@ -626,9 +531,15 @@ basic_qos(void)
 
 	/* Enable QoS */
 	bdev = &g_bdev.bdev;
-	TAILQ_INIT(&bdev->qos.queued);
-	bdev->qos.rate_limit = 2000; /* 2 I/O per millisecond */
-	bdev->qos.enabled = true;
+	bdev->internal.qos = calloc(1, sizeof(*bdev->internal.qos));
+	SPDK_CU_ASSERT_FATAL(bdev->internal.qos != NULL);
+	TAILQ_INIT(&bdev->internal.qos->queued);
+	/*
+	 * Enable both IOPS and bandwidth rate limits.
+	 * In this case, both rate limits will take equal effect.
+	 */
+	bdev->internal.qos->iops_rate_limit = 2000; /* 2 I/O per millisecond */
+	bdev->internal.qos->byte_rate_limit = 8192000; /* 8K byte per millisecond with 4K block size */
 
 	g_get_io_channel = true;
 
@@ -683,7 +594,8 @@ basic_qos(void)
 
 	/* Close the descriptor, which should stop the qos channel */
 	spdk_bdev_close(g_desc);
-	CU_ASSERT(bdev->qos.ch == NULL);
+	poll_threads();
+	CU_ASSERT(bdev->internal.qos->ch == NULL);
 
 	spdk_bdev_open(bdev, true, NULL, NULL, &g_desc);
 
@@ -698,8 +610,8 @@ basic_qos(void)
 	bdev_ch[0] = spdk_io_channel_get_ctx(io_ch[0]);
 	CU_ASSERT(bdev_ch[0]->flags == BDEV_CH_QOS_ENABLED);
 
-	/* Confirm that the qos tracking was re-enabled */
-	CU_ASSERT(bdev->qos.ch != NULL);
+	/* Confirm that the qos thread is now thread 1 */
+	CU_ASSERT(bdev->internal.qos->ch == bdev_ch[1]);
 
 	/* Tear down the channels */
 	set_thread(0);
@@ -727,9 +639,15 @@ io_during_qos_queue(void)
 
 	/* Enable QoS */
 	bdev = &g_bdev.bdev;
-	TAILQ_INIT(&bdev->qos.queued);
-	bdev->qos.rate_limit = 1000; /* 1000 I/O per second, or 1 per millisecond */
-	bdev->qos.enabled = true;
+	bdev->internal.qos = calloc(1, sizeof(*bdev->internal.qos));
+	SPDK_CU_ASSERT_FATAL(bdev->internal.qos != NULL);
+	TAILQ_INIT(&bdev->internal.qos->queued);
+	/*
+	 * Enable both IOPS and bandwidth rate limits.
+	 * In this case, IOPS rate limit will take effect first.
+	 */
+	bdev->internal.qos->iops_rate_limit = 1000; /* 1000 I/O per second, or 1 per millisecond */
+	bdev->internal.qos->byte_rate_limit = 8192000; /* 8K byte per millisecond with 4K block size */
 
 	g_get_io_channel = true;
 
@@ -809,9 +727,15 @@ io_during_qos_reset(void)
 
 	/* Enable QoS */
 	bdev = &g_bdev.bdev;
-	TAILQ_INIT(&bdev->qos.queued);
-	bdev->qos.rate_limit = 1000; /* 1000 I/O per second, or 1 per millisecond */
-	bdev->qos.enabled = true;
+	bdev->internal.qos = calloc(1, sizeof(*bdev->internal.qos));
+	SPDK_CU_ASSERT_FATAL(bdev->internal.qos != NULL);
+	TAILQ_INIT(&bdev->internal.qos->queued);
+	/*
+	 * Enable both IOPS and bandwidth rate limits.
+	 * In this case, bandwidth rate limit will take effect first.
+	 */
+	bdev->internal.qos->iops_rate_limit = 2000; /* 2000 I/O per second, or 2 per millisecond */
+	bdev->internal.qos->byte_rate_limit = 4096000; /* 4K byte per millisecond with 4K block size */
 
 	g_get_io_channel = true;
 
@@ -880,7 +804,7 @@ enomem(void)
 {
 	struct spdk_io_channel *io_ch;
 	struct spdk_bdev_channel *bdev_ch;
-	struct spdk_bdev_module_channel *module_ch;
+	struct spdk_bdev_shared_resource *shared_resource;
 	struct ut_bdev_channel *ut_ch;
 	const uint32_t IO_ARRAY_SIZE = 64;
 	const uint32_t AVAIL = 20;
@@ -894,7 +818,7 @@ enomem(void)
 	set_thread(0);
 	io_ch = spdk_bdev_get_io_channel(g_desc);
 	bdev_ch = spdk_io_channel_get_ctx(io_ch);
-	module_ch = bdev_ch->module_ch;
+	shared_resource = bdev_ch->shared_resource;
 	ut_ch = spdk_io_channel_get_ctx(bdev_ch->channel);
 	ut_ch->avail_cnt = AVAIL;
 
@@ -904,7 +828,7 @@ enomem(void)
 		rc = spdk_bdev_read_blocks(g_desc, io_ch, NULL, 0, 1, enomem_done, &status[i]);
 		CU_ASSERT(rc == 0);
 	}
-	CU_ASSERT(TAILQ_EMPTY(&module_ch->nomem_io));
+	CU_ASSERT(TAILQ_EMPTY(&shared_resource->nomem_io));
 
 	/*
 	 * Next, submit one additional I/O.  This one should fail with ENOMEM and then go onto
@@ -913,8 +837,8 @@ enomem(void)
 	status[AVAIL] = SPDK_BDEV_IO_STATUS_PENDING;
 	rc = spdk_bdev_read_blocks(g_desc, io_ch, NULL, 0, 1, enomem_done, &status[AVAIL]);
 	CU_ASSERT(rc == 0);
-	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&module_ch->nomem_io));
-	first_io = TAILQ_FIRST(&module_ch->nomem_io);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&shared_resource->nomem_io));
+	first_io = TAILQ_FIRST(&shared_resource->nomem_io);
 
 	/*
 	 * Now submit a bunch more I/O.  These should all fail with ENOMEM and get queued behind
@@ -927,10 +851,10 @@ enomem(void)
 	}
 
 	/* Assert that first_io is still at the head of the list. */
-	CU_ASSERT(TAILQ_FIRST(&module_ch->nomem_io) == first_io);
-	CU_ASSERT(bdev_io_tailq_cnt(&module_ch->nomem_io) == (IO_ARRAY_SIZE - AVAIL));
-	nomem_cnt = bdev_io_tailq_cnt(&module_ch->nomem_io);
-	CU_ASSERT(module_ch->nomem_threshold == (AVAIL - NOMEM_THRESHOLD_COUNT));
+	CU_ASSERT(TAILQ_FIRST(&shared_resource->nomem_io) == first_io);
+	CU_ASSERT(bdev_io_tailq_cnt(&shared_resource->nomem_io) == (IO_ARRAY_SIZE - AVAIL));
+	nomem_cnt = bdev_io_tailq_cnt(&shared_resource->nomem_io);
+	CU_ASSERT(shared_resource->nomem_threshold == (AVAIL - NOMEM_THRESHOLD_COUNT));
 
 	/*
 	 * Complete 1 I/O only.  The key check here is bdev_io_tailq_cnt - this should not have
@@ -938,19 +862,19 @@ enomem(void)
 	 *  list.
 	 */
 	stub_complete_io(g_bdev.io_target, 1);
-	CU_ASSERT(bdev_io_tailq_cnt(&module_ch->nomem_io) == nomem_cnt);
+	CU_ASSERT(bdev_io_tailq_cnt(&shared_resource->nomem_io) == nomem_cnt);
 
 	/*
 	 * Complete enough I/O to hit the nomem_theshold.  This should trigger retrying nomem_io,
 	 *  and we should see I/O get resubmitted to the test bdev module.
 	 */
 	stub_complete_io(g_bdev.io_target, NOMEM_THRESHOLD_COUNT - 1);
-	CU_ASSERT(bdev_io_tailq_cnt(&module_ch->nomem_io) < nomem_cnt);
-	nomem_cnt = bdev_io_tailq_cnt(&module_ch->nomem_io);
+	CU_ASSERT(bdev_io_tailq_cnt(&shared_resource->nomem_io) < nomem_cnt);
+	nomem_cnt = bdev_io_tailq_cnt(&shared_resource->nomem_io);
 
 	/* Complete 1 I/O only.  This should not trigger retrying the queued nomem_io. */
 	stub_complete_io(g_bdev.io_target, 1);
-	CU_ASSERT(bdev_io_tailq_cnt(&module_ch->nomem_io) == nomem_cnt);
+	CU_ASSERT(bdev_io_tailq_cnt(&shared_resource->nomem_io) == nomem_cnt);
 
 	/*
 	 * Send a reset and confirm that all I/O are completed, including the ones that
@@ -963,8 +887,8 @@ enomem(void)
 	/* This will complete the reset. */
 	stub_complete_io(g_bdev.io_target, 0);
 
-	CU_ASSERT(bdev_io_tailq_cnt(&module_ch->nomem_io) == 0);
-	CU_ASSERT(module_ch->io_outstanding == 0);
+	CU_ASSERT(bdev_io_tailq_cnt(&shared_resource->nomem_io) == 0);
+	CU_ASSERT(shared_resource->io_outstanding == 0);
 
 	spdk_put_io_channel(io_ch);
 	poll_threads();
@@ -976,7 +900,7 @@ enomem_multi_bdev(void)
 {
 	struct spdk_io_channel *io_ch;
 	struct spdk_bdev_channel *bdev_ch;
-	struct spdk_bdev_module_channel *module_ch;
+	struct spdk_bdev_shared_resource *shared_resource;
 	struct ut_bdev_channel *ut_ch;
 	const uint32_t IO_ARRAY_SIZE = 64;
 	const uint32_t AVAIL = 20;
@@ -999,13 +923,13 @@ enomem_multi_bdev(void)
 	set_thread(0);
 	io_ch = spdk_bdev_get_io_channel(g_desc);
 	bdev_ch = spdk_io_channel_get_ctx(io_ch);
-	module_ch = bdev_ch->module_ch;
+	shared_resource = bdev_ch->shared_resource;
 	ut_ch = spdk_io_channel_get_ctx(bdev_ch->channel);
 	ut_ch->avail_cnt = AVAIL;
 
 	second_ch = spdk_bdev_get_io_channel(second_desc);
 	second_bdev_ch = spdk_io_channel_get_ctx(second_ch);
-	SPDK_CU_ASSERT_FATAL(module_ch == second_bdev_ch->module_ch);
+	SPDK_CU_ASSERT_FATAL(shared_resource == second_bdev_ch->shared_resource);
 
 	/* Saturate io_target through bdev A. */
 	for (i = 0; i < AVAIL; i++) {
@@ -1013,7 +937,7 @@ enomem_multi_bdev(void)
 		rc = spdk_bdev_read_blocks(g_desc, io_ch, NULL, 0, 1, enomem_done, &status[i]);
 		CU_ASSERT(rc == 0);
 	}
-	CU_ASSERT(TAILQ_EMPTY(&module_ch->nomem_io));
+	CU_ASSERT(TAILQ_EMPTY(&shared_resource->nomem_io));
 
 	/*
 	 * Now submit I/O through the second bdev. This should fail with ENOMEM
@@ -1022,17 +946,17 @@ enomem_multi_bdev(void)
 	status[AVAIL] = SPDK_BDEV_IO_STATUS_PENDING;
 	rc = spdk_bdev_read_blocks(second_desc, second_ch, NULL, 0, 1, enomem_done, &status[AVAIL]);
 	CU_ASSERT(rc == 0);
-	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&module_ch->nomem_io));
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&shared_resource->nomem_io));
 
 	/* Complete first bdev's I/O. This should retry sending second bdev's nomem_io */
 	stub_complete_io(g_bdev.io_target, AVAIL);
 
-	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&module_ch->nomem_io));
-	CU_ASSERT(module_ch->io_outstanding == 1);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&shared_resource->nomem_io));
+	CU_ASSERT(shared_resource->io_outstanding == 1);
 
 	/* Now complete our retried I/O  */
 	stub_complete_io(g_bdev.io_target, 1);
-	SPDK_CU_ASSERT_FATAL(module_ch->io_outstanding == 0);
+	SPDK_CU_ASSERT_FATAL(shared_resource->io_outstanding == 0);
 
 	spdk_put_io_channel(io_ch);
 	spdk_put_io_channel(second_ch);
@@ -1043,6 +967,241 @@ enomem_multi_bdev(void)
 	teardown_test();
 }
 
+
+static void
+enomem_multi_io_target(void)
+{
+	struct spdk_io_channel *io_ch;
+	struct spdk_bdev_channel *bdev_ch;
+	struct ut_bdev_channel *ut_ch;
+	const uint32_t IO_ARRAY_SIZE = 64;
+	const uint32_t AVAIL = 20;
+	enum spdk_bdev_io_status status[IO_ARRAY_SIZE];
+	uint32_t i;
+	int new_io_device;
+	struct ut_bdev *second_bdev;
+	struct spdk_bdev_desc *second_desc;
+	struct spdk_bdev_channel *second_bdev_ch;
+	struct spdk_io_channel *second_ch;
+	int rc;
+
+	setup_test();
+
+	/* Create new io_target and a second bdev using it */
+	spdk_io_device_register(&new_io_device, stub_create_ch, stub_destroy_ch,
+				sizeof(struct ut_bdev_channel));
+	second_bdev = calloc(1, sizeof(*second_bdev));
+	SPDK_CU_ASSERT_FATAL(second_bdev != NULL);
+	register_bdev(second_bdev, "ut_bdev2", &new_io_device);
+	spdk_bdev_open(&second_bdev->bdev, true, NULL, NULL, &second_desc);
+
+	set_thread(0);
+	io_ch = spdk_bdev_get_io_channel(g_desc);
+	bdev_ch = spdk_io_channel_get_ctx(io_ch);
+	ut_ch = spdk_io_channel_get_ctx(bdev_ch->channel);
+	ut_ch->avail_cnt = AVAIL;
+
+	/* Different io_target should imply a different shared_resource */
+	second_ch = spdk_bdev_get_io_channel(second_desc);
+	second_bdev_ch = spdk_io_channel_get_ctx(second_ch);
+	SPDK_CU_ASSERT_FATAL(bdev_ch->shared_resource != second_bdev_ch->shared_resource);
+
+	/* Saturate io_target through bdev A. */
+	for (i = 0; i < AVAIL; i++) {
+		status[i] = SPDK_BDEV_IO_STATUS_PENDING;
+		rc = spdk_bdev_read_blocks(g_desc, io_ch, NULL, 0, 1, enomem_done, &status[i]);
+		CU_ASSERT(rc == 0);
+	}
+	CU_ASSERT(TAILQ_EMPTY(&bdev_ch->shared_resource->nomem_io));
+
+	/* Issue one more I/O to fill ENOMEM list. */
+	status[AVAIL] = SPDK_BDEV_IO_STATUS_PENDING;
+	rc = spdk_bdev_read_blocks(g_desc, io_ch, NULL, 0, 1, enomem_done, &status[AVAIL]);
+	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&bdev_ch->shared_resource->nomem_io));
+
+	/*
+	 * Now submit I/O through the second bdev. This should go through and complete
+	 * successfully because we're using a different io_device underneath.
+	 */
+	status[AVAIL] = SPDK_BDEV_IO_STATUS_PENDING;
+	rc = spdk_bdev_read_blocks(second_desc, second_ch, NULL, 0, 1, enomem_done, &status[AVAIL]);
+	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&second_bdev_ch->shared_resource->nomem_io));
+	stub_complete_io(second_bdev->io_target, 1);
+
+	/* Cleanup; Complete outstanding I/O. */
+	stub_complete_io(g_bdev.io_target, AVAIL);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&bdev_ch->shared_resource->nomem_io));
+	/* Complete the ENOMEM I/O */
+	stub_complete_io(g_bdev.io_target, 1);
+	CU_ASSERT(bdev_ch->shared_resource->io_outstanding == 0);
+
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&bdev_ch->shared_resource->nomem_io));
+	CU_ASSERT(bdev_ch->shared_resource->io_outstanding == 0);
+	spdk_put_io_channel(io_ch);
+	spdk_put_io_channel(second_ch);
+	spdk_bdev_close(second_desc);
+	unregister_bdev(second_bdev);
+	spdk_io_device_unregister(&new_io_device, NULL);
+	poll_threads();
+	free(second_bdev);
+	teardown_test();
+}
+
+static void
+qos_dynamic_enable_done(void *cb_arg, int status)
+{
+	int *rc = cb_arg;
+	*rc = status;
+}
+
+static void
+qos_dynamic_enable(void)
+{
+	struct spdk_io_channel *io_ch[2];
+	struct spdk_bdev_channel *bdev_ch[2];
+	struct spdk_bdev *bdev;
+	enum spdk_bdev_io_status bdev_io_status[2];
+	int status, second_status, rc, i;
+
+	setup_test();
+	reset_time();
+
+	bdev = &g_bdev.bdev;
+
+	g_get_io_channel = true;
+
+	/* Create channels */
+	set_thread(0);
+	io_ch[0] = spdk_bdev_get_io_channel(g_desc);
+	bdev_ch[0] = spdk_io_channel_get_ctx(io_ch[0]);
+	CU_ASSERT(bdev_ch[0]->flags == 0);
+
+	set_thread(1);
+	io_ch[1] = spdk_bdev_get_io_channel(g_desc);
+	bdev_ch[1] = spdk_io_channel_get_ctx(io_ch[1]);
+	CU_ASSERT(bdev_ch[1]->flags == 0);
+
+	set_thread(0);
+
+	/* Enable QoS */
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 10000, qos_dynamic_enable_done, &status);
+	poll_threads();
+	CU_ASSERT(status == 0);
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) != 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) != 0);
+
+	/*
+	 * Submit and complete 10 I/O to fill the QoS allotment for this timeslice.
+	 * Additional I/O will then be queued.
+	 */
+	set_thread(0);
+	for (i = 0; i < 10; i++) {
+		bdev_io_status[0] = SPDK_BDEV_IO_STATUS_PENDING;
+		rc = spdk_bdev_read_blocks(g_desc, io_ch[0], NULL, 0, 1, io_during_io_done, &bdev_io_status[0]);
+		CU_ASSERT(rc == 0);
+		CU_ASSERT(bdev_io_status[0] == SPDK_BDEV_IO_STATUS_PENDING);
+		poll_thread(0);
+		stub_complete_io(g_bdev.io_target, 0);
+		CU_ASSERT(bdev_io_status[0] == SPDK_BDEV_IO_STATUS_SUCCESS);
+	}
+
+	/*
+	 * Send two more I/O.  These I/O will be queued since the current timeslice allotment has been
+	 * filled already.  We want to test that when QoS is disabled that these two I/O:
+	 *  1) are not aborted
+	 *  2) are sent back to their original thread for resubmission
+	 */
+	bdev_io_status[0] = SPDK_BDEV_IO_STATUS_PENDING;
+	rc = spdk_bdev_read_blocks(g_desc, io_ch[0], NULL, 0, 1, io_during_io_done, &bdev_io_status[0]);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(bdev_io_status[0] == SPDK_BDEV_IO_STATUS_PENDING);
+	set_thread(1);
+	bdev_io_status[1] = SPDK_BDEV_IO_STATUS_PENDING;
+	rc = spdk_bdev_read_blocks(g_desc, io_ch[1], NULL, 0, 1, io_during_io_done, &bdev_io_status[1]);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(bdev_io_status[1] == SPDK_BDEV_IO_STATUS_PENDING);
+	poll_threads();
+
+	/* Disable QoS */
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 0, qos_dynamic_enable_done, &status);
+	poll_threads();
+	CU_ASSERT(status == 0);
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) == 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) == 0);
+
+	/*
+	 * All I/O should have been resubmitted back on their original thread.  Complete
+	 *  all I/O on thread 0, and ensure that only the thread 0 I/O was completed.
+	 */
+	set_thread(0);
+	stub_complete_io(g_bdev.io_target, 0);
+	poll_threads();
+	CU_ASSERT(bdev_io_status[0] == SPDK_BDEV_IO_STATUS_SUCCESS);
+	CU_ASSERT(bdev_io_status[1] == SPDK_BDEV_IO_STATUS_PENDING);
+
+	/* Now complete all I/O on thread 1 and ensure the thread 1 I/O was completed. */
+	set_thread(1);
+	stub_complete_io(g_bdev.io_target, 0);
+	poll_threads();
+	CU_ASSERT(bdev_io_status[1] == SPDK_BDEV_IO_STATUS_SUCCESS);
+
+	/* Disable QoS again */
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 0, qos_dynamic_enable_done, &status);
+	poll_threads();
+	CU_ASSERT(status == 0); /* This should succeed */
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) == 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) == 0);
+
+	/* Enable QoS on thread 0 */
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 10000, qos_dynamic_enable_done, &status);
+	poll_threads();
+	CU_ASSERT(status == 0);
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) != 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) != 0);
+
+	/* Disable QoS on thread 1 */
+	set_thread(1);
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 0, qos_dynamic_enable_done, &status);
+	/* Don't poll yet. This should leave the channels with QoS enabled */
+	CU_ASSERT(status == -1);
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) != 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) != 0);
+
+	/* Enable QoS. This should immediately fail because the previous disable QoS hasn't completed. */
+	second_status = 0;
+	spdk_bdev_set_qos_limit_iops(bdev, 10000, qos_dynamic_enable_done, &second_status);
+	poll_threads();
+	CU_ASSERT(status == 0); /* The disable should succeed */
+	CU_ASSERT(second_status < 0); /* The enable should fail */
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) == 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) == 0);
+
+	/* Enable QoS on thread 1. This should succeed now that the disable has completed. */
+	status = -1;
+	spdk_bdev_set_qos_limit_iops(bdev, 10000, qos_dynamic_enable_done, &status);
+	poll_threads();
+	CU_ASSERT(status == 0);
+	CU_ASSERT((bdev_ch[0]->flags & BDEV_CH_QOS_ENABLED) != 0);
+	CU_ASSERT((bdev_ch[1]->flags & BDEV_CH_QOS_ENABLED) != 0);
+
+	/* Tear down the channels */
+	set_thread(0);
+	spdk_put_io_channel(io_ch[0]);
+	set_thread(1);
+	spdk_put_io_channel(io_ch[1]);
+	poll_threads();
+
+	set_thread(0);
+	teardown_test();
+}
+
 int
 main(int argc, char **argv)
 {
@@ -1061,7 +1220,6 @@ main(int argc, char **argv)
 
 	if (
 		CU_add_test(suite, "basic", basic) == NULL ||
-		CU_add_test(suite, "basic_poller", basic_poller) == NULL ||
 		CU_add_test(suite, "basic_qos", basic_qos) == NULL ||
 		CU_add_test(suite, "put_channel_during_reset", put_channel_during_reset) == NULL ||
 		CU_add_test(suite, "aborted_reset", aborted_reset) == NULL ||
@@ -1069,7 +1227,9 @@ main(int argc, char **argv)
 		CU_add_test(suite, "io_during_qos_queue", io_during_qos_queue) == NULL ||
 		CU_add_test(suite, "io_during_qos_reset", io_during_qos_reset) == NULL ||
 		CU_add_test(suite, "enomem", enomem) == NULL ||
-		CU_add_test(suite, "enomem_multi_bdev", enomem_multi_bdev) == NULL
+		CU_add_test(suite, "enomem_multi_bdev", enomem_multi_bdev) == NULL ||
+		CU_add_test(suite, "enomem_multi_io_target", enomem_multi_io_target) == NULL ||
+		CU_add_test(suite, "qos_dynamic_enable", qos_dynamic_enable) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/bdev/part.c/part_ut.c b/test/unit/lib/bdev/part.c/part_ut.c
index 9afd9f90b..1f9a2b4d1 100644
--- a/test/unit/lib/bdev/part.c/part_ut.c
+++ b/test/unit/lib/bdev/part.c/part_ut.c
@@ -42,19 +42,11 @@
 #include "bdev/bdev.c"
 #include "bdev/part.c"
 
-/* Return NULL to test hardcoded defaults. */
-struct spdk_conf_section *
-spdk_conf_find_section(struct spdk_conf *cp, const char *name)
-{
-	return NULL;
-}
-
-/* Return NULL to test hardcoded defaults. */
-char *
-spdk_conf_section_get_nmval(struct spdk_conf_section *sp, const char *key, int idx1, int idx2)
-{
-	return NULL;
-}
+DEFINE_STUB(spdk_conf_find_section, struct spdk_conf_section *, (struct spdk_conf *cp,
+		const char *name), NULL);
+DEFINE_STUB(spdk_conf_section_get_nmval, char *,
+	    (struct spdk_conf_section *sp, const char *key, int idx1, int idx2), NULL);
+DEFINE_STUB(spdk_conf_section_get_intval, int, (struct spdk_conf_section *sp, const char *key), -1);
 
 static void
 _part_send_msg(spdk_thread_fn fn, void *ctx, void *thread_ctx)
@@ -76,7 +68,7 @@ static void vbdev_ut_examine(struct spdk_bdev *bdev);
 
 struct spdk_bdev_module vbdev_ut_if = {
 	.name = "vbdev_ut",
-	.examine = vbdev_ut_examine,
+	.examine_config = vbdev_ut_examine,
 };
 
 SPDK_BDEV_MODULE_REGISTER(&bdev_ut_if)
@@ -101,12 +93,6 @@ static struct spdk_bdev_fn_table part_fn_table = {
 	.destruct		= __destruct,
 };
 
-static void
-__base_free(struct spdk_bdev_part_base *base)
-{
-	free(base);
-}
-
 static void
 part_test(void)
 {
@@ -117,16 +103,16 @@ part_test(void)
 	SPDK_BDEV_PART_TAILQ		tailq = TAILQ_HEAD_INITIALIZER(tailq);
 	int rc;
 
-	base = calloc(1, sizeof(*base));
-	SPDK_CU_ASSERT_FATAL(base != NULL);
-
 	bdev_base.name = "base";
 	bdev_base.fn_table = &base_fn_table;
 	bdev_base.module = &bdev_ut_if;
 	rc = spdk_bdev_register(&bdev_base);
 	CU_ASSERT(rc == 0);
-	spdk_bdev_part_base_construct(base, &bdev_base, NULL, &vbdev_ut_if,
-				      &part_fn_table, &tailq, __base_free, 0, NULL, NULL);
+	base = spdk_bdev_part_base_construct(&bdev_base, NULL, &vbdev_ut_if,
+					     &part_fn_table, &tailq, NULL,
+					     NULL, 0, NULL, NULL);
+
+	SPDK_CU_ASSERT_FATAL(base != NULL);
 
 	spdk_bdev_part_construct(&part1, base, "test1", 0, 100, "test");
 	spdk_bdev_part_construct(&part2, base, "test2", 100, 100, "test");
diff --git a/test/unit/lib/bdev/pmem/bdev_pmem_ut.c b/test/unit/lib/bdev/pmem/bdev_pmem_ut.c
index 73b4b7ba1..6e30b7d42 100644
--- a/test/unit/lib/bdev/pmem/bdev_pmem_ut.c
+++ b/test/unit/lib/bdev/pmem/bdev_pmem_ut.c
@@ -267,7 +267,7 @@ pmemblk_check(const char *path, size_t bsize)
 void
 spdk_bdev_io_complete(struct spdk_bdev_io *bdev_io, enum spdk_bdev_io_status status)
 {
-	bdev_io->status = status;
+	bdev_io->internal.status = status;
 }
 
 int
@@ -353,10 +353,10 @@ bdev_submit_request(struct spdk_bdev *bdev, int16_t io_type, uint64_t offset_blo
 	 * Set status to value that shouldn't be returned
 	 */
 	bio.type = io_type;
-	bio.status = SPDK_BDEV_IO_STATUS_PENDING;
+	bio.internal.status = SPDK_BDEV_IO_STATUS_PENDING;
 	bio.bdev = bdev;
 	bdev_pmem_submit_request(NULL, &bio);
-	return bio.status;
+	return bio.internal.status;
 }
 
 
diff --git a/test/unit/lib/bdev/scsi_nvme.c/scsi_nvme_ut.c b/test/unit/lib/bdev/scsi_nvme.c/scsi_nvme_ut.c
index 59f30d45c..9b2eff358 100644
--- a/test/unit/lib/bdev/scsi_nvme.c/scsi_nvme_ut.c
+++ b/test/unit/lib/bdev/scsi_nvme.c/scsi_nvme_ut.c
@@ -53,15 +53,15 @@ scsi_nvme_translate_test(void)
 	int sc, sk, asc, ascq;
 
 	/* SPDK_NVME_SCT_GENERIC */
-	bdev_io.error.nvme.sct = SPDK_NVME_SCT_GENERIC;
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_ABORTED_POWER_LOSS;
+	bdev_io.internal.error.nvme.sct = SPDK_NVME_SCT_GENERIC;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_ABORTED_POWER_LOSS;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_TASK_ABORTED);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ABORTED_COMMAND);
 	CU_ASSERT_EQUAL(asc, SPDK_SCSI_ASC_WARNING);
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_POWER_LOSS_EXPECTED);
 
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_INVALID_NUM_SGL_DESCIRPTORS;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_INVALID_NUM_SGL_DESCIRPTORS;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
@@ -69,15 +69,15 @@ scsi_nvme_translate_test(void)
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
 
 	/* SPDK_NVME_SCT_COMMAND_SPECIFIC */
-	bdev_io.error.nvme.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_INVALID_FORMAT;
+	bdev_io.internal.error.nvme.sct = SPDK_NVME_SCT_COMMAND_SPECIFIC;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_INVALID_FORMAT;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
 	CU_ASSERT_EQUAL(asc, SPDK_SCSI_ASC_FORMAT_COMMAND_FAILED);
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_FORMAT_COMMAND_FAILED);
 
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_OVERLAPPING_RANGE;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_OVERLAPPING_RANGE;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
@@ -85,15 +85,15 @@ scsi_nvme_translate_test(void)
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
 
 	/* SPDK_NVME_SCT_MEDIA_ERROR */
-	bdev_io.error.nvme.sct = SPDK_NVME_SCT_MEDIA_ERROR;
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_GUARD_CHECK_ERROR;
+	bdev_io.internal.error.nvme.sct = SPDK_NVME_SCT_MEDIA_ERROR;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_GUARD_CHECK_ERROR;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_MEDIUM_ERROR);
 	CU_ASSERT_EQUAL(asc, SPDK_SCSI_ASC_LOGICAL_BLOCK_GUARD_CHECK_FAILED);
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_LOGICAL_BLOCK_GUARD_CHECK_FAILED);
 
-	bdev_io.error.nvme.sc = SPDK_NVME_SC_DEALLOCATED_OR_UNWRITTEN_BLOCK;
+	bdev_io.internal.error.nvme.sc = SPDK_NVME_SC_DEALLOCATED_OR_UNWRITTEN_BLOCK;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
@@ -101,8 +101,8 @@ scsi_nvme_translate_test(void)
 	CU_ASSERT_EQUAL(ascq, SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
 
 	/* SPDK_NVME_SCT_VENDOR_SPECIFIC */
-	bdev_io.error.nvme.sct = SPDK_NVME_SCT_VENDOR_SPECIFIC;
-	bdev_io.error.nvme.sc = 0xff;
+	bdev_io.internal.error.nvme.sct = SPDK_NVME_SCT_VENDOR_SPECIFIC;
+	bdev_io.internal.error.nvme.sc = 0xff;
 	spdk_scsi_nvme_translate(&bdev_io, &sc, &sk, &asc, &ascq);
 	CU_ASSERT_EQUAL(sc, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(sk, SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
diff --git a/test/unit/lib/bdev/vbdev_lvol.c/vbdev_lvol_ut.c b/test/unit/lib/bdev/vbdev_lvol.c/vbdev_lvol_ut.c
index 3ae2104b0..002f62b22 100644
--- a/test/unit/lib/bdev/vbdev_lvol.c/vbdev_lvol_ut.c
+++ b/test/unit/lib/bdev/vbdev_lvol.c/vbdev_lvol_ut.c
@@ -861,7 +861,7 @@ ut_lvol_clone(void)
 	g_lvolerrno = -1;
 	rc = vbdev_lvol_create(g_lvs, "lvol", sz, false, vbdev_lvol_create_complete, NULL);
 	SPDK_CU_ASSERT_FATAL(rc == 0);
-	CU_ASSERT(g_lvol != NULL);
+	SPDK_CU_ASSERT_FATAL(g_lvol != NULL);
 	CU_ASSERT(g_lvolerrno == 0);
 
 	lvol = g_lvol;
@@ -869,7 +869,7 @@ ut_lvol_clone(void)
 	/* Successful snap create */
 	vbdev_lvol_create_snapshot(lvol, "snap", vbdev_lvol_create_complete, NULL);
 	SPDK_CU_ASSERT_FATAL(rc == 0);
-	CU_ASSERT(g_lvol != NULL);
+	SPDK_CU_ASSERT_FATAL(g_lvol != NULL);
 	CU_ASSERT(g_lvolerrno == 0);
 
 	snap = g_lvol;
@@ -878,7 +878,7 @@ ut_lvol_clone(void)
 	vbdev_lvol_create_clone(snap, "clone", vbdev_lvol_create_complete, NULL);
 
 	SPDK_CU_ASSERT_FATAL(rc == 0);
-	CU_ASSERT(g_lvol != NULL);
+	SPDK_CU_ASSERT_FATAL(g_lvol != NULL);
 	CU_ASSERT(g_lvolerrno == 0);
 
 	clone = g_lvol;
@@ -943,12 +943,6 @@ ut_lvol_examine(void)
 	g_lvserrno = 0;
 	g_examine_done = false;
 
-	/* Examine with NULL bdev */
-	vbdev_lvs_examine(NULL);
-	CU_ASSERT(g_bs_dev == NULL);
-	CU_ASSERT(g_lvol_store == NULL);
-	CU_ASSERT(g_examine_done == true);
-
 	/* Examine unsuccessfully - bdev already opened */
 	g_bs_dev = NULL;
 	g_examine_done = false;
@@ -1336,15 +1330,6 @@ ut_vbdev_lvol_io_type_supported(void)
 	free(lvol);
 }
 
-static void
-ut_lvol_op_comp(void)
-{
-	struct lvol_task task;
-
-	lvol_op_comp(&task, 1);
-	CU_ASSERT(task.status == SPDK_BDEV_IO_STATUS_FAILED);
-}
-
 static void
 ut_lvol_read_write(void)
 {
@@ -1375,15 +1360,16 @@ ut_lvol_read_write(void)
 static void
 ut_vbdev_lvol_submit_request(void)
 {
+	struct spdk_lvol request_lvol = {};
 	g_io = calloc(1, sizeof(struct spdk_bdev_io) + sizeof(struct lvol_task));
 	SPDK_CU_ASSERT_FATAL(g_io != NULL);
 	g_base_bdev = calloc(1, sizeof(struct spdk_bdev));
 	SPDK_CU_ASSERT_FATAL(g_base_bdev != NULL);
 	g_task = (struct lvol_task *)g_io->driver_ctx;
-
 	g_io->bdev = g_base_bdev;
 
 	g_io->type = SPDK_BDEV_IO_TYPE_READ;
+	g_base_bdev->ctxt = &request_lvol;
 	vbdev_lvol_submit_request(g_ch, g_io);
 
 	free(g_io);
@@ -1473,7 +1459,6 @@ int main(int argc, char **argv)
 		CU_add_test(suite, "lvol_hotremove", ut_lvol_hotremove) == NULL ||
 		CU_add_test(suite, "ut_vbdev_lvol_get_io_channel", ut_vbdev_lvol_get_io_channel) == NULL ||
 		CU_add_test(suite, "ut_vbdev_lvol_io_type_supported", ut_vbdev_lvol_io_type_supported) == NULL ||
-		CU_add_test(suite, "ut_lvol_op_comp", ut_lvol_op_comp) == NULL ||
 		CU_add_test(suite, "ut_lvol_read_write", ut_lvol_read_write) == NULL ||
 		CU_add_test(suite, "ut_vbdev_lvol_submit_request", ut_vbdev_lvol_submit_request) == NULL ||
 		CU_add_test(suite, "lvol_examine", ut_lvol_examine) == NULL ||
diff --git a/test/unit/lib/blob/blob.c/blob_ut.c b/test/unit/lib/blob/blob.c/blob_ut.c
index b737154e7..cbf6d2c55 100644
--- a/test/unit/lib/blob/blob.c/blob_ut.c
+++ b/test/unit/lib/blob/blob.c/blob_ut.c
@@ -54,17 +54,6 @@ char *g_xattr_names[] = {"first", "second", "third"};
 char *g_xattr_values[] = {"one", "two", "three"};
 uint64_t g_ctx = 1729;
 
-bool g_scheduler_delay = false;
-
-struct scheduled_ops {
-	spdk_thread_fn	fn;
-	void		*ctx;
-
-	TAILQ_ENTRY(scheduled_ops)	ops_queue;
-};
-
-static TAILQ_HEAD(, scheduled_ops) g_scheduled_ops = TAILQ_HEAD_INITIALIZER(g_scheduled_ops);
-
 struct spdk_bs_super_block_ver1 {
 	uint8_t		signature[8];
 	uint32_t        version;
@@ -121,35 +110,6 @@ _get_xattr_value_null(void *arg, const char *name,
 }
 
 
-static void
-_bs_send_msg(spdk_thread_fn fn, void *ctx, void *thread_ctx)
-{
-	if (g_scheduler_delay) {
-		struct scheduled_ops *ops = calloc(1, sizeof(*ops));
-
-		SPDK_CU_ASSERT_FATAL(ops != NULL);
-		ops->fn = fn;
-		ops->ctx = ctx;
-		TAILQ_INSERT_TAIL(&g_scheduled_ops, ops, ops_queue);
-	} else {
-		fn(ctx);
-	}
-}
-
-#if 0
-static void
-_bs_flush_scheduler(void)
-{
-	struct scheduled_ops *ops;
-
-	while (!TAILQ_EMPTY(&g_scheduled_ops)) {
-		ops = TAILQ_FIRST(&g_scheduled_ops);
-		TAILQ_REMOVE(&g_scheduled_ops, ops, ops_queue);
-		ops->fn(ops->ctx);
-		free(ops);
-	}
-}
-#endif
 
 static void
 bs_op_complete(void *cb_arg, int bserrno)
@@ -524,9 +484,10 @@ blob_thin_provision(void)
 	spdk_blob_close(blob, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 
-	spdk_bs_unload(g_bs, bs_op_complete, NULL);
-	CU_ASSERT(g_bserrno == 0);
-	g_bs = NULL;
+	/* Do not shut down cleanly.  This makes sure that when we load again
+	 *  and try to recover a valid used_cluster map, that blobstore will
+	 *  ignore clusters with index 0 since these are unallocated clusters.
+	 */
 
 	/* Load an existing blob store and check if invalid_flags is set */
 	dev = init_dev();
@@ -674,6 +635,107 @@ blob_snapshot(void)
 	g_bs = NULL;
 }
 
+static void
+blob_snapshot_freeze_io(void)
+{
+	struct spdk_io_channel *channel;
+	struct spdk_bs_channel *bs_channel;
+	struct spdk_blob_store *bs;
+	struct spdk_bs_dev *dev;
+	struct spdk_blob *blob;
+	struct spdk_blob_opts opts;
+	spdk_blob_id blobid;
+	uint32_t num_of_pages = 10;
+	uint8_t payload_read[num_of_pages * SPDK_BS_PAGE_SIZE];
+	uint8_t payload_write[num_of_pages * SPDK_BS_PAGE_SIZE];
+	uint8_t payload_zero[num_of_pages * SPDK_BS_PAGE_SIZE];
+
+	memset(payload_write, 0xE5, sizeof(payload_write));
+	memset(payload_read, 0x00, sizeof(payload_read));
+	memset(payload_zero, 0x00, sizeof(payload_zero));
+
+	dev = init_dev();
+	memset(g_dev_buffer, 0, DEV_BUFFER_SIZE);
+
+	/* Test freeze I/O during snapshot */
+
+	spdk_bs_init(dev, NULL, bs_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+	bs = g_bs;
+
+	channel = spdk_bs_alloc_io_channel(bs);
+	bs_channel = spdk_io_channel_get_ctx(channel);
+
+	/* Create blob with 10 clusters */
+	spdk_blob_opts_init(&opts);
+	opts.num_clusters = 10;
+	opts.thin_provision = false;
+
+	spdk_bs_create_blob_ext(bs, &opts, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	blobid = g_blobid;
+
+	spdk_bs_open_blob(bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	blob = g_blob;
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10);
+
+	/* Enable explicitly calling callbacks. On each read/write to back device
+	 * execution will stop and wait until _bs_flush_scheduler is called */
+	g_scheduler_delay = true;
+
+	spdk_bs_create_snapshot(bs, blobid, NULL, blob_op_with_id_complete, NULL);
+
+	/* This is implementation specific.
+	 * Flag 'frozen_io' is set in _spdk_bs_snapshot_freeze_cpl callback.
+	 * Four async I/O operations happen before that. */
+
+	_bs_flush_scheduler(4);
+
+	CU_ASSERT(TAILQ_EMPTY(&bs_channel->queued_io));
+
+	/* Blob I/O should be frozen here */
+	CU_ASSERT(blob->frozen_refcnt == 1);
+
+	/* Write to the blob */
+	spdk_blob_io_write(blob, channel, payload_write, 0, num_of_pages, blob_op_complete, NULL);
+
+	/* Verify that I/O is queued */
+	CU_ASSERT(!TAILQ_EMPTY(&bs_channel->queued_io));
+	/* Verify that payload is not written to disk */
+	CU_ASSERT(memcmp(payload_zero, &g_dev_buffer[blob->active.clusters[0]*SPDK_BS_PAGE_SIZE],
+			 SPDK_BS_PAGE_SIZE) == 0);
+
+	/* Disable scheduler delay.
+	 * Finish all operations including spdk_bs_create_snapshot */
+	g_scheduler_delay = false;
+	_bs_flush_scheduler(1);
+
+	/* Verify snapshot */
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+
+	/* Verify that blob has unset frozen_io */
+	CU_ASSERT(blob->frozen_refcnt == 0);
+
+	/* Verify that postponed I/O completed successfully by comparing payload */
+	spdk_blob_io_read(blob, channel, payload_read, 0, num_of_pages, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_write, payload_read, num_of_pages * SPDK_BS_PAGE_SIZE) == 0);
+
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_bs_free_io_channel(channel);
+
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	g_bs = NULL;
+}
+
 static void
 blob_clone(void)
 {
@@ -804,6 +866,118 @@ blob_clone(void)
 
 }
 
+static void
+_blob_inflate(bool decouple_parent)
+{
+	struct spdk_blob_store *bs;
+	struct spdk_bs_dev *dev;
+	struct spdk_blob_opts opts;
+	struct spdk_blob *blob, *snapshot;
+	spdk_blob_id blobid, snapshotid;
+	struct spdk_io_channel *channel;
+	uint64_t free_clusters;
+
+	dev = init_dev();
+
+	spdk_bs_init(dev, NULL, bs_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+	bs = g_bs;
+
+	channel = spdk_bs_alloc_io_channel(bs);
+	SPDK_CU_ASSERT_FATAL(channel != NULL);
+
+	/* Create blob with 10 clusters */
+
+	spdk_blob_opts_init(&opts);
+	opts.num_clusters = 10;
+	opts.thin_provision = true;
+
+	spdk_bs_create_blob_ext(bs, &opts, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	blobid = g_blobid;
+
+	spdk_bs_open_blob(bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	blob = g_blob;
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10)
+	CU_ASSERT(spdk_blob_is_thin_provisioned(blob) == true);
+
+	/* 1) Blob with no parent */
+	if (decouple_parent) {
+		/* Decouple parent of blob with no parent (should fail) */
+		spdk_bs_blob_decouple_parent(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno != 0);
+	} else {
+		/* Inflate of thin blob with no parent should made it thick */
+		spdk_bs_inflate_blob(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+		CU_ASSERT(spdk_blob_is_thin_provisioned(blob) == false);
+	}
+
+	spdk_bs_create_snapshot(bs, blobid, NULL, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	snapshotid = g_blobid;
+
+	CU_ASSERT(spdk_blob_is_thin_provisioned(blob) == true);
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10)
+
+	spdk_bs_open_blob(bs, snapshotid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	snapshot = g_blob;
+	CU_ASSERT(snapshot->data_ro == true)
+	CU_ASSERT(snapshot->md_ro == true)
+	CU_ASSERT(spdk_blob_get_num_clusters(snapshot) == 10);
+
+	spdk_blob_close(snapshot, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	free_clusters = spdk_bs_free_cluster_count(bs);
+
+	/* 2) Blob with parent */
+	if (!decouple_parent) {
+		/* Do full blob inflation */
+		spdk_bs_inflate_blob(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+		/* all 10 clusters should be allocated */
+		CU_ASSERT(spdk_bs_free_cluster_count(bs) == free_clusters - 10);
+	} else {
+		/* Decouple parent of blob */
+		spdk_bs_blob_decouple_parent(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+		/* when only parent is removed, none of the clusters should be allocated */
+		CU_ASSERT(spdk_bs_free_cluster_count(bs) == free_clusters);
+	}
+
+	/* Now, it should be possible to delete snapshot */
+	spdk_bs_delete_blob(bs, snapshotid, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10)
+	CU_ASSERT(spdk_blob_is_thin_provisioned(blob) == decouple_parent);
+
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	g_bs = NULL;
+
+	spdk_bs_free_io_channel(channel);
+}
+
+static void
+blob_inflate(void)
+{
+	_blob_inflate(false);
+	_blob_inflate(true);
+}
+
 static void
 blob_delete(void)
 {
@@ -1439,6 +1613,202 @@ blob_rw_iov_read_only(void)
 	g_bs = NULL;
 }
 
+static void
+_blob_io_read_no_split(struct spdk_blob *blob, struct spdk_io_channel *channel,
+		       uint8_t *payload, uint64_t offset, uint64_t length,
+		       spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	uint64_t i;
+	uint8_t *buf;
+	uint64_t page_size = spdk_bs_get_page_size(blob->bs);
+
+	/* To be sure that operation is NOT splitted, read one page at the time */
+	buf = payload;
+	for (i = 0; i < length; i++) {
+		spdk_blob_io_read(blob, channel, buf, i + offset, 1, blob_op_complete, NULL);
+		if (g_bserrno != 0) {
+			/* Pass the error code up */
+			break;
+		}
+		buf += page_size;
+	}
+
+	cb_fn(cb_arg, g_bserrno);
+}
+
+static void
+_blob_io_write_no_split(struct spdk_blob *blob, struct spdk_io_channel *channel,
+			uint8_t *payload, uint64_t offset, uint64_t length,
+			spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	uint64_t i;
+	uint8_t *buf;
+	uint64_t page_size = spdk_bs_get_page_size(blob->bs);
+
+	/* To be sure that operation is NOT splitted, write one page at the time */
+	buf = payload;
+	for (i = 0; i < length; i++) {
+		spdk_blob_io_write(blob, channel, buf, i + offset, 1, blob_op_complete, NULL);
+		if (g_bserrno != 0) {
+			/* Pass the error code up */
+			break;
+		}
+		buf += page_size;
+	}
+
+	cb_fn(cb_arg, g_bserrno);
+}
+
+static void
+blob_operation_split_rw(void)
+{
+	struct spdk_blob_store *bs;
+	struct spdk_bs_dev *dev;
+	struct spdk_blob *blob;
+	struct spdk_io_channel *channel;
+	struct spdk_blob_opts opts;
+	spdk_blob_id blobid;
+	uint64_t cluster_size;
+
+	uint64_t payload_size;
+	uint8_t *payload_read;
+	uint8_t *payload_write;
+	uint8_t *payload_pattern;
+
+	uint64_t page_size;
+	uint64_t pages_per_cluster;
+	uint64_t pages_per_payload;
+
+	uint64_t i;
+
+	dev = init_dev();
+
+	spdk_bs_init(dev, NULL, bs_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+	bs = g_bs;
+
+	cluster_size = spdk_bs_get_cluster_size(bs);
+	page_size = spdk_bs_get_page_size(bs);
+	pages_per_cluster = cluster_size / page_size;
+	pages_per_payload = pages_per_cluster * 5;
+	payload_size = cluster_size * 5;
+
+	payload_read = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_read != NULL);
+
+	payload_write = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_write != NULL);
+
+	payload_pattern = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_pattern != NULL);
+
+	/* Prepare random pattern to write */
+	memset(payload_pattern, 0xFF, payload_size);
+	for (i = 0; i < pages_per_payload; i++) {
+		*((uint64_t *)(payload_pattern + page_size * i)) = (i + 1);
+	}
+
+	channel = spdk_bs_alloc_io_channel(bs);
+	SPDK_CU_ASSERT_FATAL(channel != NULL);
+
+	/* Create blob */
+	spdk_blob_opts_init(&opts);
+	opts.thin_provision = false;
+	opts.num_clusters = 5;
+
+	spdk_bs_create_blob_ext(bs, &opts, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	blobid = g_blobid;
+
+	spdk_bs_open_blob(bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	blob = g_blob;
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 5);
+
+	/* Initial read should return zeroed payload */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(spdk_mem_all_zero(payload_read, payload_size));
+
+	/* Fill whole blob except last page */
+	spdk_blob_io_write(blob, channel, payload_pattern, 0, pages_per_payload - 1,
+			   blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Write last page with a pattern */
+	spdk_blob_io_write(blob, channel, payload_pattern, pages_per_payload - 1, 1,
+			   blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Read whole blob and check consistency */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read, payload_size - page_size) == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read + payload_size - page_size, page_size) == 0);
+
+	/* Fill whole blob except first page */
+	spdk_blob_io_write(blob, channel, payload_pattern, 1, pages_per_payload - 1,
+			   blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Write first page with a pattern */
+	spdk_blob_io_write(blob, channel, payload_pattern, 0, 1,
+			   blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Read whole blob and check consistency */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read + page_size, payload_size - page_size) == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read, page_size) == 0);
+
+
+	/* Fill whole blob with a pattern (5 clusters) */
+
+	/* 1. Read test. */
+	_blob_io_write_no_split(blob, channel, payload_pattern, 0, pages_per_payload,
+				blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read, payload_size) == 0);
+
+	/* 2. Write test. */
+	spdk_blob_io_write(blob, channel, payload_pattern, 0, pages_per_payload,
+			   blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	memset(payload_read, 0xFF, payload_size);
+	_blob_io_read_no_split(blob, channel, payload_read, 0, pages_per_payload, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_pattern, payload_read, payload_size) == 0);
+
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_bs_free_io_channel(channel);
+
+	/* Unload the blob store */
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	g_bs = NULL;
+	g_blob = NULL;
+	g_blobid = 0;
+
+	free(payload_read);
+	free(payload_write);
+	free(payload_pattern);
+}
+
 static void
 blob_unmap(void)
 {
@@ -1807,44 +2177,97 @@ bs_load(void)
 	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
 	CU_ASSERT(g_bserrno == -EINVAL);
 
-	/* Load an existing blob store */
+	/* Load an existing blob store */
+	dev = init_dev();
+	spdk_bs_opts_init(&opts);
+	snprintf(opts.bstype.bstype, sizeof(opts.bstype.bstype), "TESTTYPE");
+	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+
+	super_block = (struct spdk_bs_super_block *)g_dev_buffer;
+	CU_ASSERT(super_block->clean == 1);
+	CU_ASSERT(super_block->size == dev->blockcnt * dev->blocklen);
+
+	spdk_bs_open_blob(g_bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blob != NULL);
+	blob = g_blob;
+
+	/* Verify that blobstore is marked dirty after first metadata sync */
+	spdk_blob_sync_md(blob, blob_op_complete, NULL);
+	CU_ASSERT(super_block->clean == 1);
+
+	/* Get the xattrs */
+	value = NULL;
+	rc = spdk_blob_get_xattr_value(blob, "length", &value, &value_len);
+	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(value != NULL);
+	CU_ASSERT(*(uint64_t *)value == length);
+	CU_ASSERT(value_len == 8);
+
+	rc = spdk_blob_get_xattr_value(blob, "foobar", &value, &value_len);
+	CU_ASSERT(rc == -ENOENT);
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10);
+
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	blob = NULL;
+	g_blob = NULL;
+
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	g_bs = NULL;
+
+	/* Load should fail: bdev size < saved size */
+	dev = init_dev();
+	dev->blockcnt /= 2;
+
+	spdk_bs_opts_init(&opts);
+	snprintf(opts.bstype.bstype, sizeof(opts.bstype.bstype), "TESTTYPE");
+	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
+
+	CU_ASSERT(g_bserrno == -EILSEQ);
+
+	/* Load should succeed: bdev size > saved size */
 	dev = init_dev();
+	dev->blockcnt *= 4;
+
 	spdk_bs_opts_init(&opts);
 	snprintf(opts.bstype.bstype, sizeof(opts.bstype.bstype), "TESTTYPE");
 	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
-	CU_ASSERT(g_bserrno == 0);
-	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
-
-	super_block = (struct spdk_bs_super_block *)g_dev_buffer;
-	CU_ASSERT(super_block->clean == 0);
 
-	spdk_bs_open_blob(g_bs, blobid, blob_op_with_handle_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
-	CU_ASSERT(g_blob != NULL);
-	blob = g_blob;
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
 
-	/* Get the xattrs */
-	value = NULL;
-	rc = spdk_blob_get_xattr_value(blob, "length", &value, &value_len);
-	CU_ASSERT(rc == 0);
-	SPDK_CU_ASSERT_FATAL(value != NULL);
-	CU_ASSERT(*(uint64_t *)value == length);
-	CU_ASSERT(value_len == 8);
 
-	rc = spdk_blob_get_xattr_value(blob, "foobar", &value, &value_len);
-	CU_ASSERT(rc == -ENOENT);
+	/* Test compatibility mode */
 
-	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 10);
+	dev = init_dev();
+	super_block->size = 0;
+	super_block->crc = _spdk_blob_md_page_calc_crc(super_block);
 
-	spdk_blob_close(blob, blob_op_complete, NULL);
+	spdk_bs_opts_init(&opts);
+	snprintf(opts.bstype.bstype, sizeof(opts.bstype.bstype), "TESTTYPE");
+	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
-	blob = NULL;
-	g_blob = NULL;
-	g_blobid = SPDK_BLOBID_INVALID;
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+
+	/* Create a blob */
+	spdk_bs_create_blob(g_bs, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+
+	/* Blobstore should update number of blocks in super_block */
+	CU_ASSERT(super_block->size == dev->blockcnt * dev->blocklen);
+	CU_ASSERT(super_block->clean == 0);
 
 	spdk_bs_unload(g_bs, bs_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(super_block->clean == 1);
 	g_bs = NULL;
+
 }
 
 static void
@@ -2955,7 +3378,7 @@ bs_version(void)
 	spdk_bs_load(dev, &opts, bs_op_with_handle_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
-	CU_ASSERT(super->clean == 0);
+	CU_ASSERT(super->clean == 1);
 
 	/*
 	 * Create a blob - just to make sure that when we unload it
@@ -3135,6 +3558,24 @@ blob_thin_prov_alloc(void)
 	CU_ASSERT(blob->active.num_clusters == 5);
 	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 5);
 
+	/* Grow it to 1TB - still unallocated */
+	spdk_blob_resize(blob, 262144, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(free_clusters == spdk_bs_free_cluster_count(bs));
+	CU_ASSERT(blob->active.num_clusters == 262144);
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 262144);
+
+	spdk_blob_sync_md(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	/* Sync must not change anything */
+	CU_ASSERT(free_clusters == spdk_bs_free_cluster_count(bs));
+	CU_ASSERT(blob->active.num_clusters == 262144);
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 262144);
+	/* Since clusters are not allocated,
+	 * number of metadata pages is expected to be minimal.
+	 */
+	CU_ASSERT(blob->active.num_pages == 1);
+
 	/* Shrink the blob to 3 clusters - still unallocated */
 	spdk_blob_resize(blob, 3, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
@@ -3277,8 +3718,11 @@ blob_thin_prov_rw(void)
 	struct spdk_blob_opts opts;
 	spdk_blob_id blobid;
 	uint64_t free_clusters;
+	uint64_t page_size;
 	uint8_t payload_read[10 * 4096];
 	uint8_t payload_write[10 * 4096];
+	uint64_t write_bytes;
+	uint64_t read_bytes;
 
 	dev = init_dev();
 
@@ -3287,6 +3731,7 @@ blob_thin_prov_rw(void)
 	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
 	bs = g_bs;
 	free_clusters = spdk_bs_free_cluster_count(bs);
+	page_size = spdk_bs_get_page_size(bs);
 
 	channel = spdk_bs_alloc_io_channel(bs);
 	CU_ASSERT(channel != NULL);
@@ -3325,10 +3770,17 @@ blob_thin_prov_rw(void)
 	CU_ASSERT(g_bserrno == 0);
 	CU_ASSERT(memcmp(zero, payload_read, 10 * 4096) == 0);
 
+	write_bytes = g_dev_write_bytes;
+	read_bytes = g_dev_read_bytes;
+
 	memset(payload_write, 0xE5, sizeof(payload_write));
 	spdk_blob_io_write(blob, channel, payload_write, 4, 10, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 	CU_ASSERT(free_clusters != spdk_bs_free_cluster_count(bs));
+	/* For thin-provisioned blob we need to write 10 pages plus one page metadata and
+	 * read 0 bytes */
+	CU_ASSERT(g_dev_write_bytes - write_bytes == page_size * 11);
+	CU_ASSERT(g_dev_read_bytes - read_bytes == 0);
 
 	spdk_blob_io_read(blob, channel, payload_read, 4, 10, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
@@ -3560,8 +4012,12 @@ blob_snapshot_rw(void)
 	struct spdk_blob_opts opts;
 	spdk_blob_id blobid, snapshotid;
 	uint64_t free_clusters;
+	uint64_t cluster_size;
+	uint64_t page_size;
 	uint8_t payload_read[10 * 4096];
 	uint8_t payload_write[10 * 4096];
+	uint64_t write_bytes;
+	uint64_t read_bytes;
 
 	dev = init_dev();
 
@@ -3570,6 +4026,8 @@ blob_snapshot_rw(void)
 	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
 	bs = g_bs;
 	free_clusters = spdk_bs_free_cluster_count(bs);
+	cluster_size = spdk_bs_get_cluster_size(bs);
+	page_size = spdk_bs_get_page_size(bs);
 
 	channel = spdk_bs_alloc_io_channel(bs);
 	CU_ASSERT(channel != NULL);
@@ -3616,11 +4074,20 @@ blob_snapshot_rw(void)
 
 	CU_ASSERT(spdk_blob_get_num_clusters(snapshot) == 5)
 
+	write_bytes = g_dev_write_bytes;
+	read_bytes = g_dev_read_bytes;
+
 	memset(payload_write, 0xAA, sizeof(payload_write));
 	spdk_blob_io_write(blob, channel, payload_write, 4, 10, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 	CU_ASSERT(free_clusters != spdk_bs_free_cluster_count(bs));
 
+	/* For a clone we need to allocate and copy one cluster, update one page of metadata
+	 * and then write 10 pages of payload.
+	 */
+	CU_ASSERT(g_dev_write_bytes - write_bytes == page_size * 11 + cluster_size);
+	CU_ASSERT(g_dev_read_bytes - read_bytes == cluster_size);
+
 	spdk_blob_io_read(blob, channel, payload_read, 4, 10, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 	CU_ASSERT(memcmp(payload_write, payload_read, 10 * 4096) == 0);
@@ -3761,16 +4228,337 @@ blob_snapshot_rw_iov(void)
 	g_blobid = 0;
 }
 
+/**
+ * Inflate / decouple parent rw unit tests.
+ *
+ * --------------
+ * original blob:         0         1         2         3         4
+ *                   ,---------+---------+---------+---------+---------.
+ *         snapshot  |xxxxxxxxx|xxxxxxxxx|xxxxxxxxx|xxxxxxxxx|    -    |
+ *                   +---------+---------+---------+---------+---------+
+ *         snapshot2 |    -    |yyyyyyyyy|    -    |yyyyyyyyy|    -    |
+ *                   +---------+---------+---------+---------+---------+
+ *         blob      |    -    |zzzzzzzzz|    -    |    -    |    -    |
+ *                   '---------+---------+---------+---------+---------'
+ *                   .         .         .         .         .         .
+ * --------          .         .         .         .         .         .
+ * inflate:          .         .         .         .         .         .
+ *                   ,---------+---------+---------+---------+---------.
+ *         blob      |xxxxxxxxx|zzzzzzzzz|xxxxxxxxx|yyyyyyyyy|000000000|
+ *                   '---------+---------+---------+---------+---------'
+ *
+ *         NOTE: needs to allocate 4 clusters, thin provisioning removed, dependency
+ *               on snapshot2 and snapshot removed .         .         .
+ *                   .         .         .         .         .         .
+ * ----------------  .         .         .         .         .         .
+ * decouple parent:  .         .         .         .         .         .
+ *                   ,---------+---------+---------+---------+---------.
+ *         snapshot  |xxxxxxxxx|xxxxxxxxx|xxxxxxxxx|xxxxxxxxx|    -    |
+ *                   +---------+---------+---------+---------+---------+
+ *         blob      |    -    |zzzzzzzzz|    -    |yyyyyyyyy|    -    |
+ *                   '---------+---------+---------+---------+---------'
+ *
+ *         NOTE: needs to allocate 1 cluster, 3 clusters unallocated, dependency
+ *               on snapshot2 removed and on snapshot still exists. Snapshot2
+ *               should remain a clone of snapshot.
+ */
+static void
+_blob_inflate_rw(bool decouple_parent)
+{
+	struct spdk_blob_store *bs;
+	struct spdk_bs_dev *dev;
+	struct spdk_blob *blob, *snapshot, *snapshot2;
+	struct spdk_io_channel *channel;
+	struct spdk_blob_opts opts;
+	spdk_blob_id blobid, snapshotid, snapshot2id;
+	uint64_t free_clusters;
+	uint64_t cluster_size;
+
+	uint64_t payload_size;
+	uint8_t *payload_read;
+	uint8_t *payload_write;
+	uint8_t *payload_clone;
+
+	uint64_t pages_per_cluster;
+	uint64_t pages_per_payload;
+
+	int i;
+	spdk_blob_id ids[2];
+	size_t count;
+
+	dev = init_dev();
+
+	spdk_bs_init(dev, NULL, bs_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_bs != NULL);
+	bs = g_bs;
+
+	free_clusters = spdk_bs_free_cluster_count(bs);
+	cluster_size = spdk_bs_get_cluster_size(bs);
+	pages_per_cluster = cluster_size / spdk_bs_get_page_size(bs);
+	pages_per_payload = pages_per_cluster * 5;
+
+	payload_size = cluster_size * 5;
+
+	payload_read = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_read != NULL);
+
+	payload_write = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_write != NULL);
+
+	payload_clone = malloc(payload_size);
+	SPDK_CU_ASSERT_FATAL(payload_clone != NULL);
+
+	channel = spdk_bs_alloc_io_channel(bs);
+	SPDK_CU_ASSERT_FATAL(channel != NULL);
+
+	/* Create blob */
+	spdk_blob_opts_init(&opts);
+	opts.thin_provision = true;
+	opts.num_clusters = 5;
+
+	spdk_bs_create_blob_ext(bs, &opts, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	CU_ASSERT(free_clusters == spdk_bs_free_cluster_count(bs));
+	blobid = g_blobid;
+
+	spdk_bs_open_blob(bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	blob = g_blob;
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 5);
+
+	/* 1) Initial read should return zeroed payload */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload,
+			  blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(spdk_mem_all_zero(payload_read, payload_size));
+
+	/* Fill whole blob with a pattern, except last cluster (to be sure it
+	 * isn't allocated) */
+	memset(payload_write, 0xE5, payload_size - cluster_size);
+	spdk_blob_io_write(blob, channel, payload_write, 0, pages_per_payload -
+			   pages_per_cluster, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(free_clusters != spdk_bs_free_cluster_count(bs));
+
+	/* 2) Create snapshot from blob (first level) */
+	spdk_bs_create_snapshot(bs, blobid, NULL, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	snapshotid = g_blobid;
+
+	spdk_bs_open_blob(bs, snapshotid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	snapshot = g_blob;
+	CU_ASSERT(snapshot->data_ro == true)
+	CU_ASSERT(snapshot->md_ro == true)
+
+	CU_ASSERT(spdk_blob_get_num_clusters(snapshot) == 5)
+
+	/* Write every second cluster with a pattern.
+	 *
+	 * Last cluster shouldn't be written, to be sure that snapshot nor clone
+	 * doesn't allocate it.
+	 *
+	 * payload_clone stores expected result on "blob" read at the time and
+	 * is used only to check data consistency on clone before and after
+	 * inflation. Initially we fill it with a backing snapshots pattern
+	 * used before.
+	 */
+	memset(payload_clone, 0xE5, payload_size - cluster_size);
+	memset(payload_clone + payload_size - cluster_size, 0x00, cluster_size);
+	memset(payload_write, 0xAA, payload_size);
+	for (i = 1; i < 5; i += 2) {
+		spdk_blob_io_write(blob, channel, payload_write, i * pages_per_cluster,
+				   pages_per_cluster, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+
+		/* Update expected result */
+		memcpy(payload_clone + (cluster_size * i), payload_write,
+		       cluster_size);
+	}
+	CU_ASSERT(free_clusters != spdk_bs_free_cluster_count(bs));
+
+	/* Check data consistency on clone */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload,
+			  blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_clone, payload_read, payload_size) == 0);
+
+	/* 3) Create second levels snapshot from blob */
+	spdk_bs_create_snapshot(bs, blobid, NULL, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	snapshot2id = g_blobid;
+
+	spdk_bs_open_blob(bs, snapshot2id, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	snapshot2 = g_blob;
+	CU_ASSERT(snapshot2->data_ro == true)
+	CU_ASSERT(snapshot2->md_ro == true)
+
+	CU_ASSERT(spdk_blob_get_num_clusters(snapshot2) == 5)
+
+	CU_ASSERT(snapshot2->parent_id == snapshotid);
+
+	/* Write one cluster on the top level blob. This cluster (1) covers
+	 * already allocated cluster in the snapshot2, so shouldn't be inflated
+	 * at all */
+	spdk_blob_io_write(blob, channel, payload_write, pages_per_cluster,
+			   pages_per_cluster, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Update expected result */
+	memcpy(payload_clone + cluster_size, payload_write, cluster_size);
+
+	/* Check data consistency on clone */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload,
+			  blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_clone, payload_read, payload_size) == 0);
+
+
+	/* Close all blobs */
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_blob_close(snapshot2, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_blob_close(snapshot, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Check snapshot-clone relations */
+	count = 2;
+	CU_ASSERT(spdk_blob_get_clones(bs, snapshotid, ids, &count) == 0);
+	CU_ASSERT(count == 1);
+	CU_ASSERT(ids[0] == snapshot2id);
+
+	count = 2;
+	CU_ASSERT(spdk_blob_get_clones(bs, snapshot2id, ids, &count) == 0);
+	CU_ASSERT(count == 1);
+	CU_ASSERT(ids[0] == blobid);
+
+	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == snapshot2id);
+
+	free_clusters = spdk_bs_free_cluster_count(bs);
+	if (!decouple_parent) {
+		/* Do full blob inflation */
+		spdk_bs_inflate_blob(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+
+		/* All clusters should be inflated (except one already allocated
+		 * in a top level blob) */
+		CU_ASSERT(spdk_bs_free_cluster_count(bs) == free_clusters - 4);
+
+		/* Check if relation tree updated correctly */
+		count = 2;
+		CU_ASSERT(spdk_blob_get_clones(bs, snapshotid, ids, &count) == 0);
+
+		/* snapshotid have one clone */
+		CU_ASSERT(count == 1);
+		CU_ASSERT(ids[0] == snapshot2id);
+
+		/* snapshot2id have no clones */
+		count = 2;
+		CU_ASSERT(spdk_blob_get_clones(bs, snapshot2id, ids, &count) == 0);
+		CU_ASSERT(count == 0);
+
+		CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == SPDK_BLOBID_INVALID);
+	} else {
+		/* Decouple parent of blob */
+		spdk_bs_blob_decouple_parent(bs, channel, blobid, blob_op_complete, NULL);
+		CU_ASSERT(g_bserrno == 0);
+
+		/* Only one cluster from a parent should be inflated (second one
+		 * is covered by a cluster written on a top level blob, and
+		 * already allocated) */
+		CU_ASSERT(spdk_bs_free_cluster_count(bs) == free_clusters - 1);
+
+		/* Check if relation tree updated correctly */
+		count = 2;
+		CU_ASSERT(spdk_blob_get_clones(bs, snapshotid, ids, &count) == 0);
+
+		/* snapshotid have two clones now */
+		CU_ASSERT(count == 2);
+		CU_ASSERT(ids[0] == blobid || ids[1] == blobid);
+		CU_ASSERT(ids[0] == snapshot2id || ids[1] == snapshot2id);
+
+		/* snapshot2id have no clones */
+		count = 2;
+		CU_ASSERT(spdk_blob_get_clones(bs, snapshot2id, ids, &count) == 0);
+		CU_ASSERT(count == 0);
+
+		CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == snapshotid);
+	}
+
+	/* Try to delete snapshot2 (should pass) */
+	spdk_bs_delete_blob(bs, snapshot2id, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	/* Try to delete base snapshot (for decouple_parent should fail while
+	 * dependency still exists) */
+	spdk_bs_delete_blob(bs, snapshotid, blob_op_complete, NULL);
+	CU_ASSERT(decouple_parent || g_bserrno == 0);
+	CU_ASSERT(!decouple_parent || g_bserrno != 0);
+
+	/* Reopen blob after snapshot deletion */
+	spdk_bs_open_blob(bs, blobid, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	blob = g_blob;
+
+	CU_ASSERT(spdk_blob_get_num_clusters(blob) == 5);
+
+	/* Check data consistency on inflated blob */
+	memset(payload_read, 0xFF, payload_size);
+	spdk_blob_io_read(blob, channel, payload_read, 0, pages_per_payload,
+			  blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(memcmp(payload_clone, payload_read, payload_size) == 0);
+
+	spdk_blob_close(blob, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
+	spdk_bs_free_io_channel(channel);
+
+	/* Unload the blob store */
+	spdk_bs_unload(g_bs, bs_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	g_bs = NULL;
+	g_blob = NULL;
+	g_blobid = 0;
+
+	free(payload_read);
+	free(payload_write);
+	free(payload_clone);
+}
+
+static void
+blob_inflate_rw(void)
+{
+	_blob_inflate_rw(false);
+	_blob_inflate_rw(true);
+}
+
 /**
  * Snapshot-clones relation test
  *
- *      snapshot
- *          |
- *     +----+----+
- *     |         |
- *   blob      clone
- *     |
- *  clone2
+ *         snapshot
+ *            |
+ *      +-----+-----+
+ *      |           |
+ *   blob(ro)   snapshot2
+ *      |           |
+ *   clone2      clone
  */
 static void
 blob_relations(void)
@@ -3779,8 +4567,8 @@ blob_relations(void)
 	struct spdk_bs_dev *dev;
 	struct spdk_bs_opts bs_opts;
 	struct spdk_blob_opts opts;
-	struct spdk_blob *blob, *snapshot, *clone, *clone2;
-	spdk_blob_id blobid, cloneid, snapshotid, cloneid2;
+	struct spdk_blob *blob, *snapshot, *snapshot2, *clone, *clone2;
+	spdk_blob_id blobid, cloneid, snapshotid, cloneid2, snapshotid2;
 	int rc;
 	size_t count;
 	spdk_blob_id ids[10];
@@ -3815,6 +4603,7 @@ blob_relations(void)
 	CU_ASSERT(!spdk_blob_is_thin_provisioned(blob));
 
 	/* blob should not have underlying snapshot nor clones */
+	CU_ASSERT(blob->parent_id == SPDK_BLOBID_INVALID);
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == SPDK_BLOBID_INVALID);
 	count = SPDK_COUNTOF(ids);
 	rc = spdk_blob_get_clones(bs, blobid, ids, &count);
@@ -3837,6 +4626,7 @@ blob_relations(void)
 	CU_ASSERT(spdk_blob_is_read_only(snapshot));
 	CU_ASSERT(spdk_blob_is_snapshot(snapshot));
 	CU_ASSERT(!spdk_blob_is_clone(snapshot));
+	CU_ASSERT(snapshot->parent_id == SPDK_BLOBID_INVALID);
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, snapshotid) == SPDK_BLOBID_INVALID);
 
 	/* Check if original blob is converted to the clone of snapshot */
@@ -3844,7 +4634,7 @@ blob_relations(void)
 	CU_ASSERT(!spdk_blob_is_snapshot(blob));
 	CU_ASSERT(spdk_blob_is_clone(blob));
 	CU_ASSERT(spdk_blob_is_thin_provisioned(blob));
-
+	CU_ASSERT(blob->parent_id == snapshotid);
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == snapshotid);
 
 	count = SPDK_COUNTOF(ids);
@@ -3870,7 +4660,7 @@ blob_relations(void)
 	CU_ASSERT(!spdk_blob_is_snapshot(clone));
 	CU_ASSERT(spdk_blob_is_clone(clone));
 	CU_ASSERT(spdk_blob_is_thin_provisioned(clone));
-
+	CU_ASSERT(clone->parent_id == snapshotid);
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, cloneid) == snapshotid);
 
 	count = SPDK_COUNTOF(ids);
@@ -3886,7 +4676,41 @@ blob_relations(void)
 	CU_ASSERT(ids[0] == cloneid || ids[1] == cloneid);
 
 
-	/* 4. Try to create clone from read only blob */
+	/* 4. Create snapshot of the clone */
+
+	spdk_bs_create_snapshot(bs, cloneid, NULL, blob_op_with_id_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	CU_ASSERT(g_blobid != SPDK_BLOBID_INVALID);
+	snapshotid2 = g_blobid;
+
+	spdk_bs_open_blob(bs, snapshotid2, blob_op_with_handle_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_blob != NULL);
+	snapshot2 = g_blob;
+
+	CU_ASSERT(spdk_blob_is_read_only(snapshot2));
+	CU_ASSERT(spdk_blob_is_snapshot(snapshot2));
+	CU_ASSERT(spdk_blob_is_clone(snapshot2));
+	CU_ASSERT(snapshot2->parent_id == snapshotid);
+	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, snapshotid2) == snapshotid);
+
+	/* Check if clone is converted to the clone of snapshot2 and snapshot2
+	 * is a child of snapshot */
+	CU_ASSERT(!spdk_blob_is_read_only(clone));
+	CU_ASSERT(!spdk_blob_is_snapshot(clone));
+	CU_ASSERT(spdk_blob_is_clone(clone));
+	CU_ASSERT(spdk_blob_is_thin_provisioned(clone));
+	CU_ASSERT(clone->parent_id == snapshotid2);
+	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, cloneid) == snapshotid2);
+
+	count = SPDK_COUNTOF(ids);
+	rc = spdk_blob_get_clones(bs, snapshotid2, ids, &count);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(count == 1);
+	CU_ASSERT(ids[0] == cloneid);
+
+
+	/* 5. Try to create clone from read only blob */
 
 	/* Mark blob as read only */
 	spdk_blob_set_read_only(blob);
@@ -3938,10 +4762,16 @@ blob_relations(void)
 	spdk_blob_close(snapshot, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 
+	spdk_blob_close(snapshot2, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
 	/* Try to delete snapshot with created clones */
 	spdk_bs_delete_blob(bs, snapshotid, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno != 0);
 
+	spdk_bs_delete_blob(bs, snapshotid2, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno != 0);
+
 	spdk_bs_unload(bs, bs_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 	g_bs = NULL;
@@ -3979,7 +4809,7 @@ blob_relations(void)
 	CU_ASSERT(rc == 0);
 	CU_ASSERT(count == 2);
 	CU_ASSERT(ids[0] == blobid || ids[1] == blobid);
-	CU_ASSERT(ids[0] == cloneid || ids[1] == cloneid);
+	CU_ASSERT(ids[0] == snapshotid2 || ids[1] == snapshotid2);
 
 	/* blob */
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, blobid) == snapshotid);
@@ -3990,12 +4820,20 @@ blob_relations(void)
 	CU_ASSERT(ids[0] == cloneid2);
 
 	/* clone */
-	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, cloneid) == snapshotid);
+	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, cloneid) == snapshotid2);
 	count = SPDK_COUNTOF(ids);
 	rc = spdk_blob_get_clones(bs, cloneid, ids, &count);
 	CU_ASSERT(rc == 0);
 	CU_ASSERT(count == 0);
 
+	/* snapshot2 */
+	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, snapshotid2) == snapshotid);
+	count = SPDK_COUNTOF(ids);
+	rc = spdk_blob_get_clones(bs, snapshotid2, ids, &count);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(count == 1);
+	CU_ASSERT(ids[0] == cloneid);
+
 	/* clone2 */
 	CU_ASSERT(spdk_blob_get_parent_snapshot(bs, cloneid2) == blobid);
 	count = SPDK_COUNTOF(ids);
@@ -4003,15 +4841,23 @@ blob_relations(void)
 	CU_ASSERT(rc == 0);
 	CU_ASSERT(count == 0);
 
-	/* Try to delete all blobs */
+	/* Try to delete all blobs in the worse possible order */
+
+	spdk_bs_delete_blob(bs, snapshotid, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno != 0);
+
+	spdk_bs_delete_blob(bs, snapshotid2, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno != 0);
+
 	spdk_bs_delete_blob(bs, cloneid, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno == 0);
 
-	/* Try to delete snapshot with clones */
+	spdk_bs_delete_blob(bs, snapshotid2, blob_op_complete, NULL);
+	CU_ASSERT(g_bserrno == 0);
+
 	spdk_bs_delete_blob(bs, snapshotid, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno != 0);
 
-	/* Try to delete ro blob with clones */
 	spdk_bs_delete_blob(bs, blobid, blob_op_complete, NULL);
 	CU_ASSERT(g_bserrno != 0);
 
@@ -4053,6 +4899,7 @@ int main(int argc, char **argv)
 		CU_add_test(suite, "blob_thin_provision", blob_thin_provision) == NULL ||
 		CU_add_test(suite, "blob_snapshot", blob_snapshot) == NULL ||
 		CU_add_test(suite, "blob_clone", blob_clone) == NULL ||
+		CU_add_test(suite, "blob_inflate", blob_inflate) == NULL ||
 		CU_add_test(suite, "blob_delete", blob_delete) == NULL ||
 		CU_add_test(suite, "blob_resize", blob_resize) == NULL ||
 		CU_add_test(suite, "blob_read_only", blob_read_only) == NULL ||
@@ -4089,7 +4936,10 @@ int main(int argc, char **argv)
 		CU_add_test(suite, "bs_load_iter", bs_load_iter) == NULL ||
 		CU_add_test(suite, "blob_snapshot_rw", blob_snapshot_rw) == NULL ||
 		CU_add_test(suite, "blob_snapshot_rw_iov", blob_snapshot_rw_iov) == NULL ||
-		CU_add_test(suite, "blob_relations", blob_relations) == NULL
+		CU_add_test(suite, "blob_relations", blob_relations) == NULL ||
+		CU_add_test(suite, "blob_inflate_rw", blob_inflate_rw) == NULL ||
+		CU_add_test(suite, "blob_snapshot_freeze_io", blob_snapshot_freeze_io) == NULL ||
+		CU_add_test(suite, "blob_operation_split_rw", blob_operation_split_rw) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/blob/bs_dev_common.c b/test/unit/lib/blob/bs_dev_common.c
index b24de2126..fe3105269 100644
--- a/test/unit/lib/blob/bs_dev_common.c
+++ b/test/unit/lib/blob/bs_dev_common.c
@@ -31,12 +31,16 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
+#include "bs_scheduler.c"
+
 
 #define DEV_BUFFER_SIZE (64 * 1024 * 1024)
 #define DEV_BUFFER_BLOCKLEN (4096)
 #define DEV_BUFFER_BLOCKCNT (DEV_BUFFER_SIZE / DEV_BUFFER_BLOCKLEN)
 uint8_t *g_dev_buffer;
+uint64_t g_dev_write_bytes;
+uint64_t g_dev_read_bytes;
 
 /* Define here for UT only. */
 struct spdk_io_channel g_io_channel;
@@ -58,14 +62,21 @@ dev_destroy(struct spdk_bs_dev *dev)
 	free(dev);
 }
 
+
 static void
-dev_complete(void *arg)
+dev_complete_cb(void *arg)
 {
 	struct spdk_bs_dev_cb_args *cb_args = arg;
 
 	cb_args->cb_fn(cb_args->channel, cb_args->cb_arg, 0);
 }
 
+static void
+dev_complete(void *arg)
+{
+	_bs_send_msg(dev_complete_cb, arg, NULL);
+}
+
 static void
 dev_read(struct spdk_bs_dev *dev, struct spdk_io_channel *channel, void *payload,
 	 uint64_t lba, uint32_t lba_count,
@@ -73,10 +84,11 @@ dev_read(struct spdk_bs_dev *dev, struct spdk_io_channel *channel, void *payload
 {
 	uint64_t offset, length;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	memcpy(payload, &g_dev_buffer[offset], length);
+	g_dev_read_bytes += length;
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
 }
 
@@ -87,10 +99,11 @@ dev_write(struct spdk_bs_dev *dev, struct spdk_io_channel *channel, void *payloa
 {
 	uint64_t offset, length;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	memcpy(&g_dev_buffer[offset], payload, length);
+	g_dev_write_bytes += length;
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
 }
 
@@ -115,8 +128,8 @@ dev_readv(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 	uint64_t offset, length;
 	int i;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	__check_iov(iov, iovcnt, length);
 
@@ -125,6 +138,7 @@ dev_readv(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 		offset += iov[i].iov_len;
 	}
 
+	g_dev_read_bytes += length;
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
 }
 
@@ -137,8 +151,8 @@ dev_writev(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 	uint64_t offset, length;
 	int i;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	__check_iov(iov, iovcnt, length);
 
@@ -147,6 +161,7 @@ dev_writev(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 		offset += iov[i].iov_len;
 	}
 
+	g_dev_write_bytes += length;
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
 }
 
@@ -164,8 +179,8 @@ dev_unmap(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 {
 	uint64_t offset, length;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	memset(&g_dev_buffer[offset], 0, length);
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
@@ -178,10 +193,11 @@ dev_write_zeroes(struct spdk_bs_dev *dev, struct spdk_io_channel *channel,
 {
 	uint64_t offset, length;
 
-	offset = lba * DEV_BUFFER_BLOCKLEN;
-	length = lba_count * DEV_BUFFER_BLOCKLEN;
+	offset = lba * dev->blocklen;
+	length = lba_count * dev->blocklen;
 	SPDK_CU_ASSERT_FATAL(offset + length <= DEV_BUFFER_SIZE);
 	memset(&g_dev_buffer[offset], 0, length);
+	g_dev_write_bytes += length;
 	spdk_thread_send_msg(spdk_get_thread(), dev_complete, cb_args);
 }
 
diff --git a/lib/cunit/spdk_cunit.c b/test/unit/lib/blob/bs_scheduler.c
similarity index 54%
rename from lib/cunit/spdk_cunit.c
rename to test/unit/lib/blob/bs_scheduler.c
index 55c1e9346..76fa067ee 100644
--- a/lib/cunit/spdk_cunit.c
+++ b/test/unit/lib/blob/bs_scheduler.c
@@ -31,82 +31,57 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-#include "spdk/stdinc.h"
+bool g_scheduler_delay = false;
 
-#include "spdk_cunit.h"
+struct scheduled_ops {
+	spdk_thread_fn	fn;
+	void		*ctx;
 
-static int
-spdk_cunit_get_test_result(CU_pTest test)
-{
-	CU_pFailureRecord failure = CU_get_failure_list();
+	TAILQ_ENTRY(scheduled_ops)	ops_queue;
+};
 
-	while (failure != NULL) {
-		if (failure->pTest == test) {
-			return 1;
-		}
-		failure = failure->pNext;
-	}
+static TAILQ_HEAD(, scheduled_ops) g_scheduled_ops = TAILQ_HEAD_INITIALIZER(g_scheduled_ops);
 
-	return 0;
-}
+void _bs_flush_scheduler(uint32_t);
 
 static void
-spdk_cunit_print_test_result(FILE *out, CU_pTest test)
+_bs_send_msg(spdk_thread_fn fn, void *ctx, void *thread_ctx)
 {
-	fprintf(out, "    {\n");
-	fprintf(out, "      \"Name\" : \"%s\",\n", test->pName);
-	fprintf(out, "      \"Result\" : \"%s\"\n",
-		spdk_cunit_get_test_result(test) ? "FAIL" : "PASS");
-	fprintf(out, "    }\n");
-}
+	if (g_scheduler_delay) {
+		struct scheduled_ops *ops = calloc(1, sizeof(*ops));
 
-static void
-spdk_cunit_print_suite_result(FILE *out, CU_pSuite suite)
-{
-	CU_pTest test = suite->pTest;
+		SPDK_CU_ASSERT_FATAL(ops != NULL);
+		ops->fn = fn;
+		ops->ctx = ctx;
+		TAILQ_INSERT_TAIL(&g_scheduled_ops, ops, ops_queue);
 
-	while (test != NULL) {
-		spdk_cunit_print_test_result(out, test);
-		test = test->pNext;
-		if (test != NULL) {
-			fprintf(out, "    ,\n");
-		}
+	} else {
+		fn(ctx);
 	}
 }
 
 static void
-spdk_cunit_print_registry_result(FILE *out, CU_pTestRegistry registry)
+_bs_flush_scheduler_single(void)
 {
-	CU_pSuite suite = registry->pSuite;
+	struct scheduled_ops *op;
+	TAILQ_HEAD(, scheduled_ops) ops;
+	TAILQ_INIT(&ops);
 
-	if (suite == NULL) {
-		return;
-	}
+	TAILQ_SWAP(&g_scheduled_ops, &ops, scheduled_ops, ops_queue);
 
-	fprintf(out, "{\n");
-	fprintf(out, "  \"%s unit tests\": [\n", suite->pName);
+	while (!TAILQ_EMPTY(&ops)) {
+		op = TAILQ_FIRST(&ops);
+		TAILQ_REMOVE(&ops, op, ops_queue);
 
-	while (suite != NULL) {
-		spdk_cunit_print_suite_result(out, suite);
-		suite = suite->pNext;
+		op->fn(op->ctx);
+		free(op);
 	}
-
-	fprintf(out, "  ]\n");
-	fprintf(out, "}\n");
 }
 
-int
-spdk_cunit_print_results(const char *filename)
+void
+_bs_flush_scheduler(uint32_t n)
 {
-	FILE *out;
-
-	out = fopen(filename, "w");
-	if (out == NULL) {
-		fprintf(stderr, "could not open results file %s\n", filename);
-		return -1;
+	while (n--) {
+		_bs_flush_scheduler_single();
 	}
-
-	spdk_cunit_print_registry_result(out, CU_get_registry());
-	fclose(out);
-	return 0;
 }
diff --git a/test/unit/lib/blobfs/blobfs_sync_ut/blobfs_sync_ut.c b/test/unit/lib/blobfs/blobfs_sync_ut/blobfs_sync_ut.c
index 1fb36598a..e85154b65 100644
--- a/test/unit/lib/blobfs/blobfs_sync_ut/blobfs_sync_ut.c
+++ b/test/unit/lib/blobfs/blobfs_sync_ut/blobfs_sync_ut.c
@@ -36,7 +36,7 @@
 #include "spdk/blobfs.h"
 #include "spdk/env.h"
 #include "spdk/log.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/barrier.h"
 
 #include "spdk_cunit.h"
diff --git a/test/unit/lib/ioat/ioat.c/ioat_ut.c b/test/unit/lib/ioat/ioat.c/ioat_ut.c
index 7ba993e1b..92330e326 100644
--- a/test/unit/lib/ioat/ioat.c/ioat_ut.c
+++ b/test/unit/lib/ioat/ioat.c/ioat_ut.c
@@ -31,32 +31,13 @@
  *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
-#include "spdk/stdinc.h"
-
-#include "CUnit/Basic.h"
+#include "spdk_cunit.h"
 
 #include "ioat/ioat.c"
 
-void *
-spdk_dma_zmalloc(size_t size, size_t align, uint64_t *phys_addr)
-{
-	return calloc(1, size);
-}
-
-void spdk_dma_free(void *buf)
-{
-	free(buf);
-}
-
-uint64_t spdk_vtophys(void *buf)
-{
-	return (uint64_t)buf;
-}
-
-void spdk_delay_us(unsigned int us)
-{
+#include "spdk_internal/mock.h"
 
-}
+#include "common/lib/test_env.c"
 
 int
 spdk_pci_ioat_enumerate(spdk_pci_enum_cb enum_cb, void *enum_ctx)
diff --git a/test/unit/lib/iscsi/conn.c/conn_ut.c b/test/unit/lib/iscsi/conn.c/conn_ut.c
index 988376abc..d4b4843d4 100644
--- a/test/unit/lib/iscsi/conn.c/conn_ut.c
+++ b/test/unit/lib/iscsi/conn.c/conn_ut.c
@@ -157,13 +157,35 @@ spdk_scsi_task_put(struct spdk_scsi_task *task)
 {
 }
 
+struct spdk_scsi_lun *
+spdk_scsi_dev_get_lun(struct spdk_scsi_dev *dev, int lun_id)
+{
+	return NULL;
+}
+
+int
+spdk_scsi_lun_open(struct spdk_scsi_lun *lun, spdk_scsi_remove_cb_t hotremove_cb,
+		   void *hotremove_ctx, struct spdk_scsi_desc **desc)
+{
+	return 0;
+}
+
 void
-spdk_scsi_dev_free_io_channels(struct spdk_scsi_dev *dev)
+spdk_scsi_lun_close(struct spdk_scsi_desc *desc)
+{
+}
+
+int spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_desc *desc)
+{
+	return 0;
+}
+
+void spdk_scsi_lun_free_io_channel(struct spdk_scsi_desc *desc)
 {
 }
 
 int
-spdk_scsi_dev_allocate_io_channels(struct spdk_scsi_dev *dev)
+spdk_scsi_lun_get_id(const struct spdk_scsi_lun *lun)
 {
 	return 0;
 }
@@ -174,6 +196,12 @@ spdk_scsi_port_get_name(const struct spdk_scsi_port *port)
 	return NULL;
 }
 
+void
+spdk_scsi_task_copy_status(struct spdk_scsi_task *dst,
+			   struct spdk_scsi_task *src)
+{
+}
+
 void
 spdk_put_pdu(struct spdk_iscsi_pdu *pdu)
 {
diff --git a/test/unit/lib/iscsi/init_grp.c/init_grp_ut.c b/test/unit/lib/iscsi/init_grp.c/init_grp_ut.c
index ad96267fb..5fcce81bd 100644
--- a/test/unit/lib/iscsi/init_grp.c/init_grp_ut.c
+++ b/test/unit/lib/iscsi/init_grp.c/init_grp_ut.c
@@ -36,6 +36,7 @@
 #include "CUnit/Basic.h"
 
 #include "iscsi/init_grp.c"
+#include "unit/lib/json_mock.c"
 
 SPDK_LOG_REGISTER_COMPONENT("iscsi", SPDK_LOG_ISCSI)
 
diff --git a/test/unit/lib/iscsi/iscsi.c/Makefile b/test/unit/lib/iscsi/iscsi.c/Makefile
index 2093a6eb3..bc9a9d8b5 100644
--- a/test/unit/lib/iscsi/iscsi.c/Makefile
+++ b/test/unit/lib/iscsi/iscsi.c/Makefile
@@ -41,7 +41,7 @@ SCSI_OBJS = port
 ISCSI_OBJS = md5 param
 LIBS += $(SCSI_OBJS:%=$(SPDK_ROOT_DIR)/lib/scsi/%.o)
 LIBS += $(ISCSI_OBJS:%=$(SPDK_ROOT_DIR)/lib/iscsi/%.o)
-LIBS += -lcunit -lcrypto $(ENV_LINKER_ARGS)
+LIBS += -lcunit $(ENV_LINKER_ARGS)
 
 TEST_FILE = iscsi_ut.c
 
diff --git a/test/unit/lib/iscsi/iscsi.c/iscsi_ut.c b/test/unit/lib/iscsi/iscsi.c/iscsi_ut.c
index 686045130..310b6d20b 100644
--- a/test/unit/lib/iscsi/iscsi.c/iscsi_ut.c
+++ b/test/unit/lib/iscsi/iscsi.c/iscsi_ut.c
@@ -102,6 +102,12 @@ spdk_scsi_lun_get_id(const struct spdk_scsi_lun *lun)
 	return lun->id;
 }
 
+bool
+spdk_scsi_lun_is_removing(const struct spdk_scsi_lun *lun)
+{
+	return true;
+}
+
 struct spdk_scsi_lun *
 spdk_scsi_dev_get_lun(struct spdk_scsi_dev *dev, int lun_id)
 {
@@ -197,7 +203,7 @@ maxburstlength_test(void)
 	req->final_bit = 1;
 
 	rc = spdk_iscsi_execute(&conn, req_pdu);
-	CU_ASSERT_FATAL(rc == 0);
+	CU_ASSERT(rc == 0);
 
 	response_pdu = TAILQ_FIRST(&g_write_pdu_list);
 	SPDK_CU_ASSERT_FATAL(response_pdu != NULL);
@@ -224,7 +230,7 @@ maxburstlength_test(void)
 	rc = spdk_iscsi_execute(&conn, data_out_pdu);
 	CU_ASSERT(rc == SPDK_ISCSI_CONNECTION_FATAL);
 
-	CU_ASSERT(response_pdu->task != NULL);
+	SPDK_CU_ASSERT_FATAL(response_pdu->task != NULL);
 	spdk_iscsi_task_disassociate_pdu(response_pdu->task);
 	spdk_iscsi_task_put(response_pdu->task);
 	spdk_put_pdu(response_pdu);
@@ -238,6 +244,680 @@ maxburstlength_test(void)
 	spdk_put_pdu(req_pdu);
 }
 
+static void
+underflow_for_read_transfer_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task;
+	struct spdk_iscsi_pdu *pdu;
+	struct iscsi_bhs_scsi_req *scsi_req;
+	struct iscsi_bhs_data_in *datah;
+	uint32_t residual_count = 0;
+
+	TAILQ_INIT(&g_write_pdu_list);
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task, 0, sizeof(task));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_BURST_LENGTH;
+
+	conn.sess = &sess;
+	conn.MaxRecvDataSegmentLength = 8192;
+
+	pdu = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	scsi_req = (struct iscsi_bhs_scsi_req *)&pdu->bhs;
+	scsi_req->read_bit = 1;
+
+	spdk_iscsi_task_set_pdu(&task, pdu);
+	task.parent = NULL;
+
+	task.scsi.iovs = &task.scsi.iov;
+	task.scsi.iovcnt = 1;
+	task.scsi.length = 512;
+	task.scsi.transfer_len = 512;
+	task.bytes_completed = 512;
+	task.scsi.data_transferred = 256;
+	task.scsi.status = SPDK_SCSI_STATUS_GOOD;
+
+	spdk_iscsi_task_response(&conn, &task);
+	spdk_put_pdu(pdu);
+
+	/*
+	 * In this case, a SCSI Data-In PDU should contain the Status
+	 * for the data transfer.
+	 */
+	to_be32(&residual_count, 256);
+
+	pdu = TAILQ_FIRST(&g_write_pdu_list);
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	CU_ASSERT(pdu->bhs.opcode == ISCSI_OP_SCSI_DATAIN);
+
+	datah = (struct iscsi_bhs_data_in *)&pdu->bhs;
+
+	CU_ASSERT(datah->flags == (ISCSI_DATAIN_UNDERFLOW | ISCSI_FLAG_FINAL | ISCSI_DATAIN_STATUS));
+	CU_ASSERT(datah->res_cnt == residual_count);
+
+	TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+	spdk_put_pdu(pdu);
+
+	CU_ASSERT(TAILQ_EMPTY(&g_write_pdu_list));
+}
+
+static void
+underflow_for_zero_read_transfer_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task;
+	struct spdk_iscsi_pdu *pdu;
+	struct iscsi_bhs_scsi_req *scsi_req;
+	struct iscsi_bhs_scsi_resp *resph;
+	uint32_t residual_count = 0, data_segment_len;
+
+	TAILQ_INIT(&g_write_pdu_list);
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task, 0, sizeof(task));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_BURST_LENGTH;
+
+	conn.sess = &sess;
+	conn.MaxRecvDataSegmentLength = 8192;
+
+	pdu = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	scsi_req = (struct iscsi_bhs_scsi_req *)&pdu->bhs;
+	scsi_req->read_bit = 1;
+
+	spdk_iscsi_task_set_pdu(&task, pdu);
+	task.parent = NULL;
+
+	task.scsi.length = 512;
+	task.scsi.transfer_len = 512;
+	task.bytes_completed = 512;
+	task.scsi.data_transferred = 0;
+	task.scsi.status = SPDK_SCSI_STATUS_GOOD;
+
+	spdk_iscsi_task_response(&conn, &task);
+	spdk_put_pdu(pdu);
+
+	/*
+	 * In this case, only a SCSI Response PDU is expected and
+	 * underflow must be set in it.
+	 * */
+	to_be32(&residual_count, 512);
+
+	pdu = TAILQ_FIRST(&g_write_pdu_list);
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	CU_ASSERT(pdu->bhs.opcode == ISCSI_OP_SCSI_RSP);
+
+	resph = (struct iscsi_bhs_scsi_resp *)&pdu->bhs;
+
+	CU_ASSERT(resph->flags == (ISCSI_SCSI_UNDERFLOW | 0x80));
+
+	data_segment_len = DGET24(resph->data_segment_len);
+	CU_ASSERT(data_segment_len == 0);
+	CU_ASSERT(resph->res_cnt == residual_count);
+
+	TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+	spdk_put_pdu(pdu);
+
+	CU_ASSERT(TAILQ_EMPTY(&g_write_pdu_list));
+}
+
+static void
+underflow_for_request_sense_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task;
+	struct spdk_iscsi_pdu *pdu;
+	struct iscsi_bhs_scsi_req *scsi_req;
+	struct iscsi_bhs_data_in *datah;
+	struct iscsi_bhs_scsi_resp *resph;
+	uint32_t residual_count = 0, data_segment_len;
+
+	TAILQ_INIT(&g_write_pdu_list);
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task, 0, sizeof(task));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_BURST_LENGTH;
+
+	conn.sess = &sess;
+	conn.MaxRecvDataSegmentLength = 8192;
+
+	pdu = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	scsi_req = (struct iscsi_bhs_scsi_req *)&pdu->bhs;
+	scsi_req->read_bit = 1;
+
+	spdk_iscsi_task_set_pdu(&task, pdu);
+	task.parent = NULL;
+
+	task.scsi.iovs = &task.scsi.iov;
+	task.scsi.iovcnt = 1;
+	task.scsi.length = 512;
+	task.scsi.transfer_len = 512;
+	task.bytes_completed = 512;
+
+	task.scsi.sense_data_len = 18;
+	task.scsi.data_transferred = 18;
+	task.scsi.status = SPDK_SCSI_STATUS_GOOD;
+
+	spdk_iscsi_task_response(&conn, &task);
+	spdk_put_pdu(pdu);
+
+	/*
+	 * In this case, a SCSI Data-In PDU and a SCSI Response PDU are returned.
+	 * Sense data are set both in payload and sense area.
+	 * The SCSI Data-In PDU sets FINAL and the SCSI Response PDU sets UNDERFLOW.
+	 *
+	 * Probably there will be different implementation but keeping current SPDK
+	 * implementation by adding UT will be valuable for any implementation.
+	 */
+	to_be32(&residual_count, 494);
+
+	pdu = TAILQ_FIRST(&g_write_pdu_list);
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	CU_ASSERT(pdu->bhs.opcode == ISCSI_OP_SCSI_DATAIN);
+
+	datah = (struct iscsi_bhs_data_in *)&pdu->bhs;
+
+	CU_ASSERT(datah->flags == ISCSI_FLAG_FINAL);
+
+	data_segment_len = DGET24(datah->data_segment_len);
+	CU_ASSERT(data_segment_len == 18);
+	CU_ASSERT(datah->res_cnt == 0);
+
+	TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+	spdk_put_pdu(pdu);
+
+	pdu = TAILQ_FIRST(&g_write_pdu_list);
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	CU_ASSERT(pdu->bhs.opcode == ISCSI_OP_SCSI_RSP);
+
+	resph = (struct iscsi_bhs_scsi_resp *)&pdu->bhs;
+
+	CU_ASSERT(resph->flags == (ISCSI_SCSI_UNDERFLOW | 0x80));
+
+	data_segment_len = DGET24(resph->data_segment_len);
+	CU_ASSERT(data_segment_len == task.scsi.sense_data_len + 2);
+	CU_ASSERT(resph->res_cnt == residual_count);
+
+	TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+	spdk_put_pdu(pdu);
+
+	CU_ASSERT(TAILQ_EMPTY(&g_write_pdu_list));
+}
+
+static void
+underflow_for_check_condition_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task;
+	struct spdk_iscsi_pdu *pdu;
+	struct iscsi_bhs_scsi_req *scsi_req;
+	struct iscsi_bhs_scsi_resp *resph;
+	uint32_t data_segment_len;
+
+	TAILQ_INIT(&g_write_pdu_list);
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task, 0, sizeof(task));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_BURST_LENGTH;
+
+	conn.sess = &sess;
+	conn.MaxRecvDataSegmentLength = 8192;
+
+	pdu = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	scsi_req = (struct iscsi_bhs_scsi_req *)&pdu->bhs;
+	scsi_req->read_bit = 1;
+
+	spdk_iscsi_task_set_pdu(&task, pdu);
+	task.parent = NULL;
+
+	task.scsi.iovs = &task.scsi.iov;
+	task.scsi.iovcnt = 1;
+	task.scsi.length = 512;
+	task.scsi.transfer_len = 512;
+	task.bytes_completed = 512;
+
+	task.scsi.sense_data_len = 18;
+	task.scsi.data_transferred = 18;
+	task.scsi.status = SPDK_SCSI_STATUS_CHECK_CONDITION;
+
+	spdk_iscsi_task_response(&conn, &task);
+	spdk_put_pdu(pdu);
+
+	/*
+	 * In this case, a SCSI Response PDU is returned.
+	 * Sense data is set in sense area.
+	 * Underflow is not set.
+	 */
+	pdu = TAILQ_FIRST(&g_write_pdu_list);
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	CU_ASSERT(pdu->bhs.opcode == ISCSI_OP_SCSI_RSP);
+
+	resph = (struct iscsi_bhs_scsi_resp *)&pdu->bhs;
+
+	CU_ASSERT(resph->flags == 0x80);
+
+	data_segment_len = DGET24(resph->data_segment_len);
+	CU_ASSERT(data_segment_len == task.scsi.sense_data_len + 2);
+	CU_ASSERT(resph->res_cnt == 0);
+
+	TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+	spdk_put_pdu(pdu);
+
+	CU_ASSERT(TAILQ_EMPTY(&g_write_pdu_list));
+}
+
+static void
+add_transfer_task_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task;
+	struct spdk_iscsi_pdu *pdu, *tmp;
+	struct iscsi_bhs_r2t *r2th;
+	int rc, count = 0;
+	uint32_t buffer_offset, desired_xfer_len;
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task, 0, sizeof(task));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_BURST_LENGTH;	/* 1M */
+	sess.MaxOutstandingR2T = DEFAULT_MAXR2T;	/* 4 */
+
+	conn.sess = &sess;
+	TAILQ_INIT(&conn.queued_r2t_tasks);
+	TAILQ_INIT(&conn.active_r2t_tasks);
+
+	pdu = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu != NULL);
+
+	pdu->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;	/* 64K */
+	task.scsi.transfer_len = 16 * 1024 * 1024;
+	spdk_iscsi_task_set_pdu(&task, pdu);
+
+	/* The following tests if the task is queued because R2T tasks are full. */
+	conn.pending_r2t = DEFAULT_MAXR2T;
+
+	rc = spdk_add_transfer_task(&conn, &task);
+
+	CU_ASSERT(rc == SPDK_SUCCESS);
+	CU_ASSERT(TAILQ_FIRST(&conn.queued_r2t_tasks) == &task);
+
+	TAILQ_REMOVE(&conn.queued_r2t_tasks, &task, link);
+	CU_ASSERT(TAILQ_EMPTY(&conn.queued_r2t_tasks));
+
+	/* The following tests if multiple R2Ts are issued. */
+	conn.pending_r2t = 0;
+
+	rc = spdk_add_transfer_task(&conn, &task);
+
+	CU_ASSERT(rc == SPDK_SUCCESS);
+	CU_ASSERT(TAILQ_FIRST(&conn.active_r2t_tasks) == &task);
+
+	TAILQ_REMOVE(&conn.active_r2t_tasks, &task, link);
+	CU_ASSERT(TAILQ_EMPTY(&conn.active_r2t_tasks));
+
+	CU_ASSERT(conn.data_out_cnt == 255);
+	CU_ASSERT(conn.pending_r2t == 1);
+	CU_ASSERT(conn.outstanding_r2t_tasks[0] == &task);
+	CU_ASSERT(conn.ttt == 1);
+
+	CU_ASSERT(task.data_out_cnt == 255);
+	CU_ASSERT(task.ttt == 1);
+	CU_ASSERT(task.outstanding_r2t == sess.MaxOutstandingR2T);
+	CU_ASSERT(task.next_r2t_offset ==
+		  pdu->data_segment_len + sess.MaxBurstLength * sess.MaxOutstandingR2T);
+
+
+	while (!TAILQ_EMPTY(&g_write_pdu_list)) {
+		tmp = TAILQ_FIRST(&g_write_pdu_list);
+		TAILQ_REMOVE(&g_write_pdu_list, tmp, tailq);
+
+		r2th = (struct iscsi_bhs_r2t *)&tmp->bhs;
+
+		buffer_offset = from_be32(&r2th->buffer_offset);
+		CU_ASSERT(buffer_offset == pdu->data_segment_len + sess.MaxBurstLength * count);
+
+		desired_xfer_len = from_be32(&r2th->desired_xfer_len);
+		CU_ASSERT(desired_xfer_len == sess.MaxBurstLength);
+
+		spdk_put_pdu(tmp);
+		count++;
+	}
+
+	CU_ASSERT(count == DEFAULT_MAXR2T);
+
+	spdk_put_pdu(pdu);
+}
+
+static void
+get_transfer_task_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task1, task2, *task;
+	struct spdk_iscsi_pdu *pdu1, *pdu2, *pdu;
+	int rc;
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task1, 0, sizeof(task1));
+	memset(&task2, 0, sizeof(task2));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	sess.MaxOutstandingR2T = 1;
+
+	conn.sess = &sess;
+	TAILQ_INIT(&conn.active_r2t_tasks);
+
+	pdu1 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu1 != NULL);
+
+	pdu1->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task1.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task1, pdu1);
+
+	rc = spdk_add_transfer_task(&conn, &task1);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	pdu2 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu2 != NULL);
+
+	pdu2->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task2.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task2, pdu2);
+
+	rc = spdk_add_transfer_task(&conn, &task2);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	task = spdk_get_transfer_task(&conn, 1);
+	CU_ASSERT(task == &task1);
+
+	task = spdk_get_transfer_task(&conn, 2);
+	CU_ASSERT(task == &task2);
+
+	while (!TAILQ_EMPTY(&conn.active_r2t_tasks)) {
+		task = TAILQ_FIRST(&conn.active_r2t_tasks);
+		TAILQ_REMOVE(&conn.active_r2t_tasks, task, link);
+	}
+
+	while (!TAILQ_EMPTY(&g_write_pdu_list)) {
+		pdu = TAILQ_FIRST(&g_write_pdu_list);
+		TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+		spdk_put_pdu(pdu);
+	}
+
+	spdk_put_pdu(pdu2);
+	spdk_put_pdu(pdu1);
+}
+
+static void
+del_transfer_task_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task task1, task2, task3, task4, task5, *task;
+	struct spdk_iscsi_pdu *pdu1, *pdu2, *pdu3, *pdu4, *pdu5, *pdu;
+	int rc;
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&task1, 0, sizeof(task1));
+	memset(&task2, 0, sizeof(task2));
+	memset(&task3, 0, sizeof(task3));
+	memset(&task4, 0, sizeof(task4));
+	memset(&task5, 0, sizeof(task5));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	sess.MaxOutstandingR2T = 1;
+
+	conn.sess = &sess;
+	TAILQ_INIT(&conn.active_r2t_tasks);
+	TAILQ_INIT(&conn.queued_r2t_tasks);
+
+	pdu1 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu1 != NULL);
+
+	pdu1->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task1.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task1, pdu1);
+	task1.tag = 11;
+
+	rc = spdk_add_transfer_task(&conn, &task1);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	pdu2 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu2 != NULL);
+
+	pdu2->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task2.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task2, pdu2);
+	task2.tag = 12;
+
+	rc = spdk_add_transfer_task(&conn, &task2);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	pdu3 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu3 != NULL);
+
+	pdu3->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task3.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task3, pdu3);
+	task3.tag = 13;
+
+	rc = spdk_add_transfer_task(&conn, &task3);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	pdu4 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu4 != NULL);
+
+	pdu4->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task4.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task4, pdu4);
+	task4.tag = 14;
+
+	rc = spdk_add_transfer_task(&conn, &task4);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	pdu5 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu5 != NULL);
+
+	pdu5->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task5.scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	spdk_iscsi_task_set_pdu(&task5, pdu5);
+	task5.tag = 15;
+
+	rc = spdk_add_transfer_task(&conn, &task5);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 1) == &task1);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == NULL);
+	spdk_del_transfer_task(&conn, 11);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 1) == NULL);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == &task5);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 2) == &task2);
+	spdk_del_transfer_task(&conn, 12);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 2) == NULL);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 3) == &task3);
+	spdk_del_transfer_task(&conn, 13);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 3) == NULL);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 4) == &task4);
+	spdk_del_transfer_task(&conn, 14);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 4) == NULL);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == &task5);
+	spdk_del_transfer_task(&conn, 15);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == NULL);
+
+	while (!TAILQ_EMPTY(&conn.active_r2t_tasks)) {
+		task = TAILQ_FIRST(&conn.active_r2t_tasks);
+		TAILQ_REMOVE(&conn.active_r2t_tasks, task, link);
+	}
+
+	while (!TAILQ_EMPTY(&g_write_pdu_list)) {
+		pdu = TAILQ_FIRST(&g_write_pdu_list);
+		TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+		spdk_put_pdu(pdu);
+	}
+
+	spdk_put_pdu(pdu5);
+	spdk_put_pdu(pdu4);
+	spdk_put_pdu(pdu3);
+	spdk_put_pdu(pdu2);
+	spdk_put_pdu(pdu1);
+}
+
+static void
+clear_all_transfer_tasks_test(void)
+{
+	struct spdk_iscsi_sess sess;
+	struct spdk_iscsi_conn conn;
+	struct spdk_iscsi_task *task1, *task2, *task3, *task4, *task5;
+	struct spdk_iscsi_pdu *pdu1, *pdu2, *pdu3, *pdu4, *pdu5, *pdu;
+	struct spdk_scsi_lun lun1, lun2;
+	int rc;
+
+	memset(&sess, 0, sizeof(sess));
+	memset(&conn, 0, sizeof(conn));
+	memset(&lun1, 0, sizeof(lun1));
+	memset(&lun2, 0, sizeof(lun2));
+
+	sess.MaxBurstLength = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	sess.MaxOutstandingR2T = 1;
+
+	conn.sess = &sess;
+	TAILQ_INIT(&conn.active_r2t_tasks);
+	TAILQ_INIT(&conn.queued_r2t_tasks);
+
+	task1 = spdk_iscsi_task_get(&conn, NULL, NULL);
+	SPDK_CU_ASSERT_FATAL(task1 != NULL);
+	pdu1 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu1 != NULL);
+
+	pdu1->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task1->scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task1->scsi.lun = &lun1;
+	spdk_iscsi_task_set_pdu(task1, pdu1);
+
+	rc = spdk_add_transfer_task(&conn, task1);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	task2 = spdk_iscsi_task_get(&conn, NULL, NULL);
+	SPDK_CU_ASSERT_FATAL(task2 != NULL);
+	pdu2 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu2 != NULL);
+
+	pdu2->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task2->scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task2->scsi.lun = &lun1;
+	spdk_iscsi_task_set_pdu(task2, pdu2);
+
+	rc = spdk_add_transfer_task(&conn, task2);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	task3 = spdk_iscsi_task_get(&conn, NULL, NULL);
+	SPDK_CU_ASSERT_FATAL(task3 != NULL);
+	pdu3 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu3 != NULL);
+
+	pdu3->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task3->scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task3->scsi.lun = &lun1;
+	spdk_iscsi_task_set_pdu(task3, pdu3);
+
+	rc = spdk_add_transfer_task(&conn, task3);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	task4 = spdk_iscsi_task_get(&conn, NULL, NULL);
+	SPDK_CU_ASSERT_FATAL(task4 != NULL);
+	pdu4 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu4 != NULL);
+
+	pdu4->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task4->scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task4->scsi.lun = &lun2;
+	spdk_iscsi_task_set_pdu(task4, pdu4);
+
+	rc = spdk_add_transfer_task(&conn, task4);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	task5 = spdk_iscsi_task_get(&conn, NULL, NULL);
+	SPDK_CU_ASSERT_FATAL(task5 != NULL);
+	pdu5 = spdk_get_pdu();
+	SPDK_CU_ASSERT_FATAL(pdu5 != NULL);
+
+	pdu5->data_segment_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task5->scsi.transfer_len = SPDK_ISCSI_MAX_RECV_DATA_SEGMENT_LENGTH;
+	task5->scsi.lun = &lun2;
+	spdk_iscsi_task_set_pdu(task5, pdu5);
+
+	rc = spdk_add_transfer_task(&conn, task5);
+	CU_ASSERT(rc == SPDK_SUCCESS);
+
+	CU_ASSERT(conn.ttt == 4);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 1) == task1);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 2) == task2);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 3) == task3);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 4) == task4);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == NULL);
+
+	spdk_clear_all_transfer_task(&conn, &lun1);
+
+	CU_ASSERT(TAILQ_EMPTY(&conn.queued_r2t_tasks));
+	CU_ASSERT(spdk_get_transfer_task(&conn, 1) == NULL);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 2) == NULL);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 3) == NULL);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 4) == task4);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == task5);
+
+	spdk_clear_all_transfer_task(&conn, NULL);
+
+	CU_ASSERT(spdk_get_transfer_task(&conn, 4) == NULL);
+	CU_ASSERT(spdk_get_transfer_task(&conn, 5) == NULL);
+
+	CU_ASSERT(TAILQ_EMPTY(&conn.active_r2t_tasks));
+	while (!TAILQ_EMPTY(&g_write_pdu_list)) {
+		pdu = TAILQ_FIRST(&g_write_pdu_list);
+		TAILQ_REMOVE(&g_write_pdu_list, pdu, tailq);
+		spdk_put_pdu(pdu);
+	}
+
+	spdk_put_pdu(pdu5);
+	spdk_put_pdu(pdu4);
+	spdk_put_pdu(pdu3);
+	spdk_put_pdu(pdu2);
+	spdk_put_pdu(pdu1);
+}
+
 int
 main(int argc, char **argv)
 {
@@ -257,6 +937,19 @@ main(int argc, char **argv)
 	if (
 		CU_add_test(suite, "login check target test", op_login_check_target_test) == NULL
 		|| CU_add_test(suite, "maxburstlength test", maxburstlength_test) == NULL
+		|| CU_add_test(suite, "underflow for read transfer test",
+			       underflow_for_read_transfer_test) == NULL
+		|| CU_add_test(suite, "underflow for zero read transfer test",
+			       underflow_for_zero_read_transfer_test) == NULL
+		|| CU_add_test(suite, "underflow for request sense test",
+			       underflow_for_request_sense_test) == NULL
+		|| CU_add_test(suite, "underflow for check condition test",
+			       underflow_for_check_condition_test) == NULL
+		|| CU_add_test(suite, "add transfer task test", add_transfer_task_test) == NULL
+		|| CU_add_test(suite, "get transfer task test", get_transfer_task_test) == NULL
+		|| CU_add_test(suite, "del transfer task test", del_transfer_task_test) == NULL
+		|| CU_add_test(suite, "clear all transfer tasks test",
+			       clear_all_transfer_tasks_test) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/iscsi/portal_grp.c/portal_grp_ut.c b/test/unit/lib/iscsi/portal_grp.c/portal_grp_ut.c
index b45f0adf1..77351f0ac 100644
--- a/test/unit/lib/iscsi/portal_grp.c/portal_grp_ut.c
+++ b/test/unit/lib/iscsi/portal_grp.c/portal_grp_ut.c
@@ -34,10 +34,11 @@
 #include "spdk/stdinc.h"
 #include "spdk/event.h"
 
-#include "CUnit/Basic.h"
+#include "spdk_cunit.h"
 
 #include "../common.c"
 #include "iscsi/portal_grp.c"
+#include "unit/lib/json_mock.c"
 
 struct spdk_iscsi_globals g_spdk_iscsi;
 
@@ -169,16 +170,17 @@ parse_portal_ipv4_normal_case(void)
 	const char *host_str = "192.168.2.0";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_cpuset_alloc();
-	CU_ASSERT_FATAL(cpumask_val != NULL);
+	SPDK_CU_ASSERT_FATAL(cpumask_val != NULL);
 
 	spdk_cpuset_set_cpu(cpumask_val, 0, true);
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
@@ -196,16 +198,17 @@ parse_portal_ipv6_normal_case(void)
 	const char *host_str = "[2001:ad6:1234::]";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_cpuset_alloc();
-	CU_ASSERT_FATAL(cpumask_val != NULL);
+	SPDK_CU_ASSERT_FATAL(cpumask_val != NULL);
 
 	spdk_cpuset_set_cpu(cpumask_val, 0, true);
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
@@ -223,13 +226,14 @@ parse_portal_ipv4_skip_cpumask_case(void)
 	const char *host_str = "192.168.2.0";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_app_get_core_mask();
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
@@ -245,13 +249,14 @@ parse_portal_ipv6_skip_cpumask_case(void)
 	const char *host_str = "[2001:ad6:1234::]";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_app_get_core_mask();
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
@@ -267,13 +272,14 @@ parse_portal_ipv4_skip_port_and_cpumask_case(void)
 	const char *host_str = "192.168.2.0";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_app_get_core_mask();
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
@@ -289,13 +295,14 @@ parse_portal_ipv6_skip_port_and_cpumask_case(void)
 	const char *host_str = "[2001:ad6:1234::]";
 	const char *port_str = "3260";
 	struct spdk_cpuset *cpumask_val;
-	struct spdk_iscsi_portal *p;
+	struct spdk_iscsi_portal *p = NULL;
 	int rc;
 
 	cpumask_val = spdk_app_get_core_mask();
 
 	rc = spdk_iscsi_parse_portal(string, &p, 0);
 	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(p != NULL);
 	CU_ASSERT(strcmp(p->host, host_str) == 0);
 	CU_ASSERT(strcmp(p->port, port_str) == 0);
 	CU_ASSERT(spdk_cpuset_equal(p->cpumask, cpumask_val));
diff --git a/test/unit/lib/iscsi/tgt_node.c/tgt_node_ut.c b/test/unit/lib/iscsi/tgt_node.c/tgt_node_ut.c
index 9515bc376..eda02db68 100644
--- a/test/unit/lib/iscsi/tgt_node.c/tgt_node_ut.c
+++ b/test/unit/lib/iscsi/tgt_node.c/tgt_node_ut.c
@@ -41,6 +41,7 @@
 #include "../common.c"
 #include "iscsi/tgt_node.c"
 #include "scsi/scsi_internal.h"
+#include "unit/lib/json_mock.c"
 
 struct spdk_iscsi_globals g_spdk_iscsi;
 
diff --git a/test/unit/lib/json/json_parse.c/json_parse_ut.c b/test/unit/lib/json/json_parse.c/json_parse_ut.c
index 874403973..dae804769 100644
--- a/test/unit/lib/json/json_parse.c/json_parse_ut.c
+++ b/test/unit/lib/json/json_parse.c/json_parse_ut.c
@@ -170,6 +170,10 @@ test_parse_literal(void)
 	PARSE_FAIL("fals", SPDK_JSON_PARSE_INCOMPLETE);
 	PARSE_FAIL("n", SPDK_JSON_PARSE_INCOMPLETE);
 	PARSE_FAIL("nul", SPDK_JSON_PARSE_INCOMPLETE);
+
+	PARSE_FAIL("taaaaa", SPDK_JSON_PARSE_INVALID);
+	PARSE_FAIL("faaaaa", SPDK_JSON_PARSE_INVALID);
+	PARSE_FAIL("naaaaa", SPDK_JSON_PARSE_INVALID);
 }
 
 static void
@@ -402,6 +406,9 @@ test_parse_string_escapes_unicode(void)
 	/* High surrogate without low */
 	STR_FAIL("\\uD800", SPDK_JSON_PARSE_INVALID);
 	STR_FAIL("\\uD800abcdef", SPDK_JSON_PARSE_INVALID);
+
+	/* High surrogate followed by high surrogate */
+	STR_FAIL("\\uD800\\uD800", SPDK_JSON_PARSE_INVALID);
 }
 
 static void
@@ -473,6 +480,7 @@ test_parse_number(void)
 	NUM_FAIL("3e+", SPDK_JSON_PARSE_INCOMPLETE);
 	NUM_FAIL("3e-", SPDK_JSON_PARSE_INCOMPLETE);
 	NUM_FAIL("3.e4", SPDK_JSON_PARSE_INVALID);
+	NUM_FAIL("3.2eX", SPDK_JSON_PARSE_INVALID);
 	NUM_FAIL("-", SPDK_JSON_PARSE_INCOMPLETE);
 	NUM_FAIL("NaN", SPDK_JSON_PARSE_INVALID);
 	NUM_FAIL(".123", SPDK_JSON_PARSE_INVALID);
@@ -481,6 +489,8 @@ test_parse_number(void)
 static void
 test_parse_array(void)
 {
+	char buffer[SPDK_JSON_MAX_NESTING_DEPTH + 2] = {0};
+
 	PARSE_PASS("[]", 2, "");
 	VAL_ARRAY_BEGIN(0);
 	VAL_ARRAY_END();
@@ -527,6 +537,15 @@ test_parse_array(void)
 	PARSE_FAIL("[,true]", SPDK_JSON_PARSE_INVALID);
 	PARSE_FAIL("[true}", SPDK_JSON_PARSE_INVALID);
 	PARSE_FAIL("[true,,true]", SPDK_JSON_PARSE_INVALID);
+
+	/* Nested arrays exactly up to the allowed nesting depth */
+	memset(buffer, '[', SPDK_JSON_MAX_NESTING_DEPTH);
+	buffer[SPDK_JSON_MAX_NESTING_DEPTH] = ' ';
+	PARSE_FAIL(buffer, SPDK_JSON_PARSE_INCOMPLETE);
+
+	/* Nested arrays exceeding the maximum allowed nesting depth for this implementation */
+	buffer[SPDK_JSON_MAX_NESTING_DEPTH] = '[';
+	PARSE_FAIL(buffer, SPDK_JSON_PARSE_MAX_DEPTH_EXCEEDED);
 }
 
 static void
@@ -606,6 +625,7 @@ test_parse_object(void)
 	PARSE_FAIL("{\"a\":", SPDK_JSON_PARSE_INCOMPLETE);
 	PARSE_FAIL("{\"a\":true", SPDK_JSON_PARSE_INCOMPLETE);
 	PARSE_FAIL("{\"a\":true,", SPDK_JSON_PARSE_INCOMPLETE);
+	PARSE_FAIL("{\"a\":true]", SPDK_JSON_PARSE_INVALID);
 	PARSE_FAIL("{\"a\":true,}", SPDK_JSON_PARSE_INVALID);
 	PARSE_FAIL("{\"a\":true,\"}", SPDK_JSON_PARSE_INCOMPLETE);
 	PARSE_FAIL("{\"a\":true,\"b}", SPDK_JSON_PARSE_INCOMPLETE);
@@ -870,6 +890,12 @@ test_parse_comment(void)
 	PARSE_FAIL_FLAGS("//", SPDK_JSON_PARSE_INCOMPLETE, SPDK_JSON_PARSE_FLAG_ALLOW_COMMENTS);
 	PARSE_FAIL_FLAGS("// test", SPDK_JSON_PARSE_INCOMPLETE, SPDK_JSON_PARSE_FLAG_ALLOW_COMMENTS);
 	PARSE_FAIL_FLAGS("//\n", SPDK_JSON_PARSE_INCOMPLETE, SPDK_JSON_PARSE_FLAG_ALLOW_COMMENTS);
+
+	/* Invalid character following slash */
+	PARSE_FAIL_FLAGS("[0/x", SPDK_JSON_PARSE_INVALID, SPDK_JSON_PARSE_FLAG_ALLOW_COMMENTS);
+
+	/* Single slash at end of buffer */
+	PARSE_FAIL_FLAGS("[0/", SPDK_JSON_PARSE_INCOMPLETE, SPDK_JSON_PARSE_FLAG_ALLOW_COMMENTS);
 }
 
 int main(int argc, char **argv)
diff --git a/test/unit/lib/json/json_util.c/json_util_ut.c b/test/unit/lib/json/json_util.c/json_util_ut.c
index e1996a18f..2afd963e2 100644
--- a/test/unit/lib/json/json_util.c/json_util_ut.c
+++ b/test/unit/lib/json/json_util.c/json_util_ut.c
@@ -43,6 +43,15 @@
 	v.start = buf; \
 	v.len = sizeof(x) - 1
 
+#define NUM_UINT16_PASS(s, i) \
+	NUM_SETUP(s); \
+	CU_ASSERT(spdk_json_number_to_uint16(&v, &u16) == 0); \
+	CU_ASSERT(u16 == i)
+
+#define NUM_UINT16_FAIL(s) \
+	NUM_SETUP(s); \
+	CU_ASSERT(spdk_json_number_to_uint16(&v, &u16) != 0)
+
 #define NUM_INT32_PASS(s, i) \
 	NUM_SETUP(s); \
 	CU_ASSERT(spdk_json_number_to_int32(&v, &i32) == 0); \
@@ -86,6 +95,30 @@ test_strequal(void)
 	CU_ASSERT(spdk_json_strequal(&v, "test") == false);
 }
 
+static void
+test_num_to_uint16(void)
+{
+	struct spdk_json_val v;
+	char buf[100];
+	uint16_t u16 = 0;
+
+	NUM_SETUP("1234");
+	CU_ASSERT(spdk_json_number_to_uint16(&v, &u16) == 0);
+	CU_ASSERT(u16 == 1234);
+
+	NUM_UINT16_PASS("0", 0);
+	NUM_UINT16_PASS("1234", 1234);
+	NUM_UINT16_PASS("1234.00000", 1234);
+	NUM_UINT16_PASS("1.2e1", 12);
+	NUM_UINT16_PASS("12340e-1", 1234);
+
+	NUM_UINT16_FAIL("1.2");
+	NUM_UINT16_FAIL("-1234");
+	NUM_UINT16_FAIL("1.2E0");
+	NUM_UINT16_FAIL("1.234e1");
+	NUM_UINT16_FAIL("12341e-1");
+}
+
 static void
 test_num_to_int32(void)
 {
@@ -409,6 +442,95 @@ test_decode_int32(void)
 	CU_ASSERT(spdk_json_decode_int32(&v, &i) != 0);
 }
 
+static void
+test_decode_uint16(void)
+{
+	struct spdk_json_val v;
+	uint32_t i;
+
+	/* incorrect type */
+	v.type = SPDK_JSON_VAL_STRING;
+	v.start = "Strin";
+	v.len = 5;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* invalid value (float) */
+	v.type = SPDK_JSON_VAL_NUMBER;
+	v.start = "123.4";
+	v.len = 5;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* edge case (0) */
+	v.start = "0";
+	v.len = 1;
+	i = 456;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) == 0);
+	CU_ASSERT(i == 0);
+
+	/* invalid value (negative) */
+	v.start = "-1";
+	v.len = 2;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* edge case (maximum) */
+	v.start = "65535";
+	v.len = 5;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) == 0);
+	CU_ASSERT(i == 65535);
+
+	/* invalid value (overflow) */
+	v.start = "65536";
+	v.len = 5;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* valid exponent */
+	v.start = "66E2";
+	v.len = 4;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) == 0);
+	CU_ASSERT(i == 6600);
+
+	/* invalid exponent (overflow) */
+	v.start = "66E3";
+	v.len = 4;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* invalid exponent (decimal) */
+	v.start = "65.535E2";
+	v.len = 7;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* valid exponent with decimal */
+	v.start = "65.53E2";
+	v.len = 7;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) == 0);
+	CU_ASSERT(i == 6553);
+
+	/* invalid negative exponent */
+	v.start = "40e-2";
+	v.len = 5;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* invalid negative exponent */
+	v.start = "-40e-1";
+	v.len = 6;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) != 0);
+
+	/* valid negative exponent */
+	v.start = "40e-1";
+	v.len = 5;
+	i = 0;
+	CU_ASSERT(spdk_json_decode_uint16(&v, &i) == 0);
+	CU_ASSERT(i == 4);
+}
+
 static void
 test_decode_uint32(void)
 {
@@ -658,11 +780,13 @@ int main(int argc, char **argv)
 
 	if (
 		CU_add_test(suite, "strequal", test_strequal) == NULL ||
+		CU_add_test(suite, "num_to_uint16", test_num_to_uint16) == NULL ||
 		CU_add_test(suite, "num_to_int32", test_num_to_int32) == NULL ||
 		CU_add_test(suite, "num_to_uint64", test_num_to_uint64) == NULL ||
 		CU_add_test(suite, "decode_object", test_decode_object) == NULL ||
 		CU_add_test(suite, "decode_array", test_decode_array) == NULL ||
 		CU_add_test(suite, "decode_bool", test_decode_bool) == NULL ||
+		CU_add_test(suite, "decode_uint16", test_decode_uint16) == NULL ||
 		CU_add_test(suite, "decode_int32", test_decode_int32) == NULL ||
 		CU_add_test(suite, "decode_uint32", test_decode_uint32) == NULL ||
 		CU_add_test(suite, "decode_uint64", test_decode_uint64) == NULL ||
diff --git a/test/unit/lib/json/json_write.c/json_write_ut.c b/test/unit/lib/json/json_write.c/json_write_ut.c
index 0d3fe1552..70c62fe1a 100644
--- a/test/unit/lib/json/json_write.c/json_write_ut.c
+++ b/test/unit/lib/json/json_write.c/json_write_ut.c
@@ -62,7 +62,7 @@ write_cb(void *cb_ctx, const void *data, size_t size)
 	memset(g_buf, 0, sizeof(g_buf)); \
 	g_write_pos = g_buf; \
 	w = spdk_json_write_begin(write_cb, NULL, 0); \
-	CU_ASSERT_FATAL(w != NULL)
+	SPDK_CU_ASSERT_FATAL(w != NULL)
 
 #define END(json) \
 	CU_ASSERT(spdk_json_write_end(w) == 0); \
diff --git a/test/unit/lib/lvol/lvol.c/lvol_ut.c b/test/unit/lib/lvol/lvol.c/lvol_ut.c
index e56b62418..d22c95a42 100644
--- a/test/unit/lib/lvol/lvol.c/lvol_ut.c
+++ b/test/unit/lib/lvol/lvol.c/lvol_ut.c
@@ -33,7 +33,7 @@
 
 #include "spdk_cunit.h"
 #include "spdk/blob.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk/util.h"
 
 #include "common/lib/test_env.c"
@@ -73,10 +73,12 @@ int g_lvolerrno;
 int g_lvserrno;
 int g_close_super_status;
 int g_resize_rc;
+int g_inflate_rc;
 bool g_lvs_rename_blob_open_error = false;
 struct spdk_lvol_store *g_lvol_store;
 struct spdk_lvol *g_lvol;
 spdk_blob_id g_blobid = 1;
+struct spdk_io_channel *g_io_channel;
 
 struct spdk_blob_store {
 	struct spdk_bs_opts	bs_opts;
@@ -92,6 +94,18 @@ struct lvol_ut_bs_dev {
 	struct spdk_blob_store	*bs;
 };
 
+void spdk_bs_inflate_blob(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+			  spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	cb_fn(cb_arg, g_inflate_rc);
+}
+
+void spdk_bs_blob_decouple_parent(struct spdk_blob_store *bs, struct spdk_io_channel *channel,
+				  spdk_blob_id blobid, spdk_blob_op_complete cb_fn, void *cb_arg)
+{
+	cb_fn(cb_arg, g_inflate_rc);
+}
+
 void
 spdk_bs_iter_next(struct spdk_blob_store *bs, struct spdk_blob *b,
 		  spdk_blob_op_with_handle_complete cb_fn, void *cb_arg)
@@ -166,7 +180,22 @@ spdk_bs_load(struct spdk_bs_dev *dev, struct spdk_bs_opts *opts,
 
 struct spdk_io_channel *spdk_bs_alloc_io_channel(struct spdk_blob_store *bs)
 {
-	return NULL;
+	if (g_io_channel == NULL) {
+		g_io_channel = calloc(1, sizeof(struct spdk_io_channel));
+		SPDK_CU_ASSERT_FATAL(g_io_channel != NULL);
+	}
+	g_io_channel->ref++;
+	return g_io_channel;
+}
+
+void spdk_bs_free_io_channel(struct spdk_io_channel *channel)
+{
+	g_io_channel->ref--;
+	if (g_io_channel->ref == 0) {
+		free(g_io_channel);
+		g_io_channel = NULL;
+	}
+	return;
 }
 
 int
@@ -1924,6 +1953,112 @@ lvol_create_thin_provisioned(void)
 	spdk_free_thread();
 }
 
+static void
+lvol_inflate(void)
+{
+	struct lvol_ut_bs_dev dev;
+	struct spdk_lvs_opts opts;
+	int rc = 0;
+
+	init_dev(&dev);
+
+	spdk_allocate_thread(_lvol_send_msg, NULL, NULL, NULL, NULL);
+
+	spdk_lvs_opts_init(&opts);
+	snprintf(opts.name, sizeof(opts.name), "lvs");
+
+	g_lvserrno = -1;
+	rc = spdk_lvs_init(&dev.bs_dev, &opts, lvol_store_op_with_handle_complete, NULL);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(g_lvserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_lvol_store != NULL);
+
+	spdk_lvol_create(g_lvol_store, "lvol", 10, false, lvol_op_with_handle_complete, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_lvol != NULL);
+
+	g_inflate_rc = -1;
+	spdk_lvol_inflate(g_lvol, lvol_op_complete, NULL);
+	CU_ASSERT(g_lvolerrno != 0);
+
+	g_inflate_rc = 0;
+	spdk_lvol_inflate(g_lvol, lvol_op_complete, NULL);
+	CU_ASSERT(g_lvolerrno == 0);
+
+	spdk_lvol_close(g_lvol, close_cb, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+	spdk_lvol_destroy(g_lvol, destroy_cb, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+
+	g_lvserrno = -1;
+	rc = spdk_lvs_unload(g_lvol_store, lvol_store_op_complete, NULL);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(g_lvserrno == 0);
+	g_lvol_store = NULL;
+
+	free_dev(&dev);
+
+	/* Make sure that all references to the io_channel was closed after
+	 * inflate call
+	 */
+	CU_ASSERT(g_io_channel == NULL);
+
+	spdk_free_thread();
+}
+
+static void
+lvol_decouple_parent(void)
+{
+	struct lvol_ut_bs_dev dev;
+	struct spdk_lvs_opts opts;
+	int rc = 0;
+
+	init_dev(&dev);
+
+	spdk_allocate_thread(_lvol_send_msg, NULL, NULL, NULL, NULL);
+
+	spdk_lvs_opts_init(&opts);
+	snprintf(opts.name, sizeof(opts.name), "lvs");
+
+	g_lvserrno = -1;
+	rc = spdk_lvs_init(&dev.bs_dev, &opts, lvol_store_op_with_handle_complete, NULL);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(g_lvserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_lvol_store != NULL);
+
+	spdk_lvol_create(g_lvol_store, "lvol", 10, false, lvol_op_with_handle_complete, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+	SPDK_CU_ASSERT_FATAL(g_lvol != NULL);
+
+	g_inflate_rc = -1;
+	spdk_lvol_decouple_parent(g_lvol, lvol_op_complete, NULL);
+	CU_ASSERT(g_lvolerrno != 0);
+
+	g_inflate_rc = 0;
+	spdk_lvol_decouple_parent(g_lvol, lvol_op_complete, NULL);
+	CU_ASSERT(g_lvolerrno == 0);
+
+	spdk_lvol_close(g_lvol, close_cb, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+	spdk_lvol_destroy(g_lvol, destroy_cb, NULL);
+	CU_ASSERT(g_lvserrno == 0);
+
+	g_lvserrno = -1;
+	rc = spdk_lvs_unload(g_lvol_store, lvol_store_op_complete, NULL);
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(g_lvserrno == 0);
+	g_lvol_store = NULL;
+
+	free_dev(&dev);
+
+	/* Make sure that all references to the io_channel was closed after
+	 * inflate call
+	 */
+	CU_ASSERT(g_io_channel == NULL);
+
+	spdk_free_thread();
+}
+
 int main(int argc, char **argv)
 {
 	CU_pSuite	suite = NULL;
@@ -1965,7 +2100,9 @@ int main(int argc, char **argv)
 		CU_add_test(suite, "lvol_names", lvol_names) == NULL ||
 		CU_add_test(suite, "lvol_create_thin_provisioned", lvol_create_thin_provisioned) == NULL ||
 		CU_add_test(suite, "lvol_rename", lvol_rename) == NULL ||
-		CU_add_test(suite, "lvs_rename", lvs_rename) == NULL
+		CU_add_test(suite, "lvs_rename", lvs_rename) == NULL ||
+		CU_add_test(suite, "lvol_inflate", lvol_inflate) == NULL ||
+		CU_add_test(suite, "lvol_decouple_parent", lvol_decouple_parent) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/nvme/Makefile b/test/unit/lib/nvme/Makefile
index 063ee2630..cc0151b14 100644
--- a/test/unit/lib/nvme/Makefile
+++ b/test/unit/lib/nvme/Makefile
@@ -34,7 +34,8 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = nvme.c nvme_ctrlr.c nvme_ctrlr_cmd.c nvme_ns.c nvme_ns_cmd.c nvme_pcie.c nvme_qpair.c nvme_quirks.c
+DIRS-y = nvme.c nvme_ctrlr.c nvme_ctrlr_cmd.c nvme_ns.c nvme_ns_cmd.c nvme_pcie.c nvme_qpair.c nvme_quirks.c nvme_ctrlr_ocssd_cmd.c \
+	 nvme_ns_ocssd_cmd.c
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/test/unit/lib/nvme/nvme.c/nvme_ut.c b/test/unit/lib/nvme/nvme.c/nvme_ut.c
index bfc7b5057..c4520eeb0 100644
--- a/test/unit/lib/nvme/nvme.c/nvme_ut.c
+++ b/test/unit/lib/nvme/nvme.c/nvme_ut.c
@@ -83,6 +83,10 @@ DEFINE_STUB_P(nvme_transport_ctrlr_construct, struct spdk_nvme_ctrlr,
 	       const struct spdk_nvme_ctrlr_opts *opts,
 	       void *devhandle), {0})
 
+DEFINE_STUB(spdk_nvme_qpair_process_completions, int32_t,
+	    (struct spdk_nvme_qpair *qpair,
+	     uint32_t max_completions), 0);
+
 static bool ut_destruct_called = false;
 void
 nvme_ctrlr_destruct(struct spdk_nvme_ctrlr *ctrlr)
@@ -443,7 +447,7 @@ test_spdk_nvme_detach(void)
 	g_spdk_nvme_driver = &test_driver;
 	TAILQ_INIT(&test_driver.shared_attached_ctrlrs);
 	TAILQ_INSERT_TAIL(&test_driver.shared_attached_ctrlrs, &ctrlr, tailq);
-	CU_ASSERT_FATAL(pthread_mutex_init(&test_driver.lock, NULL) == 0);
+	CU_ASSERT(pthread_mutex_init(&test_driver.lock, NULL) == 0);
 
 	/*
 	 * Controllers are ref counted so mock the function that returns
@@ -521,6 +525,7 @@ test_nvme_user_copy_cmd_complete(void)
 	struct nvme_request req;
 	int test_data = 0xdeadbeef;
 	int buff_size = sizeof(int);
+	void *buff;
 	static struct spdk_nvme_cpl cpl;
 
 	memset(&req, 0, sizeof(req));
@@ -536,10 +541,10 @@ test_nvme_user_copy_cmd_complete(void)
 	SPDK_CU_ASSERT_FATAL(req.user_buffer != NULL);
 	memset(req.user_buffer, 0, buff_size);
 	req.payload_size = buff_size;
-	req.payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	req.payload.u.contig = malloc(buff_size);
-	SPDK_CU_ASSERT_FATAL(req.payload.u.contig != NULL);
-	memcpy(req.payload.u.contig, &test_data, buff_size);
+	buff = malloc(buff_size);
+	SPDK_CU_ASSERT_FATAL(buff != NULL);
+	req.payload = NVME_PAYLOAD_CONTIG(buff, NULL);
+	memcpy(buff, &test_data, buff_size);
 	req.cmd.opc = SPDK_NVME_OPC_GET_LOG_PAGE;
 	req.pid = getpid();
 
@@ -568,7 +573,7 @@ test_nvme_user_copy_cmd_complete(void)
 
 	/* clean up */
 	free(req.user_buffer);
-	free(req.payload.u.contig);
+	free(buff);
 
 	/* return spdk_dma_zmalloc/freee to unmocked */
 	MOCK_SET_P(spdk_dma_zmalloc, void *, &ut_spdk_dma_zmalloc);
@@ -602,9 +607,9 @@ test_nvme_allocate_request_null(void)
 	CU_ASSERT(req->cb_fn == cb_fn);
 	CU_ASSERT(req->cb_arg == cb_arg);
 	CU_ASSERT(req->pid == getpid());
-	CU_ASSERT(req->payload.type == NVME_PAYLOAD_TYPE_CONTIG);
+	CU_ASSERT(nvme_payload_type(&req->payload) == NVME_PAYLOAD_TYPE_CONTIG);
 	CU_ASSERT(req->payload.md == NULL);
-	CU_ASSERT(req->payload.u.contig == NULL);
+	CU_ASSERT(req->payload.contig_or_cb_arg == NULL);
 }
 
 static void
@@ -698,8 +703,8 @@ test_nvme_allocate_request_user_copy(void)
 	CU_ASSERT(req->user_cb_arg == cb_arg);
 	CU_ASSERT(req->user_buffer == buffer);
 	CU_ASSERT(req->cb_arg == req);
-	CU_ASSERT(memcmp(req->payload.u.contig, buffer, payload_size) == 0);
-	spdk_dma_free(req->payload.u.contig);
+	CU_ASSERT(memcmp(req->payload.contig_or_cb_arg, buffer, payload_size) == 0);
+	spdk_dma_free(req->payload.contig_or_cb_arg);
 
 	/* same thing but additional path coverage, no copy */
 	host_to_controller = false;
@@ -712,8 +717,8 @@ test_nvme_allocate_request_user_copy(void)
 	CU_ASSERT(req->user_cb_arg == cb_arg);
 	CU_ASSERT(req->user_buffer == buffer);
 	CU_ASSERT(req->cb_arg == req);
-	CU_ASSERT(memcmp(req->payload.u.contig, buffer, payload_size) != 0);
-	spdk_dma_free(req->payload.u.contig);
+	CU_ASSERT(memcmp(req->payload.contig_or_cb_arg, buffer, payload_size) != 0);
+	spdk_dma_free(req->payload.contig_or_cb_arg);
 
 	/* good buffer and valid payload size but make spdk_dma_zmalloc fail */
 	/* set the mock pointer to NULL for spdk_dma_zmalloc */
diff --git a/test/unit/lib/nvme/nvme_ctrlr.c/nvme_ctrlr_ut.c b/test/unit/lib/nvme/nvme_ctrlr.c/nvme_ctrlr_ut.c
index ecac6cf42..0bf228b19 100644
--- a/test/unit/lib/nvme/nvme_ctrlr.c/nvme_ctrlr_ut.c
+++ b/test/unit/lib/nvme/nvme_ctrlr.c/nvme_ctrlr_ut.c
@@ -47,6 +47,8 @@ struct spdk_trace_flag SPDK_LOG_NVME = {
 #include "nvme/nvme_ctrlr.c"
 #include "nvme/nvme_quirks.c"
 
+pid_t g_spdk_nvme_pid;
+
 struct nvme_driver _g_nvme_driver = {
 	.lock = PTHREAD_MUTEX_INITIALIZER,
 };
@@ -177,6 +179,12 @@ nvme_transport_qpair_reset(struct spdk_nvme_qpair *qpair)
 	return 0;
 }
 
+int
+nvme_driver_init(void)
+{
+	return 0;
+}
+
 int nvme_qpair_init(struct spdk_nvme_qpair *qpair, uint16_t id,
 		    struct spdk_nvme_ctrlr *ctrlr,
 		    enum spdk_nvme_qprio qprio,
@@ -203,7 +211,7 @@ spdk_nvme_ctrlr_cmd_set_feature(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
 				uint32_t cdw11, uint32_t cdw12, void *payload, uint32_t payload_size,
 				spdk_nvme_cmd_cb cb_fn, void *cb_arg)
 {
-	CU_ASSERT_FATAL(0);
+	CU_ASSERT(0);
 	return -1;
 }
 
@@ -212,7 +220,7 @@ spdk_nvme_ctrlr_cmd_get_feature(struct spdk_nvme_ctrlr *ctrlr, uint8_t feature,
 				uint32_t cdw11, void *payload, uint32_t payload_size,
 				spdk_nvme_cmd_cb cb_fn, void *cb_arg)
 {
-	CU_ASSERT_FATAL(0);
+	CU_ASSERT(0);
 	return -1;
 }
 
@@ -231,10 +239,8 @@ nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_request *re
 	CU_ASSERT(req->cmd.opc == SPDK_NVME_OPC_ASYNC_EVENT_REQUEST);
 
 	/*
-	 * Free the request here so it does not leak.
 	 * For the purposes of this unit test, we don't need to bother emulating request submission.
 	 */
-	free(req);
 
 	return 0;
 }
@@ -264,6 +270,29 @@ nvme_completion_poll_cb(void *arg, const struct spdk_nvme_cpl *cpl)
 	status->done = true;
 }
 
+int
+spdk_nvme_wait_for_completion_robust_lock(
+	struct spdk_nvme_qpair *qpair,
+	struct nvme_completion_poll_status *status,
+	pthread_mutex_t *robust_mutex)
+{
+	status->done = true;
+	memset(&status->cpl, 0, sizeof(status->cpl));
+	status->cpl.status.sc = 0;
+	if (set_status_cpl == 1) {
+		status->cpl.status.sc = 1;
+	}
+	return spdk_nvme_cpl_is_error(&status->cpl) ? -EIO : 0;
+}
+
+int
+spdk_nvme_wait_for_completion(struct spdk_nvme_qpair *qpair,
+			      struct nvme_completion_poll_status *status)
+{
+	return spdk_nvme_wait_for_completion_robust_lock(qpair, status, NULL);
+}
+
+
 int
 nvme_ctrlr_cmd_set_async_event_config(struct spdk_nvme_ctrlr *ctrlr,
 				      union spdk_nvme_feat_async_event_configuration config, spdk_nvme_cmd_cb cb_fn,
@@ -354,22 +383,13 @@ int
 nvme_ctrlr_cmd_fw_commit(struct spdk_nvme_ctrlr *ctrlr, const struct spdk_nvme_fw_commit *fw_commit,
 			 spdk_nvme_cmd_cb cb_fn, void *cb_arg)
 {
-	struct nvme_completion_poll_status *status;
-	struct spdk_nvme_cpl status_cpl = {};
-	struct spdk_nvme_status cpl_status = {};
-
-	status = cb_arg;
 	CU_ASSERT(fw_commit->ca == SPDK_NVME_FW_COMMIT_REPLACE_IMG);
-	CU_ASSERT(status->done == false);
 	if (fw_commit->fs == 0) {
 		return -1;
 	}
-	status->done = true;
-	status->cpl = status_cpl;
-	status->cpl.status = cpl_status;
-	status->cpl.status.sc = 1;
+	set_status_cpl = 1;
 	if (ctrlr->is_resetting == true) {
-		status->cpl.status.sc = 0;
+		set_status_cpl = 0;
 	}
 	return 0;
 }
@@ -379,25 +399,10 @@ nvme_ctrlr_cmd_fw_image_download(struct spdk_nvme_ctrlr *ctrlr,
 				 uint32_t size, uint32_t offset, void *payload,
 				 spdk_nvme_cmd_cb cb_fn, void *cb_arg)
 {
-	struct nvme_completion_poll_status *status;
-	struct spdk_nvme_cpl status_cpl = {};
-	struct spdk_nvme_status cpl_status = {};
-	status = cb_arg;
-
 	if ((size != 0 && payload == NULL) || (size == 0 && payload != NULL)) {
 		return -1;
 	}
-	if (set_size > 0) {
-		CU_ASSERT(status->done == false);
-	}
 	CU_ASSERT(offset == 0);
-	status->done = true;
-	status->cpl = status_cpl;
-	status->cpl.status = cpl_status;
-	status->cpl.status.sc = 0;
-	if (set_status_cpl == 1) {
-		status->cpl.status.sc = 1;
-	}
 	return 0;
 }
 
@@ -413,58 +418,19 @@ nvme_ns_construct(struct spdk_nvme_ns *ns, uint32_t id,
 	return 0;
 }
 
-struct nvme_request *
-nvme_allocate_request(struct spdk_nvme_qpair *qpair,
-		      const struct nvme_payload *payload, uint32_t payload_size,
-		      spdk_nvme_cmd_cb cb_fn,
-		      void *cb_arg)
-{
-	struct nvme_request *req = NULL;
-	req = calloc(1, sizeof(*req));
-
-	if (req != NULL) {
-		memset(req, 0, offsetof(struct nvme_request, children));
-
-		req->payload = *payload;
-		req->payload_size = payload_size;
-
-		req->cb_fn = cb_fn;
-		req->cb_arg = cb_arg;
-		req->qpair = qpair;
-		req->pid = getpid();
-	}
-
-	return req;
-}
-
-struct nvme_request *
-nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair, void *buffer, uint32_t payload_size,
-			     spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	struct nvme_payload payload;
-
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-
-	return nvme_allocate_request(qpair, &payload, payload_size, cb_fn, cb_arg);
-}
-
-struct nvme_request *
-nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	return nvme_allocate_request_contig(qpair, NULL, 0, cb_fn, cb_arg);
-}
-
-void
-nvme_free_request(struct nvme_request *req)
-{
-	free(req);
-}
+#define DECLARE_AND_CONSTRUCT_CTRLR()	\
+	struct spdk_nvme_ctrlr	ctrlr = {};	\
+	struct spdk_nvme_qpair	adminq = {};	\
+	struct nvme_request	req;		\
+						\
+	STAILQ_INIT(&adminq.free_req);		\
+	STAILQ_INSERT_HEAD(&adminq.free_req, &req, stailq);	\
+	ctrlr.adminq = &adminq;
 
 static void
 test_nvme_ctrlr_init_en_1_rdy_0(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -518,7 +484,7 @@ test_nvme_ctrlr_init_en_1_rdy_0(void)
 static void
 test_nvme_ctrlr_init_en_1_rdy_1(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -565,7 +531,7 @@ test_nvme_ctrlr_init_en_1_rdy_1(void)
 static void
 test_nvme_ctrlr_init_en_0_rdy_0_ams_rr(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -733,7 +699,7 @@ test_nvme_ctrlr_init_en_0_rdy_0_ams_rr(void)
 static void
 test_nvme_ctrlr_init_en_0_rdy_0_ams_wrr(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -902,7 +868,7 @@ test_nvme_ctrlr_init_en_0_rdy_0_ams_wrr(void)
 static void
 test_nvme_ctrlr_init_en_0_rdy_0_ams_vs(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -1072,7 +1038,7 @@ test_nvme_ctrlr_init_en_0_rdy_0_ams_vs(void)
 static void
 test_nvme_ctrlr_init_en_0_rdy_0(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -1111,7 +1077,7 @@ test_nvme_ctrlr_init_en_0_rdy_0(void)
 static void
 test_nvme_ctrlr_init_en_0_rdy_1(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	memset(&g_ut_nvme_regs, 0, sizeof(g_ut_nvme_regs));
 
@@ -1158,7 +1124,7 @@ setup_qpairs(struct spdk_nvme_ctrlr *ctrlr, uint32_t num_io_queues)
 {
 	uint32_t i;
 
-	CU_ASSERT_FATAL(pthread_mutex_init(&ctrlr->ctrlr_lock, NULL) == 0);
+	CU_ASSERT(pthread_mutex_init(&ctrlr->ctrlr_lock, NULL) == 0);
 
 	SPDK_CU_ASSERT_FATAL(nvme_ctrlr_construct(ctrlr) == 0);
 
@@ -1623,6 +1589,8 @@ test_spdk_nvme_ctrlr_update_firmware(void)
 	payload = &point_payload;
 	ret = spdk_nvme_ctrlr_update_firmware(&ctrlr, payload, set_size, slot, commit_action, &status);
 	CU_ASSERT(ret == 0);
+
+	set_status_cpl = 0;
 }
 
 int
diff --git a/test/unit/lib/nvme/nvme_ctrlr_cmd.c/nvme_ctrlr_cmd_ut.c b/test/unit/lib/nvme/nvme_ctrlr_cmd.c/nvme_ctrlr_cmd_ut.c
index 913f449e7..8cbc44761 100644
--- a/test/unit/lib/nvme/nvme_ctrlr_cmd.c/nvme_ctrlr_cmd_ut.c
+++ b/test/unit/lib/nvme/nvme_ctrlr_cmd.c/nvme_ctrlr_cmd_ut.c
@@ -38,6 +38,8 @@
 
 #define CTRLR_CDATA_ELPE   5
 
+pid_t g_spdk_nvme_pid;
+
 struct nvme_request g_req;
 
 uint32_t error_num_entries;
@@ -54,6 +56,11 @@ uint16_t abort_sqid = 1;
 uint32_t namespace_management_nsid = 1;
 uint32_t format_nvme_nsid = 1;
 
+uint32_t expected_feature_ns = 2;
+uint32_t expected_feature_cdw10 = SPDK_NVME_FEAT_LBA_RANGE_TYPE;
+uint32_t expected_feature_cdw11 = 1;
+uint32_t expected_feature_cdw12 = 1;
+
 typedef void (*verify_request_fn_t)(struct nvme_request *req);
 verify_request_fn_t verify_fn;
 
@@ -101,6 +108,15 @@ static void verify_set_feature_cmd(struct nvme_request *req)
 	CU_ASSERT(req->cmd.cdw12 == feature_cdw12);
 }
 
+static void verify_set_feature_ns_cmd(struct nvme_request *req)
+{
+	CU_ASSERT(req->cmd.opc == SPDK_NVME_OPC_SET_FEATURES);
+	CU_ASSERT(req->cmd.cdw10 == expected_feature_cdw10);
+	CU_ASSERT(req->cmd.cdw11 == expected_feature_cdw11);
+	CU_ASSERT(req->cmd.cdw12 == expected_feature_cdw12);
+	CU_ASSERT(req->cmd.nsid == expected_feature_ns);
+}
+
 static void verify_get_feature_cmd(struct nvme_request *req)
 {
 	CU_ASSERT(req->cmd.opc == SPDK_NVME_OPC_GET_FEATURES);
@@ -108,6 +124,14 @@ static void verify_get_feature_cmd(struct nvme_request *req)
 	CU_ASSERT(req->cmd.cdw11 == get_feature_cdw11);
 }
 
+static void verify_get_feature_ns_cmd(struct nvme_request *req)
+{
+	CU_ASSERT(req->cmd.opc == SPDK_NVME_OPC_GET_FEATURES);
+	CU_ASSERT(req->cmd.cdw10 == expected_feature_cdw10);
+	CU_ASSERT(req->cmd.cdw11 == expected_feature_cdw11);
+	CU_ASSERT(req->cmd.nsid == expected_feature_ns);
+}
+
 static void verify_abort_cmd(struct nvme_request *req)
 {
 	CU_ASSERT(req->cmd.opc == SPDK_NVME_OPC_ABORT);
@@ -245,46 +269,6 @@ static void verify_fw_image_download(struct nvme_request *req)
 	CU_ASSERT(req->cmd.cdw11 == fw_img_offset >> 2);
 }
 
-struct nvme_request *
-nvme_allocate_request(struct spdk_nvme_qpair *qpair,
-		      const struct nvme_payload *payload, uint32_t payload_size,
-		      spdk_nvme_cmd_cb cb_fn,
-		      void *cb_arg)
-{
-	struct nvme_request *req = &g_req;
-
-	memset(req, 0, sizeof(*req));
-
-	req->payload = *payload;
-	req->payload_size = payload_size;
-
-	req->cb_fn = cb_fn;
-	req->cb_arg = cb_arg;
-	req->qpair = qpair;
-	req->pid = getpid();
-
-	return req;
-}
-
-struct nvme_request *
-nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair, void *buffer, uint32_t payload_size,
-			     spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	struct nvme_payload payload;
-
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-	payload.md = NULL;
-
-	return nvme_allocate_request(qpair, &payload, payload_size, cb_fn, cb_arg);
-}
-
-struct nvme_request *
-nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	return nvme_allocate_request_contig(qpair, NULL, 0, cb_fn, cb_arg);
-}
-
 struct nvme_request *
 nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair, void *buffer, uint32_t payload_size,
 				spdk_nvme_cmd_cb cb_fn, void *cb_arg, bool host_to_controller)
@@ -293,12 +277,6 @@ nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair, void *buffer, uin
 	return nvme_allocate_request_contig(qpair, buffer, payload_size, cb_fn, cb_arg);
 }
 
-void
-nvme_free_request(struct nvme_request *req)
-{
-	return;
-}
-
 int
 nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_request *req)
 {
@@ -319,10 +297,19 @@ nvme_ctrlr_submit_admin_request(struct spdk_nvme_ctrlr *ctrlr, struct nvme_reque
 	return 0;
 }
 
+#define DECLARE_AND_CONSTRUCT_CTRLR()	\
+	struct spdk_nvme_ctrlr	ctrlr = {};	\
+	struct spdk_nvme_qpair	adminq = {};	\
+	struct nvme_request	req;		\
+						\
+	STAILQ_INIT(&adminq.free_req);		\
+	STAILQ_INSERT_HEAD(&adminq.free_req, &req, stailq);	\
+	ctrlr.adminq = &adminq;
+
 static void
 test_firmware_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_firmware_page		payload = {};
 
 	verify_fn = verify_firmware_log_page;
@@ -335,7 +322,7 @@ test_firmware_get_log_page(void)
 static void
 test_health_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr				ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_health_information_page	payload = {};
 
 	verify_fn = verify_health_log_page;
@@ -348,7 +335,7 @@ test_health_get_log_page(void)
 static void
 test_error_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr				ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_error_information_entry	payload = {};
 
 	ctrlr.cdata.elpe = CTRLR_CDATA_ELPE;
@@ -363,7 +350,7 @@ test_error_get_log_page(void)
 
 static void test_intel_smart_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_smart_information_page	payload = {};
 
 	verify_fn = verify_intel_smart_log_page;
@@ -374,7 +361,7 @@ static void test_intel_smart_get_log_page(void)
 
 static void test_intel_temperature_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_temperature_page	payload = {};
 
 	verify_fn = verify_intel_temperature_log_page;
@@ -385,7 +372,7 @@ static void test_intel_temperature_get_log_page(void)
 
 static void test_intel_read_latency_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_rw_latency_page	payload = {};
 
 	verify_fn = verify_intel_read_latency_log_page;
@@ -397,7 +384,7 @@ static void test_intel_read_latency_get_log_page(void)
 
 static void test_intel_write_latency_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_rw_latency_page	payload = {};
 
 	verify_fn = verify_intel_write_latency_log_page;
@@ -409,7 +396,7 @@ static void test_intel_write_latency_get_log_page(void)
 
 static void test_intel_get_log_page_directory(void)
 {
-	struct spdk_nvme_ctrlr				ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_log_page_directory	payload = {};
 
 	verify_fn = verify_intel_get_log_page_directory;
@@ -421,7 +408,7 @@ static void test_intel_get_log_page_directory(void)
 
 static void test_intel_marketing_description_get_log_page(void)
 {
-	struct spdk_nvme_ctrlr					ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_intel_marketing_description_page	payload = {};
 
 	verify_fn = verify_intel_marketing_description_log_page;
@@ -451,18 +438,41 @@ static void test_intel_get_log_pages(void)
 static void
 test_set_feature_cmd(void)
 {
-	struct spdk_nvme_ctrlr  ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	verify_fn = verify_set_feature_cmd;
 
 	spdk_nvme_ctrlr_cmd_set_feature(&ctrlr, feature, feature_cdw11, feature_cdw12, NULL, 0, NULL, NULL);
 }
 
+static void
+test_get_feature_ns_cmd(void)
+{
+	DECLARE_AND_CONSTRUCT_CTRLR();
+
+	verify_fn = verify_get_feature_ns_cmd;
+
+	spdk_nvme_ctrlr_cmd_get_feature_ns(&ctrlr, expected_feature_cdw10,
+					   expected_feature_cdw11, NULL, 0,
+					   NULL, NULL, expected_feature_ns);
+}
+
+static void
+test_set_feature_ns_cmd(void)
+{
+	DECLARE_AND_CONSTRUCT_CTRLR();
+
+	verify_fn = verify_set_feature_ns_cmd;
+
+	spdk_nvme_ctrlr_cmd_set_feature_ns(&ctrlr, expected_feature_cdw10,
+					   expected_feature_cdw11, expected_feature_cdw12,
+					   NULL, 0, NULL, NULL, expected_feature_ns);
+}
 
 static void
 test_get_feature_cmd(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	verify_fn = verify_get_feature_cmd;
 
@@ -472,7 +482,7 @@ test_get_feature_cmd(void)
 static void
 test_abort_cmd(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_qpair	qpair = {};
 
 	STAILQ_INIT(&ctrlr.queued_aborts);
@@ -486,7 +496,7 @@ test_abort_cmd(void)
 static void
 test_io_raw_cmd(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_qpair	qpair = {};
 	struct spdk_nvme_cmd	cmd = {};
 
@@ -498,7 +508,7 @@ test_io_raw_cmd(void)
 static void
 test_io_raw_cmd_with_md(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_qpair	qpair = {};
 	struct spdk_nvme_cmd	cmd = {};
 
@@ -517,7 +527,7 @@ test_get_log_pages(void)
 static void
 test_namespace_attach(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_ctrlr_list		payload = {};
 
 	verify_fn = verify_namespace_attach;
@@ -528,7 +538,7 @@ test_namespace_attach(void)
 static void
 test_namespace_detach(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_ctrlr_list		payload = {};
 
 	verify_fn = verify_namespace_detach;
@@ -539,7 +549,7 @@ test_namespace_detach(void)
 static void
 test_namespace_create(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_ns_data		payload = {};
 
 	verify_fn = verify_namespace_create;
@@ -549,7 +559,7 @@ test_namespace_create(void)
 static void
 test_namespace_delete(void)
 {
-	struct spdk_nvme_ctrlr			ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	verify_fn = verify_namespace_delete;
 	nvme_ctrlr_cmd_delete_ns(&ctrlr, namespace_management_nsid, NULL, NULL);
@@ -558,7 +568,7 @@ test_namespace_delete(void)
 static void
 test_format_nvme(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_format format = {};
 
 	verify_fn = verify_format_nvme;
@@ -569,7 +579,7 @@ test_format_nvme(void)
 static void
 test_fw_commit(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 	struct spdk_nvme_fw_commit fw_commit = {};
 
 	fw_commit.ca = SPDK_NVME_FW_COMMIT_REPLACE_AND_ENABLE_IMG;
@@ -583,7 +593,7 @@ test_fw_commit(void)
 static void
 test_fw_image_download(void)
 {
-	struct spdk_nvme_ctrlr	ctrlr = {};
+	DECLARE_AND_CONSTRUCT_CTRLR();
 
 	verify_fn = verify_fw_image_download;
 
@@ -609,7 +619,9 @@ int main(int argc, char **argv)
 	if (
 		CU_add_test(suite, "test ctrlr cmd get_log_pages", test_get_log_pages) == NULL
 		|| CU_add_test(suite, "test ctrlr cmd set_feature", test_set_feature_cmd) == NULL
+		|| CU_add_test(suite, "test ctrlr cmd set_feature_ns", test_set_feature_ns_cmd) == NULL
 		|| CU_add_test(suite, "test ctrlr cmd get_feature", test_get_feature_cmd) == NULL
+		|| CU_add_test(suite, "test ctrlr cmd get_feature_ns", test_get_feature_ns_cmd) == NULL
 		|| CU_add_test(suite, "test ctrlr cmd abort_cmd", test_abort_cmd) == NULL
 		|| CU_add_test(suite, "test ctrlr cmd io_raw_cmd", test_io_raw_cmd) == NULL
 		|| CU_add_test(suite, "test ctrlr cmd io_raw_cmd_with_md", test_io_raw_cmd_with_md) == NULL
diff --git a/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/.gitignore b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/.gitignore
new file mode 100644
index 000000000..2813105d4
--- /dev/null
+++ b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/.gitignore
@@ -0,0 +1 @@
+nvme_ctrlr_ocssd_cmd_ut
diff --git a/examples/ioat/kperf/kmod/Makefile b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/Makefile
similarity index 90%
rename from examples/ioat/kperf/kmod/Makefile
rename to test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/Makefile
index 0def9015c..9446b8d53 100644
--- a/examples/ioat/kperf/kmod/Makefile
+++ b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/Makefile
@@ -31,11 +31,8 @@
 #  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #
 
-obj-m := dmaperf.o
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
 
-KDIR := /lib/modules/$(shell uname -r)/build
+TEST_FILE = nvme_ctrlr_ocssd_cmd_ut.c
 
-all:
-	$(MAKE) -C $(KDIR) M=$(shell pwd) modules
-clean:
-	$(MAKE) -C $(KDIR) M=$(shell pwd) clean
+include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/nvme_ctrlr_ocssd_cmd_ut.c b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/nvme_ctrlr_ocssd_cmd_ut.c
new file mode 100644
index 000000000..98eccf348
--- /dev/null
+++ b/test/unit/lib/nvme/nvme_ctrlr_ocssd_cmd.c/nvme_ctrlr_ocssd_cmd_ut.c
@@ -0,0 +1,116 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk_cunit.h"
+
+#include "nvme/nvme_ctrlr_ocssd_cmd.c"
+
+#define DECLARE_AND_CONSTRUCT_CTRLR()	\
+	struct spdk_nvme_ctrlr	ctrlr = {};	\
+	struct spdk_nvme_qpair	adminq = {};	\
+	struct nvme_request	req;		\
+						\
+	STAILQ_INIT(&adminq.free_req);		\
+	STAILQ_INSERT_HEAD(&adminq.free_req, &req, stailq);	\
+	ctrlr.adminq = &adminq;
+
+pid_t g_spdk_nvme_pid;
+struct nvme_request g_req;
+typedef void (*verify_request_fn_t)(struct nvme_request *req);
+verify_request_fn_t verify_fn;
+
+static const uint32_t expected_geometry_ns = 1;
+
+int
+nvme_ctrlr_submit_admin_request(struct spdk_nvme_ctrlr *ctrlr, struct nvme_request *req)
+{
+	verify_fn(req);
+	memset(req, 0, sizeof(*req));
+	return 0;
+}
+
+struct nvme_request *
+nvme_allocate_request_user_copy(struct spdk_nvme_qpair *qpair, void *buffer, uint32_t payload_size,
+				spdk_nvme_cmd_cb cb_fn, void *cb_arg, bool host_to_controller)
+{
+	/* For the unit test, we don't actually need to copy the buffer */
+	return nvme_allocate_request_contig(qpair, buffer, payload_size, cb_fn, cb_arg);
+}
+
+static void verify_geometry_cmd(struct nvme_request *req)
+{
+	CU_ASSERT(req->cmd.opc == SPDK_OCSSD_OPC_GEOMETRY);
+	CU_ASSERT(req->cmd.nsid == expected_geometry_ns);
+}
+
+static void
+test_geometry_cmd(void)
+{
+	DECLARE_AND_CONSTRUCT_CTRLR();
+
+	struct spdk_ocssd_geometry_data geo;
+
+	verify_fn = verify_geometry_cmd;
+
+	spdk_nvme_ocssd_ctrlr_cmd_geometry(&ctrlr, expected_geometry_ns, &geo,
+					   sizeof(geo), NULL, NULL);
+}
+
+int main(int argc, char **argv)
+{
+	CU_pSuite	suite = NULL;
+	unsigned int	num_failures;
+
+	if (CU_initialize_registry() != CUE_SUCCESS) {
+		return CU_get_error();
+	}
+
+	suite = CU_add_suite("nvme_ctrlr_cmd", NULL, NULL);
+	if (suite == NULL) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	if (
+		CU_add_test(suite, "test ocssd ctrlr geometry cmd ", test_geometry_cmd) == NULL
+	) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	CU_basic_set_mode(CU_BRM_VERBOSE);
+	CU_basic_run_tests();
+	num_failures = CU_get_number_of_failures();
+	CU_cleanup_registry();
+	return num_failures;
+}
diff --git a/test/unit/lib/nvme/nvme_ns.c/nvme_ns_ut.c b/test/unit/lib/nvme/nvme_ns.c/nvme_ns_ut.c
index 3af9f68f2..cdfb4951d 100644
--- a/test/unit/lib/nvme/nvme_ns.c/nvme_ns_ut.c
+++ b/test/unit/lib/nvme/nvme_ns.c/nvme_ns_ut.c
@@ -41,6 +41,11 @@
 
 SPDK_LOG_REGISTER_COMPONENT("nvme", SPDK_LOG_NVME)
 
+DEFINE_STUB(spdk_nvme_wait_for_completion_robust_lock, int,
+	    (struct spdk_nvme_qpair *qpair,
+	     struct nvme_completion_poll_status *status,
+	     pthread_mutex_t *robust_mutex), 0);
+
 int
 nvme_ctrlr_cmd_identify(struct spdk_nvme_ctrlr *ctrlr, uint8_t cns, uint16_t cntid, uint32_t nsid,
 			void *payload, size_t payload_size,
diff --git a/test/unit/lib/nvme/nvme_ns_cmd.c/nvme_ns_cmd_ut.c b/test/unit/lib/nvme/nvme_ns_cmd.c/nvme_ns_cmd_ut.c
index 445972de7..a8f293fc4 100644
--- a/test/unit/lib/nvme/nvme_ns_cmd.c/nvme_ns_cmd_ut.c
+++ b/test/unit/lib/nvme/nvme_ns_cmd.c/nvme_ns_cmd_ut.c
@@ -38,6 +38,10 @@
 
 #include "common/lib/test_env.c"
 
+DEFINE_STUB(spdk_nvme_qpair_process_completions, int32_t,
+	    (struct spdk_nvme_qpair *qpair,
+	     uint32_t max_completions), 0);
+
 static struct nvme_driver _g_nvme_driver = {
 	.lock = PTHREAD_MUTEX_INITIALIZER,
 };
@@ -200,6 +204,7 @@ prepare_for_test(struct spdk_nvme_ns *ns, struct spdk_nvme_ctrlr *ctrlr,
 	ctrlr->flags = 0;
 	ctrlr->min_page_size = 4096;
 	ctrlr->page_size = 4096;
+	memset(&ctrlr->opts, 0, sizeof(ctrlr->opts));
 	memset(ns, 0, sizeof(*ns));
 	ns->ctrlr = ctrlr;
 	ns->sector_size = sector_size;
@@ -500,6 +505,11 @@ test_cmd_child_request(void)
 	SPDK_CU_ASSERT_FATAL(g_request != NULL);
 	CU_ASSERT(g_request->num_children == 4);
 
+	rc = spdk_nvme_ns_cmd_read(&ns, &qpair, payload, lba, (DEFAULT_IO_QUEUE_REQUESTS + 1) * sector_size,
+				   NULL,
+				   NULL, 0);
+	SPDK_CU_ASSERT_FATAL(rc == -EINVAL);
+
 	TAILQ_FOREACH_SAFE(child, &g_request->children, child_tailq, tmp) {
 		nvme_request_remove_child(g_request, child);
 		CU_ASSERT(child->payload_offset == offset);
@@ -595,7 +605,7 @@ test_nvme_ns_cmd_dataset_management(void)
 	CU_ASSERT(g_request->cmd.nsid == ns.id);
 	CU_ASSERT(g_request->cmd.cdw10 == 0);
 	CU_ASSERT(g_request->cmd.cdw11 == SPDK_NVME_DSM_ATTR_DEALLOCATE);
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 
 	/* TRIM 256 LBAs */
@@ -607,7 +617,7 @@ test_nvme_ns_cmd_dataset_management(void)
 	CU_ASSERT(g_request->cmd.nsid == ns.id);
 	CU_ASSERT(g_request->cmd.cdw10 == 255u);
 	CU_ASSERT(g_request->cmd.cdw11 == SPDK_NVME_DSM_ATTR_DEALLOCATE);
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 
 	rc = spdk_nvme_ns_cmd_dataset_management(&ns, &qpair, SPDK_NVME_DSM_ATTR_DEALLOCATE,
@@ -636,10 +646,10 @@ test_nvme_ns_cmd_readv(void)
 	SPDK_CU_ASSERT_FATAL(rc == 0);
 	SPDK_CU_ASSERT_FATAL(g_request != NULL);
 	CU_ASSERT(g_request->cmd.opc == SPDK_NVME_OPC_READ);
-	CU_ASSERT(g_request->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	CU_ASSERT(g_request->payload.u.sgl.reset_sgl_fn == nvme_request_reset_sgl);
-	CU_ASSERT(g_request->payload.u.sgl.next_sge_fn == nvme_request_next_sge);
-	CU_ASSERT(g_request->payload.u.sgl.cb_arg == &sge_length);
+	CU_ASSERT(nvme_payload_type(&g_request->payload) == NVME_PAYLOAD_TYPE_SGL);
+	CU_ASSERT(g_request->payload.reset_sgl_fn == nvme_request_reset_sgl);
+	CU_ASSERT(g_request->payload.next_sge_fn == nvme_request_next_sge);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == &sge_length);
 	CU_ASSERT(g_request->cmd.nsid == ns.id);
 
 	rc = spdk_nvme_ns_cmd_readv(&ns, &qpair, 0x1000, 256, NULL, cb_arg, 0, nvme_request_reset_sgl,
@@ -671,10 +681,10 @@ test_nvme_ns_cmd_writev(void)
 	SPDK_CU_ASSERT_FATAL(rc == 0);
 	SPDK_CU_ASSERT_FATAL(g_request != NULL);
 	CU_ASSERT(g_request->cmd.opc == SPDK_NVME_OPC_WRITE);
-	CU_ASSERT(g_request->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	CU_ASSERT(g_request->payload.u.sgl.reset_sgl_fn == nvme_request_reset_sgl);
-	CU_ASSERT(g_request->payload.u.sgl.next_sge_fn == nvme_request_next_sge);
-	CU_ASSERT(g_request->payload.u.sgl.cb_arg == &sge_length);
+	CU_ASSERT(nvme_payload_type(&g_request->payload) == NVME_PAYLOAD_TYPE_SGL);
+	CU_ASSERT(g_request->payload.reset_sgl_fn == nvme_request_reset_sgl);
+	CU_ASSERT(g_request->payload.next_sge_fn == nvme_request_next_sge);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == &sge_length);
 	CU_ASSERT(g_request->cmd.nsid == ns.id);
 
 	rc = spdk_nvme_ns_cmd_writev(&ns, &qpair, 0x1000, 256, NULL, cb_arg, 0,
@@ -706,10 +716,10 @@ test_nvme_ns_cmd_comparev(void)
 	SPDK_CU_ASSERT_FATAL(rc == 0);
 	SPDK_CU_ASSERT_FATAL(g_request != NULL);
 	CU_ASSERT(g_request->cmd.opc == SPDK_NVME_OPC_COMPARE);
-	CU_ASSERT(g_request->payload.type == NVME_PAYLOAD_TYPE_SGL);
-	CU_ASSERT(g_request->payload.u.sgl.reset_sgl_fn == nvme_request_reset_sgl);
-	CU_ASSERT(g_request->payload.u.sgl.next_sge_fn == nvme_request_next_sge);
-	CU_ASSERT(g_request->payload.u.sgl.cb_arg == &sge_length);
+	CU_ASSERT(nvme_payload_type(&g_request->payload) == NVME_PAYLOAD_TYPE_SGL);
+	CU_ASSERT(g_request->payload.reset_sgl_fn == nvme_request_reset_sgl);
+	CU_ASSERT(g_request->payload.next_sge_fn == nvme_request_next_sge);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == &sge_length);
 	CU_ASSERT(g_request->cmd.nsid == ns.id);
 
 	rc = spdk_nvme_ns_cmd_comparev(&ns, &qpair, 0x1000, 256, NULL, cb_arg, 0,
@@ -789,7 +799,7 @@ test_nvme_ns_cmd_reservation_register(void)
 
 	CU_ASSERT(g_request->cmd.cdw10 == tmp_cdw10);
 
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 	free(payload);
 	cleanup_after_test(&qpair);
@@ -827,7 +837,7 @@ test_nvme_ns_cmd_reservation_release(void)
 
 	CU_ASSERT(g_request->cmd.cdw10 == tmp_cdw10);
 
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 	free(payload);
 	cleanup_after_test(&qpair);
@@ -865,7 +875,7 @@ test_nvme_ns_cmd_reservation_acquire(void)
 
 	CU_ASSERT(g_request->cmd.cdw10 == tmp_cdw10);
 
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 	free(payload);
 	cleanup_after_test(&qpair);
@@ -897,7 +907,7 @@ test_nvme_ns_cmd_reservation_report(void)
 
 	CU_ASSERT(g_request->cmd.cdw10 == (size / 4));
 
-	spdk_dma_free(g_request->payload.u.contig);
+	spdk_dma_free(g_request->payload.contig_or_cb_arg);
 	nvme_free_request(g_request);
 	free(payload);
 	cleanup_after_test(&qpair);
diff --git a/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/.gitignore b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/.gitignore
new file mode 100644
index 000000000..8f4f47a17
--- /dev/null
+++ b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/.gitignore
@@ -0,0 +1 @@
+nvme_ns_ocssd_cmd_ut
diff --git a/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/Makefile b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/Makefile
new file mode 100644
index 000000000..35fdb83a0
--- /dev/null
+++ b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/Makefile
@@ -0,0 +1,38 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
+
+TEST_FILE = nvme_ns_ocssd_cmd_ut.c
+
+include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/nvme_ns_ocssd_cmd_ut.c b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/nvme_ns_ocssd_cmd_ut.c
new file mode 100644
index 000000000..5d1f42b8d
--- /dev/null
+++ b/test/unit/lib/nvme/nvme_ns_ocssd_cmd.c/nvme_ns_ocssd_cmd_ut.c
@@ -0,0 +1,673 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk_cunit.h"
+
+#include "nvme/nvme_ns_ocssd_cmd.c"
+#include "nvme/nvme_ns_cmd.c"
+#include "nvme/nvme.c"
+
+#include "common/lib/test_env.c"
+
+DEFINE_STUB(spdk_nvme_qpair_process_completions, int32_t,
+	    (struct spdk_nvme_qpair *qpair,
+	     uint32_t max_completions), 0);
+
+static struct nvme_driver _g_nvme_driver = {
+	.lock = PTHREAD_MUTEX_INITIALIZER,
+};
+
+static struct nvme_request *g_request = NULL;
+
+int
+nvme_qpair_submit_request(struct spdk_nvme_qpair *qpair, struct nvme_request *req)
+{
+	g_request = req;
+
+	return 0;
+}
+
+void
+nvme_ctrlr_destruct(struct spdk_nvme_ctrlr *ctrlr)
+{
+}
+
+void
+nvme_ctrlr_proc_get_ref(struct spdk_nvme_ctrlr *ctrlr)
+{
+	return;
+}
+
+
+int
+nvme_ctrlr_process_init(struct spdk_nvme_ctrlr *ctrlr)
+{
+	return 0;
+}
+
+void
+nvme_ctrlr_proc_put_ref(struct spdk_nvme_ctrlr *ctrlr)
+{
+	return;
+}
+
+void
+spdk_nvme_ctrlr_get_default_ctrlr_opts(struct spdk_nvme_ctrlr_opts *opts, size_t opts_size)
+{
+	memset(opts, 0, sizeof(*opts));
+}
+
+bool
+spdk_nvme_transport_available(enum spdk_nvme_transport_type trtype)
+{
+	return true;
+}
+
+struct spdk_nvme_ctrlr *nvme_transport_ctrlr_construct(const struct spdk_nvme_transport_id *trid,
+		const struct spdk_nvme_ctrlr_opts *opts,
+		void *devhandle)
+{
+	return NULL;
+}
+
+int
+nvme_ctrlr_get_ref_count(struct spdk_nvme_ctrlr *ctrlr)
+{
+	return 0;
+}
+
+int
+nvme_transport_ctrlr_scan(const struct spdk_nvme_transport_id *trid,
+			  void *cb_ctx,
+			  spdk_nvme_probe_cb probe_cb,
+			  spdk_nvme_remove_cb remove_cb,
+			  bool direct_connect)
+{
+	return 0;
+}
+
+uint32_t
+spdk_nvme_ns_get_max_io_xfer_size(struct spdk_nvme_ns *ns)
+{
+	return ns->ctrlr->max_xfer_size;
+}
+
+static void
+prepare_for_test(struct spdk_nvme_ns *ns, struct spdk_nvme_ctrlr *ctrlr,
+		 struct spdk_nvme_qpair *qpair,
+		 uint32_t sector_size, uint32_t md_size, uint32_t max_xfer_size,
+		 uint32_t stripe_size, bool extended_lba)
+{
+	uint32_t num_requests = 32;
+	uint32_t i;
+
+	ctrlr->max_xfer_size = max_xfer_size;
+	/*
+	 * Clear the flags field - we especially want to make sure the SGL_SUPPORTED flag is not set
+	 *  so that we test the SGL splitting path.
+	 */
+	ctrlr->flags = 0;
+	ctrlr->min_page_size = 4096;
+	ctrlr->page_size = 4096;
+	memset(&ctrlr->opts, 0, sizeof(ctrlr->opts));
+	memset(ns, 0, sizeof(*ns));
+	ns->ctrlr = ctrlr;
+	ns->sector_size = sector_size;
+	ns->extended_lba_size = sector_size;
+	if (extended_lba) {
+		ns->flags |= SPDK_NVME_NS_EXTENDED_LBA_SUPPORTED;
+		ns->extended_lba_size += md_size;
+	}
+	ns->md_size = md_size;
+	ns->sectors_per_max_io = spdk_nvme_ns_get_max_io_xfer_size(ns) / ns->extended_lba_size;
+	ns->sectors_per_stripe = stripe_size / ns->extended_lba_size;
+
+	memset(qpair, 0, sizeof(*qpair));
+	qpair->ctrlr = ctrlr;
+	qpair->req_buf = calloc(num_requests, sizeof(struct nvme_request));
+	SPDK_CU_ASSERT_FATAL(qpair->req_buf != NULL);
+
+	for (i = 0; i < num_requests; i++) {
+		struct nvme_request *req = qpair->req_buf + i * sizeof(struct nvme_request);
+
+		STAILQ_INSERT_HEAD(&qpair->free_req, req, stailq);
+	}
+
+	g_request = NULL;
+}
+
+static void
+cleanup_after_test(struct spdk_nvme_qpair *qpair)
+{
+	free(qpair->req_buf);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_reset_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	uint64_t lba_list = 0x12345678;
+	spdk_nvme_ocssd_ns_cmd_vector_reset(&ns, &qpair, &lba_list, 1,
+					    NULL, NULL, NULL);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_RESET);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_reset(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	uint64_t lba_list[vector_size];
+	spdk_nvme_ocssd_ns_cmd_vector_reset(&ns, &qpair, lba_list, vector_size,
+					    NULL, NULL, NULL);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_RESET);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_read_with_md_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	md_size = 0x80;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size);
+	char *metadata = malloc(md_size);
+	uint64_t lba_list = 0x12345678;
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+	SPDK_CU_ASSERT_FATAL(metadata != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, md_size, max_xfer_size, 0, false);
+	rc = spdk_nvme_ocssd_ns_cmd_vector_read_with_md(&ns, &qpair, buffer, metadata,
+			&lba_list, 1, NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload.md == metadata);
+	CU_ASSERT(g_request->payload_size == PAGE_SIZE);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_READ);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+	free(metadata);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_read_with_md(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	md_size = 0x80;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size * vector_size);
+	char *metadata = malloc(md_size * vector_size);
+	uint64_t lba_list[vector_size];
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+	SPDK_CU_ASSERT_FATAL(metadata != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, md_size, max_xfer_size, 0, false);
+	rc = spdk_nvme_ocssd_ns_cmd_vector_read_with_md(&ns, &qpair, buffer, metadata,
+			lba_list, vector_size,
+			NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload.md == metadata);
+	CU_ASSERT(g_request->payload_size == max_xfer_size);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_READ);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+	free(metadata);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_read_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size);
+	uint64_t lba_list = 0x12345678;
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	rc = spdk_nvme_ocssd_ns_cmd_vector_read(&ns, &qpair, buffer, &lba_list, 1,
+						NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload_size == PAGE_SIZE);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_READ);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+	free(buffer);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_read(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size * vector_size);
+	uint64_t lba_list[vector_size];
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	rc = spdk_nvme_ocssd_ns_cmd_vector_read(&ns, &qpair, buffer, lba_list, vector_size,
+						NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload_size == max_xfer_size);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_READ);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+	free(buffer);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_write_with_md_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	md_size = 0x80;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size);
+	char *metadata = malloc(md_size);
+	uint64_t lba_list = 0x12345678;
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+	SPDK_CU_ASSERT_FATAL(metadata != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, md_size, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_write_with_md(&ns, &qpair, buffer, metadata,
+			&lba_list, 1, NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload.md == metadata);
+	CU_ASSERT(g_request->payload_size == PAGE_SIZE);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_WRITE);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+	free(metadata);
+}
+
+
+static void
+test_nvme_ocssd_ns_cmd_vector_write_with_md(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	md_size = 0x80;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size * vector_size);
+	char *metadata = malloc(md_size * vector_size);
+	uint64_t lba_list[vector_size];
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+	SPDK_CU_ASSERT_FATAL(metadata != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, md_size, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_write_with_md(&ns, &qpair, buffer, metadata,
+			lba_list, vector_size,
+			NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload.md == metadata);
+	CU_ASSERT(g_request->payload_size == max_xfer_size);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_WRITE);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+	free(metadata);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_write_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size);
+	uint64_t lba_list = 0x12345678;
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_write(&ns, &qpair, buffer,
+					    &lba_list, 1,    NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload_size == PAGE_SIZE);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_WRITE);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_write(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	char *buffer = malloc(sector_size * vector_size);
+	uint64_t lba_list[vector_size];
+
+	SPDK_CU_ASSERT_FATAL(buffer != NULL);
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_write(&ns, &qpair, buffer,
+					    lba_list, vector_size,
+					    NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+
+	CU_ASSERT(g_request->payload_size == max_xfer_size);
+	CU_ASSERT(g_request->payload.contig_or_cb_arg == buffer);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_WRITE);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+
+	free(buffer);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_copy_single_entry(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	uint64_t src_lba_list = 0x12345678;
+	uint64_t dst_lba_list = 0x87654321;
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_copy(&ns, &qpair, &dst_lba_list, &src_lba_list, 1,
+					   NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_COPY);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw10 == src_lba_list);
+	CU_ASSERT(g_request->cmd.cdw12 == 0);
+	CU_ASSERT(g_request->cmd.cdw14 == dst_lba_list);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+}
+
+static void
+test_nvme_ocssd_ns_cmd_vector_copy(void)
+{
+	const uint32_t	max_xfer_size = 0x10000;
+	const uint32_t	sector_size = 0x1000;
+	const uint32_t	vector_size = 0x10;
+
+	struct spdk_nvme_ns	ns;
+	struct spdk_nvme_ctrlr	ctrlr;
+	struct spdk_nvme_qpair	qpair;
+
+	int rc = 0;
+
+	uint64_t src_lba_list[vector_size];
+	uint64_t dst_lba_list[vector_size];
+
+	prepare_for_test(&ns, &ctrlr, &qpair, sector_size, 0, max_xfer_size, 0, false);
+	spdk_nvme_ocssd_ns_cmd_vector_copy(&ns, &qpair,
+					   dst_lba_list, src_lba_list, vector_size,
+					   NULL, NULL, 0);
+
+	SPDK_CU_ASSERT_FATAL(rc == 0);
+	SPDK_CU_ASSERT_FATAL(g_request != NULL);
+	SPDK_CU_ASSERT_FATAL(g_request->num_children == 0);
+	CU_ASSERT(g_request->cmd.opc == SPDK_OCSSD_OPC_VECTOR_COPY);
+	CU_ASSERT(g_request->cmd.nsid == ns.id);
+	CU_ASSERT(g_request->cmd.cdw12 == vector_size - 1);
+
+	nvme_free_request(g_request);
+	cleanup_after_test(&qpair);
+}
+
+int main(int argc, char **argv)
+{
+	CU_pSuite	suite = NULL;
+	unsigned int	num_failures;
+
+	if (CU_initialize_registry() != CUE_SUCCESS) {
+		return CU_get_error();
+	}
+
+	suite = CU_add_suite("nvme_ns_cmd", NULL, NULL);
+	if (suite == NULL) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	if (
+		CU_add_test(suite, "nvme_ns_ocssd_cmd_vector_reset", test_nvme_ocssd_ns_cmd_vector_reset) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_reset_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_reset_single_entry) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_read_with_md",
+			       test_nvme_ocssd_ns_cmd_vector_read_with_md) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_read_with_md_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_read_with_md_single_entry) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_read", test_nvme_ocssd_ns_cmd_vector_read) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_read_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_read_single_entry) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_write_with_md",
+			       test_nvme_ocssd_ns_cmd_vector_write_with_md) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_write_with_md_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_write_with_md_single_entry) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_write", test_nvme_ocssd_ns_cmd_vector_write) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_write_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_write_single_entry) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_copy", test_nvme_ocssd_ns_cmd_vector_copy) == NULL
+		|| CU_add_test(suite, "nvme_ocssd_ns_cmd_vector_copy_single_entry",
+			       test_nvme_ocssd_ns_cmd_vector_copy_single_entry) == NULL
+	) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	g_spdk_nvme_driver = &_g_nvme_driver;
+
+	CU_basic_set_mode(CU_BRM_VERBOSE);
+	CU_basic_run_tests();
+	num_failures = CU_get_number_of_failures();
+	CU_cleanup_registry();
+	return num_failures;
+}
diff --git a/test/unit/lib/nvme/nvme_pcie.c/nvme_pcie_ut.c b/test/unit/lib/nvme/nvme_pcie.c/nvme_pcie_ut.c
index d905506f3..b5a5d7097 100644
--- a/test/unit/lib/nvme/nvme_pcie.c/nvme_pcie_ut.c
+++ b/test/unit/lib/nvme/nvme_pcie.c/nvme_pcie_ut.c
@@ -39,9 +39,25 @@
 
 #include "nvme/nvme_pcie.c"
 
+pid_t g_spdk_nvme_pid;
+
 DEFINE_STUB(spdk_mem_register, int, (void *vaddr, size_t len), 0);
 DEFINE_STUB(spdk_mem_unregister, int, (void *vaddr, size_t len), 0);
 
+DEFINE_STUB(spdk_nvme_ctrlr_get_process,
+	    struct spdk_nvme_ctrlr_process *,
+	    (struct spdk_nvme_ctrlr *ctrlr, pid_t pid),
+	    NULL);
+
+DEFINE_STUB(spdk_nvme_ctrlr_get_current_process,
+	    struct spdk_nvme_ctrlr_process *,
+	    (struct spdk_nvme_ctrlr *ctrlr),
+	    NULL);
+
+DEFINE_STUB(spdk_nvme_wait_for_completion, int,
+	    (struct spdk_nvme_qpair *qpair,
+	     struct nvme_completion_poll_status *status), 0);
+
 struct spdk_trace_flag SPDK_LOG_NVME = {
 	.name = "nvme",
 	.enabled = false,
@@ -99,6 +115,12 @@ nvme_qpair_init(struct spdk_nvme_qpair *qpair, uint16_t id,
 	abort();
 }
 
+void
+nvme_qpair_deinit(struct spdk_nvme_qpair *qpair)
+{
+	abort();
+}
+
 int
 spdk_pci_nvme_enumerate(spdk_pci_enum_cb enum_cb, void *enum_ctx)
 {
@@ -204,20 +226,21 @@ nvme_ctrlr_get_cap(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_cap_register *
 	abort();
 }
 
-void
-nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap)
+int
+nvme_ctrlr_get_vs(struct spdk_nvme_ctrlr *ctrlr, union spdk_nvme_vs_register *vs)
 {
 	abort();
 }
 
-uint64_t
-nvme_get_quirks(const struct spdk_pci_id *id)
+void
+nvme_ctrlr_init_cap(struct spdk_nvme_ctrlr *ctrlr, const union spdk_nvme_cap_register *cap,
+		    const union spdk_nvme_vs_register *vs)
 {
 	abort();
 }
 
-void
-nvme_free_request(struct nvme_request *req)
+uint64_t
+nvme_get_quirks(const struct spdk_pci_id *id)
 {
 	abort();
 }
@@ -253,12 +276,6 @@ nvme_ctrlr_submit_admin_request(struct spdk_nvme_ctrlr *ctrlr,
 	abort();
 }
 
-struct nvme_request *
-nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	abort();
-}
-
 void
 nvme_completion_poll_cb(void *arg, const struct spdk_nvme_cpl *cpl)
 {
@@ -277,6 +294,14 @@ nvme_qpair_enable(struct spdk_nvme_qpair *qpair)
 	abort();
 }
 
+int
+nvme_request_check_timeout(struct nvme_request *req, uint16_t cid,
+			   struct spdk_nvme_ctrlr_process *active_proc,
+			   uint64_t now_tick)
+{
+	abort();
+}
+
 struct spdk_nvme_ctrlr *
 spdk_nvme_get_ctrlr_by_trid_unsafe(const struct spdk_nvme_transport_id *trid)
 {
@@ -441,10 +466,7 @@ test_sgl_req(void)
 	uint64_t		i;
 	struct io_request	io_req = {};
 
-	payload.type = NVME_PAYLOAD_TYPE_SGL;
-	payload.u.sgl.reset_sgl_fn = nvme_request_reset_sgl;
-	payload.u.sgl.next_sge_fn = nvme_request_next_sge;
-	payload.u.sgl.cb_arg = &io_req;
+	payload = NVME_PAYLOAD_SGL(nvme_request_reset_sgl, nvme_request_next_sge, &io_req, NULL);
 
 	prepare_submit_request_test(&qpair, &ctrlr);
 	req = nvme_allocate_request(&payload, 0x1000, NULL, &io_req);
@@ -519,10 +541,7 @@ test_hw_sgl_req(void)
 	uint64_t		i;
 	struct io_request	io_req = {};
 
-	payload.type = NVME_PAYLOAD_TYPE_SGL;
-	payload.u.sgl.reset_sgl_fn = nvme_request_reset_sgl;
-	payload.u.sgl.next_sge_fn = nvme_request_next_sge;
-	payload.u.sgl.cb_arg = &io_req;
+	payload = NVME_PAYLOAD_SGL(nvme_request_reset_sgl, nvme_request_next_sge, &io_req, NULL);
 
 	prepare_submit_request_test(&qpair, &ctrlr);
 	req = nvme_allocate_request(&payload, 0x1000, NULL, &io_req);
diff --git a/test/unit/lib/nvme/nvme_qpair.c/nvme_qpair_ut.c b/test/unit/lib/nvme/nvme_qpair.c/nvme_qpair_ut.c
index 1fb5c8c39..11fea8c71 100644
--- a/test/unit/lib/nvme/nvme_qpair.c/nvme_qpair_ut.c
+++ b/test/unit/lib/nvme/nvme_qpair.c/nvme_qpair_ut.c
@@ -37,6 +37,8 @@
 
 #include "common/lib/test_env.c"
 
+pid_t g_spdk_nvme_pid;
+
 bool trace_flag = false;
 #define SPDK_LOG_NVME trace_flag
 
@@ -46,66 +48,6 @@ struct nvme_driver _g_nvme_driver = {
 	.lock = PTHREAD_MUTEX_INITIALIZER,
 };
 
-struct nvme_request *
-nvme_allocate_request(struct spdk_nvme_qpair *qpair,
-		      const struct nvme_payload *payload, uint32_t payload_size,
-		      spdk_nvme_cmd_cb cb_fn,
-		      void *cb_arg)
-{
-	struct nvme_request *req;
-
-	req = STAILQ_FIRST(&qpair->free_req);
-	if (req == NULL) {
-		return NULL;
-	}
-
-	STAILQ_REMOVE_HEAD(&qpair->free_req, stailq);
-
-	/*
-	 * Only memset up to (but not including) the children
-	 *  TAILQ_ENTRY.  children, and following members, are
-	 *  only used as part of I/O splitting so we avoid
-	 *  memsetting them until it is actually needed.
-	 *  They will be initialized in nvme_request_add_child()
-	 *  if the request is split.
-	 */
-	memset(req, 0, offsetof(struct nvme_request, children));
-	req->cb_fn = cb_fn;
-	req->cb_arg = cb_arg;
-	req->payload = *payload;
-	req->payload_size = payload_size;
-	req->qpair = qpair;
-	req->pid = getpid();
-
-	return req;
-}
-
-struct nvme_request *
-nvme_allocate_request_contig(struct spdk_nvme_qpair *qpair, void *buffer, uint32_t payload_size,
-			     spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	struct nvme_payload payload;
-
-	payload.type = NVME_PAYLOAD_TYPE_CONTIG;
-	payload.u.contig = buffer;
-
-	return nvme_allocate_request(qpair, &payload, payload_size, cb_fn, cb_arg);
-}
-
-struct nvme_request *
-nvme_allocate_request_null(struct spdk_nvme_qpair *qpair, spdk_nvme_cmd_cb cb_fn, void *cb_arg)
-{
-	return nvme_allocate_request_contig(qpair, NULL, 0, cb_fn, cb_arg);
-}
-
-void
-nvme_free_request(struct nvme_request *req)
-{
-	SPDK_CU_ASSERT_FATAL(req != NULL);
-	SPDK_CU_ASSERT_FATAL(req->qpair != NULL);
-	STAILQ_INSERT_HEAD(&req->qpair->free_req, req, stailq);
-}
-
 void
 nvme_request_remove_child(struct nvme_request *parent,
 			  struct nvme_request *child)
@@ -336,6 +278,16 @@ static void test_nvme_completion_is_retry(void)
 	cpl.status.sct = SPDK_NVME_SCT_MEDIA_ERROR;
 	CU_ASSERT_FALSE(nvme_completion_is_retry(&cpl));
 
+	cpl.status.sct = SPDK_NVME_SCT_PATH;
+	cpl.status.sc = SPDK_NVME_SC_INTERNAL_PATH_ERROR;
+	cpl.status.dnr = 0;
+	CU_ASSERT_TRUE(nvme_completion_is_retry(&cpl));
+
+	cpl.status.sct = SPDK_NVME_SCT_PATH;
+	cpl.status.sc = SPDK_NVME_SC_INTERNAL_PATH_ERROR;
+	cpl.status.dnr = 1;
+	CU_ASSERT_FALSE(nvme_completion_is_retry(&cpl));
+
 	cpl.status.sct = SPDK_NVME_SCT_VENDOR_SPECIFIC;
 	CU_ASSERT_FALSE(nvme_completion_is_retry(&cpl));
 
@@ -367,6 +319,66 @@ test_get_status_string(void)
 }
 #endif
 
+static void
+test_nvme_qpair_add_cmd_error_injection(void)
+{
+	struct spdk_nvme_qpair qpair = {};
+	struct spdk_nvme_ctrlr ctrlr = {};
+	int rc;
+
+	prepare_submit_request_test(&qpair, &ctrlr);
+	ctrlr.adminq = &qpair;
+
+	/* Admin error injection at submission path */
+	rc = spdk_nvme_qpair_add_cmd_error_injection(&ctrlr, NULL,
+			SPDK_NVME_OPC_GET_FEATURES, true, 5000, 1,
+			SPDK_NVME_SCT_GENERIC, SPDK_NVME_SC_INVALID_FIELD);
+
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(!TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	/* Remove cmd error injection */
+	spdk_nvme_qpair_remove_cmd_error_injection(&ctrlr, NULL, SPDK_NVME_OPC_GET_FEATURES);
+
+	CU_ASSERT(TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	/* IO error injection at completion path */
+	rc = spdk_nvme_qpair_add_cmd_error_injection(&ctrlr, &qpair,
+			SPDK_NVME_OPC_READ, false, 0, 1,
+			SPDK_NVME_SCT_MEDIA_ERROR, SPDK_NVME_SC_UNRECOVERED_READ_ERROR);
+
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(!TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	/* Provide the same opc, and check whether allocate a new entry */
+	rc = spdk_nvme_qpair_add_cmd_error_injection(&ctrlr, &qpair,
+			SPDK_NVME_OPC_READ, false, 0, 1,
+			SPDK_NVME_SCT_MEDIA_ERROR, SPDK_NVME_SC_UNRECOVERED_READ_ERROR);
+
+	CU_ASSERT(rc == 0);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&qpair.err_cmd_head));
+	CU_ASSERT(TAILQ_NEXT(TAILQ_FIRST(&qpair.err_cmd_head), link) == NULL);
+
+	/* Remove cmd error injection */
+	spdk_nvme_qpair_remove_cmd_error_injection(&ctrlr, &qpair, SPDK_NVME_OPC_READ);
+
+	CU_ASSERT(TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	rc = spdk_nvme_qpair_add_cmd_error_injection(&ctrlr, &qpair,
+			SPDK_NVME_OPC_COMPARE, true, 0, 5,
+			SPDK_NVME_SCT_GENERIC, SPDK_NVME_SC_COMPARE_FAILURE);
+
+	CU_ASSERT(rc == 0);
+	CU_ASSERT(!TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	/* Remove cmd error injection */
+	spdk_nvme_qpair_remove_cmd_error_injection(&ctrlr, &qpair, SPDK_NVME_OPC_COMPARE);
+
+	CU_ASSERT(TAILQ_EMPTY(&qpair.err_cmd_head));
+
+	cleanup_submit_request_test(&qpair);
+}
+
 int main(int argc, char **argv)
 {
 	CU_pSuite	suite = NULL;
@@ -391,6 +403,8 @@ int main(int argc, char **argv)
 #ifdef DEBUG
 	    || CU_add_test(suite, "get_status_string", test_get_status_string) == NULL
 #endif
+	    || CU_add_test(suite, "spdk_nvme_qpair_add_cmd_error_injection",
+			   test_nvme_qpair_add_cmd_error_injection) == NULL
 	   ) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/nvmf/ctrlr.c/ctrlr_ut.c b/test/unit/lib/nvmf/ctrlr.c/ctrlr_ut.c
index dbacd2a77..2ba8ddb84 100644
--- a/test/unit/lib/nvmf/ctrlr.c/ctrlr_ut.c
+++ b/test/unit/lib/nvmf/ctrlr.c/ctrlr_ut.c
@@ -36,105 +36,125 @@
 #include "spdk_cunit.h"
 #include "spdk_internal/mock.h"
 
+#include "common/lib/test_env.c"
 #include "nvmf/ctrlr.c"
 
 SPDK_LOG_REGISTER_COMPONENT("nvmf", SPDK_LOG_NVMF)
 
 struct spdk_bdev {
 	int ut_mock;
+	uint64_t blockcnt;
 };
 
 DEFINE_STUB(spdk_nvmf_tgt_find_subsystem,
 	    struct spdk_nvmf_subsystem *,
 	    (struct spdk_nvmf_tgt *tgt, const char *subnqn),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_poll_group_create,
 	    struct spdk_nvmf_poll_group *,
 	    (struct spdk_nvmf_tgt *tgt),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB_V(spdk_nvmf_poll_group_destroy,
-	      (struct spdk_nvmf_poll_group *group))
+	      (struct spdk_nvmf_poll_group *group));
 
 DEFINE_STUB_V(spdk_nvmf_transport_qpair_fini,
-	      (struct spdk_nvmf_qpair *qpair))
+	      (struct spdk_nvmf_qpair *qpair));
 
 DEFINE_STUB(spdk_nvmf_poll_group_add,
 	    int,
 	    (struct spdk_nvmf_poll_group *group, struct spdk_nvmf_qpair *qpair),
-	    0)
+	    0);
 
 DEFINE_STUB(spdk_nvmf_poll_group_remove,
 	    int,
 	    (struct spdk_nvmf_poll_group *group, struct spdk_nvmf_qpair *qpair),
-	    0)
+	    0);
 
 DEFINE_STUB(spdk_nvmf_subsystem_get_sn,
 	    const char *,
 	    (const struct spdk_nvmf_subsystem *subsystem),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_subsystem_get_ns,
 	    struct spdk_nvmf_ns *,
 	    (struct spdk_nvmf_subsystem *subsystem, uint32_t nsid),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_subsystem_get_first_ns,
 	    struct spdk_nvmf_ns *,
 	    (struct spdk_nvmf_subsystem *subsystem),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_subsystem_get_next_ns,
 	    struct spdk_nvmf_ns *,
 	    (struct spdk_nvmf_subsystem *subsystem, struct spdk_nvmf_ns *prev_ns),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_subsystem_host_allowed,
 	    bool,
 	    (struct spdk_nvmf_subsystem *subsystem, const char *hostnqn),
-	    true)
+	    true);
 
 DEFINE_STUB(spdk_nvmf_subsystem_add_ctrlr,
 	    int,
 	    (struct spdk_nvmf_subsystem *subsystem, struct spdk_nvmf_ctrlr *ctrlr),
-	    0)
+	    0);
 
 DEFINE_STUB_V(spdk_nvmf_subsystem_remove_ctrlr,
-	      (struct spdk_nvmf_subsystem *subsystem, struct spdk_nvmf_ctrlr *ctrlr))
+	      (struct spdk_nvmf_subsystem *subsystem, struct spdk_nvmf_ctrlr *ctrlr));
 
 DEFINE_STUB(spdk_nvmf_subsystem_get_ctrlr,
 	    struct spdk_nvmf_ctrlr *,
 	    (struct spdk_nvmf_subsystem *subsystem, uint16_t cntlid),
-	    NULL)
+	    NULL);
 
 DEFINE_STUB(spdk_nvmf_ctrlr_dsm_supported,
 	    bool,
 	    (struct spdk_nvmf_ctrlr *ctrlr),
-	    false)
+	    false);
 
 DEFINE_STUB(spdk_nvmf_ctrlr_write_zeroes_supported,
 	    bool,
 	    (struct spdk_nvmf_ctrlr *ctrlr),
-	    false)
-
-DEFINE_STUB(spdk_nvmf_bdev_ctrlr_identify_ns,
-	    int,
-	    (struct spdk_nvmf_ns *ns, struct spdk_nvme_ns_data *nsdata),
-	    -1)
+	    false);
 
 DEFINE_STUB_V(spdk_nvmf_get_discovery_log_page,
-	      (struct spdk_nvmf_tgt *tgt, void *buffer, uint64_t offset, uint32_t length))
+	      (struct spdk_nvmf_tgt *tgt, void *buffer, uint64_t offset, uint32_t length));
 
 DEFINE_STUB(spdk_nvmf_request_complete,
 	    int,
 	    (struct spdk_nvmf_request *req),
-	    -1)
+	    -1);
 
 DEFINE_STUB(spdk_nvmf_request_abort,
 	    int,
 	    (struct spdk_nvmf_request *req),
-	    -1)
+	    -1);
+
+static void
+ctrlr_ut_pass_msg(spdk_thread_fn fn, void *ctx, void *thread_ctx)
+{
+	fn(ctx);
+}
+
+int
+spdk_nvmf_bdev_ctrlr_identify_ns(struct spdk_nvmf_ns *ns, struct spdk_nvme_ns_data *nsdata)
+{
+	uint64_t num_blocks;
+
+	SPDK_CU_ASSERT_FATAL(ns->bdev != NULL);
+	num_blocks = ns->bdev->blockcnt;
+	nsdata->nsze = num_blocks;
+	nsdata->ncap = num_blocks;
+	nsdata->nuse = num_blocks;
+	nsdata->nlbaf = 0;
+	nsdata->flbas.format = 0;
+	nsdata->lbaf[0].lbads = spdk_u32log2(512);
+
+	return SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE;
+}
 
 static void
 test_get_log_page(void)
@@ -226,16 +246,11 @@ nvme_status_success(const struct spdk_nvme_status *status)
 	return status->sct == SPDK_NVME_SCT_GENERIC && status->sc == SPDK_NVME_SC_SUCCESS;
 }
 
-void
-spdk_thread_send_msg(const struct spdk_thread *thread, spdk_thread_fn fn, void *ctx)
-{
-	fn(ctx);
-}
-
 static void
 test_connect(void)
 {
 	struct spdk_nvmf_fabric_connect_data connect_data;
+	struct spdk_thread *thread;
 	struct spdk_nvmf_poll_group group;
 	struct spdk_nvmf_transport transport;
 	struct spdk_nvmf_subsystem subsystem;
@@ -255,18 +270,21 @@ test_connect(void)
 	const char hostnqn[] = "nqn.2016-06.io.spdk:host1";
 	int rc;
 
+	thread = spdk_allocate_thread(ctrlr_ut_pass_msg, NULL, NULL, NULL, "ctrlr_ut");
+	SPDK_CU_ASSERT_FATAL(thread != NULL);
+
 	memset(&group, 0, sizeof(group));
+	group.thread = thread;
 
 	memset(&ctrlr, 0, sizeof(ctrlr));
-	TAILQ_INIT(&ctrlr.qpairs);
 	ctrlr.subsys = &subsystem;
+	ctrlr.qpair_mask = spdk_bit_array_create(3);
+	SPDK_CU_ASSERT_FATAL(ctrlr.qpair_mask != NULL);
 	ctrlr.vcprop.cc.bits.en = 1;
 	ctrlr.vcprop.cc.bits.iosqes = 6;
 	ctrlr.vcprop.cc.bits.iocqes = 4;
-	ctrlr.max_qpairs_allowed = 3;
 
 	memset(&admin_qpair, 0, sizeof(admin_qpair));
-	TAILQ_INSERT_TAIL(&ctrlr.qpairs, &admin_qpair, link);
 	admin_qpair.group = &group;
 
 	memset(&tgt, 0, sizeof(tgt));
@@ -287,6 +305,7 @@ test_connect(void)
 	snprintf(connect_data.hostnqn, sizeof(connect_data.hostnqn), "%s", hostnqn);
 
 	memset(&subsystem, 0, sizeof(subsystem));
+	subsystem.thread = thread;
 	subsystem.id = 1;
 	TAILQ_INIT(&subsystem.ctrlrs);
 	subsystem.tgt = &tgt;
@@ -320,6 +339,7 @@ test_connect(void)
 	CU_ASSERT(rc == SPDK_NVMF_REQUEST_EXEC_STATUS_ASYNCHRONOUS);
 	CU_ASSERT(nvme_status_success(&rsp.nvme_cpl.status));
 	CU_ASSERT(qpair.ctrlr != NULL);
+	spdk_bit_array_free(&qpair.ctrlr->qpair_mask);
 	free(qpair.ctrlr);
 	qpair.ctrlr = NULL;
 
@@ -437,8 +457,6 @@ test_connect(void)
 	CU_ASSERT(nvme_status_success(&rsp.nvme_cpl.status));
 	CU_ASSERT(qpair.ctrlr == &ctrlr);
 	qpair.ctrlr = NULL;
-	ctrlr.num_qpairs = 0;
-	TAILQ_INIT(&ctrlr.qpairs);
 
 	/* Non-existent controller */
 	memset(&rsp, 0, sizeof(rsp));
@@ -502,31 +520,37 @@ test_connect(void)
 
 	/* I/O connect with too many existing qpairs */
 	memset(&rsp, 0, sizeof(rsp));
-	ctrlr.num_qpairs = 3;
+	spdk_bit_array_set(ctrlr.qpair_mask, 0);
+	spdk_bit_array_set(ctrlr.qpair_mask, 1);
+	spdk_bit_array_set(ctrlr.qpair_mask, 2);
 	rc = spdk_nvmf_ctrlr_connect(&req);
 	CU_ASSERT(rc == SPDK_NVMF_REQUEST_EXEC_STATUS_ASYNCHRONOUS);
 	CU_ASSERT(rsp.nvme_cpl.status.sct == SPDK_NVME_SCT_COMMAND_SPECIFIC);
-	CU_ASSERT(rsp.nvme_cpl.status.sc == SPDK_NVMF_FABRIC_SC_CONTROLLER_BUSY);
+	CU_ASSERT(rsp.nvme_cpl.status.sc == SPDK_NVME_SC_INVALID_QUEUE_IDENTIFIER);
 	CU_ASSERT(qpair.ctrlr == NULL);
-	ctrlr.num_qpairs = 0;
+	spdk_bit_array_clear(ctrlr.qpair_mask, 0);
+	spdk_bit_array_clear(ctrlr.qpair_mask, 1);
+	spdk_bit_array_clear(ctrlr.qpair_mask, 2);
 
 	/* I/O connect with duplicate queue ID */
 	memset(&rsp, 0, sizeof(rsp));
 	memset(&qpair2, 0, sizeof(qpair2));
 	qpair2.group = &group;
 	qpair2.qid = 1;
-	TAILQ_INSERT_TAIL(&ctrlr.qpairs, &qpair, link);
+	spdk_bit_array_set(ctrlr.qpair_mask, 1);
 	cmd.connect_cmd.qid = 1;
 	rc = spdk_nvmf_ctrlr_connect(&req);
 	CU_ASSERT(rc == SPDK_NVMF_REQUEST_EXEC_STATUS_ASYNCHRONOUS);
-	CU_ASSERT(rsp.nvme_cpl.status.sct == SPDK_NVME_SCT_GENERIC);
-	CU_ASSERT(rsp.nvme_cpl.status.sc == SPDK_NVME_SC_COMMAND_SEQUENCE_ERROR);
+	CU_ASSERT(rsp.nvme_cpl.status.sct == SPDK_NVME_SCT_COMMAND_SPECIFIC);
+	CU_ASSERT(rsp.nvme_cpl.status.sc == SPDK_NVME_SC_INVALID_QUEUE_IDENTIFIER);
 	CU_ASSERT(qpair.ctrlr == NULL);
-	TAILQ_INIT(&ctrlr.qpairs);
 
 	/* Clean up globals */
 	MOCK_SET(spdk_nvmf_tgt_find_subsystem, struct spdk_nvmf_subsystem *, NULL);
 	MOCK_SET(spdk_nvmf_poll_group_create, struct spdk_nvmf_poll_group *, NULL);
+
+	spdk_bit_array_free(&ctrlr.qpair_mask);
+	spdk_free_thread();
 }
 
 static void
@@ -659,6 +683,81 @@ test_get_ns_id_desc_list(void)
 	CU_ASSERT(buf[53] == 0);
 }
 
+static void
+test_identify_ns(void)
+{
+	struct spdk_nvmf_subsystem subsystem = {};
+	struct spdk_nvme_cmd cmd = {};
+	struct spdk_nvme_cpl rsp = {};
+	struct spdk_nvme_ns_data nsdata = {};
+	struct spdk_bdev bdev[3] = {{.blockcnt = 1234}, {.blockcnt = 0}, {.blockcnt = 5678}};
+	struct spdk_nvmf_ns ns[3] = {{.bdev = &bdev[0]}, {.bdev = NULL}, {.bdev = &bdev[2]}};
+	struct spdk_nvmf_ns *ns_arr[3] = {&ns[0], NULL, &ns[2]};
+
+	subsystem.ns = ns_arr;
+	subsystem.max_nsid = SPDK_COUNTOF(ns_arr);
+
+	/* Invalid NSID 0 */
+	cmd.nsid = 0;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT);
+	CU_ASSERT(spdk_mem_all_zero(&nsdata, sizeof(nsdata)));
+
+	/* Valid NSID 1 */
+	cmd.nsid = 1;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_SUCCESS);
+	CU_ASSERT(nsdata.nsze == 1234);
+
+	/* Valid but inactive NSID 2 */
+	cmd.nsid = 2;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_SUCCESS);
+	CU_ASSERT(spdk_mem_all_zero(&nsdata, sizeof(nsdata)));
+
+	/* Valid NSID 3 */
+	cmd.nsid = 3;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_SUCCESS);
+	CU_ASSERT(nsdata.nsze == 5678);
+
+	/* Invalid NSID 4 */
+	cmd.nsid = 4;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT);
+	CU_ASSERT(spdk_mem_all_zero(&nsdata, sizeof(nsdata)));
+
+	/* Invalid NSID 0xFFFFFFFF (NS management not supported) */
+	cmd.nsid = 0xFFFFFFFF;
+	memset(&nsdata, 0, sizeof(nsdata));
+	memset(&rsp, 0, sizeof(rsp));
+	CU_ASSERT(spdk_nvmf_ctrlr_identify_ns(&subsystem, &cmd, &rsp,
+					      &nsdata) == SPDK_NVMF_REQUEST_EXEC_STATUS_COMPLETE);
+	CU_ASSERT(rsp.status.sct == SPDK_NVME_SCT_GENERIC);
+	CU_ASSERT(rsp.status.sc == SPDK_NVME_SC_INVALID_NAMESPACE_OR_FORMAT);
+	CU_ASSERT(spdk_mem_all_zero(&nsdata, sizeof(nsdata)));
+}
+
 int main(int argc, char **argv)
 {
 	CU_pSuite	suite = NULL;
@@ -678,7 +777,8 @@ int main(int argc, char **argv)
 		CU_add_test(suite, "get_log_page", test_get_log_page) == NULL ||
 		CU_add_test(suite, "process_fabrics_cmd", test_process_fabrics_cmd) == NULL ||
 		CU_add_test(suite, "connect", test_connect) == NULL ||
-		CU_add_test(suite, "get_ns_id_desc_list", test_get_ns_id_desc_list) == NULL
+		CU_add_test(suite, "get_ns_id_desc_list", test_get_ns_id_desc_list) == NULL ||
+		CU_add_test(suite, "identify_ns", test_identify_ns) == NULL
 	) {
 		CU_cleanup_registry();
 		return CU_get_error();
diff --git a/test/unit/lib/nvmf/ctrlr_bdev.c/ctrlr_bdev_ut.c b/test/unit/lib/nvmf/ctrlr_bdev.c/ctrlr_bdev_ut.c
index b2dd759a9..c8f4ab4b9 100644
--- a/test/unit/lib/nvmf/ctrlr_bdev.c/ctrlr_bdev_ut.c
+++ b/test/unit/lib/nvmf/ctrlr_bdev.c/ctrlr_bdev_ut.c
@@ -40,12 +40,6 @@
 
 SPDK_LOG_REGISTER_COMPONENT("nvmf", SPDK_LOG_NVMF)
 
-struct spdk_nvmf_qpair *
-spdk_nvmf_ctrlr_get_qpair(struct spdk_nvmf_ctrlr *ctrlr, uint16_t qid)
-{
-	return NULL;
-}
-
 int
 spdk_nvmf_request_complete(struct spdk_nvmf_request *req)
 {
@@ -121,6 +115,15 @@ spdk_bdev_write_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 	return 0;
 }
 
+int
+spdk_bdev_writev_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
+			struct iovec *iov, int iovcnt,
+			uint64_t offset_blocks, uint64_t num_blocks,
+			spdk_bdev_io_completion_cb cb, void *cb_arg)
+{
+	return 0;
+}
+
 int
 spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch, void *buf,
 		      uint64_t offset_blocks, uint64_t num_blocks,
@@ -129,6 +132,14 @@ spdk_bdev_read_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch, v
 	return 0;
 }
 
+int spdk_bdev_readv_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
+			   struct iovec *iov, int iovcnt,
+			   uint64_t offset_blocks, uint64_t num_blocks,
+			   spdk_bdev_io_completion_cb cb, void *cb_arg)
+{
+	return 0;
+}
+
 int
 spdk_bdev_write_zeroes_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 			      uint64_t offset_blocks, uint64_t num_blocks,
@@ -147,9 +158,8 @@ spdk_bdev_nvme_io_passthru(struct spdk_bdev_desc *desc,
 	return 0;
 }
 
-int spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
+void spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
 {
-	return -1;
 }
 
 const char *spdk_nvmf_subsystem_get_nqn(struct spdk_nvmf_subsystem *subsystem)
diff --git a/test/unit/lib/nvmf/ctrlr_discovery.c/ctrlr_discovery_ut.c b/test/unit/lib/nvmf/ctrlr_discovery.c/ctrlr_discovery_ut.c
index 22faad015..97633a80b 100644
--- a/test/unit/lib/nvmf/ctrlr_discovery.c/ctrlr_discovery_ut.c
+++ b/test/unit/lib/nvmf/ctrlr_discovery.c/ctrlr_discovery_ut.c
@@ -208,6 +208,10 @@ test_discovery_log(void)
 	struct spdk_nvmf_discovery_log_page_entry *entry;
 	struct spdk_nvme_transport_id trid = {};
 
+	tgt.opts.max_subsystems = 1024;
+	tgt.subsystems = calloc(tgt.opts.max_subsystems, sizeof(struct spdk_nvmf_subsystem *));
+	SPDK_CU_ASSERT_FATAL(tgt.subsystems != NULL);
+
 	/* Add one subsystem and verify that the discovery log contains it */
 	subsystem = spdk_nvmf_subsystem_create(&tgt, "nqn.2016-06.io.spdk:subsystem1",
 					       SPDK_NVMF_SUBTYPE_NVME, 0);
diff --git a/test/unit/lib/nvmf/request.c/request_ut.c b/test/unit/lib/nvmf/request.c/request_ut.c
index c958cd411..14a9c34e0 100644
--- a/test/unit/lib/nvmf/request.c/request_ut.c
+++ b/test/unit/lib/nvmf/request.c/request_ut.c
@@ -112,9 +112,10 @@ struct spdk_nvme_ns *spdk_nvme_ctrlr_get_ns(struct spdk_nvme_ctrlr *ctrlr, uint3
 	return NULL;
 }
 
-void
-spdk_nvmf_ctrlr_disconnect(struct spdk_nvmf_qpair *qpair)
+int
+spdk_nvmf_qpair_disconnect(struct spdk_nvmf_qpair *qpair, nvmf_qpair_disconnect_cb cb_fn, void *ctx)
 {
+	return 0;
 }
 
 static void
diff --git a/test/unit/lib/nvmf/subsystem.c/subsystem_ut.c b/test/unit/lib/nvmf/subsystem.c/subsystem_ut.c
index b8395e08f..a08621974 100644
--- a/test/unit/lib/nvmf/subsystem.c/subsystem_ut.c
+++ b/test/unit/lib/nvmf/subsystem.c/subsystem_ut.c
@@ -243,6 +243,10 @@ test_spdk_nvmf_subsystem_add_ns(void)
 	struct spdk_nvmf_ns_opts ns_opts;
 	uint32_t nsid;
 
+	tgt.opts.max_subsystems = 1024;
+	tgt.subsystems = calloc(tgt.opts.max_subsystems, sizeof(struct spdk_nvmf_subsystem *));
+	SPDK_CU_ASSERT_FATAL(tgt.subsystems != NULL);
+
 	/* Allow NSID to be assigned automatically */
 	spdk_nvmf_ns_opts_get_defaults(&ns_opts, sizeof(ns_opts));
 	nsid = spdk_nvmf_subsystem_add_ns(&subsystem, &bdev1, &ns_opts, sizeof(ns_opts));
@@ -280,6 +284,7 @@ test_spdk_nvmf_subsystem_add_ns(void)
 	spdk_nvmf_subsystem_remove_ns(&subsystem, 5, subsystem_ns_remove_cb, NULL);
 
 	free(subsystem.ns);
+	free(tgt.subsystems);
 }
 
 static void
@@ -289,6 +294,10 @@ nvmf_test_create_subsystem(void)
 	char nqn[256];
 	struct spdk_nvmf_subsystem *subsystem;
 
+	tgt.opts.max_subsystems = 1024;
+	tgt.subsystems = calloc(tgt.opts.max_subsystems, sizeof(struct spdk_nvmf_subsystem *));
+	SPDK_CU_ASSERT_FATAL(tgt.subsystems != NULL);
+
 	snprintf(nqn, sizeof(nqn), "nqn.2016-06.io.spdk:subsystem1");
 	subsystem = spdk_nvmf_subsystem_create(&tgt, nqn, SPDK_NVMF_SUBTYPE_NVME, 0);
 	SPDK_CU_ASSERT_FATAL(subsystem != NULL);
diff --git a/test/unit/lib/scsi/dev.c/dev_ut.c b/test/unit/lib/scsi/dev.c/dev_ut.c
index 60c4c0555..6fa906772 100644
--- a/test/unit/lib/scsi/dev.c/dev_ut.c
+++ b/test/unit/lib/scsi/dev.c/dev_ut.c
@@ -123,13 +123,13 @@ spdk_scsi_lun_execute_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task *tas
 }
 
 int
-spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun)
+_spdk_scsi_lun_allocate_io_channel(struct spdk_scsi_lun *lun)
 {
 	return 0;
 }
 
 void
-spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun)
+_spdk_scsi_lun_free_io_channel(struct spdk_scsi_lun *lun)
 {
 }
 
diff --git a/test/unit/lib/scsi/lun.c/Makefile b/test/unit/lib/scsi/lun.c/Makefile
index 350ae78f9..22841b0d3 100644
--- a/test/unit/lib/scsi/lun.c/Makefile
+++ b/test/unit/lib/scsi/lun.c/Makefile
@@ -35,7 +35,6 @@ SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
 
-SPDK_LIB_LIST = cunit
 TEST_FILE = lun_ut.c
 
 include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/scsi/lun.c/lun_ut.c b/test/unit/lib/scsi/lun.c/lun_ut.c
index 61b2a62e5..1381013ab 100644
--- a/test/unit/lib/scsi/lun.c/lun_ut.c
+++ b/test/unit/lib/scsi/lun.c/lun_ut.c
@@ -86,8 +86,6 @@ spdk_lun_ut_cpl_task(struct spdk_scsi_task *task)
 static void
 spdk_lun_ut_free_task(struct spdk_scsi_task *task)
 {
-	/* This should never get called since we never call spdk_scsi_task_put(). */
-	SPDK_CU_ASSERT_FATAL(0);
 }
 
 static void
@@ -125,11 +123,10 @@ spdk_dma_free(void *buf)
 	free(buf);
 }
 
-int
+void
 spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
 {
 	CU_ASSERT(0);
-	return -1;
 }
 
 int
@@ -162,10 +159,10 @@ void spdk_scsi_dev_delete_lun(struct spdk_scsi_dev *dev,
 	return;
 }
 
-int
+void
 spdk_bdev_scsi_reset(struct spdk_scsi_task *task)
 {
-	return 0;
+	return;
 }
 
 int
@@ -442,7 +439,7 @@ lun_append_task_null_lun_task_cdb_spc_inquiry(void)
 
 	CU_ASSERT_EQUAL(task.status, SPDK_SCSI_STATUS_GOOD);
 
-	spdk_scsi_task_free_data(&task);
+	spdk_scsi_task_put(&task);
 
 	/* spdk_scsi_task_process_null_lun() does not call cpl_fn */
 	CU_ASSERT_EQUAL(g_task_count, 1);
@@ -467,6 +464,8 @@ lun_append_task_null_lun_alloc_len_lt_4096(void)
 
 	CU_ASSERT_EQUAL(task.status, SPDK_SCSI_STATUS_GOOD);
 
+	spdk_scsi_task_put(&task);
+
 	/* spdk_scsi_task_process_null_lun() does not call cpl_fn */
 	CU_ASSERT_EQUAL(g_task_count, 1);
 	g_task_count = 0;
@@ -600,7 +599,6 @@ main(int argc, char **argv)
 {
 	CU_pSuite	suite = NULL;
 	unsigned int	num_failures;
-	int		rc;
 
 	if (CU_initialize_registry() != CUE_SUCCESS) {
 		return CU_get_error();
@@ -650,15 +648,6 @@ main(int argc, char **argv)
 	CU_basic_set_mode(CU_BRM_VERBOSE);
 	CU_basic_run_tests();
 	num_failures = CU_get_number_of_failures();
-
-	if (argc > 1) {
-		rc = spdk_cunit_print_results(argv[1]);
-		if (rc != 0) {
-			CU_cleanup_registry();
-			return rc;
-		}
-	}
-
 	CU_cleanup_registry();
 	return num_failures;
 }
diff --git a/test/unit/lib/scsi/scsi_bdev.c/scsi_bdev_ut.c b/test/unit/lib/scsi/scsi_bdev.c/scsi_bdev_ut.c
index edcfb1765..ef5349e9c 100644
--- a/test/unit/lib/scsi/scsi_bdev.c/scsi_bdev_ut.c
+++ b/test/unit/lib/scsi/scsi_bdev.c/scsi_bdev_ut.c
@@ -44,6 +44,12 @@ struct spdk_scsi_globals g_spdk_scsi;
 
 static uint64_t g_test_bdev_num_blocks;
 
+TAILQ_HEAD(, spdk_bdev_io) g_bdev_io_queue;
+int g_scsi_cb_called = 0;
+
+TAILQ_HEAD(, spdk_bdev_io_wait_entry) g_io_wait_queue;
+bool g_bdev_io_pool_full = false;
+
 void *
 spdk_dma_malloc(size_t size, size_t align, uint64_t *phys_addr)
 {
@@ -79,11 +85,10 @@ spdk_bdev_io_type_supported(struct spdk_bdev *bdev, enum spdk_bdev_io_type io_ty
 	return false;
 }
 
-int
+void
 spdk_bdev_free_io(struct spdk_bdev_io *bdev_io)
 {
 	CU_ASSERT(0);
-	return -1;
 }
 
 const char *
@@ -119,6 +124,7 @@ spdk_bdev_has_write_cache(const struct spdk_bdev *bdev)
 void
 spdk_scsi_lun_complete_task(struct spdk_scsi_lun *lun, struct spdk_scsi_task *task)
 {
+	g_scsi_cb_called++;
 }
 
 void
@@ -127,7 +133,7 @@ spdk_scsi_lun_complete_mgmt_task(struct spdk_scsi_lun *lun, struct spdk_scsi_tas
 }
 
 static void
-spdk_put_task(struct spdk_scsi_task *task)
+ut_put_task(struct spdk_scsi_task *task)
 {
 	if (task->alloc_len) {
 		free(task->iov.iov_base);
@@ -136,22 +142,26 @@ spdk_put_task(struct spdk_scsi_task *task)
 	task->iov.iov_base = NULL;
 	task->iov.iov_len = 0;
 	task->alloc_len = 0;
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 }
 
 
 static void
-spdk_init_task(struct spdk_scsi_task *task)
+ut_init_task(struct spdk_scsi_task *task)
 {
-	memset(task, 0, sizeof(*task));
+	memset(task, 0xFF, sizeof(*task));
+	task->iov.iov_base = NULL;
 	task->iovs = &task->iov;
 	task->iovcnt = 1;
+	task->alloc_len = 0;
+	task->dxfer_dir = SPDK_SCSI_DIR_NONE;
 }
 
 void
 spdk_bdev_io_get_scsi_status(const struct spdk_bdev_io *bdev_io,
 			     int *sc, int *sk, int *asc, int *ascq)
 {
-	switch (bdev_io->status) {
+	switch (bdev_io->internal.status) {
 	case SPDK_BDEV_IO_STATUS_SUCCESS:
 		*sc = SPDK_SCSI_STATUS_GOOD;
 		*sk = SPDK_SCSI_SENSE_NO_SENSE;
@@ -159,10 +169,10 @@ spdk_bdev_io_get_scsi_status(const struct spdk_bdev_io *bdev_io,
 		*ascq = SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE;
 		break;
 	case SPDK_BDEV_IO_STATUS_SCSI_ERROR:
-		*sc = bdev_io->error.scsi.sc;
-		*sk = bdev_io->error.scsi.sk;
-		*asc = bdev_io->error.scsi.asc;
-		*ascq = bdev_io->error.scsi.ascq;
+		*sc = bdev_io->internal.error.scsi.sc;
+		*sk = bdev_io->internal.error.scsi.sk;
+		*asc = bdev_io->internal.error.scsi.asc;
+		*ascq = bdev_io->internal.error.scsi.ascq;
 		break;
 	default:
 		*sc = SPDK_SCSI_STATUS_CHECK_CONDITION;
@@ -180,11 +190,46 @@ spdk_bdev_io_get_iovec(struct spdk_bdev_io *bdev_io, struct iovec **iovp, int *i
 	*iovcntp = 0;
 }
 
-int
-spdk_bdev_read(struct spdk_bdev_desc *bdev_desc, struct spdk_io_channel *ch,
-	       void *buf, uint64_t offset, uint64_t nbytes,
-	       spdk_bdev_io_completion_cb cb, void *cb_arg)
+static void
+ut_bdev_io_flush(void)
+{
+	struct spdk_bdev_io *bdev_io;
+	struct spdk_bdev_io_wait_entry *entry;
+
+	while (!TAILQ_EMPTY(&g_bdev_io_queue) || !TAILQ_EMPTY(&g_io_wait_queue)) {
+		while (!TAILQ_EMPTY(&g_bdev_io_queue)) {
+			bdev_io = TAILQ_FIRST(&g_bdev_io_queue);
+			TAILQ_REMOVE(&g_bdev_io_queue, bdev_io, internal.link);
+			bdev_io->internal.cb(bdev_io, true, bdev_io->internal.caller_ctx);
+			free(bdev_io);
+		}
+
+		while (!TAILQ_EMPTY(&g_io_wait_queue)) {
+			entry = TAILQ_FIRST(&g_io_wait_queue);
+			TAILQ_REMOVE(&g_io_wait_queue, entry, link);
+			entry->cb_fn(entry->cb_arg);
+		}
+	}
+}
+
+static int
+_spdk_bdev_io_op(spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
+	struct spdk_bdev_io *bdev_io;
+
+	if (g_bdev_io_pool_full) {
+		g_bdev_io_pool_full = false;
+		return -ENOMEM;
+	}
+
+	bdev_io = calloc(1, sizeof(*bdev_io));
+	SPDK_CU_ASSERT_FATAL(bdev_io != NULL);
+	bdev_io->internal.status = SPDK_BDEV_IO_STATUS_SUCCESS;
+	bdev_io->internal.cb = cb;
+	bdev_io->internal.caller_ctx = cb_arg;
+
+	TAILQ_INSERT_TAIL(&g_bdev_io_queue, bdev_io, internal.link);
+
 	return 0;
 }
 
@@ -193,7 +238,7 @@ spdk_bdev_readv(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		struct iovec *iov, int iovcnt, uint64_t offset, uint64_t nbytes,
 		spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
-	return 0;
+	return _spdk_bdev_io_op(cb, cb_arg);
 }
 
 int
@@ -202,7 +247,7 @@ spdk_bdev_writev(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		 uint64_t offset, uint64_t len,
 		 spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
-	return 0;
+	return _spdk_bdev_io_op(cb, cb_arg);
 }
 
 int
@@ -210,14 +255,14 @@ spdk_bdev_unmap_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		       uint64_t offset_blocks, uint64_t num_blocks,
 		       spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
-	return 0;
+	return _spdk_bdev_io_op(cb, cb_arg);
 }
 
 int
 spdk_bdev_reset(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
-	return 0;
+	return _spdk_bdev_io_op(cb, cb_arg);
 }
 
 int
@@ -225,6 +270,14 @@ spdk_bdev_flush_blocks(struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
 		       uint64_t offset_blocks, uint64_t num_blocks,
 		       spdk_bdev_io_completion_cb cb, void *cb_arg)
 {
+	return _spdk_bdev_io_op(cb, cb_arg);
+}
+
+int
+spdk_bdev_queue_io_wait(struct spdk_bdev *bdev, struct spdk_io_channel *ch,
+			struct spdk_bdev_io_wait_entry *entry)
+{
+	TAILQ_INSERT_TAIL(&g_io_wait_queue, entry, link);
 	return 0;
 }
 
@@ -243,7 +296,7 @@ mode_select_6_test(void)
 	char data[24];
 	int rc;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	cdb[0] = 0x15;
 	cdb[1] = 0x11;
@@ -267,7 +320,7 @@ mode_select_6_test(void)
 
 	CU_ASSERT_EQUAL(rc, 0);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 /*
@@ -284,7 +337,7 @@ mode_select_6_test2(void)
 	char cdb[16];
 	int rc;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	cdb[0] = 0x15;
 	cdb[1] = 0x00;
@@ -303,7 +356,7 @@ mode_select_6_test2(void)
 
 	CU_ASSERT_EQUAL(rc, 0);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 /*
@@ -326,7 +379,7 @@ mode_sense_6_test(void)
 	unsigned char blk_descriptor_len = 0;
 
 	memset(&bdev, 0, sizeof(struct spdk_bdev));
-	spdk_init_task(&task);
+	ut_init_task(&task);
 	memset(cdb, 0, sizeof(cdb));
 
 	cdb[0] = 0x1A;
@@ -353,7 +406,7 @@ mode_sense_6_test(void)
 	CU_ASSERT_EQUAL(dev_specific_param, 0);
 	CU_ASSERT_EQUAL(blk_descriptor_len, 8);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 /*
@@ -376,7 +429,7 @@ mode_sense_10_test(void)
 	unsigned short blk_descriptor_len = 0;
 
 	memset(&bdev, 0, sizeof(struct spdk_bdev));
-	spdk_init_task(&task);
+	ut_init_task(&task);
 	memset(cdb, 0, sizeof(cdb));
 	cdb[0] = 0x5A;
 	cdb[2] = 0x3F;
@@ -402,7 +455,7 @@ mode_sense_10_test(void)
 	CU_ASSERT_EQUAL(dev_specific_param, 0);
 	CU_ASSERT_EQUAL(blk_descriptor_len, 8);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 /*
@@ -420,7 +473,7 @@ inquiry_evpd_test(void)
 	char cdb[6];
 	int rc;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	cdb[0] = 0x12;
 	cdb[1] = 0x00; // EVPD = 0
@@ -443,7 +496,7 @@ inquiry_evpd_test(void)
 	CU_ASSERT_EQUAL(task.sense_data[12], 0x24);
 	CU_ASSERT_EQUAL(task.sense_data[13], 0x0);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 /*
@@ -462,7 +515,7 @@ inquiry_standard_test(void)
 	struct spdk_scsi_cdb_inquiry_data *inq_data;
 	int rc;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	cdb[0] = 0x12;
 	cdb[1] = 0x00; // EVPD = 0
@@ -485,7 +538,7 @@ inquiry_standard_test(void)
 	CU_ASSERT_EQUAL(inq_data->version, SPDK_SPC_VERSION_SPC3);
 	CU_ASSERT_EQUAL(rc, 0);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 static void
@@ -500,7 +553,7 @@ _inquiry_overflow_test(uint8_t alloc_len)
 	/* expects a 4K internal data buffer */
 	char data[4096], data_compare[4096];
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	cdb[0] = 0x12;
 	cdb[1] = 0x00; // EVPD = 0
@@ -526,7 +579,7 @@ _inquiry_overflow_test(uint8_t alloc_len)
 	CU_ASSERT_EQUAL(memcmp(data + alloc_len, data_compare + alloc_len, sizeof(data) - alloc_len), 0);
 	CU_ASSERT(task.data_transferred <= alloc_len);
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 static void
@@ -586,35 +639,41 @@ task_complete_test(void)
 	struct spdk_bdev_io bdev_io = {};
 	struct spdk_scsi_lun lun;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 
 	TAILQ_INIT(&lun.tasks);
 	TAILQ_INSERT_TAIL(&lun.tasks, &task, scsi_link);
 	task.lun = &lun;
 
-	bdev_io.status = SPDK_BDEV_IO_STATUS_SUCCESS;
-	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.status, &task);
+	bdev_io.internal.status = SPDK_BDEV_IO_STATUS_SUCCESS;
+	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.internal.status, &task);
 	CU_ASSERT_EQUAL(task.status, SPDK_SCSI_STATUS_GOOD);
-
-	bdev_io.status = SPDK_BDEV_IO_STATUS_SCSI_ERROR;
-	bdev_io.error.scsi.sc = SPDK_SCSI_STATUS_CHECK_CONDITION;
-	bdev_io.error.scsi.sk = SPDK_SCSI_SENSE_HARDWARE_ERROR;
-	bdev_io.error.scsi.asc = SPDK_SCSI_ASC_WARNING;
-	bdev_io.error.scsi.ascq = SPDK_SCSI_ASCQ_POWER_LOSS_EXPECTED;
-	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.status, &task);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
+
+	bdev_io.internal.status = SPDK_BDEV_IO_STATUS_SCSI_ERROR;
+	bdev_io.internal.error.scsi.sc = SPDK_SCSI_STATUS_CHECK_CONDITION;
+	bdev_io.internal.error.scsi.sk = SPDK_SCSI_SENSE_HARDWARE_ERROR;
+	bdev_io.internal.error.scsi.asc = SPDK_SCSI_ASC_WARNING;
+	bdev_io.internal.error.scsi.ascq = SPDK_SCSI_ASCQ_POWER_LOSS_EXPECTED;
+	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.internal.status, &task);
 	CU_ASSERT_EQUAL(task.status, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(task.sense_data[2] & 0xf, SPDK_SCSI_SENSE_HARDWARE_ERROR);
 	CU_ASSERT_EQUAL(task.sense_data[12], SPDK_SCSI_ASC_WARNING);
 	CU_ASSERT_EQUAL(task.sense_data[13], SPDK_SCSI_ASCQ_POWER_LOSS_EXPECTED);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
-	bdev_io.status = SPDK_BDEV_IO_STATUS_FAILED;
-	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.status, &task);
+	bdev_io.internal.status = SPDK_BDEV_IO_STATUS_FAILED;
+	spdk_bdev_scsi_task_complete_cmd(&bdev_io, bdev_io.internal.status, &task);
 	CU_ASSERT_EQUAL(task.status, SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT_EQUAL(task.sense_data[2] & 0xf, SPDK_SCSI_SENSE_ABORTED_COMMAND);
 	CU_ASSERT_EQUAL(task.sense_data[12], SPDK_SCSI_ASC_NO_ADDITIONAL_SENSE);
 	CU_ASSERT_EQUAL(task.sense_data[13], SPDK_SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 static void
@@ -628,7 +687,7 @@ lba_range_test(void)
 
 	lun.bdev = &bdev;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 	task.lun = &lun;
 	task.cdb = cdb;
 
@@ -644,7 +703,12 @@ lba_range_test(void)
 	task.transfer_len = 1 * 512;
 	rc = spdk_bdev_scsi_execute(&task);
 	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&g_bdev_io_queue));
+	ut_bdev_io_flush();
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
 	/* LBA = 4, length = 1 (LBA out of range) */
 	to_be64(&cdb[2], 4); /* LBA */
@@ -654,14 +718,21 @@ lba_range_test(void)
 	CU_ASSERT(rc == SPDK_SCSI_TASK_COMPLETE);
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT(task.sense_data[12] == SPDK_SCSI_ASC_LOGICAL_BLOCK_ADDRESS_OUT_OF_RANGE);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 
 	/* LBA = 0, length = 4 (in range, max valid size) */
 	to_be64(&cdb[2], 0); /* LBA */
 	to_be32(&cdb[10], 4); /* transfer length */
 	task.transfer_len = 4 * 512;
+	task.status = 0xFF;
 	rc = spdk_bdev_scsi_execute(&task);
 	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&g_bdev_io_queue));
+	ut_bdev_io_flush();
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
 	/* LBA = 0, length = 5 (LBA in range, length beyond end of bdev) */
 	to_be64(&cdb[2], 0); /* LBA */
@@ -671,8 +742,9 @@ lba_range_test(void)
 	CU_ASSERT(rc == SPDK_SCSI_TASK_COMPLETE);
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT(task.sense_data[12] == SPDK_SCSI_ASC_LOGICAL_BLOCK_ADDRESS_OUT_OF_RANGE);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
 }
 
 static void
@@ -686,7 +758,7 @@ xfer_len_test(void)
 
 	lun.bdev = &bdev;
 
-	spdk_init_task(&task);
+	ut_init_task(&task);
 	task.lun = &lun;
 	task.cdb = cdb;
 
@@ -702,15 +774,26 @@ xfer_len_test(void)
 	task.transfer_len = 1 * 512;
 	rc = spdk_bdev_scsi_execute(&task);
 	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&g_bdev_io_queue));
+	ut_bdev_io_flush();
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
 	/* max transfer length (as reported in block limits VPD page) */
 	to_be64(&cdb[2], 0); /* LBA */
 	to_be32(&cdb[10], SPDK_WORK_BLOCK_SIZE / 512); /* transfer length */
 	task.transfer_len = SPDK_WORK_BLOCK_SIZE;
+	task.status = 0xFF;
 	rc = spdk_bdev_scsi_execute(&task);
 	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+	SPDK_CU_ASSERT_FATAL(!TAILQ_EMPTY(&g_bdev_io_queue));
+	ut_bdev_io_flush();
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
 
 	/* max transfer length plus one block (invalid) */
 	to_be64(&cdb[2], 0); /* LBA */
@@ -721,6 +804,7 @@ xfer_len_test(void)
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT((task.sense_data[2] & 0xf) == SPDK_SCSI_SENSE_ILLEGAL_REQUEST);
 	CU_ASSERT(task.sense_data[12] == SPDK_SCSI_ASC_INVALID_FIELD_IN_CDB);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 
 	/* zero transfer length (valid) */
 	to_be64(&cdb[2], 0); /* LBA */
@@ -730,6 +814,7 @@ xfer_len_test(void)
 	CU_ASSERT(rc == SPDK_SCSI_TASK_COMPLETE);
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
 	CU_ASSERT(task.data_transferred == 0);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 
 	/* zero transfer length past end of disk (invalid) */
 	to_be64(&cdb[2], g_test_bdev_num_blocks); /* LBA */
@@ -739,8 +824,117 @@ xfer_len_test(void)
 	CU_ASSERT(rc == SPDK_SCSI_TASK_COMPLETE);
 	CU_ASSERT(task.status == SPDK_SCSI_STATUS_CHECK_CONDITION);
 	CU_ASSERT(task.sense_data[12] == SPDK_SCSI_ASC_LOGICAL_BLOCK_ADDRESS_OUT_OF_RANGE);
+	SPDK_CU_ASSERT_FATAL(TAILQ_EMPTY(&g_bdev_io_queue));
 
-	spdk_put_task(&task);
+	ut_put_task(&task);
+}
+
+static void
+_xfer_test(bool bdev_io_pool_full)
+{
+	struct spdk_bdev bdev;
+	struct spdk_scsi_lun lun;
+	struct spdk_scsi_task task;
+	uint8_t cdb[16];
+	char data[4096];
+	int rc;
+
+	lun.bdev = &bdev;
+
+	/* Test block device size of 512 MiB */
+	g_test_bdev_num_blocks = 512 * 1024 * 1024;
+
+	/* Read 1 block */
+	ut_init_task(&task);
+	task.lun = &lun;
+	task.cdb = cdb;
+	memset(cdb, 0, sizeof(cdb));
+	cdb[0] = 0x88; /* READ (16) */
+	to_be64(&cdb[2], 0); /* LBA */
+	to_be32(&cdb[10], 1); /* transfer length */
+	task.transfer_len = 1 * 512;
+	g_bdev_io_pool_full = bdev_io_pool_full;
+	rc = spdk_bdev_scsi_execute(&task);
+	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+
+	ut_bdev_io_flush();
+	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
+	ut_put_task(&task);
+
+	/* Write 1 block */
+	ut_init_task(&task);
+	task.lun = &lun;
+	task.cdb = cdb;
+	memset(cdb, 0, sizeof(cdb));
+	cdb[0] = 0x8a; /* WRITE (16) */
+	to_be64(&cdb[2], 0); /* LBA */
+	to_be32(&cdb[10], 1); /* transfer length */
+	task.transfer_len = 1 * 512;
+	g_bdev_io_pool_full = bdev_io_pool_full;
+	rc = spdk_bdev_scsi_execute(&task);
+	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+
+	ut_bdev_io_flush();
+	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
+	ut_put_task(&task);
+
+	/* Unmap 5 blocks using 2 descriptors */
+	ut_init_task(&task);
+	task.lun = &lun;
+	task.cdb = cdb;
+	memset(cdb, 0, sizeof(cdb));
+	cdb[0] = 0x42; /* UNMAP */
+	to_be16(&data[7], 2); /* 2 parameters in list */
+	memset(data, 0, sizeof(data));
+	to_be16(&data[2], 32); /* 2 descriptors */
+	to_be64(&data[8], 1); /* LBA 1 */
+	to_be32(&data[16], 2); /* 2 blocks */
+	to_be64(&data[24], 10); /* LBA 10 */
+	to_be32(&data[32], 3); /* 3 blocks */
+	spdk_scsi_task_set_data(&task, data, sizeof(data));
+	task.status = SPDK_SCSI_STATUS_GOOD;
+	g_bdev_io_pool_full = bdev_io_pool_full;
+	rc = spdk_bdev_scsi_execute(&task);
+	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+
+	ut_bdev_io_flush();
+	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
+	ut_put_task(&task);
+
+	/* Flush 1 block */
+	ut_init_task(&task);
+	task.lun = &lun;
+	task.cdb = cdb;
+	memset(cdb, 0, sizeof(cdb));
+	cdb[0] = 0x91; /* SYNCHRONIZE CACHE (16) */
+	to_be64(&cdb[2], 0); /* LBA */
+	to_be32(&cdb[10], 1); /* 1 blocks */
+	g_bdev_io_pool_full = bdev_io_pool_full;
+	rc = spdk_bdev_scsi_execute(&task);
+	CU_ASSERT(rc == SPDK_SCSI_TASK_PENDING);
+	CU_ASSERT(task.status == 0xFF);
+
+	ut_bdev_io_flush();
+	CU_ASSERT(task.status == SPDK_SCSI_STATUS_GOOD);
+	CU_ASSERT(g_scsi_cb_called == 1);
+	g_scsi_cb_called = 0;
+	ut_put_task(&task);
+}
+
+static void
+xfer_test(void)
+{
+	_xfer_test(false);
+	_xfer_test(true);
 }
 
 int
@@ -749,6 +943,9 @@ main(int argc, char **argv)
 	CU_pSuite	suite = NULL;
 	unsigned int	num_failures;
 
+	TAILQ_INIT(&g_bdev_io_queue);
+	TAILQ_INIT(&g_io_wait_queue);
+
 	if (CU_initialize_registry() != CUE_SUCCESS) {
 		return CU_get_error();
 	}
@@ -770,6 +967,7 @@ main(int argc, char **argv)
 		|| CU_add_test(suite, "task complete test", task_complete_test) == NULL
 		|| CU_add_test(suite, "LBA range test", lba_range_test) == NULL
 		|| CU_add_test(suite, "transfer length test", xfer_len_test) == NULL
+		|| CU_add_test(suite, "transfer test", xfer_test) == NULL
 		|| CU_add_test(suite, "scsi name padding test", scsi_name_padding_test) == NULL
 	) {
 		CU_cleanup_registry();
diff --git a/test/unit/lib/net/Makefile b/test/unit/lib/sock/Makefile
similarity index 100%
rename from test/unit/lib/net/Makefile
rename to test/unit/lib/sock/Makefile
diff --git a/test/unit/lib/net/sock.c/.gitignore b/test/unit/lib/sock/sock.c/.gitignore
similarity index 100%
rename from test/unit/lib/net/sock.c/.gitignore
rename to test/unit/lib/sock/sock.c/.gitignore
diff --git a/test/unit/lib/net/sock.c/Makefile b/test/unit/lib/sock/sock.c/Makefile
similarity index 100%
rename from test/unit/lib/net/sock.c/Makefile
rename to test/unit/lib/sock/sock.c/Makefile
diff --git a/test/unit/lib/net/sock.c/sock_ut.c b/test/unit/lib/sock/sock.c/sock_ut.c
similarity index 99%
rename from test/unit/lib/net/sock.c/sock_ut.c
rename to test/unit/lib/sock/sock.c/sock_ut.c
index 3c5f1d04f..9a185801b 100644
--- a/test/unit/lib/net/sock.c/sock_ut.c
+++ b/test/unit/lib/sock/sock.c/sock_ut.c
@@ -36,8 +36,8 @@
 
 #include "spdk_cunit.h"
 
-#include "net/sock.c"
-#include "net/posix/posix.c"
+#include "sock/sock.c"
+#include "sock/posix/posix.c"
 
 #define UT_IP	"test_ip"
 #define UT_PORT	1234
diff --git a/test/unit/lib/thread/Makefile b/test/unit/lib/thread/Makefile
new file mode 100644
index 000000000..d73816947
--- /dev/null
+++ b/test/unit/lib/thread/Makefile
@@ -0,0 +1,44 @@
+#
+#  BSD LICENSE
+#
+#  Copyright (c) Intel Corporation.
+#  All rights reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#    * Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#    * Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in
+#      the documentation and/or other materials provided with the
+#      distribution.
+#    * Neither the name of Intel Corporation nor the names of its
+#      contributors may be used to endorse or promote products derived
+#      from this software without specific prior written permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+
+SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
+include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
+
+DIRS-y = thread.c
+
+.PHONY: all clean $(DIRS-y)
+
+all: $(DIRS-y)
+clean: $(DIRS-y)
+
+include $(SPDK_ROOT_DIR)/mk/spdk.subdirs.mk
diff --git a/test/unit/lib/thread/thread.c/.gitignore b/test/unit/lib/thread/thread.c/.gitignore
new file mode 100644
index 000000000..1a165acb8
--- /dev/null
+++ b/test/unit/lib/thread/thread.c/.gitignore
@@ -0,0 +1 @@
+thread_ut
diff --git a/test/unit/lib/util/io_channel.c/Makefile b/test/unit/lib/thread/thread.c/Makefile
similarity index 98%
rename from test/unit/lib/util/io_channel.c/Makefile
rename to test/unit/lib/thread/thread.c/Makefile
index 6e44ffc53..23cfa45a5 100644
--- a/test/unit/lib/util/io_channel.c/Makefile
+++ b/test/unit/lib/thread/thread.c/Makefile
@@ -36,6 +36,6 @@ include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.mock.unittest.mk
 
-TEST_FILE = io_channel_ut.c
+TEST_FILE = thread_ut.c
 
 include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/util/io_channel.c/io_channel_ut.c b/test/unit/lib/thread/thread.c/thread_ut.c
similarity index 90%
rename from test/unit/lib/util/io_channel.c/io_channel_ut.c
rename to test/unit/lib/thread/thread.c/thread_ut.c
index 0febd151d..caebe348d 100644
--- a/test/unit/lib/util/io_channel.c/io_channel_ut.c
+++ b/test/unit/lib/thread/thread.c/thread_ut.c
@@ -35,7 +35,7 @@
 
 #include "spdk_cunit.h"
 
-#include "util/io_channel.c"
+#include "thread/thread.c"
 #include "common/lib/test_env.c"
 #include "common/lib/ut_multithread.c"
 
@@ -97,6 +97,63 @@ thread_send_msg(void)
 	free_threads();
 }
 
+static int
+poller_run_done(void *ctx)
+{
+	bool	*poller_run = ctx;
+
+	*poller_run = true;
+
+	return -1;
+}
+
+static void
+thread_poller(void)
+{
+	struct spdk_poller	*poller = NULL;
+	bool			poller_run = false;
+
+	allocate_threads(1);
+
+	set_thread(0);
+	reset_time();
+	/* Register a poller with no-wait time and test execution */
+	poller = spdk_poller_register(poller_run_done, &poller_run, 0);
+	CU_ASSERT(poller != NULL);
+
+	poll_threads();
+	CU_ASSERT(poller_run == true);
+
+	spdk_poller_unregister(&poller);
+	CU_ASSERT(poller == NULL);
+
+	/* Register a poller with 1000us wait time and test single execution */
+	poller_run = false;
+	poller = spdk_poller_register(poller_run_done, &poller_run, 1000);
+	CU_ASSERT(poller != NULL);
+
+	poll_threads();
+	CU_ASSERT(poller_run == false);
+
+	increment_time(1000);
+	poll_threads();
+	CU_ASSERT(poller_run == true);
+
+	reset_time();
+	poller_run = false;
+	poll_threads();
+	CU_ASSERT(poller_run == false);
+
+	increment_time(1000);
+	poll_threads();
+	CU_ASSERT(poller_run == true);
+
+	spdk_poller_unregister(&poller);
+	CU_ASSERT(poller == NULL);
+
+	free_threads();
+}
+
 static void
 for_each_cb(void *ctx)
 {
@@ -400,7 +457,6 @@ channel(void)
 
 	spdk_io_device_unregister(&device1, NULL);
 	spdk_io_device_unregister(&device2, NULL);
-	spdk_io_device_unregister(&device3, NULL);
 	CU_ASSERT(TAILQ_EMPTY(&g_io_devices));
 	spdk_free_thread();
 	CU_ASSERT(TAILQ_EMPTY(&g_threads));
@@ -425,6 +481,7 @@ main(int argc, char **argv)
 	if (
 		CU_add_test(suite, "thread_alloc", thread_alloc) == NULL ||
 		CU_add_test(suite, "thread_send_msg", thread_send_msg) == NULL ||
+		CU_add_test(suite, "thread_poller", thread_poller) == NULL ||
 		CU_add_test(suite, "thread_for_each", thread_for_each) == NULL ||
 		CU_add_test(suite, "for_each_channel_remove", for_each_channel_remove) == NULL ||
 		CU_add_test(suite, "for_each_channel_unreg", for_each_channel_unreg) == NULL ||
diff --git a/test/unit/lib/util/Makefile b/test/unit/lib/util/Makefile
index 8ce9670e9..4813e63b7 100644
--- a/test/unit/lib/util/Makefile
+++ b/test/unit/lib/util/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = bit_array.c cpuset.c crc16.c crc32_ieee.c crc32c.c io_channel.c string.c
+DIRS-y = base64.c bit_array.c cpuset.c crc16.c crc32_ieee.c crc32c.c string.c
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/test/unit/lib/util/base64.c/.gitignore b/test/unit/lib/util/base64.c/.gitignore
new file mode 100644
index 000000000..a5b175236
--- /dev/null
+++ b/test/unit/lib/util/base64.c/.gitignore
@@ -0,0 +1 @@
+base64_ut
diff --git a/test/unit/lib/vhost/vhost_blk.c/Makefile b/test/unit/lib/util/base64.c/Makefile
similarity index 94%
rename from test/unit/lib/vhost/vhost_blk.c/Makefile
rename to test/unit/lib/util/base64.c/Makefile
index 359e71975..ff6c92142 100644
--- a/test/unit/lib/vhost/vhost_blk.c/Makefile
+++ b/test/unit/lib/util/base64.c/Makefile
@@ -35,8 +35,6 @@ SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
 
-CFLAGS += -I$(SPDK_ROOT_DIR)/lib/vhost/rte_vhost
-CFLAGS += $(ENV_CFLAGS)
-TEST_FILE = vhost_blk_ut.c
+TEST_FILE = base64_ut.c
 
 include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/util/base64.c/base64_ut.c b/test/unit/lib/util/base64.c/base64_ut.c
new file mode 100644
index 000000000..0f537132a
--- /dev/null
+++ b/test/unit/lib/util/base64.c/base64_ut.c
@@ -0,0 +1,268 @@
+/*-
+ *   BSD LICENSE
+ *
+ *   Copyright (c) Intel Corporation.
+ *   All rights reserved.
+ *
+ *   Redistribution and use in source and binary forms, with or without
+ *   modification, are permitted provided that the following conditions
+ *   are met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in
+ *       the documentation and/or other materials provided with the
+ *       distribution.
+ *     * Neither the name of Intel Corporation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "spdk/stdinc.h"
+
+#include "spdk_cunit.h"
+
+#include "util/base64.c"
+
+char text_A[] = "FZB3";
+uint8_t raw_A[] = {0x15, 0x90, 0x77};
+char text_B[] = "AbC/1+c=";
+char text_urlsafe_B[] = "AbC_1-c=";
+uint8_t raw_B[] = {0x01, 0xB0, 0xBF, 0xD7, 0xE7};
+char text_C[] = "AbC/1+cC";
+char text_urlsafe_C[] = "AbC_1-cC";
+uint8_t raw_C[] = {0x01, 0xB0, 0xBF, 0xD7, 0xE7, 0x02};
+char text_D[] = "AbC/1w==";
+char text_urlsafe_D[] = "AbC_1w==";
+uint8_t raw_D[] = {0x01, 0xB0, 0xBF, 0xD7};
+char text_E[] = "AbC12===";
+char text_F[] = "AbCd112";
+char text_G[] = "AbCd12";
+char text_H[] = "AbC12";
+
+static void
+test_base64_get_encoded_strlen(void)
+{
+	uint32_t raw_lens[4] = {8, 9, 10, 11};
+	uint32_t text_strlens[4] = {12, 12, 16, 16};
+	uint32_t text_strlen;
+	int i;
+
+	for (i = 0; i < 4; i++) {
+		text_strlen = spdk_base64_get_encoded_strlen(raw_lens[i]);
+		CU_ASSERT_EQUAL(text_strlen, text_strlens[i]);
+	}
+}
+
+static void
+test_base64_get_decoded_len(void)
+{
+	uint32_t text_strlens[4] = {8, 10, 11, 12};
+	uint32_t raw_lens[4] = {6, 7, 8, 9};
+	uint32_t bin_len;
+	int i;
+
+	for (i = 0; i < 4; i++) {
+		bin_len = spdk_base64_get_decoded_len(text_strlens[i]);
+		CU_ASSERT_EQUAL(bin_len, raw_lens[i]);
+	}
+}
+
+static void
+test_base64_encode(void)
+{
+	char text[100];
+	int ret;
+
+	ret = spdk_base64_encode(text, raw_A, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_A) == 0);
+	CU_ASSERT_EQUAL(strlen(text), strlen(text_A));
+
+	ret = spdk_base64_encode(text, raw_B, sizeof(raw_B));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_B) == 0);
+	CU_ASSERT_EQUAL(strlen(text), strlen(text_B));
+
+	ret = spdk_base64_encode(text, raw_C, sizeof(raw_C));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_C) == 0);
+
+	ret = spdk_base64_encode(text, raw_D, sizeof(raw_D));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_D) == 0);
+
+	ret = spdk_base64_encode(NULL, raw_A, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_encode(text, NULL, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_encode(text, raw_A, 0);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+}
+
+static void
+test_base64_decode(void)
+{
+	char raw_buf[100];
+	void *raw = (void *)raw_buf;
+	size_t raw_len;
+	int ret;
+
+	ret = spdk_base64_decode(raw, &raw_len, text_A);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_A));
+	CU_ASSERT(memcmp(raw, raw_A, sizeof(raw_A)) == 0);
+
+	ret = spdk_base64_decode(raw, &raw_len, text_B);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_B));
+	CU_ASSERT(memcmp(raw, raw_B, sizeof(raw_B)) == 0);
+
+	ret = spdk_base64_decode(raw, &raw_len, text_C);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_C));
+	CU_ASSERT(memcmp(raw, raw_C, sizeof(raw_C)) == 0);
+
+	ret = spdk_base64_decode(raw, &raw_len, text_D);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_D));
+	CU_ASSERT(memcmp(raw, raw_D, sizeof(raw_D)) == 0);
+
+	ret = spdk_base64_decode(raw, &raw_len, text_E);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_decode(raw, &raw_len, text_F);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_decode(raw, &raw_len, text_G);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_decode(raw, &raw_len, text_H);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_decode(NULL, &raw_len, text_H);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_decode(raw, &raw_len, NULL);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+}
+
+static void
+test_base64_urlsafe_encode(void)
+{
+	char text[100];
+	int ret;
+
+	ret = spdk_base64_urlsafe_encode(text, raw_A, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_A) == 0);
+	CU_ASSERT_EQUAL(strlen(text), strlen(text_A));
+
+	ret = spdk_base64_urlsafe_encode(text, raw_B, sizeof(raw_B));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_urlsafe_B) == 0);
+	CU_ASSERT_EQUAL(strlen(text), strlen(text_urlsafe_B));
+
+	ret = spdk_base64_urlsafe_encode(text, raw_C, sizeof(raw_C));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_urlsafe_C) == 0);
+
+	ret = spdk_base64_urlsafe_encode(text, raw_D, sizeof(raw_D));
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT(strcmp(text, text_urlsafe_D) == 0);
+
+	ret = spdk_base64_urlsafe_encode(NULL, raw_A, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_encode(text, NULL, sizeof(raw_A));
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_encode(text, raw_A, 0);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+}
+
+static void
+test_base64_urlsafe_decode(void)
+{
+	char raw_buf[100];
+	void *raw = (void *)raw_buf;
+	size_t raw_len;
+	int ret;
+
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_A);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_A));
+	CU_ASSERT(memcmp(raw, raw_A, sizeof(raw_A)) == 0);
+
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_urlsafe_B);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_B));
+	CU_ASSERT(memcmp(raw, raw_B, sizeof(raw_B)) == 0);
+
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_urlsafe_C);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_C));
+	CU_ASSERT(memcmp(raw, raw_C, sizeof(raw_C)) == 0);
+
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_urlsafe_D);
+	CU_ASSERT_EQUAL(ret, 0);
+	CU_ASSERT_EQUAL(raw_len, sizeof(raw_D));
+	CU_ASSERT(memcmp(raw, raw_D, sizeof(raw_D)) == 0);
+
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_E);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_F);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_G);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, text_H);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_decode(NULL, &raw_len, text_H);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+	ret = spdk_base64_urlsafe_decode(raw, &raw_len, NULL);
+	CU_ASSERT_EQUAL(ret, -EINVAL);
+}
+
+int
+main(int argc, char **argv)
+{
+	CU_pSuite	suite = NULL;
+	unsigned int	num_failures;
+
+	if (CU_initialize_registry() != CUE_SUCCESS) {
+		return CU_get_error();
+	}
+
+	suite = CU_add_suite("base64", NULL, NULL);
+	if (suite == NULL) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	if (
+		CU_add_test(suite, "test_base64_get_encoded_strlen", test_base64_get_encoded_strlen) == NULL ||
+		CU_add_test(suite, "test_base64_get_decoded_len",
+			    test_base64_get_decoded_len) == NULL ||
+		CU_add_test(suite, "test_base64_encode", test_base64_encode) == NULL ||
+		CU_add_test(suite, "test_base64_decode", test_base64_decode) == NULL ||
+		CU_add_test(suite, "test_base64_urlsafe_encode", test_base64_urlsafe_encode) == NULL ||
+		CU_add_test(suite, "test_base64_urlsafe_decode", test_base64_urlsafe_decode) == NULL) {
+		CU_cleanup_registry();
+		return CU_get_error();
+	}
+
+	CU_basic_set_mode(CU_BRM_VERBOSE);
+
+	CU_basic_run_tests();
+
+	num_failures = CU_get_number_of_failures();
+	CU_cleanup_registry();
+
+	return num_failures;
+}
diff --git a/test/unit/lib/util/bit_array.c/bit_array_ut.c b/test/unit/lib/util/bit_array.c/bit_array_ut.c
index 65a071db9..682ce3749 100644
--- a/test/unit/lib/util/bit_array.c/bit_array_ut.c
+++ b/test/unit/lib/util/bit_array.c/bit_array_ut.c
@@ -236,6 +236,59 @@ test_errors(void)
 	spdk_bit_array_free(NULL);
 }
 
+static void
+test_count(void)
+{
+	struct spdk_bit_array *ba;
+	uint32_t i;
+
+	/* 0-bit array should have 0 bits set and 0 bits clear */
+	ba = spdk_bit_array_create(0);
+	SPDK_CU_ASSERT_FATAL(ba != NULL);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 0);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 0);
+	spdk_bit_array_free(&ba);
+
+	/* 1-bit array */
+	ba = spdk_bit_array_create(1);
+	SPDK_CU_ASSERT_FATAL(ba != NULL);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 0);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 1);
+	spdk_bit_array_set(ba, 0);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 1);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 0);
+	spdk_bit_array_free(&ba);
+
+	/* 65-bit array */
+	ba = spdk_bit_array_create(65);
+	SPDK_CU_ASSERT_FATAL(ba != NULL);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 0);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 65);
+	spdk_bit_array_set(ba, 0);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 1);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 64);
+	spdk_bit_array_set(ba, 5);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 2);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 63);
+	spdk_bit_array_set(ba, 13);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 3);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 62);
+	spdk_bit_array_clear(ba, 0);
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 2);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 63);
+	for (i = 0; i < 65; i++) {
+		spdk_bit_array_set(ba, i);
+	}
+	CU_ASSERT(spdk_bit_array_count_set(ba) == 65);
+	CU_ASSERT(spdk_bit_array_count_clear(ba) == 0);
+	for (i = 0; i < 65; i++) {
+		spdk_bit_array_clear(ba, i);
+		CU_ASSERT(spdk_bit_array_count_set(ba) == 65 - i - 1);
+		CU_ASSERT(spdk_bit_array_count_clear(ba) == i + 1);
+	}
+	spdk_bit_array_free(&ba);
+}
+
 int
 main(int argc, char **argv)
 {
@@ -257,7 +310,8 @@ main(int argc, char **argv)
 		CU_add_test(suite, "test_64bit", test_64bit) == NULL ||
 		CU_add_test(suite, "test_find", test_find) == NULL ||
 		CU_add_test(suite, "test_resize", test_resize) == NULL ||
-		CU_add_test(suite, "test_errors", test_errors) == NULL) {
+		CU_add_test(suite, "test_errors", test_errors) == NULL ||
+		CU_add_test(suite, "test_count", test_count) == NULL) {
 		CU_cleanup_registry();
 		return CU_get_error();
 	}
diff --git a/test/unit/lib/util/io_channel.c/.gitignore b/test/unit/lib/util/io_channel.c/.gitignore
deleted file mode 100644
index f957986fd..000000000
--- a/test/unit/lib/util/io_channel.c/.gitignore
+++ /dev/null
@@ -1 +0,0 @@
-io_channel_ut
diff --git a/test/unit/lib/vhost/Makefile b/test/unit/lib/vhost/Makefile
index c3aa48689..0f569f6d2 100644
--- a/test/unit/lib/vhost/Makefile
+++ b/test/unit/lib/vhost/Makefile
@@ -34,7 +34,7 @@
 SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../..)
 include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
 
-DIRS-y = vhost.c vhost_scsi.c vhost_blk.c
+DIRS-y = vhost.c
 
 .PHONY: all clean $(DIRS-y)
 
diff --git a/test/unit/lib/vhost/test_vhost.c b/test/unit/lib/vhost/test_vhost.c
index 53ce4eb34..437e12301 100644
--- a/test/unit/lib/vhost/test_vhost.c
+++ b/test/unit/lib/vhost/test_vhost.c
@@ -36,7 +36,7 @@
 #include "CUnit/Basic.h"
 #include "spdk_cunit.h"
 #include "spdk_internal/mock.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 
 #include "unit/lib/json_mock.c"
 
@@ -47,8 +47,6 @@ struct spdk_conf_section {
 	struct spdk_conf_item *item;
 };
 
-DEFINE_STUB(spdk_ring_enqueue, size_t, (struct spdk_ring *ring, void **objs, size_t count), 0);
-DEFINE_STUB(spdk_ring_dequeue, size_t, (struct spdk_ring *ring, void **objs, size_t count), 0);
 DEFINE_STUB(spdk_vhost_vq_get_desc, int, (struct spdk_vhost_dev *vdev,
 		struct spdk_vhost_virtqueue *vq, uint16_t req_idx, struct vring_desc **desc,
 		struct vring_desc **desc_table, uint32_t *desc_table_size), 0);
@@ -66,7 +64,6 @@ DEFINE_STUB(spdk_vhost_vq_used_signal, int, (struct spdk_vhost_dev *vdev,
 DEFINE_STUB_V(spdk_vhost_dev_used_signal, (struct spdk_vhost_dev *vdev));
 DEFINE_STUB_V(spdk_vhost_dev_mem_register, (struct spdk_vhost_dev *vdev));
 DEFINE_STUB_P(spdk_vhost_dev_find, struct spdk_vhost_dev, (const char *ctrlr_name), {0});
-DEFINE_STUB_V(spdk_ring_free, (struct spdk_ring *ring));
 DEFINE_STUB_P(spdk_conf_first_section, struct spdk_conf_section, (struct spdk_conf *cp), {0});
 DEFINE_STUB(spdk_conf_section_match_prefix, bool, (const struct spdk_conf_section *sp,
 		const char *name_prefix), false);
diff --git a/test/unit/lib/vhost/vhost.c/vhost_ut.c b/test/unit/lib/vhost/vhost.c/vhost_ut.c
index 06b4a9702..49e879ed5 100644
--- a/test/unit/lib/vhost/vhost.c/vhost_ut.c
+++ b/test/unit/lib/vhost/vhost.c/vhost_ut.c
@@ -35,7 +35,7 @@
 
 #include "CUnit/Basic.h"
 #include "spdk_cunit.h"
-#include "spdk/io_channel.h"
+#include "spdk/thread.h"
 #include "spdk_internal/mock.h"
 #include "common/lib/test_env.c"
 #include "unit/lib/json_mock.c"
diff --git a/test/unit/lib/vhost/vhost_blk.c/.gitignore b/test/unit/lib/vhost/vhost_blk.c/.gitignore
deleted file mode 100644
index 85cd88dfc..000000000
--- a/test/unit/lib/vhost/vhost_blk.c/.gitignore
+++ /dev/null
@@ -1 +0,0 @@
-vhost_blk_ut
diff --git a/test/unit/lib/vhost/vhost_blk.c/vhost_blk_ut.c b/test/unit/lib/vhost/vhost_blk.c/vhost_blk_ut.c
deleted file mode 100644
index 7fac97381..000000000
--- a/test/unit/lib/vhost/vhost_blk.c/vhost_blk_ut.c
+++ /dev/null
@@ -1,213 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "spdk/stdinc.h"
-
-#include "CUnit/Basic.h"
-#include "spdk_cunit.h"
-#include "spdk_internal/mock.h"
-#include "common/lib/test_env.c"
-
-#include "vhost/vhost_blk.c"
-#include "unit/lib/vhost/test_vhost.c"
-
-#include "spdk_internal/bdev.h"
-#include "spdk/env.h"
-
-DEFINE_STUB(spdk_bdev_free_io, int, (struct spdk_bdev_io *bdev_io), 0);
-DEFINE_STUB(spdk_bdev_readv, int, (struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
-				   struct iovec *iov, int iovcnt, uint64_t offset, uint64_t nbytes, spdk_bdev_io_completion_cb cb,
-				   void *cb_arg), 0);
-DEFINE_STUB(spdk_bdev_writev, int, (struct spdk_bdev_desc *desc, struct spdk_io_channel *ch,
-				    struct iovec *iov, int iovcnt, uint64_t offset, uint64_t len, spdk_bdev_io_completion_cb cb,
-				    void *cb_arg), 0);
-DEFINE_STUB_P(spdk_bdev_get_product_name, const char, (const struct spdk_bdev *bdev), {0});
-DEFINE_STUB_P(spdk_bdev_get_name, const char, (const struct spdk_bdev *bdev), {0});
-DEFINE_STUB_P(spdk_conf_section_get_val, char, (struct spdk_conf_section *sp, const char *key), {0});
-DEFINE_STUB_P(spdk_bdev_get_by_name, struct spdk_bdev, (const char *bdev_name), {0});
-DEFINE_STUB(spdk_bdev_open, int, (struct spdk_bdev *bdev, bool write,
-				  spdk_bdev_remove_cb_t remove_cb, void *remove_ctx, struct spdk_bdev_desc **desc), 0);
-DEFINE_STUB_V(spdk_bdev_close, (struct spdk_bdev_desc *desc));
-DEFINE_STUB(rte_vhost_driver_enable_features, int, (const char *path, uint64_t features), 0);
-DEFINE_STUB_P(spdk_bdev_get_io_channel, struct spdk_io_channel, (struct spdk_bdev_desc *desc), {0});
-
-SPDK_LOG_REGISTER_COMPONENT("vhost", SPDK_LOG_VHOST)
-
-uint32_t
-spdk_bdev_get_block_size(const struct spdk_bdev *bdev)
-{
-	return 512;
-}
-
-uint64_t
-spdk_bdev_get_num_blocks(const struct spdk_bdev *bdev)
-{
-	return 0x1;
-}
-
-bool
-spdk_bdev_has_write_cache(const struct spdk_bdev *bdev)
-{
-	return false;
-}
-
-static void
-vhost_blk_controller_construct_test(void)
-{
-	int rc;
-
-	MOCK_SET_P(spdk_conf_next_section, struct spdk_conf_section *, NULL);
-
-	/* VhostBlk section has non numeric suffix */
-	MOCK_SET(spdk_conf_section_match_prefix, bool, true);
-	MOCK_SET_P(spdk_conf_section_get_name, const char *, "VhostBlkx");
-	rc = spdk_vhost_blk_controller_construct();
-	CU_ASSERT(rc != 0);
-
-	/* Device has no name */
-	MOCK_SET_P(spdk_conf_section_get_name, const char *, "VhostBlk0");
-	MOCK_SET_P(spdk_conf_section_get_val, char *, NULL);
-	rc = spdk_vhost_blk_controller_construct();
-	CU_ASSERT(rc != 0);
-}
-
-static struct spdk_vhost_blk_dev *
-alloc_bvdev(void)
-{
-	struct spdk_vhost_blk_dev *bvdev = spdk_dma_zmalloc(sizeof(struct spdk_vhost_blk_dev),
-					   SPDK_CACHE_LINE_SIZE, NULL);
-
-	SPDK_CU_ASSERT_FATAL(bvdev != NULL);
-	bvdev->vdev.backend = &vhost_blk_device_backend;
-	return bvdev;
-}
-
-static void
-vhost_blk_construct_test(void)
-{
-	int rc;
-	struct spdk_bdev *ut_p_spdk_bdev = MOCK_PASS_THRU_P;
-
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, false);
-	MOCK_SET(spdk_vhost_dev_register_fail, bool, false);
-
-	/* Create device with invalid name */
-	MOCK_SET_P(spdk_bdev_get_by_name, struct spdk_bdev *, NULL);
-	rc = spdk_vhost_blk_construct("vhost.0", "0x1", NULL, true);
-	CU_ASSERT(rc != 0);
-
-	/* Device could not be opened */
-	MOCK_SET_P(spdk_bdev_get_by_name, struct spdk_bdev *, ut_p_spdk_bdev);
-	MOCK_SET(spdk_bdev_open, int, -ENOMEM);
-	rc = spdk_vhost_blk_construct("vhost.0", "0x1", "Malloc0", true);
-	CU_ASSERT(rc != 0);
-
-	/* Failed to construct controller */
-	MOCK_SET(spdk_bdev_open, int, 0);
-	MOCK_SET(spdk_vhost_dev_register_fail, bool, true);
-	rc = spdk_vhost_blk_construct("vhost.0", "0x1", "Malloc0", true);
-	CU_ASSERT(rc != 0);
-
-	/* Failed to set readonly as a feature */
-	MOCK_SET(rte_vhost_driver_enable_features, int, -1);
-	rc = spdk_vhost_blk_construct("vhost.0", "0x1", "Malloc0", true);
-	CU_ASSERT(rc != 0);
-
-	/* Failed to set readonly as a feature and failed to remove controller */
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, true);
-	rc = spdk_vhost_blk_construct("vhost.0", "0x1", "Malloc0", true);
-	CU_ASSERT(rc != 0);
-}
-
-static void
-vhost_blk_destroy_test(void)
-{
-	int rc;
-	struct spdk_vhost_blk_dev *bvdev = NULL;
-
-	bvdev = alloc_bvdev();
-
-	/* Device has an incorrect type */
-	bvdev->vdev.backend = NULL;;
-	rc = spdk_vhost_blk_destroy(&bvdev->vdev);
-	CU_ASSERT(rc == -EINVAL);
-
-	/* Failed to remove device */
-	bvdev->vdev.backend = &vhost_blk_device_backend;
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, true);
-	rc = spdk_vhost_blk_destroy(&bvdev->vdev);
-	CU_ASSERT(rc == -1);
-
-	if (rc != 0) {
-		free(bvdev);
-	}
-}
-
-static int
-test_setup(void)
-{
-	return 0;
-}
-
-int
-main(int argc, char **argv)
-{
-	CU_pSuite	suite = NULL;
-	unsigned int	num_failures;
-
-	if (CU_initialize_registry() != CUE_SUCCESS) {
-		return CU_get_error();
-	}
-
-	suite = CU_add_suite("vhost_scsi_suite", test_setup, NULL);
-	if (suite == NULL) {
-		CU_cleanup_registry();
-		return CU_get_error();
-	}
-
-	if (
-		CU_add_test(suite, "vhost_blk_controller_construct", vhost_blk_controller_construct_test) == NULL ||
-		CU_add_test(suite, "vhost_blk_construct_test", vhost_blk_construct_test) == NULL ||
-		CU_add_test(suite, "vhost_blk_destroy", vhost_blk_destroy_test) == NULL
-	) {
-		CU_cleanup_registry();
-		return CU_get_error();
-	}
-
-	CU_basic_set_mode(CU_BRM_VERBOSE);
-	CU_basic_run_tests();
-	num_failures = CU_get_number_of_failures();
-	CU_cleanup_registry();
-
-	return num_failures;
-}
diff --git a/test/unit/lib/vhost/vhost_scsi.c/.gitignore b/test/unit/lib/vhost/vhost_scsi.c/.gitignore
deleted file mode 100644
index dc775ea32..000000000
--- a/test/unit/lib/vhost/vhost_scsi.c/.gitignore
+++ /dev/null
@@ -1 +0,0 @@
-vhost_scsi_ut
diff --git a/test/unit/lib/vhost/vhost_scsi.c/Makefile b/test/unit/lib/vhost/vhost_scsi.c/Makefile
deleted file mode 100644
index 3b8a59b08..000000000
--- a/test/unit/lib/vhost/vhost_scsi.c/Makefile
+++ /dev/null
@@ -1,42 +0,0 @@
-#
-#  BSD LICENSE
-#
-#  Copyright (c) Intel Corporation.
-#  All rights reserved.
-#
-#  Redistribution and use in source and binary forms, with or without
-#  modification, are permitted provided that the following conditions
-#  are met:
-#
-#    * Redistributions of source code must retain the above copyright
-#      notice, this list of conditions and the following disclaimer.
-#    * Redistributions in binary form must reproduce the above copyright
-#      notice, this list of conditions and the following disclaimer in
-#      the documentation and/or other materials provided with the
-#      distribution.
-#    * Neither the name of Intel Corporation nor the names of its
-#      contributors may be used to endorse or promote products derived
-#      from this software without specific prior written permission.
-#
-#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-#
-
-SPDK_ROOT_DIR := $(abspath $(CURDIR)/../../../../..)
-include $(SPDK_ROOT_DIR)/mk/spdk.common.mk
-include $(SPDK_ROOT_DIR)/mk/spdk.app.mk
-
-CFLAGS += -I$(SPDK_ROOT_DIR)/lib/vhost/rte_vhost
-CFLAGS += $(ENV_CFLAGS)
-TEST_FILE = vhost_scsi_ut.c
-
-include $(SPDK_ROOT_DIR)/mk/spdk.unittest.mk
diff --git a/test/unit/lib/vhost/vhost_scsi.c/vhost_scsi_ut.c b/test/unit/lib/vhost/vhost_scsi.c/vhost_scsi_ut.c
deleted file mode 100644
index 0865dc2d5..000000000
--- a/test/unit/lib/vhost/vhost_scsi.c/vhost_scsi_ut.c
+++ /dev/null
@@ -1,307 +0,0 @@
-/*-
- *   BSD LICENSE
- *
- *   Copyright(c) Intel Corporation. All rights reserved.
- *   All rights reserved.
- *
- *   Redistribution and use in source and binary forms, with or without
- *   modification, are permitted provided that the following conditions
- *   are met:
- *
- *     * Redistributions of source code must retain the above copyright
- *       notice, this list of conditions and the following disclaimer.
- *     * Redistributions in binary form must reproduce the above copyright
- *       notice, this list of conditions and the following disclaimer in
- *       the documentation and/or other materials provided with the
- *       distribution.
- *     * Neither the name of Intel Corporation nor the names of its
- *       contributors may be used to endorse or promote products derived
- *       from this software without specific prior written permission.
- *
- *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "spdk/stdinc.h"
-
-#include "CUnit/Basic.h"
-#include "spdk_cunit.h"
-#include "spdk_internal/mock.h"
-#include "common/lib/test_env.c"
-
-#include "spdk/scsi.h"
-#include "vhost/vhost_scsi.c"
-#include "scsi/scsi_internal.h"
-#include "unit/lib/vhost/test_vhost.c"
-
-#include "spdk/env.h"
-
-DEFINE_STUB_V(spdk_scsi_task_put, (struct spdk_scsi_task *task));
-DEFINE_STUB(spdk_scsi_dev_allocate_io_channels, int, (struct spdk_scsi_dev *dev), 0);
-DEFINE_STUB_P(spdk_scsi_lun_get_bdev_name, const char, (const struct spdk_scsi_lun *lun), {0});
-DEFINE_STUB(spdk_scsi_lun_get_id, int, (const struct spdk_scsi_lun *lun), 0);
-DEFINE_STUB(spdk_scsi_dev_has_pending_tasks, bool, (const struct spdk_scsi_dev *dev), false);
-DEFINE_STUB_V(spdk_scsi_dev_free_io_channels, (struct spdk_scsi_dev *dev));
-DEFINE_STUB_V(spdk_scsi_dev_destruct, (struct spdk_scsi_dev *dev));
-DEFINE_STUB_V(spdk_scsi_dev_queue_task, (struct spdk_scsi_dev *dev, struct spdk_scsi_task *task));
-DEFINE_STUB_V(spdk_scsi_dev_queue_mgmt_task, (struct spdk_scsi_dev *dev,
-		struct spdk_scsi_task *task, enum spdk_scsi_task_func func));
-DEFINE_STUB_P(spdk_scsi_dev_find_port_by_id, struct spdk_scsi_port, (struct spdk_scsi_dev *dev,
-		uint64_t id), {0});
-DEFINE_STUB_V(spdk_scsi_task_construct, (struct spdk_scsi_task *task, spdk_scsi_task_cpl cpl_fn,
-		spdk_scsi_task_free free_fn));
-DEFINE_STUB_P(spdk_scsi_dev_get_lun, struct spdk_scsi_lun, (struct spdk_scsi_dev *dev, int lun_id), {0});
-DEFINE_STUB_V(spdk_scsi_task_process_null_lun, (struct spdk_scsi_task *task));
-DEFINE_STUB_P(spdk_scsi_lun_get_dev, const struct spdk_scsi_dev, (const struct spdk_scsi_lun *lun), {0});
-DEFINE_STUB_P(spdk_scsi_dev_get_name, const char, (const struct spdk_scsi_dev *dev), {0});
-DEFINE_STUB_P(spdk_scsi_dev_construct, struct spdk_scsi_dev, (const char *name,
-		const char *bdev_name_list[], int *lun_id_list, int num_luns, uint8_t protocol_id,
-		void (*hotremove_cb)(const struct spdk_scsi_lun *, void *), void *hotremove_ctx), {0});
-DEFINE_STUB(spdk_scsi_dev_add_port, int, (struct spdk_scsi_dev *dev, uint64_t id, const char *name),
-	    0);
-
-SPDK_LOG_REGISTER_COMPONENT("vhost", SPDK_LOG_VHOST)
-
-char *
-spdk_conf_section_get_nval(struct spdk_conf_section *sp, const char *key, int idx)
-{
-	if (idx == 0) {
-		return "0";
-	}
-
-	return NULL;
-}
-
-char *
-spdk_conf_section_get_val(struct spdk_conf_section *sp, const char *key)
-{
-	if (strcmp(key, "Name") == 0) {
-		return "Vhost.0";
-	} else if (strcmp(key, "Cpumask") == 0) {
-		return "0x1";
-	}
-
-	return NULL;
-}
-
-static int
-test_setup(void)
-{
-	return 0;
-}
-
-static struct spdk_vhost_scsi_dev *
-alloc_svdev(void)
-{
-	struct spdk_vhost_scsi_dev *svdev = spdk_dma_zmalloc(sizeof(struct spdk_vhost_scsi_dev),
-					    SPDK_CACHE_LINE_SIZE, NULL);
-
-	SPDK_CU_ASSERT_FATAL(svdev != NULL);
-	svdev->vdev.registered = true;
-	svdev->vdev.backend = &spdk_vhost_scsi_device_backend;
-	return svdev;
-}
-
-static struct spdk_scsi_dev *
-alloc_scsi_dev(void)
-{
-	struct spdk_scsi_dev *sdev;
-
-	sdev = calloc(1, sizeof(*sdev));
-	return sdev;
-}
-
-static void
-vhost_scsi_controller_construct_test(void)
-{
-	int rc;
-
-	MOCK_SET_P(spdk_conf_next_section, struct spdk_conf_section *, NULL);
-
-	/* VhostScsi section has non numeric suffix */
-	MOCK_SET(spdk_conf_section_match_prefix, bool, true);
-	MOCK_SET_P(spdk_conf_section_get_name, const char *, "VhostScsix");
-	rc = spdk_vhost_scsi_controller_construct();
-	CU_ASSERT(rc != 0);
-
-	/* Dev number has no value */
-	MOCK_SET_P(spdk_conf_section_get_name, const char *, "VhostScsi0");
-	MOCK_SET_P(spdk_conf_section_get_nmval, char *, NULL);
-	rc = spdk_vhost_scsi_controller_construct();
-	CU_ASSERT(rc != 0);
-	/*
-	 * Expecting that device has been created during the test but wasn't initialized as
-	 * spdk_vhost_scsi_controller_construct failed after creating device
-	 */
-	CU_ASSERT(g_spdk_vhost_device != NULL);
-
-	/* Remove created device */
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, false);
-	rc = spdk_vhost_scsi_dev_remove(g_spdk_vhost_device);
-	CU_ASSERT(rc == 0);
-}
-
-static void
-vhost_scsi_dev_remove_test(void)
-{
-	int rc;
-	struct spdk_vhost_scsi_dev *svdev = NULL;
-	struct spdk_scsi_dev *scsi_dev;
-
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, false);
-
-	/* Try to remove controller which is occupied */
-	svdev = alloc_svdev();
-	scsi_dev = alloc_scsi_dev();
-	svdev->scsi_dev[0] = scsi_dev;
-	rc = spdk_vhost_scsi_dev_remove(&svdev->vdev);
-	CU_ASSERT(rc == -EBUSY);
-	free(scsi_dev);
-	svdev->scsi_dev[0] = NULL;
-
-	/* Failed to remove device */
-	MOCK_SET(spdk_vhost_dev_unregister_fail, bool, true);
-	rc = spdk_vhost_scsi_dev_remove(&svdev->vdev);
-	CU_ASSERT(rc == -1);
-
-	free(svdev);
-}
-
-static void
-vhost_scsi_dev_construct_test(void)
-{
-	int rc;
-
-	/* Failed to construct vhost device */
-	MOCK_SET(spdk_vhost_dev_register_fail, bool, true);
-	rc = spdk_vhost_scsi_dev_construct("vhost.0", "0x1");
-	CU_ASSERT(rc != 0);
-}
-
-static void
-vhost_scsi_dev_remove_dev_test(void)
-{
-	int rc;
-	struct spdk_vhost_scsi_dev *svdev;
-	struct spdk_scsi_dev *scsi_dev;
-
-	svdev = alloc_svdev();
-	svdev->vdev.name = strdup("vhost.0");
-
-	/* Invalid device number */
-	rc = spdk_vhost_scsi_dev_remove_tgt(&svdev->vdev, SPDK_VHOST_SCSI_CTRLR_MAX_DEVS + 1, NULL,
-					    NULL);
-	CU_ASSERT(rc == -EINVAL);
-
-	/* Try to remove nonexistent device */
-	rc = spdk_vhost_scsi_dev_remove_tgt(&svdev->vdev, 0, NULL, NULL);
-	CU_ASSERT(rc == -ENODEV);
-
-	/* Try to remove device when controller is in use */
-	svdev->vdev.lcore = 0;
-	scsi_dev = alloc_scsi_dev();
-	svdev->scsi_dev[0] = scsi_dev;
-	rc = spdk_vhost_scsi_dev_remove_tgt(&svdev->vdev, 0, NULL, NULL);
-	CU_ASSERT(rc == -ENOTSUP);
-	free(scsi_dev);
-	free(svdev->vdev.name);
-	free(svdev);
-}
-
-static void
-vhost_scsi_dev_add_dev_test(void)
-{
-	int rc;
-	char long_name[SPDK_SCSI_DEV_MAX_NAME + 1];
-	struct spdk_vhost_scsi_dev *svdev;
-	struct spdk_vhost_dev *vdev;
-	struct spdk_scsi_dev *scsi_dev;
-
-	/* Add device to controller without name */
-	rc = spdk_vhost_scsi_dev_add_tgt(NULL, 0, "Malloc0");
-	CU_ASSERT(rc == -EINVAL);
-
-	svdev = alloc_svdev();
-	vdev = &svdev->vdev;
-
-	/* Add device when max devices is reached */
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev,
-					 SPDK_VHOST_SCSI_CTRLR_MAX_DEVS + 1, "Malloc0");
-	CU_ASSERT(rc == -EINVAL);
-
-	/* Add device but lun has no name */
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev, 0, NULL);
-	CU_ASSERT(rc == -EINVAL);
-
-	/* Add device but lun has too long name */
-	memset(long_name, 'x', sizeof(long_name));
-	long_name[SPDK_SCSI_DEV_MAX_NAME] = 0;
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev, 0, long_name);
-	CU_ASSERT(rc != 0);
-
-	/* Add device to a controller which is in use */
-	svdev->vdev.lcore = 0;
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev, 0, "Malloc0");
-	CU_ASSERT(rc == -ENOTSUP);
-
-	/* Add device to controller with already occupied device */
-	vdev->lcore = -1;
-	scsi_dev = alloc_scsi_dev();
-	svdev->scsi_dev[0] = scsi_dev;
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev, 0, "Malloc0");
-	CU_ASSERT(rc == -EEXIST);
-	free(scsi_dev);
-	svdev->scsi_dev[0] = NULL;
-
-	/* Failed to create device */
-	MOCK_SET_P(spdk_scsi_dev_construct, struct spdk_scsi_dev *, NULL);
-	rc = spdk_vhost_scsi_dev_add_tgt(vdev, 0, "Malloc0");
-	CU_ASSERT(rc == -EINVAL);
-
-	free(svdev);
-}
-
-int
-main(int argc, char **argv)
-{
-	CU_pSuite	suite = NULL;
-	unsigned int	num_failures;
-
-	if (CU_initialize_registry() != CUE_SUCCESS) {
-		return CU_get_error();
-	}
-
-	suite = CU_add_suite("vhost_scsi_suite", test_setup, NULL);
-	if (suite == NULL) {
-		CU_cleanup_registry();
-		return CU_get_error();
-	}
-
-	if (
-		CU_add_test(suite, "vhost_scsi_controller_construct",
-			    vhost_scsi_controller_construct_test) == NULL ||
-		CU_add_test(suite, "vhost_scsi_dev_remove_dev", vhost_scsi_dev_remove_dev_test) == NULL ||
-		CU_add_test(suite, "vhost_scsi_dev_remove", vhost_scsi_dev_remove_test) == NULL ||
-		CU_add_test(suite, "vhost_scsi_dev_construct", vhost_scsi_dev_construct_test) == NULL ||
-		CU_add_test(suite, "vhost_scsi_dev_add_dev", vhost_scsi_dev_add_dev_test) == NULL
-	) {
-		CU_cleanup_registry();
-		return CU_get_error();
-	}
-
-	CU_basic_set_mode(CU_BRM_VERBOSE);
-	CU_basic_run_tests();
-	num_failures = CU_get_number_of_failures();
-	CU_cleanup_registry();
-
-	return num_failures;
-}
diff --git a/test/unit/unittest.sh b/test/unit/unittest.sh
index 2af1bccfb..b88f8d1fa 100755
--- a/test/unit/unittest.sh
+++ b/test/unit/unittest.sh
@@ -9,6 +9,8 @@ set -xe
 testdir=$(readlink -f $(dirname $0))
 rootdir=$(readlink -f $(dirname $0)/../..)
 
+cd "$rootdir"
+
 # if ASAN is enabled, use it.  If not use valgrind if installed but allow
 # the env variable to override the default shown below.
 if [ -z ${valgrind+x} ]; then
@@ -46,6 +48,7 @@ fi
 $valgrind $testdir/include/spdk/histogram_data.h/histogram_ut
 
 $valgrind $testdir/lib/bdev/bdev.c/bdev_ut
+$valgrind $testdir/lib/bdev/bdev_raid.c/bdev_raid_ut
 $valgrind $testdir/lib/bdev/part.c/part_ut
 $valgrind $testdir/lib/bdev/scsi_nvme.c/scsi_nvme_ut
 $valgrind $testdir/lib/bdev/gpt/gpt.c/gpt_ut
@@ -66,13 +69,15 @@ $testdir/lib/blobfs/blobfs_sync_ut/blobfs_sync_ut
 
 $valgrind $testdir/lib/event/subsystem.c/subsystem_ut
 
-$valgrind $testdir/lib/net/sock.c/sock_ut
+$valgrind $testdir/lib/sock/sock.c/sock_ut
 
 $valgrind $testdir/lib/nvme/nvme.c/nvme_ut
 $valgrind $testdir/lib/nvme/nvme_ctrlr.c/nvme_ctrlr_ut
 $valgrind $testdir/lib/nvme/nvme_ctrlr_cmd.c/nvme_ctrlr_cmd_ut
+$valgrind $testdir/lib/nvme/nvme_ctrlr_ocssd_cmd.c/nvme_ctrlr_ocssd_cmd_ut
 $valgrind $testdir/lib/nvme/nvme_ns.c/nvme_ns_ut
 $valgrind $testdir/lib/nvme/nvme_ns_cmd.c/nvme_ns_cmd_ut
+$valgrind $testdir/lib/nvme/nvme_ns_ocssd_cmd.c/nvme_ns_ocssd_cmd_ut
 $valgrind $testdir/lib/nvme/nvme_qpair.c/nvme_qpair_ut
 $valgrind $testdir/lib/nvme/nvme_pcie.c/nvme_pcie_ut
 $valgrind $testdir/lib/nvme/nvme_quirks.c/nvme_quirks_ut
@@ -107,17 +112,17 @@ $valgrind $testdir/lib/iscsi/iscsi.c/iscsi_ut
 $valgrind $testdir/lib/iscsi/init_grp.c/init_grp_ut $testdir/lib/iscsi/init_grp.c/init_grp.conf
 $valgrind $testdir/lib/iscsi/portal_grp.c/portal_grp_ut $testdir/lib/iscsi/portal_grp.c/portal_grp.conf
 
+$valgrind $testdir/lib/thread/thread.c/thread_ut
+
+$valgrind $testdir/lib/util/base64.c/base64_ut
 $valgrind $testdir/lib/util/bit_array.c/bit_array_ut
 $valgrind $testdir/lib/util/crc16.c/crc16_ut
 $valgrind $testdir/lib/util/crc32_ieee.c/crc32_ieee_ut
 $valgrind $testdir/lib/util/crc32c.c/crc32c_ut
-$valgrind $testdir/lib/util/io_channel.c/io_channel_ut
 $valgrind $testdir/lib/util/string.c/string_ut
 
 if [ $(uname -s) = Linux ]; then
 $valgrind $testdir/lib/vhost/vhost.c/vhost_ut
-$valgrind $testdir/lib/vhost/vhost_scsi.c/vhost_scsi_ut
-$valgrind $testdir/lib/vhost/vhost_blk.c/vhost_blk_ut
 fi
 
 # local unit test coverage
@@ -147,7 +152,7 @@ echo "====================="
 echo "All unit tests passed"
 echo "====================="
 if [ "$cov_avail" = "yes" ]; then
-	echo "Note: coverage report is here: ./$UT_COVERAGE"
+	echo "Note: coverage report is here: $rootdir/$UT_COVERAGE"
 else
 	echo "WARN: lcov not installed or SPDK built without coverage!"
 fi
diff --git a/test/vhost/common/autotest.config b/test/vhost/common/autotest.config
index 87500afd5..96b0d08be 100644
--- a/test/vhost/common/autotest.config
+++ b/test/vhost/common/autotest.config
@@ -1,38 +1,38 @@
-vhost_0_reactor_mask=0x1
+vhost_0_reactor_mask="[0]"
 vhost_0_master_core=0
 
-VM_0_qemu_mask=0x6
+VM_0_qemu_mask=1-2
 VM_0_qemu_numa_node=0
 
-VM_1_qemu_mask=0x18
+VM_1_qemu_mask=3-4
 VM_1_qemu_numa_node=0
 
-VM_2_qemu_mask=0x60
+VM_2_qemu_mask=5-6
 VM_2_qemu_numa_node=0
 
-VM_3_qemu_mask=0x180
+VM_3_qemu_mask=7-8
 VM_3_qemu_numa_node=0
 
-VM_4_qemu_mask=0x600
+VM_4_qemu_mask=9-10
 VM_4_qemu_numa_node=0
 
-VM_5_qemu_mask=0x1800
+VM_5_qemu_mask=11-12
 VM_5_qemu_numa_node=0
 
-VM_6_qemu_mask=0x1800000
+VM_6_qemu_mask=13-14
 VM_6_qemu_numa_node=1
 
-VM_7_qemu_mask=0x6000000
+VM_7_qemu_mask=15-16
 VM_7_qemu_numa_node=1
 
-VM_8_qemu_mask=0x18000000
+VM_8_qemu_mask=17-18
 VM_8_qemu_numa_node=1
 
-VM_9_qemu_mask=0x60000000
+VM_9_qemu_mask=19-20
 VM_9_qemu_numa_node=1
 
-VM_10_qemu_mask=0x180000000
+VM_10_qemu_mask=21-22
 VM_10_qemu_numa_node=1
 
-VM_11_qemu_mask=0x600000000
+VM_11_qemu_mask=23-24
 VM_11_qemu_numa_node=1
diff --git a/test/vhost/common/common.sh b/test/vhost/common/common.sh
index 4b50cd64c..3a5de6071 100644
--- a/test/vhost/common/common.sh
+++ b/test/vhost/common/common.sh
@@ -3,7 +3,7 @@ set -e
 : ${SPDK_VHOST_VERBOSE=false}
 : ${QEMU_PREFIX="/usr/local/qemu/spdk-2.12-pre"}
 
-BASE_DIR=$(readlink -f $(dirname $0))
+BASE_DIR=$(readlink -f $(dirname ${BASH_SOURCE[0]}))
 
 # Default running dir -> spdk/..
 [[ -z "$TEST_DIR" ]] && TEST_DIR=$BASE_DIR/../../../../
@@ -121,7 +121,9 @@ function spdk_vhost_run()
 				assert_number "$vhost_num"
 				;;
 			--conf-path=*) local vhost_conf_path="${param#*=}" ;;
+			--json-path=*) local vhost_json_path="${param#*=}" ;;
 			--memory=*) local memory=${param#*=} ;;
+			--no-pci*) local no_pci="-u" ;;
 			*)
 				error "Invalid parameter '$param'"
 				return 1
@@ -130,10 +132,6 @@ function spdk_vhost_run()
 	done
 
 	local vhost_dir="$(get_vhost_dir $vhost_num)"
-	if [[ -z "$vhost_conf_path" ]]; then
-		error "Missing mandatory parameter '--conf-path'"
-		return 1
-	fi
 	local vhost_app="$SPDK_BUILD_DIR/app/vhost/vhost"
 	local vhost_log_file="$vhost_dir/vhost.log"
 	local vhost_pid_file="$vhost_dir/vhost.pid"
@@ -161,13 +159,14 @@ function spdk_vhost_run()
 		return 1
 	fi
 
-	cp $vhost_conf_template $vhost_conf_file
-	$SPDK_BUILD_DIR/scripts/gen_nvme.sh >> $vhost_conf_file
-
-	local cmd="$vhost_app -m $reactor_mask -p $master_core -c $vhost_conf_file -s $memory -r $vhost_dir/rpc.sock"
+	local cmd="$vhost_app -m $reactor_mask -p $master_core -s $memory -r $vhost_dir/rpc.sock $no_pci"
+	if [[ -n "$vhost_conf_path" ]]; then
+		cp $vhost_conf_template $vhost_conf_file
+		$SPDK_BUILD_DIR/scripts/gen_nvme.sh >> $vhost_conf_file
+		cmd="$vhost_app -m $reactor_mask -p $master_core -c $vhost_conf_file -s $memory -r $vhost_dir/rpc.sock $no_pci"
+	fi
 
 	notice "Loging to:   $vhost_log_file"
-	notice "Config file: $vhost_conf_file"
 	notice "Socket:      $vhost_socket"
 	notice "Command:     $cmd"
 
@@ -178,10 +177,21 @@ function spdk_vhost_run()
 
 	notice "waiting for app to run..."
 	waitforlisten "$vhost_pid" "$vhost_dir/rpc.sock"
+	#do not generate nvmes if pci access is disabled
+	if [[ -z "$vhost_conf_path" ]] && [[ -z "$no_pci" ]]; then
+		$SPDK_BUILD_DIR/scripts/gen_nvme.sh "--json" | $SPDK_BUILD_DIR/scripts/rpc.py\
+		 -s $vhost_dir/rpc.sock load_subsystem_config
+	fi
+
+	if [[ -n "$vhost_json_path" ]]; then
+		$SPDK_BUILD_DIR/scripts/rpc.py -s $vhost_dir/rpc.sock load_config\
+		 --filename "$vhost_json_path/conf.json"
+	fi
+
 	notice "vhost started - pid=$vhost_pid"
 	timing_exit vhost_start
 
-	rm $vhost_conf_file
+	rm -f $vhost_conf_file
 }
 
 function spdk_vhost_kill()
@@ -625,7 +635,7 @@ function vm_setup()
 	local task_mask=${!qemu_mask_param}
 
 	notice "TASK MASK: $task_mask"
-	local cmd="taskset -a $task_mask $QEMU_PREFIX/bin/qemu-system-x86_64 ${eol}"
+	local cmd="taskset -a -c $task_mask $QEMU_PREFIX/bin/qemu-system-x86_64 ${eol}"
 	local vm_socket_offset=$(( 10000 + 100 * vm_num ))
 
 	local ssh_socket=$(( vm_socket_offset + 0 ))
@@ -638,9 +648,20 @@ function vm_setup()
 	local cpu_num=0
 
 	set +x
-	for ((cpu=0; cpu<$(nproc --all); cpu++))
-	do
-		(($task_mask&1<<$cpu)) && ((cpu_num++)) || :
+	# cpu list for taskset can be comma separated or range
+	# or both at the same time, so first split on commas
+	cpu_list=$(echo $task_mask | tr "," "\n")
+	queue_number=0
+	for c in $cpu_list; do
+		# if range is detected - count how many cpus
+		if [[ $c =~ [0-9]+-[0-9]+ ]]; then
+			val=$(($c-1))
+			val=${val#-}
+		else
+			val=1
+		fi
+		cpu_num=$((cpu_num+val))
+		queue_number=$((queue_number+val))
 	done
 
 	if [ -z $queue_number ]; then
@@ -715,7 +736,7 @@ function vm_setup()
 			spdk_vhost_blk)
 				notice "using socket $vhost_dir/naa.$disk.$vm_num"
 				cmd+="-chardev socket,id=char_$disk,path=$vhost_dir/naa.$disk.$vm_num ${eol}"
-				cmd+="-device vhost-user-blk-pci,num-queues=$queue_number,chardev=char_$disk,config-ro=$read_only ${eol}"
+				cmd+="-device vhost-user-blk-pci,num-queues=$queue_number,chardev=char_$disk ${eol}"
 				;;
 			kernel_vhost)
 				if [[ -z $disk ]]; then
@@ -726,7 +747,7 @@ function vm_setup()
 					return 1
 				fi
 				notice "Using kernel vhost disk wwn=$disk"
-				cmd+=" -device vhost-scsi-pci,wwpn=$disk ${eol}"
+				cmd+=" -device vhost-scsi-pci,wwpn=$disk,num_queues=$queue_number ${eol}"
 				;;
 			*)
 				error "unknown mode '$disk_type', use: virtio, spdk_vhost_scsi, spdk_vhost_blk or kernel_vhost"
@@ -989,6 +1010,7 @@ function run_fio()
 				mkdir -p $out
 				;;
 			--local) run_server_mode=false ;;
+			--json) json="--json" ;;
 		*)
 			error "Invalid argument '$arg'"
 			return 1
@@ -1034,7 +1056,7 @@ function run_fio()
 
 	python $SPDK_BUILD_DIR/test/vhost/common/run_fio.py --job-file=/root/$job_fname \
 		$([[ ! -z "$fio_bin" ]] && echo "--fio-bin=$fio_bin") \
-		--out=$out ${fio_disks%,}
+		--out=$out $json ${fio_disks%,}
 }
 
 # Shutdown or kill any running VM and SPDK APP.
diff --git a/test/vhost/common/run_fio.py b/test/vhost/common/run_fio.py
index 4010df476..2bf897edb 100755
--- a/test/vhost/common/run_fio.py
+++ b/test/vhost/common/run_fio.py
@@ -23,6 +23,7 @@ def show_help():
         -f, --fio-bin     Location of FIO binary on local host (Default "fio")
         -o, --out         Directory used to save generated job files and
                           files with test results
+        -J, --json        Use JSON format for output
         -p, --perf-vmex   Enable aggregating statistic for VMEXITS for VMs
     """)
 
@@ -43,12 +44,14 @@ def save_file(path, mode, contents):
     fh.close()
 
 
-def run_fio(vms, fio_cfg_fname, out_path, perf_vmex=False):
+def run_fio(vms, fio_cfg_fname, out_path, perf_vmex=False, json=False):
         global fio_bin
         job_name = os.path.splitext(os.path.basename(fio_cfg_fname))[0]
 
         # Build command for FIO
         fio_cmd = " ".join([fio_bin, "--eta=never"])
+        if json:
+            fio_cmd = " ".join([fio_bin, "--output-format=json"])
         for vm in vms:
             # vm[0] = IP address, vm[1] = Port number
             fio_cmd = " ".join([fio_cmd,
@@ -114,11 +117,12 @@ def main():
     fio_cfg = None
     out_dir = None
     perf_vmex = False
+    json = False
 
     try:
-        opts, args = getopt.getopt(sys.argv[1:], "hj:f:o:p",
+        opts, args = getopt.getopt(sys.argv[1:], "hJj:f:o:p",
                                    ["help", "job-file=", "fio-bin=",
-                                    "out=", "perf-vmex"])
+                                    "out=", "perf-vmex", "json"])
     except getopt.GetoptError:
         show_help()
         sys.exit(1)
@@ -139,6 +143,8 @@ def main():
             out_dir = a
         elif o in ("-f", "--fio-bin"):
             fio_bin = a
+        elif o in ("-J", "--json"):
+            json = True
 
     if fio_cfg is None:
         print("ERROR! No FIO job provided!")
@@ -155,7 +161,7 @@ def main():
         vms.append((ip, port, filenames))
 
     print("Running job file: {0}".format(fio_cfg))
-    run_fio(vms, fio_cfg, out_dir, perf_vmex)
+    run_fio(vms, fio_cfg, out_dir, perf_vmex, json)
 
 
 if __name__ == "__main__":
diff --git a/test/vhost/ext4test/spdk_vm_base.xml b/test/vhost/ext4test/spdk_vm_base.xml
deleted file mode 100644
index 9fb9e2241..000000000
--- a/test/vhost/ext4test/spdk_vm_base.xml
+++ /dev/null
@@ -1,69 +0,0 @@
-<?xml version="1.0"?>
-<domain xmlns:qemu="http://libvirt.org/schemas/domain/qemu/1.0" type="kvm">
-  <name/>
-  <memory unit="GiB">2</memory>
-  <currentMemory unit="GiB">2</currentMemory>
-  <vcpu placement="static">4</vcpu>
-  <os>
-    <type arch="x86_64" machine="pc-i440fx-1.6">hvm</type>
-    <boot dev="hd"/>
-  </os>
-  <features>
-    <acpi/>
-    <apic/>
-    <pae/>
-  </features>
-  <cpu mode="host-model">
-    <model fallback="allow"/>
-  </cpu>
-  <clock offset="utc"/>
-  <on_poweroff>destroy</on_poweroff>
-  <on_reboot>restart</on_reboot>
-  <on_crash>destroy</on_crash>
-  <devices>
-    <emulator/>
-    <disk type="file" device="disk">
-      <driver name="qemu" type="qcow2"/>
-      <source file=""/>
-      <backingStore/>
-      <target dev="hda" bus="ide"/>
-      <address type="drive" domain="0" bus="0" slot="0" function="0"/>
-    </disk>
-    <controller type="usb" index="0">
-      <address type="pci" domain="0x0000" bus="0x00" slot="0x01" function="0x2"/>
-    </controller>
-    <controller type="pci" index="0" model="pci-root"/>
-    <interface type="network">
-      <mac address="02:de:ad:de:ad:01"/>
-      <source network="test_net"/>
-      <model type="virtio"/>
-      <address type="pci" domain="0x0000" bus="0x00" slot="0x03" function="0x0"/>
-    </interface>
-    <serial type="pty">
-      <target port="0"/>
-    </serial>
-    <console type="pty">
-      <target type="serial" port="0"/>
-    </console>
-    <input type="mouse" bus="ps2"/>
-    <input type="keyboard" bus="ps2"/>
-    <graphics type="vnc" port="-1" autoport="yes"/>
-    <video>
-      <model type="cirrus" vram="16384" heads="1"/>
-      <address type="pci" domain="0x0000" bus="0x00" slot="0x02" function="0x0"/>
-    </video>
-    <memballoon model="virtio">
-      <address type="pci" domain="0x0000" bus="0x00" slot="0x05" function="0x0"/>
-    </memballoon>
-  </devices>
-  <qemu:commandline>
-    <qemu:arg value="-object"/>
-    <qemu:arg value="memory-backend-file,id=mem,size=2048M,mem-path=/mnt/huge,share=on"/>
-    <qemu:arg value="-numa"/>
-    <qemu:arg value="node,memdev=mem"/>
-    <qemu:arg value="-chardev"/>
-    <qemu:arg value="socket,id=char0,path=/tmp/naa.123"/>
-    <qemu:arg value="-device"/>
-    <qemu:arg value="vhost-user-scsi-pci,id=scsi0,chardev=char0"/>
-  </qemu:commandline>
-</domain>
diff --git a/test/vhost/fiotest/autotest.sh b/test/vhost/fiotest/autotest.sh
index 7bff0103b..2a87c8e95 100755
--- a/test/vhost/fiotest/autotest.sh
+++ b/test/vhost/fiotest/autotest.sh
@@ -1,8 +1,8 @@
 #!/usr/bin/env bash
 set -e
-BASE_DIR=$(readlink -f $(dirname $0))
-[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $BASE_DIR/../common && pwd)"
-[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $BASE_DIR/../../../../ && pwd)"
+AUTOTEST_BASE_DIR=$(readlink -f $(dirname $0))
+[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $AUTOTEST_BASE_DIR/../common && pwd)"
+[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $AUTOTEST_BASE_DIR/../../../../ && pwd)"
 
 dry_run=false
 no_shutdown=false
@@ -82,7 +82,7 @@ if [[ $test_type =~ "spdk_vhost" ]]; then
 	notice ""
 	notice "running SPDK"
 	notice ""
-	spdk_vhost_run --conf-path=$BASE_DIR
+	spdk_vhost_run --json-path=$AUTOTEST_BASE_DIR
 	notice ""
 fi
 
@@ -119,68 +119,13 @@ for vm_conf in ${vms[@]}; do
 					notice "Creating vhost block controller naa.$disk.${conf[0]} with device $disk"
 					$rpc_py construct_vhost_blk_controller naa.$disk.${conf[0]} $disk
 				else
-					notice "Trying to remove nonexistent controller"
-					if $rpc_py remove_vhost_controller unk0 > /dev/null; then
-						error "Removing nonexistent controller succeeded, but it shouldn't"
-					fi
 					notice "Creating controller naa.$disk.${conf[0]}"
 					$rpc_py construct_vhost_scsi_controller naa.$disk.${conf[0]}
 
-					notice "Adding initial device (0) to naa.$disk.${conf[0]}"
-					$rpc_py add_vhost_scsi_lun naa.$disk.${conf[0]} 0 $disk
-
-					notice "Trying to remove nonexistent device on existing controller"
-					if $rpc_py remove_vhost_scsi_target naa.$disk.${conf[0]} 1 > /dev/null; then
-						error "Removing nonexistent device (1) from controller naa.$disk.${conf[0]} succeeded, but it shouldn't"
-					fi
-
-					notice "Trying to remove existing device from a controller"
-					$rpc_py remove_vhost_scsi_target naa.$disk.${conf[0]} 0
-
-					notice "Trying to remove a just-deleted device from a controller again"
-					if $rpc_py remove_vhost_scsi_target naa.$disk.${conf[0]} 0 > /dev/null; then
-						error "Removing device 0 from controller naa.$disk.${conf[0]} succeeded, but it shouldn't"
-					fi
-
-					notice "Re-adding device 0 to naa.$disk.${conf[0]}"
+					notice "Adding device (0) to naa.$disk.${conf[0]}"
 					$rpc_py add_vhost_scsi_lun naa.$disk.${conf[0]} 0 $disk
 				fi
 			done
-
-			notice "Trying to create scsi controller with incorrect cpumask"
-			if $rpc_py construct_vhost_scsi_controller vhost.invalid.cpumask --cpumask 0x2; then
-				error "Creating scsi controller with incorrect cpumask succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to remove device from nonexistent scsi controller"
-			if $rpc_py remove_vhost_scsi_target vhost.nonexistent.name 0; then
-				error "Removing device from nonexistent scsi controller succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to add device to nonexistent scsi controller"
-			if $rpc_py add_vhost_scsi_lun vhost.nonexistent.name 0 Malloc0; then
-				error "Adding device to nonexistent scsi controller succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to create scsi controller with incorrect name"
-			if $rpc_py construct_vhost_scsi_controller .; then
-				error "Creating scsi controller with incorrect name succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to create block controller with incorrect cpumask"
-			if $rpc_py construct_vhost_blk_controller vhost.invalid.cpumask  Malloc0 --cpumask 0x2; then
-				error "Creating block controller with incorrect cpumask succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to remove nonexistent block controller"
-			if $rpc_py remove_vhost_controller vhost.nonexistent.name; then
-				error "Removing nonexistent block controller succeeded, but it shouldn't"
-			fi
-
-			notice "Trying to create block controller with incorrect name"
-			if $rpc_py construct_vhost_blk_controller . Malloc0; then
-				error "Creating block controller with incorrect name succeeded, but it shouldn't"
-			fi
 		done <<< "${conf[2]}"
 		unset IFS;
 		$rpc_py get_vhost_controllers
@@ -232,7 +177,7 @@ for vm_num in $used_vms; do
 
 	qemu_mask_param="VM_${vm_num}_qemu_mask"
 
-	host_name="VM-$vm_num-${!qemu_mask_param}"
+	host_name="VM-$vm_num"
 	notice "Setting up hostname: $host_name"
 	vm_ssh $vm_num "hostname $host_name"
 	vm_start_fio_server $fio_bin $readonly $vm_num
diff --git a/test/vhost/fiotest/conf.json b/test/vhost/fiotest/conf.json
new file mode 100644
index 000000000..7a1594b24
--- /dev/null
+++ b/test/vhost/fiotest/conf.json
@@ -0,0 +1,80 @@
+{
+  "subsystems": [
+    {
+      "subsystem": "copy",
+      "config": null
+    },
+    {
+      "subsystem": "interface",
+      "config": null
+    },
+    {
+      "subsystem": "net_framework",
+      "config": null
+    },
+    {
+      "subsystem": "bdev",
+      "config": [
+        {
+          "params": {
+            "base_bdev": "Nvme0n1",
+            "split_size_mb": 0,
+            "split_count": 4
+          },
+          "method": "construct_split_vbdev"
+        },
+        {
+          "params": {
+            "block_size": 4096,
+            "num_blocks": 32768
+          },
+          "method": "construct_malloc_bdev"
+        },
+        {
+          "params": {
+            "block_size": 4096,
+            "num_blocks": 32768
+          },
+          "method": "construct_malloc_bdev"
+        }
+      ]
+    },
+    {
+      "subsystem": "nbd",
+      "config": []
+    },
+    {
+      "subsystem": "scsi",
+      "config": null
+    },
+    {
+      "subsystem": "vhost",
+      "config": [
+        {
+          "params": {
+            "cpumask": "0x1",
+            "ctrlr": "vhost.0"
+          },
+          "method": "construct_vhost_scsi_controller"
+        },
+        {
+          "params": {
+            "scsi_target_num": 0,
+            "bdev_name": "Malloc0",
+            "ctrlr": "vhost.0"
+          },
+          "method": "add_vhost_scsi_lun"
+        },
+        {
+          "params": {
+            "dev_name": "Malloc1",
+            "readonly": true,
+            "ctrlr": "vhost.1",
+            "cpumask": "0x1"
+          },
+          "method": "construct_vhost_blk_controller"
+        }
+      ]
+    }
+  ]
+}
diff --git a/test/vhost/fiotest/vhost.conf.in b/test/vhost/fiotest/vhost.conf.in
deleted file mode 100644
index 151cb3bcd..000000000
--- a/test/vhost/fiotest/vhost.conf.in
+++ /dev/null
@@ -1,23 +0,0 @@
-[Global]
-
-[Ioat]
-  Disable Yes
-
-[Malloc]
-  NumberOfLuns 2
-  LunSizeInMB 128
-  BlockSize 4096
-
-[Split]
-  Split Nvme0n1 4
-
-[VhostScsi0]
-  Name vhost.0
-  Dev 0 Malloc0
-  Cpumask 0x1
-
-[VhostBlk0]
-  Name vhost.1
-  Dev Malloc1
-  ReadOnly yes
-  Cpumask 0x1
diff --git a/test/vhost/hotplug/vhost.conf.base b/test/vhost/hotplug/vhost.conf.base
index 5e72d3f54..0b0de7490 100644
--- a/test/vhost/hotplug/vhost.conf.base
+++ b/test/vhost/hotplug/vhost.conf.base
@@ -1,7 +1,7 @@
 [Global]
 
 [Ioat]
-  Disable Yes
+  Enable No
 
 [Nvme]
   HotplugEnable Yes
diff --git a/test/vhost/initiator/autotest.config b/test/vhost/initiator/autotest.config
index 150ac6773..61a1a2424 100644
--- a/test/vhost/initiator/autotest.config
+++ b/test/vhost/initiator/autotest.config
@@ -1,5 +1,5 @@
-vhost_0_reactor_mask=0x1
+vhost_0_reactor_mask=["0"]
 vhost_0_master_core=0
 
-VM_0_qemu_mask=0x7FE
+VM_0_qemu_mask=1-10
 VM_0_qemu_numa_node=0
diff --git a/test/vhost/initiator/bdev.conf b/test/vhost/initiator/bdev.conf
index 6622ce284..d9198d088 100644
--- a/test/vhost/initiator/bdev.conf
+++ b/test/vhost/initiator/bdev.conf
@@ -21,4 +21,4 @@
   Queues 8
 
 [Ioat]
-  Disable Yes
+  Enable No
diff --git a/test/vhost/initiator/bdev_pci.conf b/test/vhost/initiator/bdev_pci.conf
index 726f24b26..635891b3f 100644
--- a/test/vhost/initiator/bdev_pci.conf
+++ b/test/vhost/initiator/bdev_pci.conf
@@ -2,4 +2,4 @@
   Enable Yes
 
 [Ioat]
-  Disable Yes
+  Enable No
diff --git a/test/vhost/initiator/blockdev.sh b/test/vhost/initiator/blockdev.sh
index c3108ec97..084b08bc5 100755
--- a/test/vhost/initiator/blockdev.sh
+++ b/test/vhost/initiator/blockdev.sh
@@ -1,9 +1,18 @@
 #!/usr/bin/env bash
 
 set -e
-BASE_DIR=$(readlink -f $(dirname $0))
-[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $BASE_DIR/../common && pwd)"
-ROOT_DIR=$(readlink -f $BASE_DIR/../../..)
+INITIATOR_DIR=$(readlink -f $(dirname $0))
+[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $INITIATOR_DIR/../common && pwd)"
+ROOT_DIR=$(readlink -f $INITIATOR_DIR/../../..)
+
+PLUGIN_DIR=$ROOT_DIR/examples/bdev/fio_plugin
+FIO_PATH="/usr/src/fio"
+virtio_bdevs=""
+virtio_with_unmap=""
+os_image="/home/sys_sgsw/vhost_vm_image.qcow2"
+#different linux distributions have different versions of targetcli that have different names for ramdisk option
+targetcli_rd_name=""
+kernel_vhost_disk="naa.5012345678901234"
 
 function usage()
 {
@@ -11,8 +20,8 @@ function usage()
 	echo "Script for running vhost initiator tests."
 	echo "Usage: $(basename $1) [-h|--help] [--fiobin=PATH]"
 	echo "-h, --help            Print help and exit"
-	echo "    --vm_image=PATH   Path to VM image used in these tests [default=/home/sys_sgsw/vhost_vm_image.qcow2]"
-	echo "    --fiobin=PATH     Path to fio binary on host [default=/usr/src/fio/fio]"
+	echo "    --vm_image=PATH   Path to VM image used in these tests [default=$os_image]"
+	echo "    --fiopath=PATH    Path to fio directory on host [default=$FIO_PATH]"
 }
 
 while getopts 'h-:' optchar; do
@@ -20,7 +29,7 @@ while getopts 'h-:' optchar; do
 		-)
 		case "$OPTARG" in
 			help) usage $0 && exit 0 ;;
-			fiobin=*) FIO_BIN="${OPTARG#*=}" ;;
+			fiopath=*) FIO_PATH="${OPTARG#*=}" ;;
 			vm_image=*) os_image="${OPTARG#*=}" ;;
 			*) usage $0 echo "Invalid argument '$OPTARG'" && exit 1 ;;
 		esac
@@ -31,15 +40,11 @@ while getopts 'h-:' optchar; do
 done
 
 source $COMMON_DIR/common.sh
-source $BASE_DIR/autotest.config
+source $INITIATOR_DIR/autotest.config
 PLUGIN_DIR=$ROOT_DIR/examples/bdev/fio_plugin
 RPC_PY="$ROOT_DIR/scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
-FIO_BIN="/usr/src/fio/fio"
-virtio_bdevs=""
-virtio_with_unmap=""
-os_image="/home/sys_sgsw/vhost_vm_image.qcow2"
 
-if [ ! -x $FIO_BIN ]; then
+if [ ! -x $FIO_PATH ]; then
 	error "Invalid path of fio binary"
 fi
 
@@ -48,10 +53,26 @@ if [[ $EUID -ne 0 ]]; then
 	exit 1
 fi
 
-trap 'rm -f *.state $ROOT_DIR/spdk.tar.gz; error_exit "${FUNCNAME}""${LINENO}"' ERR SIGTERM SIGABRT
+if targetcli ls backstores | grep ramdisk ; then
+	targetcli_rd_name="ramdisk"
+elif targetcli ls backstores | grep rd_mcp ; then
+	targetcli_rd_name="rd_mcp"
+else
+	error "targetcli: cannot create a ramdisk.\
+	 Neither backstores/ramdisk nor backstores/rd_mcp is available"
+fi
+
+function remove_kernel_vhost()
+{
+	targetcli "/vhost delete $kernel_vhost_disk"
+	targetcli "/backstores/$targetcli_rd_name delete ramdisk"
+}
+
+trap 'rm -f *.state $ROOT_DIR/spdk.tar.gz $ROOT_DIR/fio.tar.gz $(get_vhost_dir)/Virtio0;\
+ error_exit "${FUNCNAME}""${LINENO}"' ERR SIGTERM SIGABRT
 function run_spdk_fio() {
-	LD_PRELOAD=$PLUGIN_DIR/fio_plugin $FIO_BIN --ioengine=spdk_bdev\
-         "$@" --spdk_mem=1024  --spdk_single_seg=1
+	LD_PRELOAD=$PLUGIN_DIR/fio_plugin $FIO_PATH/fio --ioengine=spdk_bdev\
+         "$@" --spdk_mem=1024 --spdk_single_seg=1
 }
 
 function create_bdev_config()
@@ -62,6 +83,8 @@ function create_bdev_config()
 		error "Nvme0n1 bdev not found!"
 	fi
 
+	$RPC_PY construct_split_vbdev Nvme0n1 6
+
 	$RPC_PY construct_vhost_scsi_controller naa.Nvme0n1_scsi0.0
 	$RPC_PY add_vhost_scsi_lun naa.Nvme0n1_scsi0.0 0 Nvme0n1p0
 	$RPC_PY add_vhost_scsi_lun naa.Nvme0n1_scsi0.0 1 Nvme0n1p1
@@ -79,14 +102,14 @@ function create_bdev_config()
 	$RPC_PY construct_vhost_scsi_controller naa.Malloc1.0
 	$RPC_PY add_vhost_scsi_lun naa.Malloc1.0 0 Malloc1
 
-	vbdevs=$(discover_bdevs $ROOT_DIR $BASE_DIR/bdev.conf)
+	vbdevs=$(discover_bdevs $ROOT_DIR $INITIATOR_DIR/bdev.conf)
 	virtio_bdevs=$(jq -r '[.[].name] | join(":")' <<< $vbdevs)
 	virtio_with_unmap=$(jq -r '[.[] | select(.supported_io_types.unmap==true).name]
 	 | join(":")' <<< $vbdevs)
 }
 
 timing_enter spdk_vhost_run
-spdk_vhost_run --conf-path=$BASE_DIR
+spdk_vhost_run
 timing_exit spdk_vhost_run
 
 timing_enter create_bdev_config
@@ -94,20 +117,27 @@ create_bdev_config
 timing_exit create_bdev_config
 
 timing_enter run_spdk_fio
-run_spdk_fio $BASE_DIR/bdev.fio --filename=$virtio_bdevs --section=job_randwrite --section=job_randrw \
-	--section=job_write --section=job_rw --spdk_conf=$BASE_DIR/bdev.conf
+run_spdk_fio $INITIATOR_DIR/bdev.fio --filename=$virtio_bdevs --section=job_randwrite --section=job_randrw \
+	--section=job_write --section=job_rw --spdk_conf=$INITIATOR_DIR/bdev.conf
 report_test_completion "vhost_run_spdk_fio"
 timing_exit run_spdk_fio
 
 timing_enter run_spdk_fio_unmap
-run_spdk_fio $BASE_DIR/bdev.fio --filename=$virtio_with_unmap --spdk_conf=$BASE_DIR/bdev.conf \
-	--spdk_conf=$BASE_DIR/bdev.conf
+run_spdk_fio $INITIATOR_DIR/bdev.fio --filename=$virtio_with_unmap --spdk_conf=$INITIATOR_DIR/bdev.conf \
+	--spdk_conf=$INITIATOR_DIR/bdev.conf
 timing_exit run_spdk_fio_unmap
 
+timing_enter create_kernel_vhost
+targetcli "/backstores/$targetcli_rd_name create name=ramdisk size=1GB"
+targetcli "/vhost create $kernel_vhost_disk"
+targetcli "/vhost/$kernel_vhost_disk/tpg1/luns create /backstores/$targetcli_rd_name/ramdisk"
+timing_exit create_kernel_vhost
+
 timing_enter setup_vm
 vm_no="0"
 vm_setup --disk-type=spdk_vhost_scsi --force=$vm_no --os=$os_image \
- --disks="Nvme0n1_scsi0:Malloc0:Malloc1:Nvme0n1_blk0,spdk_vhost_blk:Nvme0n1_blk1,spdk_vhost_blk" \
+ --disks="Nvme0n1_scsi0:Malloc0:Malloc1:$kernel_vhost_disk,kernel_vhost:Virtio0,virtio:\
+ Nvme0n1_blk0,spdk_vhost_blk:Nvme0n1_blk1,spdk_vhost_blk" \
  --queue_num=8 --memory=6144
 vm_run $vm_no
 
@@ -120,11 +150,17 @@ touch $ROOT_DIR/spdk.tar.gz
 tar --exclude="spdk.tar.gz" --exclude="*.o" --exclude="*.d" --exclude=".git" -C $ROOT_DIR -zcf $ROOT_DIR/spdk.tar.gz .
 vm_scp $vm_no $ROOT_DIR/spdk.tar.gz "127.0.0.1:/root"
 vm_ssh $vm_no "mkdir -p /root/spdk; tar -zxf /root/spdk.tar.gz -C /root/spdk --strip-components=1"
+
+touch $ROOT_DIR/fio.tar.gz
+tar --exclude="fio.tar.gz" --exclude="*.o" --exclude="*.d" --exclude=".git" -C $FIO_PATH -zcf $ROOT_DIR/fio.tar.gz .
+vm_scp $vm_no $ROOT_DIR/fio.tar.gz "127.0.0.1:/root"
+vm_ssh $vm_no "rm -rf /root/fio_src; mkdir -p /root/fio_src; tar -zxf /root/fio.tar.gz -C /root/fio_src --strip-components=1"
 timing_exit vm_scp_spdk
 
 timing_enter vm_build_spdk
 nproc=$(vm_ssh $vm_no "nproc")
-vm_ssh $vm_no " cd spdk ; make clean ; ./configure --with-fio=/root/fio_src ; make -j${nproc}"
+vm_ssh $vm_no " cd /root/fio_src ; make clean ; make -j${nproc} ; make install"
+vm_ssh $vm_no " cd spdk ; ./configure --with-fio=/root/fio_src ; make clean ; make -j${nproc}"
 timing_exit vm_build_spdk
 
 vm_ssh $vm_no "/root/spdk/scripts/setup.sh"
@@ -152,7 +188,11 @@ timing_enter vm_shutdown_all
 vm_shutdown_all
 timing_exit vm_shutdown_all
 
-rm -f *.state $ROOT_DIR/spdk.tar.gz
+rm -f *.state $ROOT_DIR/spdk.tar.gz $ROOT_DIR/fio.tar.gz $(get_vhost_dir)/Virtio0
+timing_enter remove_kernel_vhost
+remove_kernel_vhost
+timing_exit remove_kernel_vhost
+
 timing_enter spdk_vhost_kill
 spdk_vhost_kill
 timing_exit spdk_vhost_kill
diff --git a/test/vhost/initiator/json_config.sh b/test/vhost/initiator/json_config.sh
new file mode 100755
index 000000000..86078c9a2
--- /dev/null
+++ b/test/vhost/initiator/json_config.sh
@@ -0,0 +1,64 @@
+#!/usr/bin/env bash
+set -ex
+INITIATOR_JSON_DIR=$(readlink -f $(dirname $0))
+. $INITIATOR_JSON_DIR/../../json_config/common.sh
+
+# Load spdk_tgt with controllers used by virtio initiator
+# Test also virtio_pci bdevs
+function construct_vhost_devices() {
+	$rpc_py construct_split_vbdev Nvme0n1 4
+	$rpc_py construct_vhost_scsi_controller naa.Nvme0n1p0.0
+	$rpc_py construct_vhost_scsi_controller naa.Nvme0n1p1.1
+	$rpc_py add_vhost_scsi_lun naa.Nvme0n1p0.0 0 Nvme0n1p0
+	$rpc_py add_vhost_scsi_lun naa.Nvme0n1p1.1 0 Nvme0n1p1
+	$rpc_py construct_vhost_blk_controller naa.Nvme0n1p2.0 Nvme0n1p2
+	$rpc_py construct_vhost_blk_controller naa.Nvme0n1p3.1 Nvme0n1p3
+	pci_scsi=$(lspci -nn -D | grep '1af4:1004' | head -1 | awk '{print $1;}')
+	pci_blk=$(lspci -nn -D | grep '1af4:1001' | head -1 | awk '{print $1;}')
+	if [ ! -z $pci_scsi ]; then
+		$rpc_py construct_virtio_dev -t pci -a $pci_scsi -d scsi Virtio0
+	fi
+	if [ ! -z $pci_blk ]; then
+		$rpc_py construct_virtio_dev -t pci -a $pci_blk -d blk Virtio1
+	fi
+}
+
+# Load virtio initiator with bdevs
+function connect_to_vhost_devices_from_initiator() {
+	$rpc_py construct_virtio_dev -t user -a naa.Nvme0n1p0.0 -d scsi Nvme0n1p0
+	$rpc_py construct_virtio_dev -t user -a naa.Nvme0n1p2.0 -d blk Nvme0n1p2
+}
+
+function disconnect_and_clear_vhost_devices() {
+	$clear_config_py clear_config
+}
+
+function test_subsystems() {
+	run_spdk_tgt
+	rootdir=$(readlink -f $INITIATOR_JSON_DIR/../../..)
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	load_nvme
+
+	construct_vhost_devices
+	test_json_config
+	run_initiator
+	rpc_py="$initiator_rpc_py"
+	clear_config_py="$initiator_clear_config_py"
+	$rpc_py start_subsystem_init
+	connect_to_vhost_devices_from_initiator
+	test_json_config
+	disconnect_and_clear_vhost_devices
+        test_global_params "virtio_initiator"
+	clear_config_py="$spdk_clear_config_py"
+	$clear_config_py clear_config
+	kill_targets
+}
+
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"' ERR
+timing_enter json_config_virtio_initiator
+
+test_subsystems
+timing_exit json_config_virtio_initiator
+report_test_completion json_config_virtio_initiator
diff --git a/test/vhost/initiator/vhost.conf.in b/test/vhost/initiator/vhost.conf.in
deleted file mode 100644
index c5c542892..000000000
--- a/test/vhost/initiator/vhost.conf.in
+++ /dev/null
@@ -1,5 +0,0 @@
-[Ioat]
-  Disable Yes
-
-[Split]
-  Split Nvme0n1 6
diff --git a/test/vhost/integrity/integrity_start.sh b/test/vhost/integrity/integrity_start.sh
index e6b843493..a4e7ebe63 100755
--- a/test/vhost/integrity/integrity_start.sh
+++ b/test/vhost/integrity/integrity_start.sh
@@ -1,6 +1,7 @@
 #!/usr/bin/env bash
 set -e
 
+INTEGRITY_BASE_DIR=$(readlink -f $(dirname $0))
 ctrl_type="spdk_vhost_scsi"
 vm_fs="ext4"
 
@@ -55,7 +56,7 @@ trap 'error_exit "${FUNCNAME}" "${LINENO}"' SIGTERM SIGABRT ERR
 vm_kill_all
 
 notice "Starting SPDK vhost"
-spdk_vhost_run --conf-path=$BASE_DIR
+spdk_vhost_run
 notice "..."
 
 # Set up lvols and vhost controllers
@@ -82,7 +83,7 @@ vm_run 0
 vm_wait_for_boot 600 0
 
 # Run tests on VM
-vm_scp 0 $BASE_DIR/integrity_vm.sh root@127.0.0.1:/root/integrity_vm.sh
+vm_scp 0 $INTEGRITY_BASE_DIR/integrity_vm.sh root@127.0.0.1:/root/integrity_vm.sh
 vm_ssh 0 "~/integrity_vm.sh $ctrl_type \"$vm_fs\""
 
 notice "Shutting down virtual machine..."
diff --git a/test/vhost/integrity/vhost.conf.in b/test/vhost/integrity/vhost.conf.in
deleted file mode 100644
index 5fab30fd7..000000000
--- a/test/vhost/integrity/vhost.conf.in
+++ /dev/null
@@ -1,4 +0,0 @@
-[Global]
-
-[Ioat]
-  Disable Yes
diff --git a/test/vhost/json_config/json_config.sh b/test/vhost/json_config/json_config.sh
new file mode 100755
index 000000000..d5683f1d5
--- /dev/null
+++ b/test/vhost/json_config/json_config.sh
@@ -0,0 +1,25 @@
+#!/usr/bin/env bash
+set -ex
+VHOST_JSON_DIR=$(readlink -f $(dirname $0))
+. $VHOST_JSON_DIR/../../json_config/common.sh
+
+function test_subsystems() {
+	run_spdk_tgt
+
+	rpc_py="$spdk_rpc_py"
+	clear_config_py="$spdk_clear_config_py"
+	load_nvme
+
+	upload_vhost
+	test_json_config
+	$clear_config_py clear_config
+
+	kill_targets
+}
+
+trap 'on_error_exit "${FUNCNAME}" "${LINENO}"' ERR
+timing_enter json_config_vhost
+
+test_subsystems
+timing_exit json_config_vhost
+report_test_completion json_config_vhost
diff --git a/test/vhost/lvol/autotest.config b/test/vhost/lvol/autotest.config
index 15790c322..9b653cd7f 100644
--- a/test/vhost/lvol/autotest.config
+++ b/test/vhost/lvol/autotest.config
@@ -1,74 +1,74 @@
-vhost_0_reactor_mask=0xfffffffff
+vhost_0_reactor_mask="[0-31]"
 vhost_0_master_core=0
 
-VM_0_qemu_mask=0x2
+VM_0_qemu_mask=1
 VM_0_qemu_numa_node=0
 
-VM_1_qemu_mask=0x4
+VM_1_qemu_mask=2
 VM_1_qemu_numa_node=0
 
-VM_2_qemu_mask=0x8
+VM_2_qemu_mask=3
 VM_2_qemu_numa_node=0
 
-VM_3_qemu_mask=0x10
+VM_3_qemu_mask=4
 VM_3_qemu_numa_node=0
 
-VM_4_qemu_mask=0x20
+VM_4_qemu_mask=5
 VM_4_qemu_numa_node=0
 
-VM_5_qemu_mask=0x40
+VM_5_qemu_mask=6
 VM_5_qemu_numa_node=0
 
-VM_6_qemu_mask=0x80
+VM_6_qemu_mask=7
 VM_6_qemu_numa_node=0
 
-VM_7_qemu_mask=0x100
+VM_7_qemu_mask=8
 VM_7_qemu_numa_node=0
 
-VM_8_qemu_mask=0x200
+VM_8_qemu_mask=9
 VM_8_qemu_numa_node=0
 
-VM_9_qemu_mask=0x400
+VM_9_qemu_mask=10
 VM_9_qemu_numa_node=0
 
-VM_10_qemu_mask=0x800
+VM_10_qemu_mask=11
 VM_10_qemu_numa_node=0
 
-VM_11_qemu_mask=0x1000
+VM_11_qemu_mask=12
 VM_11_qemu_numa_node=0
 
-VM_12_qemu_mask=0x40000
+VM_12_qemu_mask=13
 VM_12_qemu_numa_node=1
 
-VM_13_qemu_mask=0x80000
+VM_13_qemu_mask=14
 VM_13_qemu_numa_node=1
 
-VM_14_qemu_mask=0x100000
+VM_14_qemu_mask=15
 VM_14_qemu_numa_node=1
 
-VM_15_qemu_mask=0x200000
+VM_15_qemu_mask=16
 VM_15_qemu_numa_node=1
 
-VM_16_qemu_mask=0x400000
+VM_16_qemu_mask=17
 VM_16_qemu_numa_node=1
 
-VM_17_qemu_mask=0x800000
+VM_17_qemu_mask=18
 VM_17_qemu_numa_node=1
 
-VM_18_qemu_mask=0x1000000
+VM_18_qemu_mask=19
 VM_18_qemu_numa_node=1
 
-VM_19_qemu_mask=0x2000000
+VM_19_qemu_mask=20
 VM_19_qemu_numa_node=1
 
-VM_20_qemu_mask=0x4000000
+VM_20_qemu_mask=21
 VM_20_qemu_numa_node=1
 
-VM_21_qemu_mask=0x8000000
+VM_21_qemu_mask=22
 VM_21_qemu_numa_node=1
 
-VM_22_qemu_mask=0x10000000
+VM_22_qemu_mask=23
 VM_22_qemu_numa_node=1
 
-VM_23_qemu_mask=0x20000000
+VM_23_qemu_mask=24
 VM_23_qemu_numa_node=1
diff --git a/test/vhost/lvol/lvol_test.sh b/test/vhost/lvol/lvol_test.sh
index 9b10a922d..30a0b8b4a 100755
--- a/test/vhost/lvol/lvol_test.sh
+++ b/test/vhost/lvol/lvol_test.sh
@@ -4,9 +4,9 @@ set -e
 rootdir=$(readlink -f $(dirname $0))/../../..
 source "$rootdir/scripts/common.sh"
 
-BASE_DIR=$(readlink -f $(dirname $0))
-[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $BASE_DIR/../../../../ && pwd)"
-[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $BASE_DIR/../common && pwd)"
+LVOL_TEST_DIR=$(readlink -f $(dirname $0))
+[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $LVOL_TEST_DIR/../../../../ && pwd)"
+[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $LVOL_TEST_DIR/../common && pwd)"
 
 . $COMMON_DIR/common.sh
 rpc_py="python $SPDK_BUILD_DIR/scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
@@ -113,7 +113,7 @@ fi
 
 if $distribute_cores; then
     # FIXME: this need to be handled entirely in common.sh
-    source $BASE_DIR/autotest.config
+    source $LVOL_TEST_DIR/autotest.config
 fi
 
 trap 'error_exit "${FUNCNAME}" "${LINENO}"' SIGTERM SIGABRT ERR
@@ -121,7 +121,7 @@ trap 'error_exit "${FUNCNAME}" "${LINENO}"' SIGTERM SIGABRT ERR
 vm_kill_all
 
 notice "running SPDK vhost"
-spdk_vhost_run --conf-path=$BASE_DIR
+spdk_vhost_run
 notice "..."
 
 trap 'clean_lvol_cfg; error_exit "${FUNCNAME}" "${LINENO}"' SIGTERM SIGABRT ERR
diff --git a/test/vhost/lvol/vhost.conf.in b/test/vhost/lvol/vhost.conf.in
deleted file mode 100644
index 8e3501847..000000000
--- a/test/vhost/lvol/vhost.conf.in
+++ /dev/null
@@ -1,3 +0,0 @@
-[Global]
-[Ioat]
-    Disable Yes
diff --git a/test/vhost/migration/autotest.config b/test/vhost/migration/autotest.config
index a86f7a2f9..ccda306ea 100644
--- a/test/vhost/migration/autotest.config
+++ b/test/vhost/migration/autotest.config
@@ -1,14 +1,14 @@
-vhost_0_reactor_mask=0x1
+vhost_0_reactor_mask=["0"]
 vhost_0_master_core=0
 
-vhost_1_reactor_mask=0x1
+vhost_1_reactor_mask=["0"]
 vhost_1_master_core=0
 
-VM_0_qemu_mask=0x1
+VM_0_qemu_mask=1
 VM_0_qemu_numa_node=0
 
-VM_1_qemu_mask=0x1
+VM_1_qemu_mask=1
 VM_1_qemu_numa_node=0
 
-VM_2_qemu_mask=0x1
+VM_2_qemu_mask=1
 VM_2_qemu_numa_node=0
diff --git a/test/vhost/migration/migration-tc1.sh b/test/vhost/migration/migration-tc1.sh
index a86301522..a6432eae2 100644
--- a/test/vhost/migration/migration-tc1.sh
+++ b/test/vhost/migration/migration-tc1.sh
@@ -5,7 +5,7 @@ function migration_tc1_clean_vhost_config()
 
 	notice "Removing vhost devices & controllers via RPC ..."
 	# Delete bdev first to remove all LUNs and SCSI targets
-	$rpc delete_bdev Malloc0
+	$rpc delete_malloc_bdev Malloc0
 
 	# Delete controllers
 	$rpc remove_vhost_controller $incoming_vm_ctrlr
@@ -54,10 +54,10 @@ function migration_tc1()
 	# Use 2 VMs:
 	# incoming VM - the one we want to migrate
 	# targe VM - the one which will accept migration
-	local job_file="$BASE_DIR/migration-tc1.job"
+	local job_file="$MIGRATION_DIR/migration-tc1.job"
 
 	# Run vhost
-	spdk_vhost_run --conf-path=$BASE_DIR
+	spdk_vhost_run
 	migration_tc1_configure_vhost
 
 	notice "Setting up VMs"
diff --git a/test/vhost/migration/migration-tc2.sh b/test/vhost/migration/migration-tc2.sh
index 4840b05dc..ead0f8646 100644
--- a/test/vhost/migration/migration-tc2.sh
+++ b/test/vhost/migration/migration-tc2.sh
@@ -101,11 +101,11 @@ function migration_tc2_configure_vhost()
 	waitforlisten "$nvmf_tgt_pid" "$nvmf_dir/rpc.sock"
 	timing_exit start_nvmf_tgt
 
-	spdk_vhost_run --conf-path=$BASE_DIR --memory=512 --vhost-num=0
+	spdk_vhost_run --memory=512 --vhost-num=0 --no-pci
 	# Those are global intentionaly
 	vhost_1_reactor_mask=0x2
 	vhost_1_master_core=1
-	spdk_vhost_run --conf-path=$BASE_DIR --memory=512 --vhost-num=1
+	spdk_vhost_run --memory=512 --vhost-num=1 --no-pci
 
 	local rdma_ip_list=$(get_available_rdma_ips)
 	local nvmf_target_ip=$(echo "$rdma_ip_list" | head -n 1)
@@ -160,7 +160,7 @@ function migration_tc2()
 	# Use 2 VMs:
 	# incoming VM - the one we want to migrate
 	# targe VM - the one which will accept migration
-	local job_file="$BASE_DIR/migration-tc2.job"
+	local job_file="$MIGRATION_DIR/migration-tc2.job"
 
 	migration_tc2_configure_vhost
 
diff --git a/test/vhost/migration/migration-tc3a.sh b/test/vhost/migration/migration-tc3a.sh
index 77dc56222..b9eba44f5 100644
--- a/test/vhost/migration/migration-tc3a.sh
+++ b/test/vhost/migration/migration-tc3a.sh
@@ -1,16 +1,28 @@
 source $SPDK_BUILD_DIR/test/nvmf/common.sh
-source $BASE_DIR/autotest.config
+source $MIGRATION_DIR/autotest.config
 
-MGMT_TARGET_IP="10.102.17.181"
-MGMT_INITIATOR_IP="10.102.17.180"
-RDMA_TARGET_IP="10.0.0.1"
-RDMA_INITIATOR_IP="10.0.0.2"
 incoming_vm=1
 target_vm=2
 incoming_vm_ctrlr=naa.VhostScsi0.$incoming_vm
 target_vm_ctrlr=naa.VhostScsi0.$target_vm
 share_dir=$TEST_DIR/share
-job_file=$BASE_DIR/migration-tc3.job
+job_file=$MIGRATION_DIR/migration-tc3.job
+
+if [ -z "$MGMT_TARGET_IP" ]; then
+	error "No IP address of target is given"
+fi
+
+if [ -z "$MGMT_INITIATOR_IP" ]; then
+	error "No IP address of initiator  is given"
+fi
+
+if [ -z "$RDMA_TARGET_IP" ]; then
+	error "No IP address of targets RDMA capable NIC is given"
+fi
+
+if [ -z "$RDMA_INITIATOR_IP" ]; then
+	error "No IP address of initiators RDMA capable NIC is given"
+fi
 
 function ssh_remote()
 {
@@ -106,7 +118,7 @@ function host1_start_vhost()
 
 	notice "Starting vhost0 instance on local server"
 	trap 'host1_cleanup_vhost; error_exit "${FUNCNAME}" "${LINENO}"' INT ERR EXIT
-	spdk_vhost_run --conf-path=$BASE_DIR --vhost-num=0
+	spdk_vhost_run --vhost-num=0 --no-pci
 	$rpc_0 construct_nvme_bdev -b Nvme0 -t rdma -f ipv4 -a $RDMA_TARGET_IP -s 4420 -n "nqn.2018-02.io.spdk:cnode1"
 	$rpc_0 construct_vhost_scsi_controller $incoming_vm_ctrlr
 	$rpc_0 add_vhost_scsi_lun $incoming_vm_ctrlr 0 Nvme0n1
@@ -149,8 +161,12 @@ function host_2_create_share()
 	ssh_remote $MGMT_INITIATOR_IP "uname -a"
 	ssh_remote $MGMT_INITIATOR_IP "mkdir -p $share_dir"
 	ssh_remote $MGMT_INITIATOR_IP "mkdir -p $VM_BASE_DIR"
-	ssh_remote $MGMT_INITIATOR_IP "sshfs -o ssh_command=\"ssh -i $SPDK_VHOST_SSH_KEY_FILE\" root@$MGMT_TARGET_IP:$VM_BASE_DIR $VM_BASE_DIR"
-	ssh_remote $MGMT_INITIATOR_IP "sshfs -o ssh_command=\"ssh -i $SPDK_VHOST_SSH_KEY_FILE\" root@$MGMT_TARGET_IP:$share_dir $share_dir"
+	ssh_remote $MGMT_INITIATOR_IP "sshfs -o\
+	 ssh_command=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o ControlMaster=auto\
+	 -i $SPDK_VHOST_SSH_KEY_FILE\" root@$MGMT_TARGET_IP:$VM_BASE_DIR $VM_BASE_DIR"
+	ssh_remote $MGMT_INITIATOR_IP "sshfs -o\
+	 ssh_command=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o ControlMaster=auto\
+	 -i $SPDK_VHOST_SSH_KEY_FILE\" root@$MGMT_TARGET_IP:$share_dir $share_dir"
 	ssh_remote $MGMT_INITIATOR_IP "mkdir -p $share_dir/spdk"
 	ssh_remote $MGMT_INITIATOR_IP "tar -zxf $share_dir/spdk.tar.gz -C $share_dir/spdk --strip-components=1"
 	ssh_remote $MGMT_INITIATOR_IP "cd $share_dir/spdk; make clean; ./configure --with-rdma --enable-debug; make -j40"
@@ -158,7 +174,9 @@ function host_2_create_share()
 
 function host_2_start_vhost()
 {
-	ssh_remote $MGMT_INITIATOR_IP "nohup $share_dir/spdk/test/vhost/migration/migration.sh --test-cases=3b --work-dir=$TEST_DIR --os=$share_dir/migration.qcow2 &>$share_dir/output.log &"
+	ssh_remote $MGMT_INITIATOR_IP "nohup $share_dir/spdk/test/vhost/migration/migration.sh\
+	 --test-cases=3b --work-dir=$TEST_DIR --os=$share_dir/migration.qcow2\
+	 --rdma-tgt-ip=$RDMA_TARGET_IP &>$share_dir/output.log &"
 	notice "Waiting for remote to be done with vhost & VM setup..."
 	wait_for_remote
 }
diff --git a/test/vhost/migration/migration-tc3b.sh b/test/vhost/migration/migration-tc3b.sh
index 79e21c541..888b4f246 100755
--- a/test/vhost/migration/migration-tc3b.sh
+++ b/test/vhost/migration/migration-tc3b.sh
@@ -2,9 +2,8 @@
 # as we are usin non-interactive session to connect to remote.
 # Without -m it would be not possible to suspend the process.
 set -m
-source $BASE_DIR/autotest.config
+source $MIGRATION_DIR/autotest.config
 
-RDMA_TARGET_IP="10.0.0.1"
 incoming_vm=1
 target_vm=2
 target_vm_ctrl=naa.VhostScsi0.$target_vm
@@ -34,7 +33,7 @@ function host_2_start_vhost()
 
 	notice "Starting vhost 1 instance on remote server"
 	trap 'host_2_cleanup_vhost; error_exit "${FUNCNAME}" "${LINENO}"' INT ERR EXIT
-	spdk_vhost_run --conf-path=$BASE_DIR --vhost-num=1
+	spdk_vhost_run --vhost-num=1 --no-pci
 
 	$rpc construct_nvme_bdev -b Nvme0 -t rdma -f ipv4 -a $RDMA_TARGET_IP -s 4420 -n "nqn.2018-02.io.spdk:cnode1"
 	$rpc construct_vhost_scsi_controller $target_vm_ctrl
diff --git a/test/vhost/migration/migration.sh b/test/vhost/migration/migration.sh
index 5fb8cdd00..bdfcd8453 100755
--- a/test/vhost/migration/migration.sh
+++ b/test/vhost/migration/migration.sh
@@ -11,7 +11,10 @@ declare -A vms_ctrlrs_disks
 # By default use Guest fio
 fio_bin=""
 test_cases=""
-
+MGMT_TARGET_IP=""
+MGMT_INITIATOR_IP=""
+RDMA_TARGET_IP=""
+RDMA_INITIATOR_IP=""
 function usage()
 {
 	[[ ! -z $2 ]] && ( echo "$2"; echo ""; )
@@ -23,6 +26,10 @@ function usage()
 	echo "    --fio-bin=FIO         Use specific fio binary (will be uploaded to VM)"
 	echo "    --test-cases=TESTS    Coma-separated list of tests to run. Implemented test cases are: 1"
 	echo "                          See test/vhost/test_plan.md for more info."
+	echo "    --mgmt-tgt-ip=IP      IP address of target."
+	echo "    --mgmt-init-ip=IP     IP address of initiator."
+	echo "    --rdma-tgt-ip=IP      IP address of targets rdma capable NIC."
+	echo "    --rdma-init-ip=IP     IP address of initiators rdma capable NIC."
 	echo "-x                        set -x for script debug"
 }
 
@@ -36,6 +43,10 @@ for param in "$@"; do
 		--os=*) os_image="${param#*=}" ;;
 		--fio-bin=*) fio_bin="${param}" ;;
 		--test-cases=*) test_cases="${param#*=}" ;;
+		--mgmt-tgt-ip=*) MGMT_TARGET_IP="${param#*=}" ;;
+		--mgmt-init-ip=*) MGMT_INITIATOR_IP="${param#*=}" ;;
+		--rdma-tgt-ip=*) RDMA_TARGET_IP="${param#*=}" ;;
+		--rdma-init-ip=*) RDMA_INITIATOR_IP="${param#*=}" ;;
 		-x) set -x ;;
 		-v) SPDK_VHOST_VERBOSE=true	;;
 		*)
@@ -45,6 +56,7 @@ for param in "$@"; do
 done
 
 . $(readlink -e "$(dirname $0)/../common/common.sh") || exit 1
+MIGRATION_DIR=$(readlink -f $(dirname $0))
 
 [[ ! -z "$test_cases" ]] || fail "Need '--test-cases=' parameter"
 
@@ -131,7 +143,7 @@ for test_case in ${test_cases//,/ }; do
 	notice "==============================="
 
 	timing_enter migration-tc${test_case}
-	source $BASE_DIR/migration-tc${test_case}.sh
+	source $MIGRATION_DIR/migration-tc${test_case}.sh
 	timing_exit migration-tc${test_case}
 done
 
diff --git a/test/vhost/migration/vhost.conf.in b/test/vhost/migration/vhost.conf.in
deleted file mode 100644
index 967a08766..000000000
--- a/test/vhost/migration/vhost.conf.in
+++ /dev/null
@@ -1,5 +0,0 @@
-[Global]
-  NoPci Yes
-
-[Ioat]
-  Disable Yes
diff --git a/test/vhost/other/conf.json b/test/vhost/other/conf.json
new file mode 100644
index 000000000..7a60c68c9
--- /dev/null
+++ b/test/vhost/other/conf.json
@@ -0,0 +1,43 @@
+{
+  "subsystems": [
+    {
+      "subsystem": "copy",
+      "config": null
+    },
+    {
+      "subsystem": "interface",
+      "config": null
+    },
+    {
+      "subsystem": "net_framework",
+      "config": null
+    },
+    {
+      "subsystem": "bdev",
+      "config": [
+        {
+          "params": {
+            "block_size": 4096,
+            "num_blocks": 32768
+          },
+          "method": "construct_malloc_bdev"
+        },
+        {
+          "params": {
+            "block_size": 4096,
+            "num_blocks": 32768
+          },
+          "method": "construct_malloc_bdev"
+        }
+      ]
+    },
+    {
+      "subsystem": "nbd",
+      "config": []
+    },
+    {
+      "subsystem": "scsi",
+      "config": null
+    }
+  ]
+}
diff --git a/test/vhost/other/negative.sh b/test/vhost/other/negative.sh
index 45ace64b4..b40b5ea2e 100755
--- a/test/vhost/other/negative.sh
+++ b/test/vhost/other/negative.sh
@@ -1,8 +1,8 @@
 #!/usr/bin/env bash
 
-BASE_DIR=$(readlink -f $(dirname $0))
-[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $BASE_DIR/../common && pwd)"
-[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $BASE_DIR/../../../../ && pwd)"
+NEGATIVE_BASE_DIR=$(readlink -f $(dirname $0))
+[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $NEGATIVE_BASE_DIR/../common && pwd)"
+[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $NEGATIVE_BASE_DIR/../../../../ && pwd)"
 
 function usage()
 {
@@ -42,7 +42,7 @@ VHOST_APP="$SPDK_BUILD_DIR/app/vhost/vhost"
 
 notice "Testing vhost command line arguments"
 # Printing help will force vhost to exit without error
-$VHOST_APP -c /path/to/non_existing_file/conf -S $BASE_DIR -e 0x0 -s 1024 -d -q -h
+$VHOST_APP -c /path/to/non_existing_file/conf -S $NEGATIVE_BASE_DIR -e 0x0 -s 1024 -d -q -h
 
 # Testing vhost create pid file option. Vhost will exit with error as invalid config path is given
 if $VHOST_APP -c /path/to/non_existing_file/conf -f $SPDK_VHOST_SCSI_TEST_DIR/vhost.pid; then
@@ -58,3 +58,87 @@ fi
 if ! $VHOST_APP -t vhost_scsi -h;  then
 	warning "vhost did not started with trace flags enabled but ignoring this as it might not be a debug build"
 fi
+
+if [[ $RUN_NIGHTLY -eq 1 ]]; then
+	# Run with valid config and try some negative rpc calls
+	notice "==============="
+	notice ""
+	notice "running SPDK"
+	notice ""
+	spdk_vhost_run --json-path=$NEGATIVE_BASE_DIR
+	notice ""
+
+	rpc_py="python $SPDK_BUILD_DIR/scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
+
+	# General commands
+	notice "Trying to remove nonexistent controller"
+	if $rpc_py remove_vhost_controller unk0 > /dev/null; then
+		error "Removing nonexistent controller succeeded, but it shouldn't"
+	fi
+
+	# SCSI
+	notice "Trying to create scsi controller with incorrect cpumask"
+	if $rpc_py construct_vhost_scsi_controller vhost.invalid.cpumask --cpumask 0x2; then
+		error "Creating scsi controller with incorrect cpumask succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to remove device from nonexistent scsi controller"
+	if $rpc_py remove_vhost_scsi_target vhost.nonexistent.name 0; then
+		error "Removing device from nonexistent scsi controller succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to add device to nonexistent scsi controller"
+	if $rpc_py add_vhost_scsi_lun vhost.nonexistent.name 0 Malloc0; then
+		error "Adding device to nonexistent scsi controller succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to create scsi controller with incorrect name"
+	if $rpc_py construct_vhost_scsi_controller .; then
+		error "Creating scsi controller with incorrect name succeeded, but it shouldn't"
+	fi
+
+	notice "Creating controller naa.0"
+	$rpc_py construct_vhost_scsi_controller naa.0
+
+	notice "Adding initial device (0) to naa.0"
+	$rpc_py add_vhost_scsi_lun naa.0 0 Malloc0
+
+	notice "Trying to remove nonexistent device on existing controller"
+	if $rpc_py remove_vhost_scsi_target naa.0 1 > /dev/null; then
+		error "Removing nonexistent device (1) from controller naa.0 succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to remove existing device from a controller"
+	$rpc_py remove_vhost_scsi_target naa.0 0
+
+	notice "Trying to remove a just-deleted device from a controller again"
+	if $rpc_py remove_vhost_scsi_target naa.0 0 > /dev/null; then
+		error "Removing device 0 from controller naa.0 succeeded, but it shouldn't"
+	fi
+
+	notice "Re-adding device 0 to naa.0"
+	$rpc_py add_vhost_scsi_lun naa.0 0 Malloc0
+
+	# BLK
+	notice "Trying to create block controller with incorrect cpumask"
+	if $rpc_py construct_vhost_blk_controller vhost.invalid.cpumask  Malloc0 --cpumask 0x2; then
+		error "Creating block controller with incorrect cpumask succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to remove nonexistent block controller"
+	if $rpc_py remove_vhost_controller vhost.nonexistent.name; then
+		error "Removing nonexistent block controller succeeded, but it shouldn't"
+	fi
+
+	notice "Trying to create block controller with incorrect name"
+	if $rpc_py construct_vhost_blk_controller . Malloc0; then
+		error "Creating block controller with incorrect name succeeded, but it shouldn't"
+	fi
+
+	notice "Testing done -> shutting down"
+	notice "killing vhost app"
+	spdk_vhost_kill
+
+	notice "EXIT DONE"
+	notice "==============="
+fi
diff --git a/test/vhost/perf_bench/vhost_perf.sh b/test/vhost/perf_bench/vhost_perf.sh
new file mode 100755
index 000000000..c8849de25
--- /dev/null
+++ b/test/vhost/perf_bench/vhost_perf.sh
@@ -0,0 +1,229 @@
+#!/usr/bin/env bash
+set -e
+
+vm_count=1
+vm_memory=2048
+vm_image="/home/sys_sgsw/vhost_vm_image.qcow2"
+max_disks=""
+ctrl_type="spdk_vhost_scsi"
+use_split=false
+throttle=false
+
+lvol_stores=()
+lvol_bdevs=()
+used_vms=""
+
+fio_bin="--fio-bin=/home/sys_sgsw/fio_ubuntu"
+
+function usage()
+{
+	[[ ! -z $2 ]] && ( echo "$2"; echo ""; )
+	echo "Shortcut script for doing automated test"
+	echo "Usage: $(basename $1) [OPTIONS]"
+	echo
+	echo "-h, --help                  Print help and exit"
+	echo "    --fio-bin=PATH          Path to FIO binary on host.;"
+	echo "                            Binary will be copied to VM, static compilation"
+	echo "                            of binary is recommended."
+	echo "    --fio-job=PATH          Fio config to use for test."
+	echo "    --vm-count=INT          Total number of virtual machines to launch in this test;"
+	echo "                            Each VM will get one bdev (lvol or split vbdev)"
+	echo "                            to run FIO test."
+	echo "                            Default: 1"
+	echo "    --vm-memory=INT         Amount of RAM memory (in MB) to pass to a single VM."
+	echo "                            Default: 2048 MB"
+	echo "    --vm-image=PATH         OS image to use for running the VMs."
+	echo "                            Default: /home/sys_sgsw/vhost_vm_image.qcow2"
+	echo "    --max-disks=INT         Maximum number of NVMe drives to use in test."
+	echo "                            Default: will use all available NVMes."
+	echo "    --ctrl-type=TYPE        Controller type to use for test:"
+	echo "                            spdk_vhost_scsi - use spdk vhost scsi"
+	echo "                            spdk_vhost_blk - use spdk vhost block"
+	echo "                            Default: spdk_vhost_scsi"
+	echo "    --use-split             Use split vbdevs instead of Logical Volumes"
+	echo "    --throttle=INT          I/Os throttle rate in IOPS for each device on the VMs."
+	echo "    --custom-cpu-cfg=PATH   Custom CPU config for test."
+	echo "                            Default: spdk/test/vhost/common/autotest.config"
+	echo "-x                          set -x for script debug"
+	exit 0
+}
+
+function cleanup_lvol_cfg()
+{
+	notice "Removing lvol bdevs"
+	for lvol_bdev in "${lvol_bdevs[@]}"; do
+		$rpc_py destroy_lvol_bdev $lvol_bdev
+		notice "lvol bdev $lvol_bdev removed"
+	done
+
+	notice "Removing lvol stores"
+	for lvol_store in "${lvol_stores[@]}"; do
+		$rpc_py destroy_lvol_store -u $lvol_store
+		notice "lvol store $lvol_store removed"
+	done
+}
+
+function cleanup_split_cfg()
+{
+	notice "Removing split vbdevs"
+	for (( i=0; i<$max_disks; i++ ));do
+		$rpc_py destruct_split_vbdev Nvme${i}n1
+	done
+}
+
+while getopts 'xh-:' optchar; do
+	case "$optchar" in
+		-)
+		case "$OPTARG" in
+			help) usage $0 ;;
+			fio-bin=*) fio_bin="--fio-bin=${OPTARG#*=}" ;;
+			fio-job=*) fio_job="${OPTARG#*=}" ;;
+			vm-count=*) vm_count="${OPTARG#*=}" ;;
+			vm-memory=*) vm_memory="${OPTARG#*=}" ;;
+			vm-image=*) vm_image="${OPTARG#*=}" ;;
+			max-disks=*) max_disks="${OPTARG#*=}" ;;
+			ctrl-type=*) ctrl_type="${OPTARG#*=}" ;;
+			use-split) use_split=true ;;
+			throttle) throttle=true ;;
+			custom-cpu-cfg=*) custom_cpu_cfg="${OPTARG#*=}" ;;
+			thin-provisioning) thin=" -t " ;;
+			multi-os) multi_os=true ;;
+			*) usage $0 "Invalid argument '$OPTARG'" ;;
+		esac
+		;;
+	h) usage $0 ;;
+	x) set -x
+		x="-x" ;;
+	*) usage $0 "Invalid argument '$OPTARG'"
+	esac
+done
+
+. $(readlink -e "$(dirname $0)/../common/common.sh") || exit 1
+. $(readlink -e "$(dirname $0)/../../../scripts/common.sh") || exit 1
+COMMON_DIR="$(cd $(readlink -f $(dirname $0))/../common && pwd)"
+rpc_py="python $SPDK_BUILD_DIR/scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
+
+if [[ -n $custom_cpu_cfg ]]; then
+	source $custom_cpu_cfg
+fi
+
+if [[ -z $fio_job ]]; then
+	warning "No FIO job specified! Will use default from common directory."
+	fio_job="$COMMON_DIR/fio_jobs/default_integrity.job"
+fi
+
+trap 'error_exit "${FUNCNAME}" "${LINENO}"' INT ERR
+notice "Get NVMe disks:"
+nvmes=($(iter_pci_class_code 01 08 02))
+
+if [[ -z $max_disks ]]; then
+	max_disks=${#nvmes[@]}
+fi
+
+if [[ ${#nvmes[@]} -lt max_disks ]]; then
+	fail "Number of NVMe drives (${#nvmes[@]}) is lower than number of requested disks for test ($max_disks)"
+fi
+
+notice "running SPDK vhost"
+spdk_vhost_run
+notice "..."
+
+# Calculate number of needed splits per NVMe
+# so that each VM gets it's own bdev during test
+splits=()
+
+#Calculate least minimum number of splits on each disks
+for i in `seq 0 $((max_disks - 1))`; do
+	splits+=( $((vm_count / max_disks)) )
+done
+
+# Split up the remainder
+for i in `seq 0 $((vm_count % max_disks - 1))`; do
+	(( splits[i]++ ))
+done
+
+notice "Preparing NVMe setup..."
+notice "Using $max_disks physical NVMe drives"
+notice "Nvme split list: ${splits[@]}"
+# Prepare NVMes - Lvols or Splits
+if [[ $use_split == true ]]; then
+	notice "Using split vbdevs"
+	trap 'cleanup_split_cfg; error_exit "${FUNCNAME}" "${LINENO}"' INT ERR
+	split_bdevs=()
+	for (( i=0; i<$max_disks; i++ ));do
+		out=$($rpc_py construct_split_vbdev Nvme${i}n1 ${splits[$i]})
+		for s in $out; do
+			split_bdevs+=("$s")
+		done
+	done
+	bdevs=("${split_bdevs[@]}")
+else
+	notice "Using logical volumes"
+	trap 'cleanup_lvol_cfg; error_exit "${FUNCNAME}" "${LINENO}"' INT ERR
+	for (( i=0; i<$max_disks; i++ ));do
+		ls_guid=$($rpc_py construct_lvol_store Nvme${i}n1 lvs_$i)
+		lvol_stores+=("$ls_guid")
+		for (( j=0; j<${splits[$i]}; j++)); do
+			free_mb=$(get_lvs_free_mb "$ls_guid")
+			size=$((free_mb / (${splits[$i]}-j) ))
+			lb_name=$($rpc_py construct_lvol_bdev -u $ls_guid lbd_$j $size)
+			lvol_bdevs+=("$lb_name")
+		done
+	done
+	bdevs=("${lvol_bdevs[@]}")
+fi
+
+# Prepare VMs and controllers
+for (( i=0; i<$vm_count; i++)); do
+	vm="vm_$i"
+
+	setup_cmd="vm_setup --disk-type=$ctrl_type --force=$i"
+	setup_cmd+=" --os=$vm_image"
+
+	if [[ "$ctrl_type" == "spdk_vhost_scsi" ]]; then
+		$rpc_py construct_vhost_scsi_controller naa.0.$i
+		$rpc_py add_vhost_scsi_lun naa.0.$i 0 ${bdevs[$i]}
+		setup_cmd+=" --disks=0"
+	elif [[ "$ctrl_type" == "spdk_vhost_blk" ]]; then
+		$rpc_py construct_vhost_blk_controller naa.$i.$i ${bdevs[$i]}
+		setup_cmd+=" --disks=$i"
+	fi
+	$setup_cmd
+	used_vms+=" $i"
+done
+
+# Start VMs
+# Run VMs
+vm_run $used_vms
+vm_wait_for_boot 300 $used_vms
+
+# Run FIO
+fio_disks=""
+for vm_num in $used_vms; do
+	vm_dir=$VM_BASE_DIR/$vm_num
+	host_name="VM-$vm_num"
+	vm_ssh $vm_num "hostname $host_name"
+	vm_start_fio_server $fio_bin $vm_num
+
+	if [[ "$ctrl_type" == "spdk_vhost_scsi" ]]; then
+		vm_check_scsi_location $vm_num
+	elif [[ "$ctrl_type" == "spdk_vhost_blk" ]]; then
+		vm_check_blk_location $vm_num
+	fi
+
+	fio_disks+=" --vm=${vm_num}$(printf ':/dev/%s' $SCSI_DISK)"
+done
+
+# Run FIO traffic
+run_fio $fio_bin --job-file="$fio_job" --out="$TEST_DIR/fio_results" --json $fio_disks
+
+notice "Shutting down virtual machines..."
+vm_shutdown_all
+
+#notice "Shutting down SPDK vhost app..."
+if [[ $use_split == true ]]; then
+	cleanup_split_cfg
+else
+	cleanup_lvol_cfg
+fi
+spdk_vhost_kill
diff --git a/test/vhost/readonly/readonly.sh b/test/vhost/readonly/readonly.sh
index bd273e85d..f80e8f78b 100755
--- a/test/vhost/readonly/readonly.sh
+++ b/test/vhost/readonly/readonly.sh
@@ -1,12 +1,12 @@
 #!/usr/bin/env bash
 
 set -e
-BASE_DIR=$(readlink -f $(dirname $0))
-[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $BASE_DIR/../../../../ && pwd)"
-[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $BASE_DIR/../common && pwd)"
+READONLY_BASE_DIR=$(readlink -f $(dirname $0))
+[[ -z "$TEST_DIR" ]] && TEST_DIR="$(cd $READONLY_BASE_DIR/../../../../ && pwd)"
+[[ -z "$COMMON_DIR" ]] && COMMON_DIR="$(cd $READONLY_BASE_DIR/../common && pwd)"
 source $COMMON_DIR/common.sh
 
-rpc_py="$BASE_DIR/../../../scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
+rpc_py="$READONLY_BASE_DIR/../../../scripts/rpc.py -s $(get_vhost_dir)/rpc.sock"
 
 vm_img=""
 disk="Nvme0n1"
@@ -90,7 +90,7 @@ function blk_ro_tc1()
 	vm_run $vm_no
 	vm_wait_for_boot 600 $vm_no
 	notice "Preparing partition and file on guest VM"
-	vm_ssh $vm_no "bash -s" < $BASE_DIR/disabled_readonly_vm.sh
+	vm_ssh $vm_no "bash -s" < $READONLY_BASE_DIR/disabled_readonly_vm.sh
 	sleep 1
 
 	vm_shutdown_all
@@ -102,7 +102,7 @@ function blk_ro_tc1()
 	vm_run $vm_no
 	vm_wait_for_boot 600 $vm_no
 	notice "Testing readonly feature on guest VM"
-	vm_ssh $vm_no "bash -s" < $BASE_DIR/enabled_readonly_vm.sh
+	vm_ssh $vm_no "bash -s" < $READONLY_BASE_DIR/enabled_readonly_vm.sh
 	sleep 3
 
 	vm_shutdown_all
@@ -114,13 +114,13 @@ function blk_ro_tc1()
 	vm_run $vm_no
 	vm_wait_for_boot 600 $vm_no
 	notice "Removing partition and file from test disk on guest VM"
-	vm_ssh $vm_no "bash -s" < $BASE_DIR/delete_partition_vm.sh
+	vm_ssh $vm_no "bash -s" < $READONLY_BASE_DIR/delete_partition_vm.sh
 	sleep 1
 
 	vm_shutdown_all
 }
 
-spdk_vhost_run --conf-path=$BASE_DIR
+spdk_vhost_run
 if [[ -z $x ]]; then
 	set +x
 fi
diff --git a/test/vhost/readonly/vhost.conf.in b/test/vhost/readonly/vhost.conf.in
deleted file mode 100644
index f23f7e478..000000000
--- a/test/vhost/readonly/vhost.conf.in
+++ /dev/null
@@ -1,2 +0,0 @@
-[Ioat]
-  Disable Yes
